{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import io\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"\n",
    "| Name                                                                                                                                                                  | Hub URL                                                                                                                              | Description                                                                                                                                                                                                      | Type               | Category | #Languages | Train #Samples | Dev #Samples | Test #Samples | Avg. chars / train | Avg. chars / dev | Avg. chars / test |\n",
    "| :-------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------------------------------------------------------------------------------------------------------------------------- | :--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | :----------------- | :------- | ---------: | -------------: | -----------: | ------------: | -----------------: | ---------------: | ----------------: |\n",
    "| [BUCC](https://comparable.limsi.fr/bucc2018/bucc2018-task.html)                                                                                                       | [mteb/bucc-bitext-mining](https://huggingface.co/datasets/mteb/bucc-bitext-mining)                                                   | BUCC bitext mining dataset                                                                                                                                                                                       | BitextMining       | s2s      |          4 |              0 |            0 |        641684 |                  0 |                0 |             101.3 |\n",
    "| [Tatoeba](https://github.com/facebookresearch/LASER/tree/main/data/tatoeba/v1)                                                                                        | [mteb/tatoeba-bitext-mining](https://huggingface.co/datasets/mteb/tatoeba-bitext-mining)                                             | 1,000 English-aligned sentence pairs for each language based on the Tatoeba corpus                                                                                                                               | BitextMining       | s2s      |        112 |              0 |            0 |          2000 |                  0 |                0 |              39.4 |\n",
    "| [Bornholm parallel](https://aclanthology.org/W19-6138/)                                                                                                               | [strombergnlp/bornholmsk_parallel](https://huggingface.co/datasets/strombergnlp/bornholmsk_parallel)                                 | Danish Bornholmsk Parallel Corpus.                                                                                                                                                                               | BitextMining       | s2s      |          2 |            100 |          100 |           100 |               64.6 |             86.2 |              89.7 |\n",
    "| [DiaBLaBitextMining](https://inria.hal.science/hal-03021633) | [rbawden/DiaBLa](https://huggingface.co/datasets/rbawden/DiaBLa) | English-French Parallel Corpus. DiaBLa is an English-French dataset for the evaluation of Machine Translation (MT) for informal, written bilingual dialogue. | BitextMining | s2s | 1 | 5748 | 0 | 0 | 0 | 0 | 0 |\n",
    "| [FloresBitextMining](https://huggingface.co/datasets/facebook/flores) | [facebook/flores](https://huggingface.co/datasets/facebook/flores) | FLORES is a benchmark dataset for machine translation between English and low-resource languages. | BitextMining | s2s | 200 | 0 | 997 | 1012 | 0 | 0 | 0 |\n",
    "| [AmazonCounterfactualClassification](https://arxiv.org/abs/2104.06893)                                                                                                | [mteb/amazon_counterfactual](https://huggingface.co/datasets/mteb/amazon_counterfactual)                                             | A collection of Amazon customer reviews annotated for counterfactual detection pair classification.                                                                                                              | Classification     | s2s      |          4 |           4018 |          335 |           670 |              107.3 |            109.2 |             106.1 |\n",
    "| [AmazonPolarityClassification](https://dl.acm.org/doi/10.1145/2507157.2507163)                                                                                        | [mteb/amazon_polarity](https://huggingface.co/datasets/mteb/amazon_polarity)                                                         | Amazon Polarity Classification Dataset.                                                                                                                                                                          | Classification     | s2s      |          1 |        3600000 |            0 |        400000 |              431.6 |                0 |             431.4 |\n",
    "| [AmazonReviewsClassification](https://arxiv.org/abs/2010.02573)                                                                                                       | [mteb/amazon_reviews_multi](https://huggingface.co/datasets/mteb/amazon_reviews_multi)                                               | A collection of Amazon reviews specifically designed to aid research in multilingual text classification.                                                                                                        | Classification     | s2s      |          6 |        1200000 |        30000 |         30000 |              160.5 |            159.2 |             160.4 |\n",
    "| [MasakhaNEWSClassification](https://arxiv.org/abs/2304.09972) | [masakhane/masakhanews](https://huggingface.co/datasets/masakhane/masakhanews) | MasakhaNEWS is the largest publicly available dataset for news topic classification in 16 languages widely spoken in Africa. The train/validation/test sets are available for all the 16 languages. | Classification | s2s | 16 | 1476 | 211 | 422 | 5064.8 | 4756.1 | 5116.6 |\n",
    "| [Banking77Classification](https://arxiv.org/abs/2003.04807)                                                                                                           | [mteb/banking77](https://huggingface.co/datasets/mteb/banking77)                                                                     | Dataset composed of online banking queries annotated with their corresponding intents.                                                                                                                           | Classification     | s2s      |          1 |          10003 |            0 |          3080 |               59.5 |                0 |              54.2 |\n",
    "| [EmotionClassification](https://www.aclweb.org/anthology/D18-1404)                                                                                                    | [mteb/emotion](https://huggingface.co/datasets/mteb/emotion)                                                                         | Emotion is a dataset of English Twitter messages with six basic emotions: anger, fear, joy, love, sadness, and surprise. For more detailed information please refer to the paper.                                | Classification     | s2s      |          1 |          16000 |         2000 |          2000 |               96.8 |             95.3 |              96.6 |\n",
    "| [ImdbClassification](http://www.aclweb.org/anthology/P11-1015)                                                                                                        | [mteb/imdb](https://huggingface.co/datasets/mteb/imdb)                                                                               | Large Movie Review Dataset                                                                                                                                                                                       | Classification     | p2p      |          1 |          25000 |            0 |         25000 |             1325.1 |                0 |            1293.8 |\n",
    "| [MassiveIntentClassification](https://arxiv.org/abs/2204.08582#:~:text=MASSIVE%20contains%201M%20realistic%2C%20parallel,diverse%20languages%20from%2029%20genera.)   | [mteb/amazon_massive_intent](https://huggingface.co/datasets/mteb/amazon_massive_intent)                                             | MASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages                                                                                                | Classification     | s2s      |         51 |          11514 |         2033 |          2974 |               35.0 |             34.8 |              34.6 |\n",
    "| [MassiveScenarioClassification](https://arxiv.org/abs/2204.08582#:~:text=MASSIVE%20contains%201M%20realistic%2C%20parallel,diverse%20languages%20from%2029%20genera.) | [mteb/amazon_massive_scenario](https://huggingface.co/datasets/mteb/amazon_massive_scenario)                                         | MASSIVE: A 1M-Example Multilingual Natural Language Understanding Dataset with 51 Typologically-Diverse Languages                                                                                                | Classification     | s2s      |         51 |          11514 |         2033 |          2974 |               35.0 |             34.8 |              34.6 |\n",
    "| [MTOPDomainClassification](https://arxiv.org/pdf/2008.09335.pdf)                                                                                                      | [mteb/mtop_domain](https://huggingface.co/datasets/mteb/mtop_domain)                                                                 | MTOP: Multilingual Task-Oriented Semantic Parsing                                                                                                                                                                | Classification     | s2s      |          6 |          15667 |         2235 |          4386 |               36.6 |             36.5 |              36.8 |\n",
    "| [MTOPIntentClassification](https://arxiv.org/pdf/2008.09335.pdf)                                                                                                      | [mteb/mtop_intent](https://huggingface.co/datasets/mteb/mtop_intent)                                                                 | MTOP: Multilingual Task-Oriented Semantic Parsing                                                                                                                                                                | Classification     | s2s      |          6 |          15667 |         2235 |          4386 |               36.6 |             36.5 |              36.8 |\n",
    "| [ToxicConversationsClassification](https://www.kaggle.com/competitions/jigsaw-unintended-bias-in-toxicity-classification/overview)                                    | [mteb/toxic_conversations_50k](https://huggingface.co/datasets/mteb/toxic_conversations_50k)                                         | Collection of comments from the Civil Comments platform together with annotations if the comment is toxic or not.                                                                                                | Classification     | s2s      |          1 |          50000 |            0 |         50000 |              298.8 |                0 |             296.6 |\n",
    "| [TweetSentimentExtractionClassification](https://www.kaggle.com/competitions/tweet-sentiment-extraction/overview)                                                     | [mteb/tweet_sentiment_extraction](https://huggingface.co/datasets/mteb/tweet_sentiment_extraction)                                   |                                                                                                                                                                                                                  | Classification     | s2s      |          1 |          27481 |            0 |          3534 |               68.3 |                0 |              67.8 |\n",
    "| [AngryTweetsClassification](https://aclanthology.org/2021.nodalida-main.53/)                                                                                          | [mteb/DDSC/angry-tweets](https://huggingface.co/datasets/DDSC/angry-tweets)                                                          | A sentiment dataset with 3 classes (positiv, negativ, neutral) for Danish tweets                                                                                                                                 | Classification     | s2s      |          1 |           2410 |            0 |          1050 |              153.0 |                0 |             156.1 |\n",
    "| [DKHateClassification](https://aclanthology.org/2020.lrec-1.430/)                                                                                                     | [DDSC/dkhate](https://huggingface.co/datasets/DDSC/dkhate)                                                                           | Danish Tweets annotated for Hate Speech                                                                                                                                                                          | Classification     | s2s      |          1 |           2960 |            0 |           329 |               88.2 |                0 |             104.0 |\n",
    "| [DalajClassification](https://spraakbanken.gu.se/en/resources/dalaj-1-0)                                                                                               | [AI-Sweden/SuperLim](https://huggingface.co/datasets/AI-Sweden/SuperLim)                                                             | A Swedish dataset for linguistic accebtablity. Available as a part of Superlim                                                                                                                                   | Classification     | s2s      |          1 |           3840 |          445 |           444 |              243.7 |            242.5 |             243.8 |\n",
    "| [DanishPoliticalCommentsClassification](https://huggingface.co/datasets/danish_political_comments)                                                                    | [danish_political_comments](https://huggingface.co/datasets/danish_political_comments)                                               | A dataset of Danish political comments rated for sentiment                                                                                                                                                       | Classification     | s2s      |          1 |           9010 |            0 |             0 |               69.9 |                0 |                 0 |\n",
    "| [LccClassification](https://github.com/fnielsen/lcc-sentiment)                                                                                                        | [DDSC/lcc](https://huggingface.co/datasets/DDSC/lcc)                                                                                 | The leipzig corpora collection, annotated for sentiment                                                                                                                                                          | Classification     | s2s      |          1 |            349 |            0 |           150 |              113.5 |                0 |             118.7 |\n",
    "| [NoRecClassification](https://aclanthology.org/L18-1661/)                                                                                                             | [ScandEval/norec-mini](https://huggingface.co/datasets/ScandEval/norec-mini)                                                         | A Norwegian dataset for sentiment classification on review                                                                                                                                                       | Classification     | s2s      |          1 |           1020 |          256 |          2050 |               86.9 |             89.6 |              82.0 |\n",
    "| [NordicLangClassification](https://aclanthology.org/2021.vardial-1.8/)                                                                                                | [strombergnlp/nordic_langid](https://huggingface.co/datasets/strombergnlp/nordic_langid)                                             | A dataset for Nordic language identification.                                                                                                                                                                    | Classification     | s2s      |          6 |          57000 |            0 |          3000 |               78.4 |                0 |              78.2 |\n",
    "| [NorwegianParliamentClassification](https://huggingface.co/datasets/NbAiLab/norwegian_parliament)                                                                     | [NbAiLab/norwegian_parliament](https://huggingface.co/datasets/NbAiLab/norwegian_parliament)                                         | Norwegian parliament speeches annotated for sentiment                                                                                                                                                            | Classification     | s2s      |          1 |           3600 |         1200 |          1200 |             1773.6 |           1911.0 |            1884.0 |\n",
    "| [ScalaDaClassification](https://aclanthology.org/2023.nodalida-1.20/)                                                                                                 | [ScandEval/scala-da](https://huggingface.co/datasets/ScandEval/scala-da)                                                             | A modified version of DDT modified for linguistic acceptability classification                                                                                                                                   | Classification     | s2s      |          1 |           1024 |          256 |          2048 |              107.6 |            100.8 |             109.4 |\n",
    "| [ScalaNbClassification](https://aclanthology.org/2023.nodalida-1.20/)                                                                                                 | [ScandEval/scala-nb](https://huggingface.co/datasets/ScandEval/scala-nb)                                                             | A Norwegian dataset for linguistic acceptability classification for Bokm√•l                                                                                                                                       | Classification     | s2s      |          1 |           1024 |          256 |          2048 |               95.5 |             94.8 |              98.4 |\n",
    "| [ScalaNnClassification](https://aclanthology.org/2023.nodalida-1.20/)                                                                                                 | [ScandEval/scala-nn](https://huggingface.co/datasets/ScandEval/scala-nn)                                                             | A Norwegian dataset for linguistic acceptability classification for Nynorsk                                                                                                                                      | Classification     | s2s      |          1 |           1024 |          256 |          2048 |              105.3 |            103.5 |             104.8 |\n",
    "| [ScalaSvClassification](https://aclanthology.org/2023.nodalida-1.20/)                                                                                                 | [ScandEval/scala-sv](https://huggingface.co/datasets/ScandEval/scala-sv)                                                             | A Swedish dataset for linguistic acceptability classification                                                                                                                                                    | Classification     | s2s      |          1 |           1024 |          256 |          2048 |              102.6 |            113.0 |              98.3 |\n",
    "| [SweRecClassificition](https://aclanthology.org/2023.nodalida-1.20/)                                                                                                  | [ScandEval/swerec-mini](https://huggingface.co/datasets/ScandEval/swerec-mini)                                                       | A Swedish dataset for sentiment classification on reviews                                                                                                                                                        | Classification     | s2s      |          1 |           1024 |          256 |          2048 |              317.7 |            293.4 |             318.8 |\n",
    "| [CBD](http://2019.poleval.pl/files/poleval2019.pdf)                                                                                                                   | [PL-MTEB/cbd](https://huggingface.co/datasets/PL-MTEB/cbd)                                                                           | Polish Tweets annotated for cyberbullying detection.                                                                                                                                                             | Classification     | s2s      |          1 |          10041 |            0 |          1000 |               93.6 |                0 |              93.2 |\n",
    "| [PolEmo2.0-IN](https://aclanthology.org/K19-1092.pdf)                                                                                                                 | [PL-MTEB/polemo2_in](https://huggingface.co/datasets/PL-MTEB/polemo2_in)                                                             | A collection of Polish online reviews from four domains: medicine, hotels, products and school. The PolEmo2.0-IN task is to predict the sentiment of in-domain (medicine and hotels) reviews.                    | Classification     | s2s      |          1 |           5783 |          723 |           722 |              780.6 |            769.4 |             756.2 |\n",
    "| [PolEmo2.0-OUT](https://aclanthology.org/K19-1092.pdf)                                                                                                                | [PL-MTEB/polemo2_out](https://huggingface.co/datasets/PL-MTEB/polemo2_out)                                                           | A collection of Polish online reviews from four domains: medicine, hotels, products and school. The PolEmo2.0-OUT task is to predict the sentiment of out-of-domain (products and school) reviews using models train on reviews from medicine and hotels domains. | Classification | s2s | 1 | 5783 | 494 | 494 | 780.6 | 589.3 | 587.0 |\n",
    "| [AllegroReviews](https://aclanthology.org/2020.acl-main.111.pdf)                                                                                                      | [PL-MTEB/allegro-reviews](https://huggingface.co/datasets/PL-MTEB/allegro-reviews)                                                   | A Polish dataset for sentiment classification on reviews from e-commerce marketplace Allegro.                                                                                                                    | Classification     | s2s      |          1 |           9577 |         1002 |          1006 |              477.9 |            480.9 |             477.2 |\n",
    "| [PAC](https://arxiv.org/pdf/2211.13112.pdf)                                                                                                                           | [laugustyniak/abusive-clauses-pl](https://huggingface.co/datasets/laugustyniak/abusive-clauses-pl)                                   | Polish Abusive Clauses Dataset                                                                                                                                                                                   | Classification     | s2s      |          1 |           4284 |         1519 |          3453 |              185.3 |            256.8 |             185.3 |\n",
    "| [AlloProfClusteringP2P](https://huggingface.co/datasets/lyon-nlp/alloprof) | [lyon-nlp/alloprof](https://huggingface.co/datasets/lyon-nlp/alloprof) | Clustering of document titles and descriptions from Allo Prof dataset. Clustering of 10 sets on the document topic. | Clustering | p2p | 1 | 2798 | 0 | 0 | 0 | 0 | 0 |\n",
    "| [AlloProfClusteringS2S](https://huggingface.co/datasets/lyon-nlp/alloprof) | [lyon-nlp/alloprof](https://huggingface.co/datasets/lyon-nlp/alloprof) | Clustering of document titles from Allo Prof dataset. Clustering of 10 sets on the document topic. | Clustering | s2s | 1 | 2798 | 0 | 0 | 0 | 0 | 0 |\n",
    "| [ArxivClusteringP2P](https://www.kaggle.com/Cornell-University/arxiv)                                                                                                 | [mteb/arxiv-clustering-p2p](https://huggingface.co/datasets/mteb/arxiv-clustering-p2p)                                               | Clustering of titles+abstract from arxiv. Clustering of 30 sets, either on the main or secondary category                                                                                                        | Clustering         | p2p      |          1 |              0 |            0 |        732723 |                  0 |                0 |            1009.9 |\n",
    "| [ArxivClusteringS2S](https://www.kaggle.com/Cornell-University/arxiv)                                                                                                 | [mteb/arxiv-clustering-s2s](https://huggingface.co/datasets/mteb/arxiv-clustering-s2s)                                               | Clustering of titles from arxiv. Clustering of 30 sets, either on the main or secondary category                                                                                                                 | Clustering         | s2s      |          1 |              0 |            0 |        732723 |                  0 |                0 |              74.0 |\n",
    "| [BiorxivClusteringP2P](https://api.biorxiv.org/)                                                                                                                      | [mteb/biorxiv-clustering-p2p](https://huggingface.co/datasets/mteb/biorxiv-clustering-p2p)                                           | Clustering of titles+abstract from biorxiv. Clustering of 10 sets, based on the main category.                                                                                                                   | Clustering         | p2p      |          1 |              0 |            0 |         75000 |                  0 |                0 |            1666.2 |\n",
    "| [BiorxivClusteringS2S](https://api.biorxiv.org/)                                                                                                                      | [mteb/biorxiv-clustering-s2s](https://huggingface.co/datasets/mteb/biorxiv-clustering-s2s)                                           | Clustering of titles from biorxiv. Clustering of 10 sets, based on the main category.                                                                                                                            | Clustering         | s2s      |          1 |              0 |            0 |         75000 |                  0 |                0 |             101.6 |\n",
    "| [BlurbsClusteringP2P](https://www.inf.uni-hamburg.de/en/inst/ab/lt/resources/data/germeval-2019-hmc.html)                                                             | [slvnwhrl/blurbs-clustering-p2p](https://huggingface.co/datasets/slvnwhrl/blurbs-clustering-p2p)                                     | Clustering of book titles+blurbs. Clustering of 28 sets, either on the main or secondary genre                                                                                                                   | Clustering         | p2p      |          1 |              0 |            0 |        174637 |                  0 |                0 |            664.09 |\n",
    "| [BlurbsClusteringS2S](https://www.inf.uni-hamburg.de/en/inst/ab/lt/resources/data/germeval-2019-hmc.html)                                                             | [slvnwhrl/blurbs-clustering-s2s](https://huggingface.co/datasets/slvnwhrl/blurbs-clustering-s2s)                                     | Clustering of book titles. Clustering of 28 sets, either on the main or secondary genre.                                                                                                                         | Clustering         | s2s      |          1 |              0 |            0 |        174637 |                  0 |                0 |             23.02 |\n",
    "| [HALClusteringS2S](https://huggingface.co/datasets/lyon-nlp/clustering-hal-s2s) | [lyon-nlp/clustering-hal-s2s](https://huggingface.co/datasets/lyon-nlp/clustering-hal-s2s) | Clustering of titles from HAL. Clustering of 10 sets on the main category. | Clustering | s2s | 1 | 85375 | 0 | 0 | 0 | 0 | 0 |\n",
    "| [MedrxivClusteringP2P](https://api.medrxiv.org/)                                                                                                                      | [mteb/medrxiv-clustering-p2p](https://huggingface.co/datasets/mteb/medrxiv-clustering-p2p)                                           | Clustering of titles+abstract from medrxiv. Clustering of 10 sets, based on the main category.                                                                                                                   | Clustering         | p2p      |          1 |              0 |            0 |         37500 |                  0 |                0 |            1981.2 |\n",
    "| [MedrxivClusteringS2S](https://api.medrxiv.org/)                                                                                                                      | [mteb/medrxiv-clustering-s2s](https://huggingface.co/datasets/mteb/medrxiv-clustering-s2s)                                           | Clustering of titles from medrxiv. Clustering of 10 sets, based on the main category.                                                                                                                            | Clustering         | s2s      |          1 |              0 |            0 |         37500 |                  0 |                0 |             114.7 |\n",
    "| [RedditClustering](https://arxiv.org/abs/2104.07081)                                                                                                                  | [mteb/reddit-clustering](https://huggingface.co/datasets/mteb/reddit-clustering)                                                     | Clustering of titles from 199 subreddits. Clustering of 25 sets, each with 10-50 classes, and each class with 100 - 1000 sentences.                                                                              | Clustering         | s2s      |          1 |              0 |            0 |        420464 |                  0 |                0 |              64.7 |\n",
    "| [RedditClusteringP2P](https://huggingface.co/datasets/sentence-transformers/reddit-title-body)                                                                        | [mteb/reddit-clustering-p2p](https://huggingface.co/datasets/mteb/reddit-clustering-p2p)                                             | Clustering of title+posts from reddit. Clustering of 10 sets of 50k paragraphs and 40 sets of 10k paragraphs.                                                                                                    | Clustering         | p2p      |          1 |              0 |            0 |        459399 |                  0 |                0 |             727.7 |\n",
    "| [StackExchangeClustering](https://arxiv.org/abs/2104.07081)                                                                                                           | [mteb/stackexchange-clustering](https://huggingface.co/datasets/mteb/stackexchange-clustering)                                       | Clustering of titles from 121 stackexchanges. Clustering of 25 sets, each with 10-50 classes, and each class with 100 - 1000 sentences.                                                                          | Clustering         | s2s      |          1 |              0 |       417060 |        373850 |                  0 |             56.8 |              57.0 |\n",
    "| [StackExchangeClusteringP2P](https://huggingface.co/datasets/flax-sentence-embeddings/stackexchange_title_body_jsonl)                                                 | [mteb/stackexchange-clustering-p2p](https://huggingface.co/datasets/mteb/stackexchange-clustering-p2p)                               | Clustering of title+body from stackexchange. Clustering of 5 sets of 10k paragraphs and 5 sets of 5k paragraphs.                                                                                                 | Clustering         | p2p      |          1 |              0 |            0 |         75000 |                  0 |                0 |            1090.7 |\n",
    "| [TenKGnadClusteringP2P](https://tblock.github.io/10kGNAD/)                                                                                                            | [slvnwhrl/tenkgnad-clustering-p2p](https://huggingface.co/datasets/slvnwhrl/tenkgnad-clustering-p2p)                                 | Clustering of news article titles+subheadings+texts. Clustering of 10 splits on the news article category.                                                                                                       | Clustering         | p2p      |          1 |              0 |            0 |         45914 |                  0 |                0 |           2641.03 |\n",
    "| [TenKGnadClusteringS2S](https://tblock.github.io/10kGNAD/)                                                                                                            | [slvnwhrl/tenkgnad-clustering-s2s](https://huggingface.co/datasets/slvnwhrl/tenkgnad-clustering-s2s)                                 | Clustering of news article titles. Clustering of 10 splits on the news article category.                                                                                                                         | Clustering         | s2s      |          1 |              0 |            0 |         45914 |                  0 |                0 |             50.96 |\n",
    "| [TwentyNewsgroupsClustering](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html)                                                                           | [mteb/twentynewsgroups-clustering](https://huggingface.co/datasets/mteb/twentynewsgroups-clustering)                                 | Clustering of the 20 Newsgroups dataset (subject only).                                                                                                                                                          | Clustering         | s2s      |          1 |              0 |            0 |         59545 |                  0 |                0 |              32.0 |\n",
    "| [8TagsClustering](https://aclanthology.org/2020.lrec-1.207.pdf)                                                                                                       | [PL-MTEB/8tags-clustering](https://huggingface.co/datasets/PL-MTEB/8tags-clustering)                                                 | Clustering of headlines from social media posts in Polish belonging to 8 categories: film, history, food, medicine, motorization, work, sport and technology.                                                    | Clustering         | s2s      |          1 |          40001 |         5000 |          4372 |               78.2 |             77.6 |              79.2 |\n",
    "| [OpusparcusPC](https://gem-benchmark.com/data_cards/opusparcus) | [GEM/opusparcus](https://huggingface.co/datasets/GEM/opusparcus) | Opusparcus is a paraphrase corpus for six European language: German, English, Finnish, French, Russian, and Swedish. The paraphrases consist of subtitles from movies and TV shows. | PairClassification | s2s | 6 | 1007 | 0 | 0 | 0 | 0 | 0 |\n",
    "| [SprintDuplicateQuestions](https://www.aclweb.org/anthology/D18-1131/)                                                                                                | [mteb/sprintduplicatequestions-pairclassification](https://huggingface.co/datasets/mteb/sprintduplicatequestions-pairclassification) | Duplicate questions from the Sprint community.                                                                                                                                                                   | PairClassification | s2s      |          1 |              0 |       101000 |        101000 |                  0 |             65.2 |              67.9 |\n",
    "| [TwitterSemEval2015](https://alt.qcri.org/semeval2015/task1/)                                                                                                         | [mteb/twittersemeval2015-pairclassification](https://huggingface.co/datasets/mteb/twittersemeval2015-pairclassification)             | Paraphrase-Pairs of Tweets from the SemEval 2015 workshop.                                                                                                                                                       | PairClassification | s2s      |          1 |              0 |            0 |         16777 |                  0 |                0 |              38.3 |\n",
    "| [TwitterURLCorpus](https://languagenet.github.io/)                                                                                                                    | [mteb/twitterurlcorpus-pairclassification](https://huggingface.co/datasets/mteb/twitterurlcorpus-pairclassification)                 | Paraphrase-Pairs of Tweets.                                                                                                                                                                                      | PairClassification | s2s      |          1 |              0 |            0 |         51534 |                  0 |                0 |              79.5 |\n",
    "| [PPC](https://arxiv.org/pdf/2207.12759.pdf)                                                                                                                           | [PL-MTEB/ppc-pairclassification](https://huggingface.co/datasets/PL-MTEB/ppc-pairclassification)                                     | Polish Paraphrase Corpus                                                                                                                                                                                         | PairClassification | s2s      |          1 |           5000 |         1000 |          1000 |               41.0 |             41.0 |              40.2 |\n",
    "| [PSC](http://www.lrec-conf.org/proceedings/lrec2014/pdf/1211_Paper.pdf)                                                                                               | [PL-MTEB/psc-pairclassification](https://huggingface.co/datasets/PL-MTEB/psc-pairclassification)                                     | Polish Summaries Corpus                                                                                                                                                                                          | PairClassification | s2s      |          1 |           4302 |            0 |          1078 |              537.1 |                0 |             549.3 |\n",
    "| [SICK-E-PL](https://aclanthology.org/2020.lrec-1.207.pdf)                                                                                                             | [PL-MTEB/sicke-pl-pairclassification](https://huggingface.co/datasets/PL-MTEB/sicke-pl-pairclassification)                           | Polish version of SICK dataset for textual entailment.                                                                                                                                                           | PairClassification | s2s      |          1 |           4439 |          495 |          4906 |               43.4 |             44.7 |              43.2 |\n",
    "| [CDSC-E](https://aclanthology.org/P17-1073.pdf)                                                                                                                       | [PL-MTEB/cdsce-pairclassification](https://huggingface.co/datasets/PL-MTEB/cdsce-pairclassification)                                 | Compositional Distributional Semantics Corpus for textual entailment.                                                                                                                                            | PairClassification | s2s      |          1 |           8000 |         1000 |          1000 |               71.9 |             73.5 |              75.2 |\n",
    "| [AskUbuntuDupQuestions](https://github.com/taolei87/askubuntu)                                                                                                        | [mteb/askubuntudupquestions-reranking](https://huggingface.co/datasets/mteb/askubuntudupquestions-reranking)                         | AskUbuntu Question Dataset - Questions from AskUbuntu with manual annotations marking pairs of questions as similar or non-similar                                                                               | Reranking          | s2s      |          1 |              0 |            0 |          2255 |                  0 |                0 |              52.5 |\n",
    "| [MindSmallReranking](https://msnews.github.io/assets/doc/ACL2020_MIND.pdf)                                                                                            | [mteb/mind_small](https://huggingface.co/datasets/mteb/mind_small)                                                                   | Microsoft News Dataset: A Large-Scale English Dataset for News Recommendation Research                                                                                                                           | Reranking          | s2s      |          1 |         231530 |            0 |        107968 |               69.0 |                0 |              70.9 |\n",
    "| [SciDocsRR](https://allenai.org/data/scidocs)                                                                                                                         | [mteb/scidocs-reranking](https://huggingface.co/datasets/mteb/scidocs-reranking)                                                     | Ranking of related scientific papers based on their title.                                                                                                                                                       | Reranking          | s2s      |          1 |              0 |        19594 |         19599 |                  0 |             69.4 |              69.0 |\n",
    "| [StackOverflowDupQuestions](https://www.microsoft.com/en-us/research/uploads/prod/2019/03/nl4se18LinkSO.pdf)                                                          | [mteb/stackoverflowdupquestions-reranking](https://huggingface.co/datasets/mteb/stackoverflowdupquestions-reranking)                 | Stack Overflow Duplicate Questions Task for questions with the tags Java, JavaScript and Python                                                                                                                  | Reranking          | s2s      |          1 |          23018 |            0 |          3467 |               49.6 |                0 |              49.8 |\n",
    "| [AlloprofRetrieval](https://huggingface.co/datasets/antoinelb7/alloprof) | [lyon-nlp/alloprof](https://huggingface.co/datasets/lyon-nlp/alloprof) | This dataset was provided by AlloProf, an organisation in Quebec, Canada offering resources and a help forum curated by a large number of teachers to students on all subjects taught from in primary and secondary school | Retrieval | s2p | 1 | 2798 | 0 | 0 | 0 | 0 | 0 |\n",
    "| [ArguAna](http://argumentation.bplaced.net/arguana/data)                                                                                                              | [BeIR/arguana](https://huggingface.co/datasets/BeIR/arguana)                                                                         | NFCorpus: A Full-Text Learning to Rank Dataset for Medical Information Retrieval                                                                                                                                 | Retrieval          | p2p      |          1 |              0 |            0 |         10080 |                  0 |                0 |            1052.9 |\n",
    "| [BSARDRetrieval](https://huggingface.co/datasets/maastrichtlawtech/bsard) | [maastrichtlawtech/bsard](https://huggingface.co/datasets/maastrichtlawtech/bsard) | The Belgian Statutory Article Retrieval Dataset (BSARD) is a French native dataset for studying legal information retrieval. BSARD consists of more than 22,600 statutory articles from Belgian law and about 1,100 legal questions posed by Belgian citizens and labeled by experienced jurists with relevant articles from the corpus. | Retrieval | s2p | 1 | 222 | 0 | 0 | 0 | 0 | 0 |\n",
    "| [ClimateFEVER](https://www.sustainablefinance.uzh.ch/en/research/climate-fever.html)                                                                                  | [BeIR/climate-fever](https://huggingface.co/datasets/BeIR/climate-fever)                                                             | CLIMATE-FEVER is a dataset adopting the FEVER methodology that consists of 1,535 real-world claims regarding climate-change.                                                                                     | Retrieval          | s2p      |          1 |              0 |            0 |       5418128 |                  0 |                0 |             539.1 |\n",
    "| [CQADupstackAndroidRetrieval](http://nlp.cis.unimelb.edu.au/resources/cqadupstack/)                                                                                   | [BeIR/cqadupstack/android](https://huggingface.co/datasets/BeIR/cqadupstack-qrels)                                                   | CQADupStack: A Benchmark Data Set for Community Question-Answering Research                                                                                                                                      | Retrieval          | s2p      |          1 |              0 |            0 |         23697 |                  0 |                0 |             578.7 |\n",
    "| [CQADupstackEnglishRetrieval](http://nlp.cis.unimelb.edu.au/resources/cqadupstack/)                                                                                   | [BeIR/cqadupstack/english](https://huggingface.co/datasets/BeIR/cqadupstack-qrels)                                                   | CQADupStack: A Benchmark Data Set for Community Question-Answering Research                                                                                                                                      | Retrieval          | s2p      |          1 |              0 |            0 |         41791 |                  0 |                0 |             467.1 |\n",
    "| [CQADupstackGamingRetrieval](http://nlp.cis.unimelb.edu.au/resources/cqadupstack/)                                                                                    | [BeIR/cqadupstack/gaming](https://huggingface.co/datasets/BeIR/cqadupstack-qrels)                                                    | CQADupStack: A Benchmark Data Set for Community Question-Answering Research                                                                                                                                      | Retrieval          | s2p      |          1 |              0 |            0 |         46896 |                  0 |                0 |             474.7 |\n",
    "| [CQADupstackGisRetrieval](http://nlp.cis.unimelb.edu.au/resources/cqadupstack/)                                                                                       | [BeIR/cqadupstack/gis](https://huggingface.co/datasets/BeIR/cqadupstack-qrels)                                                       | CQADupStack: A Benchmark Data Set for Community Question-Answering Research                                                                                                                                      | Retrieval          | s2p      |          1 |              0 |            0 |         38522 |                  0 |                0 |             991.1 |\n",
    "| [CQADupstackMathematicaRetrieval](http://nlp.cis.unimelb.edu.au/resources/cqadupstack/)                                                                               | [BeIR/cqadupstack/mathematica](https://huggingface.co/datasets/BeIR/cqadupstack-qrels)                                               | CQADupStack: A Benchmark Data Set for Community Question-Answering Research                                                                                                                                      | Retrieval          | s2p      |          1 |              0 |            0 |         17509 |                  0 |                0 |            1103.7 |\n",
    "| [CQADupstackPhysicsRetrieval](http://nlp.cis.unimelb.edu.au/resources/cqadupstack/)                                                                                   | [BeIR/cqadupstack/physics](https://huggingface.co/datasets/BeIR/cqadupstack-qrels)                                                   | CQADupStack: A Benchmark Data Set for Community Question-Answering Research                                                                                                                                      | Retrieval          | s2p      |          1 |              0 |            0 |         39355 |                  0 |                0 |             799.4 |\n",
    "| [CQADupstackProgrammersRetrieval](http://nlp.cis.unimelb.edu.au/resources/cqadupstack/)                                                                               | [BeIR/cqadupstack/programmers](https://huggingface.co/datasets/BeIR/cqadupstack-qrels)                                               | CQADupStack: A Benchmark Data Set for Community Question-Answering Research                                                                                                                                      | Retrieval          | s2p      |          1 |              0 |            0 |         33052 |                  0 |                0 |            1030.2 |\n",
    "| [CQADupstackStatsRetrieval](http://nlp.cis.unimelb.edu.au/resources/cqadupstack/)                                                                                     | [BeIR/cqadupstack/stats](https://huggingface.co/datasets/BeIR/cqadupstack-qrels)                                                     | CQADupStack: A Benchmark Data Set for Community Question-Answering Research                                                                                                                                      | Retrieval          | s2p      |          1 |              0 |            0 |         42921 |                  0 |                0 |            1041.0 |\n",
    "| [CQADupstackTexRetrieval](http://nlp.cis.unimelb.edu.au/resources/cqadupstack/)                                                                                       | [BeIR/cqadupstack/tex](https://huggingface.co/datasets/BeIR/cqadupstack-qrels)                                                       | CQADupStack: A Benchmark Data Set for Community Question-Answering Research                                                                                                                                      | Retrieval          | s2p      |          1 |              0 |            0 |         71090 |                  0 |                0 |            1246.9 |\n",
    "| [CQADupstackUnixRetrieval](http://nlp.cis.unimelb.edu.au/resources/cqadupstack/)                                                                                      | [BeIR/cqadupstack/unix](https://huggingface.co/datasets/BeIR/cqadupstack-qrels)                                                      | CQADupStack: A Benchmark Data Set for Community Question-Answering Research                                                                                                                                      | Retrieval          | s2p      |          1 |              0 |            0 |         48454 |                  0 |                0 |             984.7 |\n",
    "| [CQADupstackWebmastersRetrieval](http://nlp.cis.unimelb.edu.au/resources/cqadupstack/)                                                                                | [BeIR/cqadupstack/webmasters](https://huggingface.co/datasets/BeIR/cqadupstack-qrels)                                                | CQADupStack: A Benchmark Data Set for Community Question-Answering Research                                                                                                                                      | Retrieval          | s2p      |          1 |              0 |            0 |         17911 |                  0 |                0 |             689.8 |\n",
    "| [CQADupstackWordpressRetrieval](http://nlp.cis.unimelb.edu.au/resources/cqadupstack/)                                                                                 | [BeIR/cqadupstack/wordpress](https://huggingface.co/datasets/BeIR/cqadupstack-qrels)                                                 | CQADupStack: A Benchmark Data Set for Community Question-Answering Research                                                                                                                                      | Retrieval          | s2p      |          1 |              0 |            0 |         49146 |                  0 |                0 |            1111.9 |\n",
    "| [DBPedia](https://github.com/iai-group/DBpedia-Entity/)                                                                                                               | [BeIR/dbpedia-entity](https://huggingface.co/datasets/BeIR/dbpedia-entity)                                                           | DBpedia-Entity is a standard test collection for entity search over the DBpedia knowledge base                                                                                                                   | Retrieval          | s2p      |          1 |              0 |      4635989 |       4636322 |                  0 |            310.2 |             310.1 |\n",
    "| [FEVER](https://fever.ai/)                                                                                                                                            | [BeIR/fever](https://huggingface.co/datasets/BeIR/fever)                                                                             | FEVER (Fact Extraction and VERification) consists of 185,445 claims generated by altering sentences extracted from Wikipedia and subsequently verified without knowledge of the sentence they were derived from. | Retrieval          | s2p      |          1 |              0 |            0 |       5423234 |                  0 |                0 |             538.6 |\n",
    "| [FiQA2018](https://sites.google.com/view/fiqa/)                                                                                                                       | [BeIR/fiqa](https://huggingface.co/datasets/BeIR/fiqa)                                                                               | Financial Opinion Mining and Question Answering                                                                                                                                                                  | Retrieval          | s2p      |          1 |              0 |            0 |         58286 |                  0 |                0 |             760.4 |\n",
    "| [HagridRetrieval](https://github.com/project-miracl/hagrid) | [miracl/hagrid](https://huggingface.co/datasets/miracl/hagrid) | HAGRID (Human-in-the-loop Attributable Generative Retrieval for Information-seeking Dataset) is a dataset for generative information-seeking scenarios. It consists of queries along with a set of manually labelled relevant passages | Retrieval | s2p | 1 | 716 | 0 | 0 | 0 | 0 | 0 |\n",
    "| [HotpotQA](https://hotpotqa.github.io/)                                                                                                                               | [BeIR/hotpotqa](https://huggingface.co/datasets/BeIR/hotpotqa)                                                                       | HotpotQA is a question answering dataset featuring natural, multi-hop questions, with strong supervision for supporting facts to enable more explainable question answering systems.                             | Retrieval          | s2p      |          1 |              0 |            0 |       5240734 |                  0 |                0 |             288.6 |\n",
    "| [MSMARCO](https://microsoft.github.io/msmarco/)                                                                                                                       | [BeIR/msmarco](https://huggingface.co/datasets/BeIR/msmarco)                                                                         | MS MARCO is a collection of datasets focused on deep learning in search. Note that the dev set is used for the leaderboard.                                                                                      | Retrieval          | s2p      |          1 |              0 |      8848803 |       8841866 |                  0 |            336.6 |             336.8 |\n",
    "| [MSMARCOv2](https://microsoft.github.io/msmarco/TREC-Deep-Learning.html)                                                                                              | [BeIR/msmarco-v2](https://huggingface.co/datasets/BeIR/msmarco-v2)                                                                   | MS MARCO is a collection of datasets focused on deep learning in search                                                                                                                                          | Retrieval          | s2p      |          1 |      138641342 |    138368101 |             0 |              341.4 |            342.0 |                 0 |\n",
    "| [NFCorpus](https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/)                                                                                                   | [BeIR/nfcorpus](https://huggingface.co/datasets/BeIR/nfcorpus)                                                                       | NFCorpus: A Full-Text Learning to Rank Dataset for Medical Information Retrieval                                                                                                                                 | Retrieval          | s2p      |          1 |              0 |            0 |          3956 |                  0 |                0 |            1462.7 |\n",
    "| [NQ](https://ai.google.com/research/NaturalQuestions/)                                                                                                                | [BeIR/nq](https://huggingface.co/datasets/BeIR/nq)                                                                                   | NFCorpus: A Full-Text Learning to Rank Dataset for Medical Information Retrieval                                                                                                                                 | Retrieval          | s2p      |          1 |              0 |            0 |       2684920 |                  0 |                0 |             492.7 |\n",
    "| [QuoraRetrieval](https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs)                                                                              | [BeIR/quora](https://huggingface.co/datasets/BeIR/quora)                                                                             | QuoraRetrieval is based on questions that are marked as duplicates on the Quora platform. Given a question, find other (duplicate) questions.                                                                    | Retrieval          | s2s      |          1 |              0 |            0 |        532931 |                  0 |                0 |              62.9 |\n",
    "| [SCIDOCS](https://allenai.org/data/scidocs)                                                                                                                           | [BeIR/scidocs](https://huggingface.co/datasets/BeIR/scidocs)                                                                         | SciDocs, a new evaluation benchmark consisting of seven document-level tasks ranging from citation prediction, to document classification and recommendation.                                                    | Retrieval          | s2p      |          1 |              0 |            0 |         26657 |                  0 |                0 |            1161.9 |\n",
    "| [SciFact](https://github.com/allenai/scifact)                                                                                                                         | [BeIR/scifact](https://huggingface.co/datasets/BeIR/scifact)                                                                         | SciFact verifies scientific claims using evidence from the research literature containing scientific paper abstracts.                                                                                            | Retrieval          | s2p      |          1 |              0 |            0 |          5483 |                  0 |                0 |            1422.3 |\n",
    "| [Touche2020](https://webis.de/events/touche-20/shared-task-1.html)                                                                                                    | [BeIR/webis-touche2020](https://huggingface.co/datasets/BeIR/webis-touche2020)                                                       | Touch√© Task 1: Argument Retrieval for Controversial Questions                                                                                                                                                    | Retrieval          | s2p      |          1 |              0 |            0 |        382594 |                  0 |                0 |            1720.1 |\n",
    "| [TRECCOVID](https://ir.nist.gov/covidSubmit/index.html)                                                                                                               | [BeIR/trec-covid](https://huggingface.co/datasets/BeIR/trec-covid)                                                                   | TRECCOVID is an ad-hoc search challenge based on the CORD-19 dataset containing scientific articles related to the COVID-19 pandemic                                                                             | Retrieval          | s2p      |          1 |              0 |            0 |        171382 |                  0 |                0 |            1117.4 |\n",
    "| [ArguAna-PL](http://argumentation.bplaced.net/arguana/data)                                                                                                           | [BeIR-PL/arguana-pl](https://huggingface.co/datasets/clarin-knext/arguana-pl) | NFCorpus: A Full-Text Learning to Rank Dataset for Medical Information Retrieval | Retrieval | p2p | 1 | 0 | 0 | 10080 | 0 | 0 | 1052.9 |\n",
    "| [DBPedia-PL](https://github.com/iai-group/DBpedia-Entity/)                                                                                                            | [BeIR-PL/dbpedia-pl](https://huggingface.co/datasets/clarin-knext/dbpedia-pl) | DBpedia-Entity is a standard test collection for entity search over the DBpedia knowledge base | Retrieval | s2p | 1 | 0 | 4635989 | 4636322 | 0 | 310.2 | 310.1 |\n",
    "| [FiQA-PL](https://sites.google.com/view/fiqa/)                                                                                                                        | [BeIR-PL/fiqa-pl](https://huggingface.co/datasets/clarin-knext/fiqa-pl) | Financial Opinion Mining and Question Answering | Retrieval | s2p | 1 | 0 | 0 | 58286 | 0 | 0 | 760.4 |\n",
    "| [HotpotQA-PL](https://hotpotqa.github.io/) | [BeIR-PL/hotpotqa-pl](https://huggingface.co/datasets/clarin-knext/hotpotqa-pl) | HotpotQA is a question answering dataset featuring natural, multi-hop questions, with strong supervision for supporting facts to enable more explainable question answering systems. | Retrieval | s2p | 1 | 0 | 0 | 5240734 | 0 | 0 | 288.6 |\n",
    "| [MSMARCO-PL](https://microsoft.github.io/msmarco/) | [BeIR-PL/msmarco-pl](https://huggingface.co/datasets/clarin-knext/msmarco-pl) | MS MARCO is a collection of datasets focused on deep learning in search. Note that the dev set is used for the leaderboard. | Retrieval | s2p | 1 | 0 | 8848803 | 8841866 | 0 | 336.6 | 336.8 |\n",
    "| [NFCorpus-PL](https://www.cl.uni-heidelberg.de/statnlpgroup/nfcorpus/) | [BeIR-PL/nfcorpus-pl](https://huggingface.co/datasets/clarin-knext/nfcorpus-pl) | NFCorpus: A Full-Text Learning to Rank Dataset for Medical Information Retrieval | Retrieval | s2p | 1 | 0 | 0 | 3956 | 0 | 0 | 1462.7 |\n",
    "| [NQ-PL](https://ai.google.com/research/NaturalQuestions/) | [BeIR-PL/nq-pl](https://huggingface.co/datasets/clarin-knext/nq-pl) | Natural Questions: A Benchmark for Question Answering Research | Retrieval | s2p | 1 | 0 | 0 | 2684920 | 0 | 0 | 492.7 |\n",
    "| [Quora-PL](https://quoradata.quora.com/First-Quora-Dataset-Release-Question-Pairs) | [BeIR-PL/quora-pl](https://huggingface.co/datasets/clarin-knext/quora-pl) | QuoraRetrieval is based on questions that are marked as duplicates on the Quora platform. Given a question, find other (duplicate) questions. | Retrieval | s2s | 1 | 0 | 0 | 532931 | 0 | 0 | 62.9 |\n",
    "| [SCIDOCS-PL](https://allenai.org/data/scidocs) | [BeIR-PL/scidocs-pl](https://huggingface.co/datasets/clarin-knext/scidocs-pl) | SciDocs, a new evaluation benchmark consisting of seven document-level tasks ranging from citation prediction, to document classification and recommendation. | Retrieval | s2p | 1 | 0 | 0 | 26657 | 0 | 0 | 1161.9 |\n",
    "| [SciFact-PL](https://github.com/allenai/scifact) | [BeIR-PL/scifact-pl](https://huggingface.co/datasets/clarin-knext/scifact-pl) | SciFact verifies scientific claims using evidence from the research literature containing scientific paper abstracts. | Retrieval | s2p | 1 | 0 | 0 | 5483 | 0 | 0 | 1422.3 |\n",
    "| [SweFAQ](https://spraakbanken.gu.se/en/resources/swefaq)                                                                                                                  | [AI-Sweden/SuperLim](https://huggingface.co/datasets/AI-Sweden/SuperLim)                                                             | Frequently asked questions from Swedish authorities' websites                                                                                                                                                    | Retrieval          | s2p      |          1 |              0 |            0 |           513 |                  0 |                0 |            390.57 |\n",
    "| [BIOSSES](https://tabilab.cmpe.boun.edu.tr/BIOSSES/DataSet.html)                                                                                                      | [mteb/biosses-sts](https://huggingface.co/datasets/mteb/biosses-sts)                                                                 | Biomedical Semantic Similarity Estimation.                                                                                                                                                                       | STS                | s2s      |          1 |              0 |            0 |           200 |                  0 |                0 |             156.6 |\n",
    "| [SICK-R](https://www.aclweb.org/anthology/S14-2001.pdf)                                                                                                               | [mteb/sickr-sts](https://huggingface.co/datasets/mteb/sickr-sts)                                                                     | Semantic Textual Similarity SICK-R dataset as described here:                                                                                                                                                    | STS                | s2s      |          1 |              0 |            0 |         19854 |                  0 |                0 |              46.1 |\n",
    "| [STS12](https://www.aclweb.org/anthology/S12-1051.pdf)                                                                                                                | [mteb/sts12-sts](https://huggingface.co/datasets/mteb/sts12-sts)                                                                     | SemEval STS 2012 dataset.                                                                                                                                                                                        | STS                | s2s      |          1 |           4468 |            0 |          6216 |              100.7 |                0 |              64.7 |\n",
    "| [STS13](https://www.aclweb.org/anthology/S13-1004/)                                                                                                                   | [mteb/sts13-sts](https://huggingface.co/datasets/mteb/sts13-sts)                                                                     | SemEval STS 2013 dataset.                                                                                                                                                                                        | STS                | s2s      |          1 |              0 |            0 |          3000 |                  0 |                0 |              54.0 |\n",
    "| [STS14](http://alt.qcri.org/semeval2014/task10/)                                                                                                                      | [mteb/sts14-sts](https://huggingface.co/datasets/mteb/sts14-sts)                                                                     | SemEval STS 2014 dataset. Currently only the English dataset                                                                                                                                                     | STS                | s2s      |          1 |              0 |            0 |          7500 |                  0 |                0 |              54.3 |\n",
    "| [STS15](http://alt.qcri.org/semeval2015/task2/)                                                                                                                       | [mteb/sts15-sts](https://huggingface.co/datasets/mteb/sts15-sts)                                                                     | SemEval STS 2015 dataset                                                                                                                                                                                         | STS                | s2s      |          1 |              0 |            0 |          6000 |                  0 |                0 |              57.7 |\n",
    "| [STS16](http://alt.qcri.org/semeval2016/task1/)                                                                                                                       | [mteb/sts16-sts](https://huggingface.co/datasets/mteb/sts16-sts)                                                                     | SemEval STS 2016 dataset                                                                                                                                                                                         | STS                | s2s      |          1 |              0 |            0 |          2372 |                  0 |                0 |              65.3 |\n",
    "| [STS17](http://alt.qcri.org/semeval2016/task1/)                                                                                                                       | [mteb/sts17-crosslingual-sts](https://huggingface.co/datasets/mteb/sts17-crosslingual-sts)                                           | STS 2017 dataset                                                                                                                                                                                                 | STS                | s2s      |         11 |              0 |            0 |           500 |                  0 |                0 |              43.3 |\n",
    "| [STS22](https://competitions.codalab.org/competitions/33835)                                                                                                          | [mteb/sts22-crosslingual-sts](https://huggingface.co/datasets/mteb/sts22-crosslingual-sts)                                           | SemEval 2022 Task 8: Multilingual News Article Similarity                                                                                                                                                        | STS                | s2s      |         18 |              0 |            0 |          8060 |                  0 |                0 |            1992.8 |\n",
    "| [STSBenchmark](http://ixa2.si.ehu.es/stswiki/index.php/STSbenchmark)                                                                                                  | [mteb/stsbenchmark-sts](https://huggingface.co/datasets/mteb/stsbenchmark-sts)                                                       | Semantic Textual Similarity Benchmark (STSbenchmark) dataset.                                                                                                                                                    | STS                | s2s      |          1 |          11498 |         3000 |          2758 |               57.6 |             64.0 |              53.6 |\n",
    "| [SICK-R-PL](https://aclanthology.org/2020.lrec-1.207.pdf)                                                                                                             | [PL-MTEB/sickr-pl-sts](https://huggingface.co/datasets/PL-MTEB/sickr-pl-sts)                                                         | Polish version of SICK dataset for textual relatedness.                                                                                                                                                          | STS                | s2s      |          1 |           8878 |          990 |          9812 |               42.9 |             44.0 |              42.8 |\n",
    "| [CDSC-R](https://aclanthology.org/P17-1073.pdf)                                                                                                                       | [PL-MTEB/cdscr-sts](https://huggingface.co/datasets/PL-MTEB/cdscr-sts)                                                               | Compositional Distributional Semantics Corpus for textual relatedness.                                                                                                                                           | STS                | s2s      |          1 |          16000 |         2000 |          2000 |               72.1 |             73.2 |              75.0 |\n",
    "| [SummEval](https://github.com/Yale-LILY/SummEval)                                                                                                     | [mteb/summeval](https://huggingface.co/datasets/mteb/summeval)                                                                       | News Article Summary Semantic Similarity Estimation.                                                                                                                                                             | Summarization      | s2s      |          1 |              0 |            0 |          2800 |                  0 |                0 |             359.8 |\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Hub URL</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>Category</th>\n",
       "      <th>#Languages</th>\n",
       "      <th>Train #Samples</th>\n",
       "      <th>Dev #Samples</th>\n",
       "      <th>Test #Samples</th>\n",
       "      <th>Avg. chars / train</th>\n",
       "      <th>Avg. chars / dev</th>\n",
       "      <th>Avg. chars / test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[BUCC](https://comparable.limsi.fr/bucc2018/bu...</td>\n",
       "      <td>[mteb/bucc-bitext-mining](https://huggingface....</td>\n",
       "      <td>BUCC bitext mining dataset                    ...</td>\n",
       "      <td>BitextMining</td>\n",
       "      <td>s2s</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>641684</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>101.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Tatoeba](https://github.com/facebookresearch/...</td>\n",
       "      <td>[mteb/tatoeba-bitext-mining](https://huggingfa...</td>\n",
       "      <td>1,000 English-aligned sentence pairs for each ...</td>\n",
       "      <td>BitextMining</td>\n",
       "      <td>s2s</td>\n",
       "      <td>112</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>39.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Bornholm parallel](https://aclanthology.org/W...</td>\n",
       "      <td>[strombergnlp/bornholmsk_parallel](https://hug...</td>\n",
       "      <td>Danish Bornholmsk Parallel Corpus.            ...</td>\n",
       "      <td>BitextMining</td>\n",
       "      <td>s2s</td>\n",
       "      <td>2</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>64.6</td>\n",
       "      <td>86.2</td>\n",
       "      <td>89.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[DiaBLaBitextMining](https://inria.hal.science...</td>\n",
       "      <td>[rbawden/DiaBLa](https://huggingface.co/datase...</td>\n",
       "      <td>English-French Parallel Corpus. DiaBLa is an E...</td>\n",
       "      <td>BitextMining</td>\n",
       "      <td>s2s</td>\n",
       "      <td>1</td>\n",
       "      <td>5748</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[FloresBitextMining](https://huggingface.co/da...</td>\n",
       "      <td>[facebook/flores](https://huggingface.co/datas...</td>\n",
       "      <td>FLORES is a benchmark dataset for machine tran...</td>\n",
       "      <td>BitextMining</td>\n",
       "      <td>s2s</td>\n",
       "      <td>200</td>\n",
       "      <td>0</td>\n",
       "      <td>997</td>\n",
       "      <td>1012</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>[STS22](https://competitions.codalab.org/compe...</td>\n",
       "      <td>[mteb/sts22-crosslingual-sts](https://huggingf...</td>\n",
       "      <td>SemEval 2022 Task 8: Multilingual News Article...</td>\n",
       "      <td>STS</td>\n",
       "      <td>s2s</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8060</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1992.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>[STSBenchmark](http://ixa2.si.ehu.es/stswiki/i...</td>\n",
       "      <td>[mteb/stsbenchmark-sts](https://huggingface.co...</td>\n",
       "      <td>Semantic Textual Similarity Benchmark (STSbenc...</td>\n",
       "      <td>STS</td>\n",
       "      <td>s2s</td>\n",
       "      <td>1</td>\n",
       "      <td>11498</td>\n",
       "      <td>3000</td>\n",
       "      <td>2758</td>\n",
       "      <td>57.6</td>\n",
       "      <td>64.0</td>\n",
       "      <td>53.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>[SICK-R-PL](https://aclanthology.org/2020.lrec...</td>\n",
       "      <td>[PL-MTEB/sickr-pl-sts](https://huggingface.co/...</td>\n",
       "      <td>Polish version of SICK dataset for textual rel...</td>\n",
       "      <td>STS</td>\n",
       "      <td>s2s</td>\n",
       "      <td>1</td>\n",
       "      <td>8878</td>\n",
       "      <td>990</td>\n",
       "      <td>9812</td>\n",
       "      <td>42.9</td>\n",
       "      <td>44.0</td>\n",
       "      <td>42.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>[CDSC-R](https://aclanthology.org/P17-1073.pdf...</td>\n",
       "      <td>[PL-MTEB/cdscr-sts](https://huggingface.co/dat...</td>\n",
       "      <td>Compositional Distributional Semantics Corpus ...</td>\n",
       "      <td>STS</td>\n",
       "      <td>s2s</td>\n",
       "      <td>1</td>\n",
       "      <td>16000</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>72.1</td>\n",
       "      <td>73.2</td>\n",
       "      <td>75.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>[SummEval](https://github.com/Yale-LILY/SummEv...</td>\n",
       "      <td>[mteb/summeval](https://huggingface.co/dataset...</td>\n",
       "      <td>News Article Summary Semantic Similarity Estim...</td>\n",
       "      <td>Summarization</td>\n",
       "      <td>s2s</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2800</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>359.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>121 rows √ó 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  Name  \\\n",
       "1    [BUCC](https://comparable.limsi.fr/bucc2018/bu...   \n",
       "2    [Tatoeba](https://github.com/facebookresearch/...   \n",
       "3    [Bornholm parallel](https://aclanthology.org/W...   \n",
       "4    [DiaBLaBitextMining](https://inria.hal.science...   \n",
       "5    [FloresBitextMining](https://huggingface.co/da...   \n",
       "..                                                 ...   \n",
       "117  [STS22](https://competitions.codalab.org/compe...   \n",
       "118  [STSBenchmark](http://ixa2.si.ehu.es/stswiki/i...   \n",
       "119  [SICK-R-PL](https://aclanthology.org/2020.lrec...   \n",
       "120  [CDSC-R](https://aclanthology.org/P17-1073.pdf...   \n",
       "121  [SummEval](https://github.com/Yale-LILY/SummEv...   \n",
       "\n",
       "                                               Hub URL  \\\n",
       "1    [mteb/bucc-bitext-mining](https://huggingface....   \n",
       "2    [mteb/tatoeba-bitext-mining](https://huggingfa...   \n",
       "3    [strombergnlp/bornholmsk_parallel](https://hug...   \n",
       "4    [rbawden/DiaBLa](https://huggingface.co/datase...   \n",
       "5    [facebook/flores](https://huggingface.co/datas...   \n",
       "..                                                 ...   \n",
       "117  [mteb/sts22-crosslingual-sts](https://huggingf...   \n",
       "118  [mteb/stsbenchmark-sts](https://huggingface.co...   \n",
       "119  [PL-MTEB/sickr-pl-sts](https://huggingface.co/...   \n",
       "120  [PL-MTEB/cdscr-sts](https://huggingface.co/dat...   \n",
       "121  [mteb/summeval](https://huggingface.co/dataset...   \n",
       "\n",
       "                                           Description                 Type  \\\n",
       "1    BUCC bitext mining dataset                    ...  BitextMining          \n",
       "2    1,000 English-aligned sentence pairs for each ...  BitextMining          \n",
       "3    Danish Bornholmsk Parallel Corpus.            ...  BitextMining          \n",
       "4    English-French Parallel Corpus. DiaBLa is an E...        BitextMining    \n",
       "5    FLORES is a benchmark dataset for machine tran...        BitextMining    \n",
       "..                                                 ...                  ...   \n",
       "117  SemEval 2022 Task 8: Multilingual News Article...  STS                   \n",
       "118  Semantic Textual Similarity Benchmark (STSbenc...  STS                   \n",
       "119  Polish version of SICK dataset for textual rel...  STS                   \n",
       "120  Compositional Distributional Semantics Corpus ...  STS                   \n",
       "121  News Article Summary Semantic Similarity Estim...  Summarization         \n",
       "\n",
       "      Category #Languages Train #Samples Dev #Samples Test #Samples  \\\n",
       "1    s2s               4              0            0        641684    \n",
       "2    s2s             112              0            0          2000    \n",
       "3    s2s               2            100          100           100    \n",
       "4         s2s          1           5748            0             0    \n",
       "5         s2s        200              0          997          1012    \n",
       "..         ...        ...            ...          ...           ...   \n",
       "117  s2s              18              0            0          8060    \n",
       "118  s2s               1          11498         3000          2758    \n",
       "119  s2s               1           8878          990          9812    \n",
       "120  s2s               1          16000         2000          2000    \n",
       "121  s2s               1              0            0          2800    \n",
       "\n",
       "    Avg. chars / train Avg. chars / dev Avg. chars / test  \n",
       "1                   0                0             101.3   \n",
       "2                   0                0              39.4   \n",
       "3                64.6             86.2              89.7   \n",
       "4                   0                0                 0   \n",
       "5                   0                0                 0   \n",
       "..                 ...              ...               ...  \n",
       "117                 0                0            1992.8   \n",
       "118              57.6             64.0              53.6   \n",
       "119              42.9             44.0              42.8   \n",
       "120              72.1             73.2              75.0   \n",
       "121                 0                0             359.8   \n",
       "\n",
       "[121 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_table(io.StringIO(text), sep=\"|\", header=0, skipinitialspace=True).dropna(how=\"all\", axis=1).iloc[1:]\n",
    "df.columns = df.columns.str.strip()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "find = lambda x: re.search(r\"\\[(.*?)\\]\", x).group(1)\n",
    "\n",
    "df[\"cls\"] = df[\"Name\"].apply(find)\n",
    "df[\"URL\"] = df[\"Hub URL\"].apply(find)\n",
    "df[\"Type\"] = df[\"Type\"].str.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cls</th>\n",
       "      <th>URL</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AmazonCounterfactualClassification</td>\n",
       "      <td>mteb/amazon_counterfactual</td>\n",
       "      <td>Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AmazonPolarityClassification</td>\n",
       "      <td>mteb/amazon_polarity</td>\n",
       "      <td>Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AmazonReviewsClassification</td>\n",
       "      <td>mteb/amazon_reviews_multi</td>\n",
       "      <td>Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>MasakhaNEWSClassification</td>\n",
       "      <td>masakhane/masakhanews</td>\n",
       "      <td>Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Banking77Classification</td>\n",
       "      <td>mteb/banking77</td>\n",
       "      <td>Classification</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>STS22</td>\n",
       "      <td>mteb/sts22-crosslingual-sts</td>\n",
       "      <td>STS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>118</th>\n",
       "      <td>STSBenchmark</td>\n",
       "      <td>mteb/stsbenchmark-sts</td>\n",
       "      <td>STS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>119</th>\n",
       "      <td>SICK-R-PL</td>\n",
       "      <td>PL-MTEB/sickr-pl-sts</td>\n",
       "      <td>STS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>CDSC-R</td>\n",
       "      <td>PL-MTEB/cdscr-sts</td>\n",
       "      <td>STS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>SummEval</td>\n",
       "      <td>mteb/summeval</td>\n",
       "      <td>Summarization</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>116 rows √ó 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    cls                          URL  \\\n",
       "6    AmazonCounterfactualClassification   mteb/amazon_counterfactual   \n",
       "7          AmazonPolarityClassification         mteb/amazon_polarity   \n",
       "8           AmazonReviewsClassification    mteb/amazon_reviews_multi   \n",
       "9             MasakhaNEWSClassification        masakhane/masakhanews   \n",
       "10              Banking77Classification               mteb/banking77   \n",
       "..                                  ...                          ...   \n",
       "117                               STS22  mteb/sts22-crosslingual-sts   \n",
       "118                        STSBenchmark        mteb/stsbenchmark-sts   \n",
       "119                           SICK-R-PL         PL-MTEB/sickr-pl-sts   \n",
       "120                              CDSC-R            PL-MTEB/cdscr-sts   \n",
       "121                            SummEval                mteb/summeval   \n",
       "\n",
       "               Type  \n",
       "6    Classification  \n",
       "7    Classification  \n",
       "8    Classification  \n",
       "9    Classification  \n",
       "10   Classification  \n",
       "..              ...  \n",
       "117             STS  \n",
       "118             STS  \n",
       "119             STS  \n",
       "120             STS  \n",
       "121   Summarization  \n",
       "\n",
       "[116 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[[\"cls\",\"URL\",\"Type\"]][df[\"Type\"] != \"BitextMining\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['AmazonCounterfactualClassification',\n",
       " 'AmazonPolarityClassification',\n",
       " 'AmazonReviewsClassification',\n",
       " 'MasakhaNEWSClassification',\n",
       " 'Banking77Classification',\n",
       " 'EmotionClassification',\n",
       " 'ImdbClassification',\n",
       " 'MassiveIntentClassification',\n",
       " 'MassiveScenarioClassification',\n",
       " 'MTOPDomainClassification',\n",
       " 'MTOPIntentClassification',\n",
       " 'ToxicConversationsClassification',\n",
       " 'TweetSentimentExtractionClassification',\n",
       " 'AngryTweetsClassification',\n",
       " 'DKHateClassification',\n",
       " 'DalajClassification',\n",
       " 'DanishPoliticalCommentsClassification',\n",
       " 'LccClassification',\n",
       " 'NoRecClassification',\n",
       " 'NordicLangClassification',\n",
       " 'NorwegianParliamentClassification',\n",
       " 'ScalaDaClassification',\n",
       " 'ScalaNbClassification',\n",
       " 'ScalaNnClassification',\n",
       " 'ScalaSvClassification',\n",
       " 'SweRecClassificition',\n",
       " 'CBD',\n",
       " 'PolEmo2.0-IN',\n",
       " 'PolEmo2.0-OUT',\n",
       " 'AllegroReviews',\n",
       " 'PAC',\n",
       " 'AlloProfClusteringP2P',\n",
       " 'AlloProfClusteringS2S',\n",
       " 'ArxivClusteringP2P',\n",
       " 'ArxivClusteringS2S',\n",
       " 'BiorxivClusteringP2P',\n",
       " 'BiorxivClusteringS2S',\n",
       " 'BlurbsClusteringP2P',\n",
       " 'BlurbsClusteringS2S',\n",
       " 'HALClusteringS2S',\n",
       " 'MedrxivClusteringP2P',\n",
       " 'MedrxivClusteringS2S',\n",
       " 'RedditClustering',\n",
       " 'RedditClusteringP2P',\n",
       " 'StackExchangeClustering',\n",
       " 'StackExchangeClusteringP2P',\n",
       " 'TenKGnadClusteringP2P',\n",
       " 'TenKGnadClusteringS2S',\n",
       " 'TwentyNewsgroupsClustering',\n",
       " '8TagsClustering',\n",
       " 'OpusparcusPC',\n",
       " 'SprintDuplicateQuestions',\n",
       " 'TwitterSemEval2015',\n",
       " 'TwitterURLCorpus',\n",
       " 'PPC',\n",
       " 'PSC',\n",
       " 'SICK-E-PL',\n",
       " 'CDSC-E',\n",
       " 'AskUbuntuDupQuestions',\n",
       " 'MindSmallReranking',\n",
       " 'SciDocsRR',\n",
       " 'StackOverflowDupQuestions',\n",
       " 'AlloprofRetrieval',\n",
       " 'ArguAna',\n",
       " 'BSARDRetrieval',\n",
       " 'ClimateFEVER',\n",
       " 'CQADupstackAndroidRetrieval',\n",
       " 'CQADupstackEnglishRetrieval',\n",
       " 'CQADupstackGamingRetrieval',\n",
       " 'CQADupstackGisRetrieval',\n",
       " 'CQADupstackMathematicaRetrieval',\n",
       " 'CQADupstackPhysicsRetrieval',\n",
       " 'CQADupstackProgrammersRetrieval',\n",
       " 'CQADupstackStatsRetrieval',\n",
       " 'CQADupstackTexRetrieval',\n",
       " 'CQADupstackUnixRetrieval',\n",
       " 'CQADupstackWebmastersRetrieval',\n",
       " 'CQADupstackWordpressRetrieval',\n",
       " 'DBPedia',\n",
       " 'FEVER',\n",
       " 'FiQA2018',\n",
       " 'HagridRetrieval',\n",
       " 'HotpotQA',\n",
       " 'MSMARCO',\n",
       " 'MSMARCOv2',\n",
       " 'NFCorpus',\n",
       " 'NQ',\n",
       " 'QuoraRetrieval',\n",
       " 'SCIDOCS',\n",
       " 'SciFact',\n",
       " 'Touche2020',\n",
       " 'TRECCOVID',\n",
       " 'ArguAna-PL',\n",
       " 'DBPedia-PL',\n",
       " 'FiQA-PL',\n",
       " 'HotpotQA-PL',\n",
       " 'MSMARCO-PL',\n",
       " 'NFCorpus-PL',\n",
       " 'NQ-PL',\n",
       " 'Quora-PL',\n",
       " 'SCIDOCS-PL',\n",
       " 'SciFact-PL',\n",
       " 'SweFAQ',\n",
       " 'BIOSSES',\n",
       " 'SICK-R',\n",
       " 'STS12',\n",
       " 'STS13',\n",
       " 'STS14',\n",
       " 'STS15',\n",
       " 'STS16',\n",
       " 'STS17',\n",
       " 'STS22',\n",
       " 'STSBenchmark',\n",
       " 'SICK-R-PL',\n",
       " 'CDSC-R',\n",
       " 'SummEval']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"cls\"][df[\"Type\"] != \"BitextMining\"].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Hub URL</th>\n",
       "      <th>Description</th>\n",
       "      <th>Type</th>\n",
       "      <th>Category</th>\n",
       "      <th>#Languages</th>\n",
       "      <th>Train #Samples</th>\n",
       "      <th>Dev #Samples</th>\n",
       "      <th>Test #Samples</th>\n",
       "      <th>Avg. chars / train</th>\n",
       "      <th>Avg. chars / dev</th>\n",
       "      <th>Avg. chars / test</th>\n",
       "      <th>cls</th>\n",
       "      <th>URL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>[AskUbuntuDupQuestions](https://github.com/tao...</td>\n",
       "      <td>[mteb/askubuntudupquestions-reranking](https:/...</td>\n",
       "      <td>AskUbuntu Question Dataset - Questions from As...</td>\n",
       "      <td>Reranking</td>\n",
       "      <td>s2s</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2255</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>52.5</td>\n",
       "      <td>AskUbuntuDupQuestions</td>\n",
       "      <td>mteb/askubuntudupquestions-reranking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>[MindSmallReranking](https://msnews.github.io/...</td>\n",
       "      <td>[mteb/mind_small](https://huggingface.co/datas...</td>\n",
       "      <td>Microsoft News Dataset: A Large-Scale English ...</td>\n",
       "      <td>Reranking</td>\n",
       "      <td>s2s</td>\n",
       "      <td>1</td>\n",
       "      <td>231530</td>\n",
       "      <td>0</td>\n",
       "      <td>107968</td>\n",
       "      <td>69.0</td>\n",
       "      <td>0</td>\n",
       "      <td>70.9</td>\n",
       "      <td>MindSmallReranking</td>\n",
       "      <td>mteb/mind_small</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>[SciDocsRR](https://allenai.org/data/scidocs) ...</td>\n",
       "      <td>[mteb/scidocs-reranking](https://huggingface.c...</td>\n",
       "      <td>Ranking of related scientific papers based on ...</td>\n",
       "      <td>Reranking</td>\n",
       "      <td>s2s</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19594</td>\n",
       "      <td>19599</td>\n",
       "      <td>0</td>\n",
       "      <td>69.4</td>\n",
       "      <td>69.0</td>\n",
       "      <td>SciDocsRR</td>\n",
       "      <td>mteb/scidocs-reranking</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>[StackOverflowDupQuestions](https://www.micros...</td>\n",
       "      <td>[mteb/stackoverflowdupquestions-reranking](htt...</td>\n",
       "      <td>Stack Overflow Duplicate Questions Task for qu...</td>\n",
       "      <td>Reranking</td>\n",
       "      <td>s2s</td>\n",
       "      <td>1</td>\n",
       "      <td>23018</td>\n",
       "      <td>0</td>\n",
       "      <td>3467</td>\n",
       "      <td>49.6</td>\n",
       "      <td>0</td>\n",
       "      <td>49.8</td>\n",
       "      <td>StackOverflowDupQuestions</td>\n",
       "      <td>mteb/stackoverflowdupquestions-reranking</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 Name  \\\n",
       "64  [AskUbuntuDupQuestions](https://github.com/tao...   \n",
       "65  [MindSmallReranking](https://msnews.github.io/...   \n",
       "66  [SciDocsRR](https://allenai.org/data/scidocs) ...   \n",
       "67  [StackOverflowDupQuestions](https://www.micros...   \n",
       "\n",
       "                                              Hub URL  \\\n",
       "64  [mteb/askubuntudupquestions-reranking](https:/...   \n",
       "65  [mteb/mind_small](https://huggingface.co/datas...   \n",
       "66  [mteb/scidocs-reranking](https://huggingface.c...   \n",
       "67  [mteb/stackoverflowdupquestions-reranking](htt...   \n",
       "\n",
       "                                          Description       Type   Category  \\\n",
       "64  AskUbuntu Question Dataset - Questions from As...  Reranking  s2s         \n",
       "65  Microsoft News Dataset: A Large-Scale English ...  Reranking  s2s         \n",
       "66  Ranking of related scientific papers based on ...  Reranking  s2s         \n",
       "67  Stack Overflow Duplicate Questions Task for qu...  Reranking  s2s         \n",
       "\n",
       "   #Languages Train #Samples Dev #Samples Test #Samples Avg. chars / train  \\\n",
       "64         1              0            0          2255                  0    \n",
       "65         1         231530            0        107968               69.0    \n",
       "66         1              0        19594         19599                  0    \n",
       "67         1          23018            0          3467               49.6    \n",
       "\n",
       "   Avg. chars / dev Avg. chars / test                        cls  \\\n",
       "64               0              52.5       AskUbuntuDupQuestions   \n",
       "65               0              70.9          MindSmallReranking   \n",
       "66            69.4              69.0                   SciDocsRR   \n",
       "67               0              49.8   StackOverflowDupQuestions   \n",
       "\n",
       "                                         URL  \n",
       "64      mteb/askubuntudupquestions-reranking  \n",
       "65                           mteb/mind_small  \n",
       "66                    mteb/scidocs-reranking  \n",
       "67  mteb/stackoverflowdupquestions-reranking  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df[\"Type\"] == \"Reranking\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
