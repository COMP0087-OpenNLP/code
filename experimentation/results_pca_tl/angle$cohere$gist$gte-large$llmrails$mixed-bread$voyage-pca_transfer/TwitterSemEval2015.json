{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8655897955534363,
      "accuracy_threshold": 0.8596384525299072,
      "ap": 0.7621664553207876,
      "f1": 0.6982367758186397,
      "f1_threshold": 0.8409742712974548,
      "precision": 0.6679518072289157,
      "recall": 0.7313984168865435
    },
    "dot": {
      "accuracy": 0.8220182392561245,
      "accuracy_threshold": 0.24574050307273865,
      "ap": 0.6095194469392304,
      "f1": 0.5810875842155918,
      "f1_threshold": 0.22704118490219116,
      "precision": 0.5340557275541795,
      "recall": 0.637203166226913
    },
    "euclidean": {
      "accuracy": 0.8663646659116648,
      "accuracy_threshold": 0.2691779136657715,
      "ap": 0.7644253752858615,
      "f1": 0.7002772876228888,
      "f1_threshold": 0.2928459048271179,
      "precision": 0.6703667953667953,
      "recall": 0.732981530343008
    },
    "evaluation_time": 3.49,
    "manhattan": {
      "accuracy": 0.866543482148179,
      "accuracy_threshold": 6.950408458709717,
      "ap": 0.7643176951484179,
      "f1": 0.698974358974359,
      "f1_threshold": 7.42543888092041,
      "precision": 0.6798004987531172,
      "recall": 0.7192612137203166
    },
    "max": {
      "accuracy": 0.866543482148179,
      "ap": 0.7644253752858615,
      "f1": 0.7002772876228888
    }
  }
}