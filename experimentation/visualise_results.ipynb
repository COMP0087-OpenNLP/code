{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualise the results of different models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import itertools\n",
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASK_LIST_CLASSIFICATION = [\n",
    "    \"AmazonCounterfactualClassification\",\n",
    "    \"AmazonPolarityClassification\",\n",
    "    \"AmazonReviewsClassification\",\n",
    "    \"Banking77Classification\",\n",
    "    \"EmotionClassification\",\n",
    "    \"ImdbClassification\",\n",
    "    \"MassiveIntentClassification\",\n",
    "    \"MassiveScenarioClassification\",\n",
    "    \"MTOPDomainClassification\",\n",
    "    \"MTOPIntentClassification\",\n",
    "    \"ToxicConversationsClassification\",\n",
    "    \"TweetSentimentExtractionClassification\",\n",
    "]\n",
    "\n",
    "TASK_LIST_CLUSTERING = [\n",
    "    \"ArxivClusteringP2P\",\n",
    "    \"ArxivClusteringS2S\",\n",
    "    \"BiorxivClusteringP2P\",\n",
    "    \"BiorxivClusteringS2S\",\n",
    "    \"MedrxivClusteringP2P\",\n",
    "    \"MedrxivClusteringS2S\",\n",
    "    \"RedditClustering\",\n",
    "    \"RedditClusteringP2P\",\n",
    "    \"StackExchangeClustering\",\n",
    "    \"StackExchangeClusteringP2P\",\n",
    "    \"TwentyNewsgroupsClustering\",\n",
    "]\n",
    "\n",
    "TASK_LIST_PAIR_CLASSIFICATION = [\n",
    "    \"SprintDuplicateQuestions\",\n",
    "    \"TwitterSemEval2015\",\n",
    "    \"TwitterURLCorpus\",\n",
    "]\n",
    "\n",
    "TASK_LIST_RERANKING = [\n",
    "    \"AskUbuntuDupQuestions\",\n",
    "    \"MindSmallReranking\",\n",
    "    \"SciDocsRR\",\n",
    "    \"StackOverflowDupQuestions\",\n",
    "]\n",
    "\n",
    "TASK_LIST_RETRIEVAL = [\n",
    "    \"ArguAna\",\n",
    "    \"ClimateFEVER\",\n",
    "    \"CQADupstackAndroidRetrieval\",\n",
    "    \"CQADupstackEnglishRetrieval\",\n",
    "    \"CQADupstackGamingRetrieval\",\n",
    "    \"CQADupstackGisRetrieval\",\n",
    "    \"CQADupstackMathematicaRetrieval\",\n",
    "    \"CQADupstackPhysicsRetrieval\",\n",
    "    \"CQADupstackProgrammersRetrieval\",\n",
    "    \"CQADupstackStatsRetrieval\",\n",
    "    \"CQADupstackTexRetrieval\",\n",
    "    \"CQADupstackUnixRetrieval\",\n",
    "    \"CQADupstackWebmastersRetrieval\",\n",
    "    \"CQADupstackWordpressRetrieval\",\n",
    "    \"DBPedia\",\n",
    "    \"FEVER\",\n",
    "    \"FiQA2018\",\n",
    "    \"HotpotQA\",\n",
    "    \"MSMARCO\",\n",
    "    \"NFCorpus\",\n",
    "    \"NQ\",\n",
    "    \"QuoraRetrieval\",\n",
    "    \"SCIDOCS\",\n",
    "    \"SciFact\",\n",
    "    \"Touche2020\",\n",
    "    \"TRECCOVID\",\n",
    "]\n",
    "\n",
    "TASK_LIST_STS = [\n",
    "    \"BIOSSES\",\n",
    "    \"SICK-R\",\n",
    "    \"STS12\",\n",
    "    \"STS13\",\n",
    "    \"STS14\",\n",
    "    \"STS15\",\n",
    "    \"STS16\",\n",
    "    \"STS17\",\n",
    "    \"STS22\",\n",
    "    \"STSBenchmark\",\n",
    "    \"SummEval\",\n",
    "]\n",
    "\n",
    "TASK_LIST = (\n",
    "    TASK_LIST_CLASSIFICATION\n",
    "    + TASK_LIST_CLUSTERING\n",
    "    + TASK_LIST_PAIR_CLASSIFICATION\n",
    "    + TASK_LIST_RERANKING\n",
    "    + TASK_LIST_RETRIEVAL\n",
    "    + TASK_LIST_STS\n",
    ")\n",
    "\n",
    "MODEL_LIST = {\n",
    "    \"embed-english-v3.0\": \"Cohere\",\n",
    "    \"angle\": \"AnglE\",\n",
    "    \"text-embedding-3-large\": \"OpenAI\",\n",
    "    \"voyage-2\": \"Voyage\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TO-DOs\n",
    "- optional parameters to control which tasks/models are printed\n",
    "- cosine similarity against average value\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make pandas dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "directory = 'results'\n",
    "\n",
    "# Get all the .csv file paths in the directory\n",
    "file_paths = glob.glob(directory + '/*.csv')\n",
    "\n",
    "dataframes = [pd.read_csv(file_path) for file_path in file_paths]\n",
    "df = pd.concat(dataframes, ignore_index=True)\n",
    "df.dropna(subset=['value'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['stack_size'] = df['model'].apply(lambda x: x.count('$') + 1)\n",
    "df = df[df['model'] != 'basic_huggingface']\n",
    "df = df.sort_values(by='stack_size')\n",
    "df['value'] = df['value'].apply(lambda x: round(x, 5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tasks that were tested are:\n",
      "['STS' 'Classification' 'Clustering' 'PairClassification' 'Reranking'\n",
      " 'Retrieval']\n",
      "The datasets that were tested are:\n",
      "['STSBenchmark' 'MTOPIntentClassification'\n",
      " 'ToxicConversationsClassification'\n",
      " 'TweetSentimentExtractionClassification' 'ArxivClusteringS2S'\n",
      " 'BiorxivClusteringS2S' 'MedrxivClusteringP2P' 'MedrxivClusteringS2S'\n",
      " 'RedditClustering' 'StackExchangeClustering' 'StackExchangeClusteringP2P'\n",
      " 'TwentyNewsgroupsClustering' 'SprintDuplicateQuestions' 'STS22'\n",
      " 'TwitterSemEval2015' 'AskUbuntuDupQuestions' 'SciDocsRR'\n",
      " 'StackOverflowDupQuestions' 'ArguAna' 'FiQA2018' 'NFCorpus' 'SCIDOCS'\n",
      " 'MTOPDomainClassification' 'SciFact' 'MassiveScenarioClassification'\n",
      " 'ImdbClassification' 'MassiveIntentClassification'\n",
      " 'EmotionClassification' 'Banking77Classification'\n",
      " 'AmazonReviewsClassification' 'AmazonCounterfactualClassification'\n",
      " 'BIOSSES' 'STS12' 'SICK-R' 'STS13' 'STS14' 'STS15' 'STS16' 'STS17']\n"
     ]
    }
   ],
   "source": [
    "print(\"The tasks that were tested are:\")\n",
    "tasks_list = df['task'].unique()\n",
    "print(tasks_list)\n",
    "\n",
    "# Remove the STS average value (to reduce confusion)\n",
    "df = df[df['dataset'] != 'average']\n",
    "\n",
    "print(\"The datasets that were tested are:\")\n",
    "datasets_list = df['dataset'].unique()\n",
    "print(datasets_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The llms that were tested are:\n",
      "['angle' 'llmrails' 'cohere' 'voyage' 'gist' 'angle$cohere'\n",
      " 'cohere$voyage' 'angle$llmrails' 'llmrails$voyage' 'gist$voyage'\n",
      " 'angle$voyage' 'cohere$llmrails' 'gist$llmrails' 'angle$gist'\n",
      " 'cohere$gist' 'angle$cohere$voyage' 'cohere$gist$llmrails'\n",
      " 'angle$cohere$llmrails' 'gist$llmrails$voyage' 'cohere$gist$voyage'\n",
      " 'angle$gist$voyage' 'angle$gist$llmrails' 'angle$cohere$gist'\n",
      " 'cohere$llmrails$voyage' 'angle$llmrails$voyage']\n"
     ]
    }
   ],
   "source": [
    "print(\"The llms that were tested are:\")\n",
    "model_list_raw = df['model'].unique()\n",
    "print(model_list_raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dataset</th>\n",
       "      <th>Count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AmazonCounterfactualClassification</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>STS12</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>STS13</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>STS14</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>STS15</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>STS16</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>STS17</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>STS22</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SICK-R</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>STSBenchmark</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SciFact</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SprintDuplicateQuestions</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>StackExchangeClustering</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>StackExchangeClusteringP2P</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>StackOverflowDupQuestions</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>ToxicConversationsClassification</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>TweetSentimentExtractionClassification</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SciDocsRR</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>TwentyNewsgroupsClustering</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SCIDOCS</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>NFCorpus</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AmazonReviewsClassification</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ArguAna</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ArxivClusteringS2S</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AskUbuntuDupQuestions</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BIOSSES</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Banking77Classification</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BiorxivClusteringS2S</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>RedditClustering</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>EmotionClassification</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ImdbClassification</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MTOPDomainClassification</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>MTOPIntentClassification</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>MassiveIntentClassification</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>MassiveScenarioClassification</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>MedrxivClusteringP2P</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>MedrxivClusteringS2S</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FiQA2018</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>TwitterSemEval2015</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   dataset  Count\n",
       "0       AmazonCounterfactualClassification     25\n",
       "21                                   STS12     25\n",
       "22                                   STS13     25\n",
       "23                                   STS14     25\n",
       "24                                   STS15     25\n",
       "25                                   STS16     25\n",
       "26                                   STS17     25\n",
       "27                                   STS22     25\n",
       "20                                  SICK-R     25\n",
       "28                            STSBenchmark     25\n",
       "30                                 SciFact     25\n",
       "31                SprintDuplicateQuestions     25\n",
       "32                 StackExchangeClustering     25\n",
       "33              StackExchangeClusteringP2P     25\n",
       "34               StackOverflowDupQuestions     25\n",
       "35        ToxicConversationsClassification     25\n",
       "36  TweetSentimentExtractionClassification     25\n",
       "29                               SciDocsRR     25\n",
       "37              TwentyNewsgroupsClustering     25\n",
       "19                                 SCIDOCS     25\n",
       "17                                NFCorpus     25\n",
       "1              AmazonReviewsClassification     25\n",
       "2                                  ArguAna     25\n",
       "3                       ArxivClusteringS2S     25\n",
       "4                    AskUbuntuDupQuestions     25\n",
       "5                                  BIOSSES     25\n",
       "6                  Banking77Classification     25\n",
       "7                     BiorxivClusteringS2S     25\n",
       "18                        RedditClustering     25\n",
       "8                    EmotionClassification     25\n",
       "10                      ImdbClassification     25\n",
       "11                MTOPDomainClassification     25\n",
       "12                MTOPIntentClassification     25\n",
       "13             MassiveIntentClassification     25\n",
       "14           MassiveScenarioClassification     25\n",
       "15                    MedrxivClusteringP2P     25\n",
       "16                    MedrxivClusteringS2S     25\n",
       "9                                 FiQA2018     25\n",
       "38                      TwitterSemEval2015     25"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make sure all datasets are tested\n",
    "count_by_category = df.groupby('dataset').size().reset_index(name='Count')\n",
    "count_by_category = count_by_category.sort_values(by='Count', ascending=True)\n",
    "assert count_by_category['Count'].nunique() == 1, \"Not all datasets are tested\"\n",
    "count_by_category\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_groups_of_models(df):\n",
    "    all__models = df['model'].unique().tolist()\n",
    "    concat_models = []\n",
    "    for model in all__models:\n",
    "        if '$' in model:\n",
    "            concat_models.append(model)\n",
    "\n",
    "    model_lists = []\n",
    "    for model in concat_models:\n",
    "        lst = model.split('$')\n",
    "        lst.append(model)\n",
    "        model_lists.append(lst)\n",
    "\n",
    "    df_list = []\n",
    "    for model_list in model_lists:\n",
    "        df_list.append(df[df['model'].isin(model_list)])\n",
    "\n",
    "    return df_list\n",
    "\n",
    "df_list = generate_groups_of_models(df)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from prettytable import PrettyTable\n",
    "def generate_table(scores, improvement_str):\n",
    "    table = PrettyTable([\"Number of models\", \"Models\", improvement_str])\n",
    "\n",
    "    for concat_score_list in scores:\n",
    "        concat_score = 0\n",
    "        other_scores = 0\n",
    "        llm_count = 0\n",
    "        concat_model = \"\"\n",
    "\n",
    "        for model, score in concat_score_list:\n",
    "            if '+' in model:\n",
    "                concat_model = model\n",
    "                concat_score += score\n",
    "            else:\n",
    "                other_scores += score\n",
    "                llm_count += 1\n",
    "        \n",
    "        if concat_model==\"\":\n",
    "            continue\n",
    "\n",
    "        other_scores /= llm_count\n",
    "        improvement = (concat_score - other_scores)*100\n",
    "\n",
    "        table.add_row([concat_model.count('+')+1, concat_model, improvement])\n",
    "\n",
    "    table.reversesort = True\n",
    "    table.sortby = improvement_str\n",
    "    print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot bar graphs per group of concat-model and its base models for every task\n",
    "\n",
    "The cell below generates separate bar graphs of the average values of a concat-model and its base models for every MTEB task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_task_averages(df, tasks_to_not_show=[]):\n",
    "    average_values = df.groupby(['model', 'task'])['value'].mean().reset_index()\n",
    "\n",
    "    grouped_by_task = average_values.groupby('task').agg({\n",
    "        'model': list,\n",
    "        'value': list\n",
    "    }).reset_index()\n",
    "    task_scores = {}\n",
    "\n",
    "    for i, row in grouped_by_task.iterrows():\n",
    "        model_list = row['model']\n",
    "        value_list = row['value']\n",
    "        task = row['task']\n",
    "\n",
    "        if task in tasks_to_not_show:\n",
    "            continue\n",
    "\n",
    "        combined = sorted(zip(model_list, value_list), reverse=True, key=lambda x: x[1])\n",
    "        model_list, value_list = zip(*combined)\n",
    "\n",
    "        colours = ['gold' if '$' in model else 'skyblue' for model in model_list]\n",
    "        group_spacing = 0.05\n",
    "        bar_height = 0.3\n",
    "        y_pos = 0\n",
    "        y_positions = []\n",
    "\n",
    "        model_list = list(model_list)\n",
    "        for i, model in enumerate(model_list):\n",
    "            y_positions.append(y_pos)\n",
    "            y_pos += (bar_height + group_spacing)\n",
    "\n",
    "            if '$' in model:\n",
    "                lst = model.split('$')\n",
    "                lst = [MODEL_LIST.get(l, l) for l in lst]\n",
    "                model_list[i] = ' + '.join(lst)\n",
    "            else:\n",
    "                model_list[i] = MODEL_LIST.get(model, model)\n",
    "\n",
    "        plt.figure(figsize=(8, 3))\n",
    "        bars = plt.barh(y_positions, value_list, color=colours, height=bar_height)\n",
    "        plt.ylabel('Model')\n",
    "        plt.xlabel('Value')\n",
    "        plt.title(f'Average values across {\", \".join(model_list)} models for {task} task')\n",
    "        plt.yticks(np.arange(len(model_list)) * (bar_height + group_spacing), model_list)\n",
    "\n",
    "        for bar in bars:\n",
    "            plt.text(bar.get_width(), bar.get_y() + bar.get_height()/2, round(bar.get_width(), 3), va='center', ha='left')\n",
    "\n",
    "        plt.xlim(0, max(value_list) * 1.1)\n",
    "        plt.show()\n",
    "\n",
    "        task_scores[task] = list(zip(model_list, value_list))\n",
    "        \n",
    "    return task_scores\n",
    "        \n",
    "scores = []\n",
    "for dataframe in df_list:\n",
    "    model_scores_per_task = plot_task_averages(dataframe)\n",
    "    scores.append(model_scores_per_task)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement of concatenated models per task\n",
    "\n",
    "The cell below prints tables of the improvement of the score of the concatenated model from the average of the scores of the models it is made up by (for each task). Each score of the base model comes from the average of its scores on the subtasks for a task.\n",
    "\n",
    "The tables are ordered to show the concat-models with the best improvement at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------------------+-----------------------------------------------+\n",
      "| Number of models |           Models           | Improvement when concatenated on task STS (%) |\n",
      "+------------------+----------------------------+-----------------------------------------------+\n",
      "|        2         |       AnglE + voyage       |               2.791150000000009               |\n",
      "|        2         |     llmrails + voyage      |               2.6148999999999867              |\n",
      "|        3         |  AnglE + cohere + voyage   |               2.6137333333333346              |\n",
      "|        2         |       gist + voyage        |               2.490300000000012               |\n",
      "|        3         |  gist + llmrails + voyage  |               2.431900000000009               |\n",
      "|        3         | AnglE + llmrails + voyage  |               2.4083000000000188              |\n",
      "|        3         | cohere + llmrails + voyage |               2.115933333333331               |\n",
      "|        3         |   AnglE + gist + voyage    |               2.115199999999995               |\n",
      "|        2         |      cohere + voyage       |               1.9971500000000142              |\n",
      "|        3         |   cohere + gist + voyage   |               1.7967333333333335              |\n",
      "|        3         | AnglE + cohere + llmrails  |               1.2090333333333314              |\n",
      "|        2         |     cohere + llmrails      |               1.1076499999999934              |\n",
      "|        3         |   AnglE + cohere + gist    |               0.9133333333333327              |\n",
      "|        3         |  cohere + gist + llmrails  |               0.815733333333335               |\n",
      "|        2         |       AnglE + cohere       |               0.7926999999999906              |\n",
      "|        2         |       cohere + gist        |               0.7486499999999952              |\n",
      "|        2         |      gist + llmrails       |               0.6643000000000066              |\n",
      "|        3         |  AnglE + gist + llmrails   |               0.6341000000000041              |\n",
      "|        2         |      AnglE + llmrails      |               0.4437499999999983              |\n",
      "|        2         |        AnglE + gist        |              0.26884999999999826              |\n",
      "+------------------+----------------------------+-----------------------------------------------+\n",
      "+------------------+----------------------------+----------------------------------------------------------+\n",
      "| Number of models |           Models           | Improvement when concatenated on task Classification (%) |\n",
      "+------------------+----------------------------+----------------------------------------------------------+\n",
      "|        3         |   cohere + gist + voyage   |                    3.141666666666665                     |\n",
      "|        2         |       gist + voyage        |                    3.1003636363636344                    |\n",
      "|        2         |      cohere + voyage       |                    3.043227272727267                     |\n",
      "|        3         | cohere + llmrails + voyage |                    2.9937272727272535                    |\n",
      "|        3         |  AnglE + cohere + voyage   |                    2.8979090909090788                    |\n",
      "|        2         |     llmrails + voyage      |                    2.876454545454543                     |\n",
      "|        2         |       AnglE + voyage       |                    2.7453181818181793                    |\n",
      "|        3         |  gist + llmrails + voyage  |                    2.563939393939396                     |\n",
      "|        3         |   AnglE + gist + voyage    |                    2.316303030303024                     |\n",
      "|        3         | AnglE + llmrails + voyage  |                    2.0740909090908977                    |\n",
      "|        3         |  cohere + gist + llmrails  |                    1.2876666666666647                    |\n",
      "|        2         |       cohere + gist        |                    1.229681818181827                     |\n",
      "|        2         |       AnglE + cohere       |                    1.1850909090908912                    |\n",
      "|        2         |     cohere + llmrails      |                    1.101136363636357                     |\n",
      "|        3         |   AnglE + cohere + gist    |                    1.0184848484848463                    |\n",
      "|        3         | AnglE + cohere + llmrails  |                    0.8844545454545383                    |\n",
      "|        2         |      gist + llmrails       |                   0.37636363636364134                    |\n",
      "|        2         |        AnglE + gist        |                    0.3495909090909133                    |\n",
      "|        3         |  AnglE + gist + llmrails   |                   0.19212121212122124                    |\n",
      "|        2         |      AnglE + llmrails      |                   0.05450000000000177                    |\n",
      "+------------------+----------------------------+----------------------------------------------------------+\n",
      "+------------------+----------------------------+------------------------------------------------------+\n",
      "| Number of models |           Models           | Improvement when concatenated on task Clustering (%) |\n",
      "+------------------+----------------------------+------------------------------------------------------+\n",
      "|        3         |   cohere + gist + voyage   |                  1.885916666666665                   |\n",
      "|        3         | cohere + llmrails + voyage |                  1.8509583333333357                  |\n",
      "|        2         |      cohere + voyage       |                  1.5949374999999988                  |\n",
      "|        2         |       gist + voyage        |                  1.5641874999999972                  |\n",
      "|        3         |  AnglE + cohere + voyage   |                  1.4278749999999951                  |\n",
      "|        3         |  cohere + gist + llmrails  |                  1.4212500000000017                  |\n",
      "|        3         |  gist + llmrails + voyage  |                  1.419374999999995                   |\n",
      "|        2         |       AnglE + voyage       |                  1.3960000000000028                  |\n",
      "|        3         | AnglE + llmrails + voyage  |                  1.3454583333333325                  |\n",
      "|        2         |     llmrails + voyage      |                  1.2727499999999947                  |\n",
      "|        3         |   AnglE + gist + voyage    |                  1.0921666666666663                  |\n",
      "|        2         |     cohere + llmrails      |                  1.0550625000000036                  |\n",
      "|        2         |       cohere + gist        |                  1.0266250000000032                  |\n",
      "|        3         | AnglE + cohere + llmrails  |                  0.9722083333333298                  |\n",
      "|        3         |   AnglE + cohere + gist    |                  0.8120416666666685                  |\n",
      "|        2         |       AnglE + cohere       |                  0.7326874999999955                  |\n",
      "|        2         |      gist + llmrails       |                 0.38381250000000255                  |\n",
      "|        3         |  AnglE + gist + llmrails   |                 0.21862500000000007                  |\n",
      "|        2         |      AnglE + llmrails      |                 0.07900000000000129                  |\n",
      "|        2         |        AnglE + gist        |                0.0026874999999981775                 |\n",
      "+------------------+----------------------------+------------------------------------------------------+\n",
      "+------------------+----------------------------+--------------------------------------------------------------+\n",
      "| Number of models |           Models           | Improvement when concatenated on task PairClassification (%) |\n",
      "+------------------+----------------------------+--------------------------------------------------------------+\n",
      "|        2         |     llmrails + voyage      |                      3.2059999999999977                      |\n",
      "|        2         |       AnglE + voyage       |                      3.0690000000000106                      |\n",
      "|        3         |  AnglE + cohere + voyage   |                      3.0465000000000075                      |\n",
      "|        2         |       gist + voyage        |                      2.772999999999992                       |\n",
      "|        2         |      cohere + voyage       |                      2.585499999999996                       |\n",
      "|        3         |   AnglE + gist + voyage    |                      2.4758333333333438                      |\n",
      "|        3         | AnglE + llmrails + voyage  |                      2.443166666666674                       |\n",
      "|        3         |  gist + llmrails + voyage  |                      2.3223333333333263                      |\n",
      "|        3         | cohere + llmrails + voyage |                      2.2934999999999928                      |\n",
      "|        3         |   cohere + gist + voyage   |                      2.231666666666665                       |\n",
      "|        3         |   AnglE + cohere + gist    |                      1.0424999999999907                      |\n",
      "|        3         | AnglE + cohere + llmrails  |                      0.9878333333333433                      |\n",
      "|        2         |     cohere + llmrails      |                      0.8965000000000112                      |\n",
      "|        2         |       AnglE + cohere       |                      0.8335000000000092                      |\n",
      "|        2         |       cohere + gist        |                      0.7624999999999993                      |\n",
      "|        3         |  cohere + gist + llmrails  |                      0.5469999999999975                      |\n",
      "|        2         |      gist + llmrails       |                     0.32849999999999824                      |\n",
      "|        3         |  AnglE + gist + llmrails   |                      0.2986666666666582                      |\n",
      "|        2         |        AnglE + gist        |                      0.2174999999999927                      |\n",
      "|        2         |      AnglE + llmrails      |                     0.16999999999999238                      |\n",
      "+------------------+----------------------------+--------------------------------------------------------------+\n",
      "+------------------+----------------------------+-----------------------------------------------------+\n",
      "| Number of models |           Models           | Improvement when concatenated on task Reranking (%) |\n",
      "+------------------+----------------------------+-----------------------------------------------------+\n",
      "|        3         |  AnglE + cohere + voyage   |                  2.064666666666659                  |\n",
      "|        2         |       AnglE + voyage       |                  1.9326666666666603                 |\n",
      "|        2         |     llmrails + voyage      |                  1.8215000000000092                 |\n",
      "|        2         |       gist + voyage        |                  1.7498333333333282                 |\n",
      "|        3         |  gist + llmrails + voyage  |                  1.5722222222222415                 |\n",
      "|        3         | AnglE + llmrails + voyage  |                  1.5418888888888982                 |\n",
      "|        3         |   AnglE + gist + voyage    |                  1.535333333333322                  |\n",
      "|        2         |      cohere + voyage       |                  1.3946666666666663                 |\n",
      "|        3         | cohere + llmrails + voyage |                  1.1378888888888938                 |\n",
      "|        3         |   cohere + gist + voyage   |                  1.097999999999999                  |\n",
      "|        3         | AnglE + cohere + llmrails  |                  0.8982222222222114                 |\n",
      "|        3         |   AnglE + cohere + gist    |                  0.8823333333333405                 |\n",
      "|        2         |       cohere + gist        |                  0.6748333333333356                 |\n",
      "|        2         |     cohere + llmrails      |                  0.6331666666666735                 |\n",
      "|        2         |       AnglE + cohere       |                  0.5800000000000027                 |\n",
      "|        2         |        AnglE + gist        |                 0.20883333333332477                 |\n",
      "|        3         |  cohere + gist + llmrails  |                  0.1988888888888929                 |\n",
      "|        3         |  AnglE + gist + llmrails   |                 0.17455555555554447                 |\n",
      "|        2         |      gist + llmrails       |                 0.13066666666666782                 |\n",
      "|        2         |      AnglE + llmrails      |                  0.0731666666666686                 |\n",
      "+------------------+----------------------------+-----------------------------------------------------+\n",
      "+------------------+----------------------------+-----------------------------------------------------+\n",
      "| Number of models |           Models           | Improvement when concatenated on task Retrieval (%) |\n",
      "+------------------+----------------------------+-----------------------------------------------------+\n",
      "|        3         |  AnglE + cohere + voyage   |                  4.690733333333336                  |\n",
      "|        2         |     llmrails + voyage      |                  4.297899999999993                  |\n",
      "|        2         |       AnglE + voyage       |                  4.152499999999998                  |\n",
      "|        2         |       gist + voyage        |                  3.580999999999995                  |\n",
      "|        3         |  gist + llmrails + voyage  |                  3.3763333333333367                 |\n",
      "|        3         | AnglE + cohere + llmrails  |                  3.1610666666666623                 |\n",
      "|        3         |   AnglE + gist + voyage    |                  3.154733333333332                  |\n",
      "|        3         | AnglE + llmrails + voyage  |                  3.1396666666666686                 |\n",
      "|        2         |     cohere + llmrails      |                  3.0784000000000034                 |\n",
      "|        3         |   AnglE + cohere + gist    |                  2.8321333333333367                 |\n",
      "|        3         | cohere + llmrails + voyage |                  2.8255333333333246                 |\n",
      "|        2         |       AnglE + cohere       |                  2.6171999999999973                 |\n",
      "|        3         |   cohere + gist + voyage   |                  2.319599999999994                  |\n",
      "|        2         |      cohere + voyage       |                  2.291899999999991                  |\n",
      "|        2         |       cohere + gist        |                  2.2546999999999984                 |\n",
      "|        3         |  cohere + gist + llmrails  |                  1.8453333333333322                 |\n",
      "|        2         |      gist + llmrails       |                  1.2530999999999959                 |\n",
      "|        3         |  AnglE + gist + llmrails   |                  1.036066666666674                  |\n",
      "|        2         |        AnglE + gist        |                  0.5223000000000033                 |\n",
      "|        2         |      AnglE + llmrails      |                  0.3778000000000059                 |\n",
      "+------------------+----------------------------+-----------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "all_task_scores = {i: [] for i in tasks_list}\n",
    "for d in scores:\n",
    "    for k, v in d.items():\n",
    "        all_task_scores[k].append(v)\n",
    "        \n",
    "for task, s in all_task_scores.items():\n",
    "    generate_table(s, f\"Improvement when concatenated on task {task} (%)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot bar graphs per group of concat-model and its base models\n",
    "\n",
    "The cell below generates bar graphs of the average values of a concat-model and its base models over all MTEB tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_all_models(df):\n",
    "    average_values = df.groupby(['model'])['value'].mean().reset_index()\n",
    "\n",
    "    model_list = average_values['model'].tolist()\n",
    "    value_list = average_values['value'].tolist()\n",
    "\n",
    "    combined = sorted(zip(model_list, value_list), key=lambda x: x[1])\n",
    "    model_list, value_list = zip(*combined)\n",
    "\n",
    "    combined_model_list = []\n",
    "    colours = []\n",
    "\n",
    "    group_spacing = 0.05\n",
    "    bar_height = 0.3\n",
    "    y_pos = 0\n",
    "    y_positions = []\n",
    "\n",
    "    for model in model_list:\n",
    "        # define color based on if it's concat model or not\n",
    "        colours.append('gold' if '$' in model else 'skyblue')\n",
    "        y_positions.append(y_pos)\n",
    "        y_pos += (bar_height + group_spacing)\n",
    "\n",
    "        # replace model code with full name\n",
    "        if '$' in model:\n",
    "            lst = model.split('$')\n",
    "            lst = [MODEL_LIST.get(l, l) for l in lst]\n",
    "            combined_model_list.append(' + '.join(lst))\n",
    "        else:\n",
    "            combined_model_list.append(MODEL_LIST.get(model, model))\n",
    "        \n",
    "    plt.figure(figsize=(8, 3))\n",
    "    bars = plt.barh(y_positions, value_list, color=colours, height=bar_height)\n",
    "    plt.xlabel('Value')\n",
    "    plt.ylabel('Model')\n",
    "    plt.title(f'Average values of models across all tasks')\n",
    "    plt.yticks(y_positions, combined_model_list)\n",
    "    \n",
    "    for bar in bars:\n",
    "        plt.text(bar.get_width(), bar.get_y() + bar.get_height()/2, round(bar.get_width(), 3), va='center', ha='left')\n",
    "\n",
    "    plt.xlim(0, max(value_list) * 1.1)\n",
    "    plt.show()\n",
    "\n",
    "    task_scores = list(zip(combined_model_list, value_list))\n",
    "\n",
    "    return task_scores\n",
    "\n",
    "\"\"\"The below code lets you plot all models on the same bar graph (not recommended as there are too many models)\"\"\"\n",
    "# def plot_all_models(df_list):\n",
    "#     scores = []\n",
    "#     y_pos = 0\n",
    "#     y_positions = []\n",
    "#     all_model_names = []\n",
    "#     all_values = []\n",
    "#     all_colours = []\n",
    "\n",
    "#     for df in df_list:\n",
    "#         average_values = df.groupby(['model'])['value'].mean().reset_index()\n",
    "\n",
    "#         model_list = average_values['model'].tolist()\n",
    "#         value_list = average_values['value'].tolist()\n",
    "\n",
    "#         combined = sorted(zip(model_list, value_list), key=lambda x: x[1])\n",
    "#         model_list, value_list = zip(*combined)\n",
    "\n",
    "#         combined_model_list = []\n",
    "#         colours = []\n",
    "\n",
    "#         group_spacing = 0.05\n",
    "#         bar_height = 0.3\n",
    "\n",
    "#         for model in model_list:\n",
    "#             # define color based on if it's concat model or not\n",
    "#             colours.append('gold' if '$' in model else 'skyblue')\n",
    "#             y_positions.append(y_pos)\n",
    "#             y_pos += (bar_height + group_spacing)\n",
    "\n",
    "#             # replace model code with full name\n",
    "#             if '$' in model:\n",
    "#                 lst = model.split('$')\n",
    "#                 lst = [MODEL_LIST.get(l, l) for l in lst]\n",
    "#                 combined_model_list.append(' + '.join(lst))\n",
    "#             else:\n",
    "#                 combined_model_list.append(MODEL_LIST.get(model, model))\n",
    "        \n",
    "#         all_model_names.extend(combined_model_list)\n",
    "#         all_values.extend(value_list)\n",
    "#         all_colours.extend(colours)\n",
    "\n",
    "#         task_scores = list(zip(combined_model_list, value_list))\n",
    "#         y_pos += 0.5\n",
    "#         scores.append(task_scores)\n",
    "    \n",
    "#     plt.figure(figsize=(10, 50))\n",
    "#     bars = plt.barh(y_positions, all_values, color=all_colours, height=bar_height)\n",
    "#     plt.xlabel('Value')\n",
    "#     plt.ylabel('Model')\n",
    "#     plt.title(f'Average values of models across all tasks')\n",
    "#     plt.yticks(y_positions, all_model_names)\n",
    "    \n",
    "#     for bar in bars:\n",
    "#         plt.text(bar.get_width(), bar.get_y() + bar.get_height()/2, round(bar.get_width(), 3), va='center', ha='left')\n",
    "\n",
    "#     plt.xlim(0, max(all_values) * 1.1)\n",
    "#     plt.show()\n",
    "\n",
    "#     return scores\n",
    "\n",
    "\n",
    "scores = []\n",
    "for dataframe in df_list:\n",
    "    score = plot_all_models(dataframe)\n",
    "    scores.append(score)\n",
    "\n",
    "# scores = plot_all_models(df_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Improvement of concatenated models\n",
    "\n",
    "The cell below prints a table of the improvement of the score of the concatenated model from the average of the scores of the models it is made up by. Each score of the base model comes from the average of its scores on the MTEB tasks.\n",
    "\n",
    "The table is ordered to show the concat-models with the best improvement at the top."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------------------------+-------------------------------------------+\n",
      "| Number of models |           Models           | Average improvement when concatenated (%) |\n",
      "+------------------+----------------------------+-------------------------------------------+\n",
      "|        3         |  AnglE + cohere + voyage   |             2.6968717948717913            |\n",
      "|        2         |       AnglE + voyage       |             2.6147820512820497            |\n",
      "|        2         |     llmrails + voyage      |             2.598410256410244             |\n",
      "|        2         |       gist + voyage        |             2.5697692307692366            |\n",
      "|        3         | cohere + llmrails + voyage |             2.334008547008548             |\n",
      "|        3         |  gist + llmrails + voyage  |             2.3107777777777727            |\n",
      "|        2         |      cohere + voyage       |             2.2313076923076935            |\n",
      "|        3         |   cohere + gist + voyage   |             2.2299572649572608            |\n",
      "|        3         | AnglE + llmrails + voyage  |             2.1249230769230687            |\n",
      "|        3         |   AnglE + gist + voyage    |             2.0692307692307677            |\n",
      "|        2         |     cohere + llmrails      |             1.3003589743589727            |\n",
      "|        3         | AnglE + cohere + llmrails  |             1.2839145299145316            |\n",
      "|        3         |   AnglE + cohere + gist    |             1.172452991452988             |\n",
      "|        3         |  cohere + gist + llmrails  |             1.1438205128205259            |\n",
      "|        2         |       cohere + gist        |             1.1294615384615403            |\n",
      "|        2         |       AnglE + cohere       |             1.110705128205125             |\n",
      "|        2         |      gist + llmrails       |             0.5427692307692245            |\n",
      "|        3         |  AnglE + gist + llmrails   |             0.4231965811965721            |\n",
      "|        2         |        AnglE + gist        |             0.2622692307692409            |\n",
      "|        2         |      AnglE + llmrails      |            0.20814102564101766            |\n",
      "+------------------+----------------------------+-------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "generate_table(scores, \"Average improvement when concatenated (%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Internal MTEB leaderboard\n",
    "\n",
    "The cell below prints a table of scores per task for each base-model and concat-model. The table is in order of highest to lowest average scores for all the MTEB tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------------------+-----------+---------------+----------------+------------+--------------------+-----------+-----------+-------+\n",
      "|         Model name         | Dimension | Average value | Classification | Clustering | PairClassification | Reranking | Retrieval |  STS  |\n",
      "+----------------------------+-----------+---------------+----------------+------------+--------------------+-----------+-----------+-------+\n",
      "|   AnglE + cohere + gist    |    3072   |     0.6848    |     0.746      |   0.463    |       0.878        |   0.691   |   0.497   | 0.849 |\n",
      "| AnglE + cohere + llmrails  |    3072   |     0.6832    |     0.743      |   0.459    |       0.881        |   0.692   |   0.496   | 0.848 |\n",
      "|  cohere + gist + llmrails  |    3072   |    0.68296    |     0.751      |   0.465    |       0.874        |   0.685   |   0.483   | 0.844 |\n",
      "|       cohere + gist        |    2048   |    0.68294    |     0.751      |   0.466    |       0.871        |   0.685   |   0.481   | 0.844 |\n",
      "|  AnglE + cohere + voyage   |    3072   |    0.68294    |     0.741      |   0.462    |       0.877        |    0.69   |   0.497   | 0.848 |\n",
      "|  gist + llmrails + voyage  |    3072   |     0.6827    |     0.739      |   0.458    |       0.876        |   0.695   |   0.501   | 0.849 |\n",
      "|   AnglE + gist + voyage    |    3072   |    0.68184    |     0.735      |   0.458    |       0.876        |   0.693   |   0.503   | 0.849 |\n",
      "|       AnglE + cohere       |    2048   |    0.68102    |     0.746      |   0.462    |       0.874        |   0.683   |   0.484   | 0.844 |\n",
      "|      gist + llmrails       |    2048   |    0.68077    |     0.741      |   0.451    |       0.879        |   0.693   |   0.496   | 0.847 |\n",
      "|     cohere + llmrails      |    2048   |    0.68058    |     0.748      |   0.459    |       0.877        |   0.685   |   0.483   | 0.841 |\n",
      "|        AnglE + gist        |    2048   |    0.68029    |     0.737      |   0.454    |       0.876        |   0.693   |   0.494   | 0.849 |\n",
      "|  AnglE + gist + llmrails   |    3072   |    0.67977    |     0.736      |   0.451    |       0.879        |   0.693   |   0.496   | 0.848 |\n",
      "| AnglE + llmrails + voyage  |    3072   |    0.67968    |     0.731      |   0.456    |       0.879        |   0.694   |   0.498   | 0.848 |\n",
      "|       gist + voyage        |    2048   |    0.67945    |     0.734      |   0.461    |       0.867        |    0.69   |   0.499   | 0.844 |\n",
      "|   cohere + gist + voyage   |    3072   |    0.67943    |     0.746      |   0.468    |       0.867        |   0.681   |   0.474   |  0.84 |\n",
      "|            gist            |    1024   |    0.67941    |     0.739      |   0.455    |       0.871        |   0.691   |    0.49   | 0.846 |\n",
      "|       AnglE + voyage       |    2048   |    0.67816    |     0.725      |   0.458    |       0.873        |   0.691   |   0.503   | 0.847 |\n",
      "| cohere + llmrails + voyage |    3072   |    0.67776    |     0.744      |   0.462    |       0.871        |   0.682   |   0.475   | 0.839 |\n",
      "|           angle            |    1024   |    0.67593    |     0.729      |   0.452    |       0.877        |    0.69   |   0.488   | 0.846 |\n",
      "|      AnglE + llmrails      |    2048   |    0.67568    |     0.733      |   0.447    |       0.881        |   0.692   |   0.487   | 0.844 |\n",
      "|     llmrails + voyage      |    2048   |    0.67567    |      0.73      |    0.45    |       0.876        |   0.691   |   0.499   | 0.839 |\n",
      "|          llmrails          |    1024   |    0.67127    |     0.736      |    0.44    |       0.881        |   0.693   |   0.478   | 0.834 |\n",
      "|      cohere + voyage       |    2048   |    0.66831    |     0.734      |   0.462    |       0.857        |   0.673   |   0.454   |  0.83 |\n",
      "|           cohere           |    1024   |    0.66389    |     0.739      |   0.457    |       0.855        |   0.665   |   0.427   | 0.827 |\n",
      "|           voyage           |    1024   |     0.6281    |     0.667      |   0.435    |       0.807        |   0.653   |   0.435   | 0.793 |\n",
      "+----------------------------+-----------+---------------+----------------+------------+--------------------+-----------+-----------+-------+\n"
     ]
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "\n",
    "def generate_table_all(df):\n",
    "    task_list = sorted(df['task'].unique().tolist())\n",
    "    table = PrettyTable([\"Model name\", \"Dimension\", 'Average value'] + task_list)\n",
    "    models = {}\n",
    "    for _, row in df.iterrows():\n",
    "        model = row['model']\n",
    "        task = row['task']\n",
    "        value = row['value']\n",
    "\n",
    "        if model not in models:\n",
    "            models[model] = {}\n",
    "        \n",
    "        if task not in models[model]:\n",
    "            models[model][task] = [1, value]\n",
    "        else:\n",
    "            models[model][task][0] += 1\n",
    "            models[model][task][1] += value\n",
    "\n",
    "    for model, task_dict in models.items():\n",
    "        model_name = model\n",
    "        if '$' in model:\n",
    "            lst = model.split('$')\n",
    "            lst = [MODEL_LIST.get(l, l) for l in lst]\n",
    "            model_name = ' + '.join(lst)\n",
    "            \n",
    "        row = [model_name, (model.count('$')+1)*1024]\n",
    "        sorted_vals = sorted(task_dict.items(), key=lambda x: x[0])\n",
    "\n",
    "        sums = 0\n",
    "        count = 0\n",
    "        for task, val in sorted_vals:\n",
    "            sums += val[1]\n",
    "            count += val[0]\n",
    "\n",
    "        average = sums/count\n",
    "\n",
    "        i = 0\n",
    "        vals = []\n",
    "        for task_name, val in sorted_vals:\n",
    "            count, value = val\n",
    "            if task_name != task_list[i]:\n",
    "                vals.append(0)\n",
    "                i+= 1\n",
    "            i += 1\n",
    "            vals.append(value/count)\n",
    "\n",
    "        vals = [np.round(val,3) for val in vals]\n",
    "        table.add_row(row + [np.round(average, 5)] + vals)\n",
    "\n",
    "    table.reversesort = True\n",
    "    table.sortby = 'Average value'\n",
    "\n",
    "    return table\n",
    "\n",
    "table = generate_table_all(df)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Performance of similar vs dissimilar embeddings when concatenated\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Generate a list of lists where each sub list contains a concat-model and its base models\"\"\"\n",
    "def generate_model_groups_names(df):\n",
    "    all__models = df['model'].unique().tolist()\n",
    "    concat_models = []\n",
    "    for model in all__models:\n",
    "        if '$' in model:\n",
    "            concat_models.append(model)\n",
    "\n",
    "    model_group_lists = []\n",
    "    for model in concat_models:\n",
    "        lst = model.split('$')\n",
    "        lst.append(model)\n",
    "        model_group_lists.append(lst)\n",
    "\n",
    "    return model_group_lists\n",
    "\n",
    "\"\"\"Get the average cosine similarity between two models for all datapoints in a particular task\"\"\"\n",
    "def get_cosine_similarity_for_task(model_name1, model_name2, task_name):\n",
    "\n",
    "    # get average cosine similarity between two models for all datapoints in all tasks\n",
    "    embeddings1: datasets.Dataset = datasets.load_from_disk(f\"data/{model_name1}/{task_name}\")\n",
    "    embeddings2: datasets.Dataset = datasets.load_from_disk(f\"data/{model_name2}/{task_name}\")\n",
    "\n",
    "    ds = datasets.concatenate_datasets([embeddings1, embeddings2], axis=1)\n",
    "    df = ds.to_pandas()\n",
    "    df.columns = [model_name1, model_name2]\n",
    "    \n",
    "    avg_similarity = 0\n",
    "    count = 0\n",
    "    for _, row in df.iterrows():\n",
    "        count += 1\n",
    "        embedding1 = row[model_name1]\n",
    "        embedding2 = row[model_name2]\n",
    "        similarity = np.dot(embedding1, embedding2) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding2))\n",
    "        avg_similarity += similarity\n",
    "\n",
    "    return avg_similarity/count\n",
    "\n",
    "\"\"\"Get the average cosine similarity between two models for all datapoints over all tasks\"\"\"\n",
    "def get_cosine_similarity(model_name1, model_name2):\n",
    "    # iterate through every task\n",
    "    dfs = []\n",
    "    for task in TASK_LIST:\n",
    "        # get average cosine similarity between two models for all datapoints in all tasks\n",
    "        embeddings1: datasets.Dataset = datasets.load_from_disk(f\"data/{model_name1}/{task}\")\n",
    "        embeddings2: datasets.Dataset = datasets.load_from_disk(f\"data/{model_name2}/{task}\")\n",
    "\n",
    "        ds = datasets.concatenate_datasets([embeddings1, embeddings2], axis=1)\n",
    "        df = ds.to_pandas()\n",
    "        df.columns = [model_name1, model_name2]\n",
    "        dfs.append(df)\n",
    "    \n",
    "    df_combined = pd.concat(dfs)\n",
    "    \n",
    "    avg_similarity = 0\n",
    "    count = 0\n",
    "    for _, row in df_combined.iterrows():\n",
    "        count += 1\n",
    "        embedding1 = row[model_name1]\n",
    "        embedding2 = row[model_name2]\n",
    "        similarity = np.dot(embedding1, embedding2) / (np.linalg.norm(embedding1) * np.linalg.norm(embedding2))\n",
    "        avg_similarity += similarity\n",
    "\n",
    "    return avg_similarity/count\n",
    "\n",
    "\"\"\"Get the average performance/value for each model and return it as a dictionary\"\"\"\n",
    "def get_average_values(df):\n",
    "    concat_model_average_value = {}\n",
    "    average_values = df.groupby(['model'])['value'].mean().reset_index()\n",
    "\n",
    "    model_list = average_values['model'].tolist()\n",
    "    value_list = average_values['value'].tolist()\n",
    "\n",
    "    for model, value in zip(model_list, value_list):\n",
    "        concat_model_average_value[model] = value\n",
    "    \n",
    "    return concat_model_average_value\n",
    "\n",
    "def get_average_values_for_task(df):\n",
    "    concat_model_average_value = {}\n",
    "    average_values_all_tasks = df.groupby(['model', 'task'])['value'].mean().reset_index()['task'==task]\n",
    "    average_values = average_values_all_tasks[average_values_all_tasks['task'] == 'STS']\n",
    "\n",
    "    model_list = average_values['model'].tolist()\n",
    "    value_list = average_values['value'].tolist()\n",
    "\n",
    "    for model, value in zip(model_list, value_list):\n",
    "        concat_model_average_value[model] = value\n",
    "    \n",
    "    return concat_model_average_value\n",
    "\n",
    "model_group_lists = generate_model_groups_names(df)\n",
    "\n",
    "embedding_pair_cosine_similarity = {}\n",
    "for task in TASK_LIST:\n",
    "    concat_model_average_value_task = get_average_values_for_task(df, task)\n",
    "    all_similarities = []\n",
    "    average_value = []\n",
    "\n",
    "    for group in model_group_lists:\n",
    "        concat_model = \"\"\n",
    "        new_group = []\n",
    "        for model in group:\n",
    "            if '$' in model:\n",
    "                concat_model = model\n",
    "            else:\n",
    "                new_group.append(model)\n",
    "\n",
    "        all_pairs = list(itertools.combinations(new_group, 2))\n",
    "        average_cosine_similarity = 0\n",
    "\n",
    "        for pair in all_pairs:\n",
    "            pair = tuple(sorted(pair))\n",
    "            pair_similarity = 0\n",
    "\n",
    "            if pair in embedding_pair_cosine_similarity:\n",
    "                if task in embedding_pair_cosine_similarity[pair]:\n",
    "                    pair_similarity = embedding_pair_cosine_similarity[pair][task]\n",
    "                else:\n",
    "                    pair_similarity = get_cosine_similarity_for_task(pair[0], pair[1], task)\n",
    "                    embedding_pair_cosine_similarity[pair][task] = pair_similarity\n",
    "            else:\n",
    "                pair_similarity = get_cosine_similarity_for_task(pair[0], pair[1], task)\n",
    "                embedding_pair_cosine_similarity[pair] = {task: pair_similarity}\n",
    "            \n",
    "            average_cosine_similarity += pair_similarity\n",
    "        \n",
    "        average_cosine_similarity /= len(all_pairs)\n",
    "        all_similarities.append(average_cosine_similarity)\n",
    "        average_value.append(concat_model_average_value_task[concat_model])\n",
    "\n",
    "    plt.plot(all_similarities, average_value)\n",
    "    plt.xlabel(f'Average cosine similarity of base model pairs in concat-model for task {task}') \n",
    "    plt.ylabel('Average performance of concat-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_similarities = []\n",
    "average_value = []\n",
    "embedding_pair_cosine_similarity = {}\n",
    "\n",
    "model_group_lists = generate_model_groups_names(df)\n",
    "concat_model_average_value = get_average_values(df)\n",
    "\n",
    "for group in model_group_lists:\n",
    "    concat_model = \"\"\n",
    "    new_group = []\n",
    "    for model in group:\n",
    "        if '$' in model:\n",
    "            concat_model = model\n",
    "        else:\n",
    "            new_group.append(model)\n",
    "\n",
    "    all_pairs = list(itertools.combinations(new_group, 2))\n",
    "    average_cosine_similarity = 0\n",
    "\n",
    "    for pair in all_pairs:\n",
    "        pair = tuple(sorted(pair))\n",
    "        pair_similarity = 0\n",
    "\n",
    "        if pair in embedding_pair_cosine_similarity:\n",
    "            pair_similarity = embedding_pair_cosine_similarity[pair]\n",
    "        else:\n",
    "            pair_similarity = get_cosine_similarity(pair[0], pair[1])\n",
    "            embedding_pair_cosine_similarity[pair] = pair_similarity\n",
    "        \n",
    "        average_cosine_similarity += pair_similarity\n",
    "    \n",
    "    average_cosine_similarity /= len(all_pairs)\n",
    "    all_similarities.append(average_cosine_similarity)\n",
    "    average_value.append(concat_model_average_value[concat_model])\n",
    "\n",
    "plt.plot(all_similarities, average_value)\n",
    "plt.xlabel(f'Average cosine similarity of base model pairs in a concat-model over all tasks') \n",
    "plt.ylabel('Average performance of concat-model')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
