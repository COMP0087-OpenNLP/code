Num models to be evaluated: 255
Models to be evaluated: ['angle', 'cohere', 'flag-embedding', 'gist', 'gte-large', 'llmrails', 'mixed-bread', 'voyage', 'angle$cohere', 'angle$flag-embedding', 'angle$gist', 'angle$gte-large', 'angle$llmrails', 'angle$mixed-bread', 'angle$voyage', 'cohere$flag-embedding', 'cohere$gist', 'cohere$gte-large', 'cohere$llmrails', 'cohere$mixed-bread', 'cohere$voyage', 'flag-embedding$gist', 'flag-embedding$gte-large', 'flag-embedding$llmrails', 'flag-embedding$mixed-bread', 'flag-embedding$voyage', 'gist$gte-large', 'gist$llmrails', 'gist$mixed-bread', 'gist$voyage', 'gte-large$llmrails', 'gte-large$mixed-bread', 'gte-large$voyage', 'llmrails$mixed-bread', 'llmrails$voyage', 'mixed-bread$voyage', 'angle$cohere$flag-embedding', 'angle$cohere$gist', 'angle$cohere$gte-large', 'angle$cohere$llmrails', 'angle$cohere$mixed-bread', 'angle$cohere$voyage', 'angle$flag-embedding$gist', 'angle$flag-embedding$gte-large', 'angle$flag-embedding$llmrails', 'angle$flag-embedding$mixed-bread', 'angle$flag-embedding$voyage', 'angle$gist$gte-large', 'angle$gist$llmrails', 'angle$gist$mixed-bread', 'angle$gist$voyage', 'angle$gte-large$llmrails', 'angle$gte-large$mixed-bread', 'angle$gte-large$voyage', 'angle$llmrails$mixed-bread', 'angle$llmrails$voyage', 'angle$mixed-bread$voyage', 'cohere$flag-embedding$gist', 'cohere$flag-embedding$gte-large', 'cohere$flag-embedding$llmrails', 'cohere$flag-embedding$mixed-bread', 'cohere$flag-embedding$voyage', 'cohere$gist$gte-large', 'cohere$gist$llmrails', 'cohere$gist$mixed-bread', 'cohere$gist$voyage', 'cohere$gte-large$llmrails', 'cohere$gte-large$mixed-bread', 'cohere$gte-large$voyage', 'cohere$llmrails$mixed-bread', 'cohere$llmrails$voyage', 'cohere$mixed-bread$voyage', 'flag-embedding$gist$gte-large', 'flag-embedding$gist$llmrails', 'flag-embedding$gist$mixed-bread', 'flag-embedding$gist$voyage', 'flag-embedding$gte-large$llmrails', 'flag-embedding$gte-large$mixed-bread', 'flag-embedding$gte-large$voyage', 'flag-embedding$llmrails$mixed-bread', 'flag-embedding$llmrails$voyage', 'flag-embedding$mixed-bread$voyage', 'gist$gte-large$llmrails', 'gist$gte-large$mixed-bread', 'gist$gte-large$voyage', 'gist$llmrails$mixed-bread', 'gist$llmrails$voyage', 'gist$mixed-bread$voyage', 'gte-large$llmrails$mixed-bread', 'gte-large$llmrails$voyage', 'gte-large$mixed-bread$voyage', 'llmrails$mixed-bread$voyage', 'angle$cohere$flag-embedding$gist', 'angle$cohere$flag-embedding$gte-large', 'angle$cohere$flag-embedding$llmrails', 'angle$cohere$flag-embedding$mixed-bread', 'angle$cohere$flag-embedding$voyage', 'angle$cohere$gist$gte-large', 'angle$cohere$gist$llmrails', 'angle$cohere$gist$mixed-bread', 'angle$cohere$gist$voyage', 'angle$cohere$gte-large$llmrails', 'angle$cohere$gte-large$mixed-bread', 'angle$cohere$gte-large$voyage', 'angle$cohere$llmrails$mixed-bread', 'angle$cohere$llmrails$voyage', 'angle$cohere$mixed-bread$voyage', 'angle$flag-embedding$gist$gte-large', 'angle$flag-embedding$gist$llmrails', 'angle$flag-embedding$gist$mixed-bread', 'angle$flag-embedding$gist$voyage', 'angle$flag-embedding$gte-large$llmrails', 'angle$flag-embedding$gte-large$mixed-bread', 'angle$flag-embedding$gte-large$voyage', 'angle$flag-embedding$llmrails$mixed-bread', 'angle$flag-embedding$llmrails$voyage', 'angle$flag-embedding$mixed-bread$voyage', 'angle$gist$gte-large$llmrails', 'angle$gist$gte-large$mixed-bread', 'angle$gist$gte-large$voyage', 'angle$gist$llmrails$mixed-bread', 'angle$gist$llmrails$voyage', 'angle$gist$mixed-bread$voyage', 'angle$gte-large$llmrails$mixed-bread', 'angle$gte-large$llmrails$voyage', 'angle$gte-large$mixed-bread$voyage', 'angle$llmrails$mixed-bread$voyage', 'cohere$flag-embedding$gist$gte-large', 'cohere$flag-embedding$gist$llmrails', 'cohere$flag-embedding$gist$mixed-bread', 'cohere$flag-embedding$gist$voyage', 'cohere$flag-embedding$gte-large$llmrails', 'cohere$flag-embedding$gte-large$mixed-bread', 'cohere$flag-embedding$gte-large$voyage', 'cohere$flag-embedding$llmrails$mixed-bread', 'cohere$flag-embedding$llmrails$voyage', 'cohere$flag-embedding$mixed-bread$voyage', 'cohere$gist$gte-large$llmrails', 'cohere$gist$gte-large$mixed-bread', 'cohere$gist$gte-large$voyage', 'cohere$gist$llmrails$mixed-bread', 'cohere$gist$llmrails$voyage', 'cohere$gist$mixed-bread$voyage', 'cohere$gte-large$llmrails$mixed-bread', 'cohere$gte-large$llmrails$voyage', 'cohere$gte-large$mixed-bread$voyage', 'cohere$llmrails$mixed-bread$voyage', 'flag-embedding$gist$gte-large$llmrails', 'flag-embedding$gist$gte-large$mixed-bread', 'flag-embedding$gist$gte-large$voyage', 'flag-embedding$gist$llmrails$mixed-bread', 'flag-embedding$gist$llmrails$voyage', 'flag-embedding$gist$mixed-bread$voyage', 'flag-embedding$gte-large$llmrails$mixed-bread', 'flag-embedding$gte-large$llmrails$voyage', 'flag-embedding$gte-large$mixed-bread$voyage', 'flag-embedding$llmrails$mixed-bread$voyage', 'gist$gte-large$llmrails$mixed-bread', 'gist$gte-large$llmrails$voyage', 'gist$gte-large$mixed-bread$voyage', 'gist$llmrails$mixed-bread$voyage', 'gte-large$llmrails$mixed-bread$voyage', 'angle$cohere$flag-embedding$gist$gte-large', 'angle$cohere$flag-embedding$gist$llmrails', 'angle$cohere$flag-embedding$gist$mixed-bread', 'angle$cohere$flag-embedding$gist$voyage', 'angle$cohere$flag-embedding$gte-large$llmrails', 'angle$cohere$flag-embedding$gte-large$mixed-bread', 'angle$cohere$flag-embedding$gte-large$voyage', 'angle$cohere$flag-embedding$llmrails$mixed-bread', 'angle$cohere$flag-embedding$llmrails$voyage', 'angle$cohere$flag-embedding$mixed-bread$voyage', 'angle$cohere$gist$gte-large$llmrails', 'angle$cohere$gist$gte-large$mixed-bread', 'angle$cohere$gist$gte-large$voyage', 'angle$cohere$gist$llmrails$mixed-bread', 'angle$cohere$gist$llmrails$voyage', 'angle$cohere$gist$mixed-bread$voyage', 'angle$cohere$gte-large$llmrails$mixed-bread', 'angle$cohere$gte-large$llmrails$voyage', 'angle$cohere$gte-large$mixed-bread$voyage', 'angle$cohere$llmrails$mixed-bread$voyage', 'angle$flag-embedding$gist$gte-large$llmrails', 'angle$flag-embedding$gist$gte-large$mixed-bread', 'angle$flag-embedding$gist$gte-large$voyage', 'angle$flag-embedding$gist$llmrails$mixed-bread', 'angle$flag-embedding$gist$llmrails$voyage', 'angle$flag-embedding$gist$mixed-bread$voyage', 'angle$flag-embedding$gte-large$llmrails$mixed-bread', 'angle$flag-embedding$gte-large$llmrails$voyage', 'angle$flag-embedding$gte-large$mixed-bread$voyage', 'angle$flag-embedding$llmrails$mixed-bread$voyage', 'angle$gist$gte-large$llmrails$mixed-bread', 'angle$gist$gte-large$llmrails$voyage', 'angle$gist$gte-large$mixed-bread$voyage', 'angle$gist$llmrails$mixed-bread$voyage', 'angle$gte-large$llmrails$mixed-bread$voyage', 'cohere$flag-embedding$gist$gte-large$llmrails', 'cohere$flag-embedding$gist$gte-large$mixed-bread', 'cohere$flag-embedding$gist$gte-large$voyage', 'cohere$flag-embedding$gist$llmrails$mixed-bread', 'cohere$flag-embedding$gist$llmrails$voyage', 'cohere$flag-embedding$gist$mixed-bread$voyage', 'cohere$flag-embedding$gte-large$llmrails$mixed-bread', 'cohere$flag-embedding$gte-large$llmrails$voyage', 'cohere$flag-embedding$gte-large$mixed-bread$voyage', 'cohere$flag-embedding$llmrails$mixed-bread$voyage', 'cohere$gist$gte-large$llmrails$mixed-bread', 'cohere$gist$gte-large$llmrails$voyage', 'cohere$gist$gte-large$mixed-bread$voyage', 'cohere$gist$llmrails$mixed-bread$voyage', 'cohere$gte-large$llmrails$mixed-bread$voyage', 'flag-embedding$gist$gte-large$llmrails$mixed-bread', 'flag-embedding$gist$gte-large$llmrails$voyage', 'flag-embedding$gist$gte-large$mixed-bread$voyage', 'flag-embedding$gist$llmrails$mixed-bread$voyage', 'flag-embedding$gte-large$llmrails$mixed-bread$voyage', 'gist$gte-large$llmrails$mixed-bread$voyage', 'angle$cohere$flag-embedding$gist$gte-large$llmrails', 'angle$cohere$flag-embedding$gist$gte-large$mixed-bread', 'angle$cohere$flag-embedding$gist$gte-large$voyage', 'angle$cohere$flag-embedding$gist$llmrails$mixed-bread', 'angle$cohere$flag-embedding$gist$llmrails$voyage', 'angle$cohere$flag-embedding$gist$mixed-bread$voyage', 'angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread', 'angle$cohere$flag-embedding$gte-large$llmrails$voyage', 'angle$cohere$flag-embedding$gte-large$mixed-bread$voyage', 'angle$cohere$flag-embedding$llmrails$mixed-bread$voyage', 'angle$cohere$gist$gte-large$llmrails$mixed-bread', 'angle$cohere$gist$gte-large$llmrails$voyage', 'angle$cohere$gist$gte-large$mixed-bread$voyage', 'angle$cohere$gist$llmrails$mixed-bread$voyage', 'angle$cohere$gte-large$llmrails$mixed-bread$voyage', 'angle$flag-embedding$gist$gte-large$llmrails$mixed-bread', 'angle$flag-embedding$gist$gte-large$llmrails$voyage', 'angle$flag-embedding$gist$gte-large$mixed-bread$voyage', 'angle$flag-embedding$gist$llmrails$mixed-bread$voyage', 'angle$flag-embedding$gte-large$llmrails$mixed-bread$voyage', 'angle$gist$gte-large$llmrails$mixed-bread$voyage', 'cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread', 'cohere$flag-embedding$gist$gte-large$llmrails$voyage', 'cohere$flag-embedding$gist$gte-large$mixed-bread$voyage', 'cohere$flag-embedding$gist$llmrails$mixed-bread$voyage', 'cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage', 'cohere$gist$gte-large$llmrails$mixed-bread$voyage', 'flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage', 'angle$cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread', 'angle$cohere$flag-embedding$gist$gte-large$llmrails$voyage', 'angle$cohere$flag-embedding$gist$gte-large$mixed-bread$voyage', 'angle$cohere$flag-embedding$gist$llmrails$mixed-bread$voyage', 'angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage', 'angle$cohere$gist$gte-large$llmrails$mixed-bread$voyage', 'angle$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage', 'cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage', 'angle$cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage']
Number of cores:  24
Running in parallel with 12 processes
INFO:main:Running task: ArxivClusteringS2S
INFO:main:Running task: ArxivClusteringS2S
INFO:main:Running task: ArxivClusteringS2S
INFO:main:Running task: ArxivClusteringS2S
INFO:main:Running task: ArxivClusteringS2S
INFO:main:Running task: ArxivClusteringS2S
INFO:main:Running task: ArxivClusteringS2S
INFO:main:Running task: ArxivClusteringS2S
INFO:main:Running task: ArxivClusteringS2S
INFO:main:Running task: ArxivClusteringS2S
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model gte-large$llmrails...
Creating model gte-large$llmrails for task ArxivClusteringS2S
Loading gte-large from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model cohere$llmrails...
Creating model cohere$llmrails for task ArxivClusteringS2S
Loading cohere from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model cohere$gte-large$llmrails...
Creating model cohere$gte-large$llmrails for task ArxivClusteringS2S
Loading cohere from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
Evaluating the model angle$cohere$flag-embedding...
Creating model angle$cohere$flag-embedding for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model mixed-bread...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name mixed-bread
Converting results/mixed-bread to results/mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model voyage...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name voyage
Converting results/voyage to results/voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere...
Creating model angle$cohere for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading cohere from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
Evaluating the model angle...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name angle
Converting results/angle to results/angle_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name cohere
Converting results/cohere to results/cohere_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model flag-embedding...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name flag-embedding
Converting results/flag-embedding to results/flag-embedding_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model gist...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name gist
Converting results/gist to results/gist_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model gte-large...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name gte-large
Converting results/gte-large to results/gte-large_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model llmrails...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name llmrails
Converting results/llmrails to results/llmrails_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:29<14:31, 29.05s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:32<16:10, 32.34s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:33<16:47, 33.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:33<16:58, 33.96s/it]Clustering:   3%|▎         | 1/31 [00:33<16:58, 33.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:43<09:48, 20.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model angle$flag-embedding$gist...
Creating model angle$flag-embedding$gist for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [01:06<16:11, 33.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [01:16<18:49, 38.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [01:17<19:13, 39.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [01:31<15:30, 33.22s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [01:36<24:24, 50.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:47<23:54, 47.82s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [01:53<18:32, 39.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [01:57<18:40, 40.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [02:09<21:10, 45.39s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [02:15<16:49, 37.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [02:26<23:34, 50.52s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Evaluating the model flag-embedding$mixed-bread...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name flag-embedding$mixed-bread
Converting results/flag-embedding$mixed-bread to results/flag-embedding$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model flag-embedding$voyage...
Creating model flag-embedding$voyage for task ArxivClusteringS2S
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
Clustering:   6%|▋         | 2/31 [01:42<25:00, 51.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [02:39<18:22, 40.85s/it]Clustering:  13%|█▎        | 4/31 [02:39<18:52, 41.95s/it]INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [02:50<19:30, 43.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [03:00<17:26, 40.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model angle$gist$llmrails...
Creating model angle$gist$llmrails for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model angle$llmrails$mixed-bread...
Creating model angle$llmrails$mixed-bread for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
Evaluating the model cohere$flag-embedding$mixed-bread...
Creating model cohere$flag-embedding$mixed-bread for task ArxivClusteringS2S
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
    - ArxivClusteringS2S, s2s
Clustering


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
    - ArxivClusteringS2S, s2s
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [02:31<23:29, 50.35s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [03:32<19:57, 46.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [03:34<19:53, 45.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [03:35<15:54, 38.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model angle$llmrails...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name angle$llmrails
Converting results/angle$llmrails to results/angle$llmrails_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$mixed-bread...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name angle$mixed-bread
Converting results/angle$mixed-bread to results/angle$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$voyage...
Creating model angle$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:58<29:10, 58.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [03:45<20:38, 47.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [01:09<34:30, 69.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model flag-embedding$gist$gte-large...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name flag-embedding$gist$gte-large
Converting results/flag-embedding$gist$gte-large to results/flag-embedding$gist$gte-large_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model flag-embedding$gist$llmrails...
Creating model flag-embedding$gist$llmrails for task ArxivClusteringS2S
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [04:42<22:32, 54.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [01:29<44:38, 89.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [04:48<19:49, 49.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  19%|█▉        | 6/31 [04:57<23:16, 55.88s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [04:07<30:50, 68.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [02:18<34:18, 70.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [05:04<25:23, 60.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [01:27<43:59, 87.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [02:29<36:37, 75.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [05:42<22:30, 56.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [01:09<34:46, 69.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [05:56<21:17, 55.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [02:41<38:11, 79.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [03:19<31:01, 66.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [06:11<25:07, 62.82s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [05:41<33:36, 77.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [02:50<40:53, 84.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [03:46<35:36, 76.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [06:52<23:13, 60.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [07:02<21:35, 58.90s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [04:26<29:59, 66.66s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [02:28<36:14, 74.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [07:15<24:12, 63.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [04:03<37:40, 80.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [03:48<33:49, 72.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [08:01<20:33, 58.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [05:00<33:55, 75.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [08:07<23:47, 64.88s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [07:16<34:55, 83.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model flag-embedding$gte-large$voyage...
Creating model flag-embedding$gte-large$voyage for task ArxivClusteringS2S
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [08:21<23:27, 63.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [03:45<35:27, 75.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [05:53<32:08, 74.17s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [04:54<31:27, 69.91s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [05:27<36:52, 81.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [08:58<21:17, 60.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [08:27<31:46, 79.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [09:24<22:22, 63.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [06:45<27:45, 66.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [06:30<34:54, 80.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [09:52<24:54, 74.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [05:18<37:07, 82.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  16%|█▌        | 5/31 [06:21<32:58, 76.08s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [07:06<38:08, 88.00s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [07:53<26:49, 67.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [09:44<30:11, 78.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Evaluating the model gte-large$mixed-bread$voyage...
Creating model gte-large$mixed-bread$voyage for task ArxivClusteringS2S
Loading gte-large from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
Clustering:  35%|███▌      | 11/31 [10:56<26:02, 78.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [07:55<34:18, 82.33s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [06:34<34:45, 80.22s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [07:39<32:00, 76.82s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [11:40<26:54, 84.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [09:11<26:59, 70.39s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [08:48<38:37, 92.69s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [11:23<31:08, 84.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [09:17<32:46, 81.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [12:32<33:56, 101.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [08:49<29:50, 74.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [12:32<26:32, 83.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [08:11<35:50, 86.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [10:17<25:23, 69.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [10:04<34:59, 87.46s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [12:37<28:34, 81.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [13:41<28:46, 95.93s/it]Clustering:  26%|██▌       | 8/31 [10:36<31:02, 81.00s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [10:09<29:15, 76.34s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [09:29<33:20, 83.35s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [11:48<26:29, 75.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [14:34<28:34, 95.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [11:32<33:34, 87.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [11:43<28:07, 76.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [11:15<26:44, 72.93s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [15:17<27:10, 95.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [15:23<38:51, 122.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [10:44<30:59, 80.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [12:36<29:20, 80.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [12:13<23:56, 68.39s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  32%|███▏      | 10/31 [12:50<25:49, 73.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [13:22<27:10, 81.53s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [16:11<27:05, 95.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [11:42<26:57, 73.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [16:32<23:55, 89.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [13:21<24:14, 69.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [14:18<23:19, 73.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [16:11<40:40, 122.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [12:21<22:02, 62.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  35%|███▌      | 11/31 [13:20<22:39, 67.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [17:05<34:56, 116.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [17:10<22:34, 84.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [17:29<19:57, 79.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model angle$flag-embedding$gist$llmrails...
Creating model angle$flag-embedding$gist$llmrails for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [14:17<20:31, 64.82s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [14:59<30:11, 90.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [15:24<21:26, 71.48s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [18:19<29:22, 103.67s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [18:31<20:54, 83.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [15:23<28:26, 85.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [18:40<18:00, 77.17s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [14:19<26:34, 79.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [16:25<19:18, 68.17s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  42%|████▏     | 13/31 [15:24<19:38, 65.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Evaluating the model angle$flag-embedding$llmrails$mixed-bread...
Creating model angle$flag-embedding$llmrails$mixed-bread for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [18:20<39:18, 124.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [19:40<18:29, 79.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [19:48<26:26, 99.16s/it] INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [19:59<16:50, 77.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [17:01<31:41, 100.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [17:27<17:39, 66.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [16:34<18:54, 66.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [17:13<29:28, 93.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model angle$gist$llmrails$mixed-bread...
Creating model angle$gist$llmrails$mixed-bread for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [16:05<27:50, 87.91s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  58%|█████▊    | 18/31 [20:47<16:20, 75.39s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [20:52<14:03, 70.33s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [20:14<36:21, 121.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [21:16<23:58, 95.93s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [18:36<16:48, 67.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:46<23:13, 46.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [17:56<19:03, 71.46s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [21:51<12:14, 66.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [21:55<14:39, 73.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [19:02<31:56, 106.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [19:40<15:28, 66.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [19:06<29:42, 99.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [22:31<20:56, 89.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [19:05<17:39, 70.66s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  68%|██████▊   | 21/31 [22:48<10:39, 63.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [18:17<30:19, 101.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [22:58<07:09, 47.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [22:19<34:38, 122.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [23:11<13:34, 74.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [20:46<14:19, 66.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [20:57<30:52, 108.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [24:04<19:38, 90.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [20:27<17:14, 73.91s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [24:10<07:18, 54.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [24:12<11:41, 70.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [21:03<29:33, 104.35s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [24:23<07:50, 52.33s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [21:55<13:24, 67.05s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [24:45<05:43, 49.08s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [21:22<14:46, 68.19s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [20:24<30:55, 109.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [24:25<32:54, 123.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [25:17<17:03, 85.33s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [25:17<07:04, 53.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [25:32<04:50, 48.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [22:57<12:00, 65.54s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [25:55<05:38, 48.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [26:04<03:36, 43.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [23:13<29:54, 112.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [22:47<14:41, 73.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [23:25<32:12, 120.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [26:56<16:24, 89.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [24:19<11:42, 70.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [27:06<05:31, 55.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [24:28<07:48, 52.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [27:18<03:30, 52.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [22:38<31:02, 116.39s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [23:51<12:54, 70.40s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  52%|█████▏    | 16/31 [26:45<32:08, 128.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [27:37<04:00, 48.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [27:54<13:19, 79.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [27:59<02:27, 49.05s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [28:05<08:53, 59.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [25:24<07:04, 53.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [25:15<29:23, 117.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [24:53<11:20, 68.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [28:41<03:31, 52.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [25:02<07:33, 50.34s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [25:30<29:55, 119.69s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [28:49<01:38, 49.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [28:56<00:36, 36.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [26:18<06:13, 53.34s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [29:19<02:25, 48.37s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [29:27<08:48, 66.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [28:39<28:55, 123.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [29:30<00:00, 35.84s/it]Clustering: 100%|██████████| 31/31 [29:30<00:00, 57.11s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 1770.38 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43283776898275794, 'v_measure_std': 0.14303485545354225, 'main_score': 0.43283776898275794, 'evaluation_time': 1770.38}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [25:53<06:43, 50.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [24:56<30:44, 122.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [27:00<04:59, 49.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Creating model cohere$llmrails for task EmotionClassification
Loading cohere from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [27:20<03:25, 41.05s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 14.13 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5536500000000001, 'f1': 0.4935988799644602, 'accuracy_stderr': 0.02276625792702876, 'f1_stderr': 0.013435930945199664, 'main_score': 0.5536500000000001, 'evaluation_time': 14.13}
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [30:04<01:34, 47.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [30:08<06:50, 58.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [30:15<00:36, 36.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [26:41<05:47, 49.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$llmrails for task TwitterSemEval2015
Loading cohere from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 3.26 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8760207426834357, 'accuracy_threshold': 0.7815780292494154, 'f1': 0.7133927383960633, 'f1_threshold': 0.7659065385252465, 'precision': 0.7192276749798874, 'recall': 0.7076517150395778, 'ap': 0.7861894922965518}, 'manhattan': {'accuracy': 0.8765571913929785, 'accuracy_threshold': 23.51872952868507, 'f1': 0.715714661753093, 'f1_threshold': 24.520720905562087, 'precision': 0.7140231092436975, 'recall': 0.7174142480211082, 'ap': 0.7874035280171889}, 'euclidean': {'accuracy': 0.8760207426834357, 'accuracy_threshold': 0.6609417078484949, 'f1': 0.7133927383960633, 'f1_threshold': 0.6842418588378845, 'precision': 0.7192276749798874, 'recall': 0.7076517150395778, 'ap': 0.7861894922965518}, 'dot': {'accuracy': 0.8760207426834357, 'accuracy_threshold': 0.7815780292494157, 'f1': 0.7133927383960633, 'f1_threshold': 0.7659065385252467, 'precision': 0.7192276749798874, 'recall': 0.7076517150395778, 'ap': 0.7861894922965518}, 'max': {'accuracy': 0.8765571913929785, 'f1': 0.715714661753093, 'ap': 0.7874035280171889}, 'evaluation_time': 3.26}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [27:27<28:28, 122.00s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS15 as it already exists
Creating model cohere$llmrails for task AmazonCounterfactualClassification
Loading cohere from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 1.48 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7897014925373134, 'f1': 0.7320162958251217, 'ap': 0.4332670537954881, 'accuracy_stderr': 0.035183698305040915, 'f1_stderr': 0.03418532884028887, 'ap_stderr': 0.04294907567357771, 'main_score': 0.7897014925373134}, 'evaluation_time': 1.48}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [27:30<27:54, 119.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [30:48<00:00, 35.47s/it]Clustering: 100%|██████████| 31/31 [30:48<00:00, 59.64s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 1848.78 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43285936340638115, 'v_measure_std': 0.1428657027541072, 'main_score': 0.43285936340638115, 'evaluation_time': 1848.78}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [28:14<03:00, 45.05s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [27:19<04:37, 46.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [31:06<05:49, 58.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [30:25<25:44, 118.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [28:46<02:03, 41.09s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [27:47<03:23, 40.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [26:52<28:14, 121.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [31:35<04:07, 49.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [29:54<27:31, 127.00s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [30:29<01:59, 59.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [29:34<04:02, 60.67s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [30:37<00:44, 44.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [33:24<04:29, 67.34s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [30:19<29:42, 137.09s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [32:45<24:59, 124.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [30:04<02:34, 51.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model flag-embedding$gist$llmrails$mixed-bread...
Creating model flag-embedding$gist$llmrails$mixed-bread for task ArxivClusteringS2S
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [33:57<02:51, 57.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [31:24<00:00, 44.93s/it]Clustering: 100%|██████████| 31/31 [31:24<00:00, 60.78s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 1884.24 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4297691193247998, 'v_measure_std': 0.14212844964995136, 'main_score': 0.4297691193247998, 'evaluation_time': 1884.24}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Creating model flag-embedding$voyage for task SciFact
Loading flag-embedding from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [30:41<01:34, 47.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [29:45<29:33, 136.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 5183 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '4983', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.', 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [31:14<22:34, 112.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:37<18:42, 37.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [30:52<00:36, 36.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 300 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '1', 'text': '0-dimensional biomaterials show inductive properties.'}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/mteb/evaluation/evaluators/utils.py:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [34:40<01:45, 52.87s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 7.69 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.6567
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.7262
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.7392
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.7674
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.7842
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.7891
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.6259
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.7002
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.7096
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.7243
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.7285
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.7287
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.6259
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.7764
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.8099
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.8899
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9633
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 1.0000
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.6567
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2833
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1807
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.1010
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0109
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0011
INFO:root:

INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:root:MRR@1: 0.6567
INFO:root:MRR@3: 0.7156
INFO:root:MRR@5: 0.7239
INFO:root:MRR@10: 0.7332
INFO:root:MRR@100: 0.7365
INFO:root:MRR@1000: 0.7367
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 8.57 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.65667, 'ndcg_at_3': 0.72625, 'ndcg_at_5': 0.73919, 'ndcg_at_10': 0.76739, 'ndcg_at_100': 0.78423, 'ndcg_at_1000': 0.78913, 'map_at_1': 0.62594, 'map_at_3': 0.70024, 'map_at_5': 0.70955, 'map_at_10': 0.72433, 'map_at_100': 0.72848, 'map_at_1000': 0.72871, 'recall_at_1': 0.62594, 'recall_at_3': 0.77644, 'recall_at_5': 0.80994, 'recall_at_10': 0.88989, 'recall_at_100': 0.96333, 'recall_at_1000': 1.0, 'precision_at_1': 0.65667, 'precision_at_3': 0.28333, 'precision_at_5': 0.18067, 'precision_at_10': 0.101, 'precision_at_100': 0.01093, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.65667, 'mrr_at_3': 0.71556, 'mrr_at_5': 0.72389, 'mrr_at_10': 0.73325, 'mrr_at_100': 0.73645, 'mrr_at_1000': 0.73669, 'evaluation_time': 8.57}
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name angle$cohere
Converting results/angle$cohere to results/angle$cohere_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$flag-embedding...
Creating model angle$flag-embedding for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [34:49<00:39, 39.54s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [31:45<24:19, 121.66s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [31:26<00:00, 35.59s/it]Clustering: 100%|██████████| 31/31 [31:26<00:00, 60.86s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 1886.73 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4269806625405721, 'v_measure_std': 0.14274830753278903, 'main_score': 0.4269806625405721, 'evaluation_time': 1886.73}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [34:22<21:24, 116.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [01:21<19:59, 41.35s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:32<16:24, 32.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Creating model angle$voyage for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 11.15 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5453, 'f1': 0.47781184680865885, 'accuracy_stderr': 0.021783250446157032, 'f1_stderr': 0.013015749218558602, 'main_score': 0.5453, 'evaluation_time': 11.15}
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [35:39<00:00, 42.93s/it]Clustering: 100%|██████████| 31/31 [35:39<00:00, 69.03s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 2139.97 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4336594709749619, 'v_measure_std': 0.14227213783717546, 'main_score': 0.4336594709749619, 'evaluation_time': 2139.97}
INFO:main:Running task: EmotionClassification
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [40:08<56:31, 282.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [10:03<2:48:50, 349.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [41:38<48:49, 266.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Creating model gte-large$llmrails for task EmotionClassification
Loading gte-large from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 8.39 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5439, 'f1': 0.47672639029108554, 'accuracy_stderr': 0.02614459791237954, 'f1_stderr': 0.015553722138886932, 'main_score': 0.5439, 'evaluation_time': 8.39}
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$voyage for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [10:28<1:33:54, 201.22s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 3.59 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8724444179531502, 'accuracy_threshold': 0.8574678797754884, 'f1': 0.7061987704918032, 'f1_threshold': 0.8422102863616086, 'precision': 0.6861622697859632, 'recall': 0.7274406332453826, 'ap': 0.7748876219942693}, 'manhattan': {'accuracy': 0.8704774393514931, 'accuracy_threshold': 18.883942642661808, 'f1': 0.7022187621642663, 'f1_threshold': 19.821316020059456, 'precision': 0.6908348225682921, 'recall': 0.7139841688654354, 'ap': 0.770804099141756}, 'euclidean': {'accuracy': 0.8724444179531502, 'accuracy_threshold': 0.5339140758446917, 'f1': 0.7061987704918032, 'f1_threshold': 0.5617645656956198, 'precision': 0.6861622697859632, 'recall': 0.7274406332453826, 'ap': 0.7748876219942693}, 'dot': {'accuracy': 0.8724444179531502, 'accuracy_threshold': 0.8574678797754887, 'f1': 0.7061987704918032, 'f1_threshold': 0.8422102863616088, 'precision': 0.6861622697859632, 'recall': 0.7274406332453826, 'ap': 0.7748876219942693}, 'max': {'accuracy': 0.8724444179531502, 'f1': 0.7061987704918032, 'ap': 0.7748876219942693}, 'evaluation_time': 3.59}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [44:33<44:10, 265.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [42:21<50:36, 276.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS15 as it already exists
Creating model angle$voyage for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [40:48<38:28, 209.87s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [44:41<28:11, 187.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model gte-large$llmrails for task TwitterSemEval2015
Loading gte-large from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 1.39 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7349253731343283, 'f1': 0.6734186745615456, 'ap': 0.35991350917746046, 'accuracy_stderr': 0.0390189334350232, 'f1_stderr': 0.0367200815470586, 'ap_stderr': 0.03733893395389031, 'main_score': 0.7349253731343283}, 'evaluation_time': 1.39}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 4.10 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8737557370209215, 'accuracy_threshold': 0.861014187335968, 'f1': 0.7195027195027196, 'f1_threshold': 0.8493456840515137, 'precision': 0.7065106815869786, 'recall': 0.732981530343008, 'ap': 0.7873319647516179}, 'manhattan': {'accuracy': 0.8726828396018358, 'accuracy_threshold': 18.856285095214844, 'f1': 0.7161190965092403, 'f1_threshold': 19.305011749267578, 'precision': 0.697151424287856, 'recall': 0.7361477572559367, 'ap': 0.7823591028423152}, 'euclidean': {'accuracy': 0.8737557370209215, 'accuracy_threshold': 0.5272302627563477, 'f1': 0.7195027195027196, 'f1_threshold': 0.5489159822463989, 'precision': 0.7065106815869786, 'recall': 0.732981530343008, 'ap': 0.7873317473428169}, 'dot': {'accuracy': 0.8737557370209215, 'accuracy_threshold': 0.8610142469406128, 'f1': 0.7195027195027196, 'f1_threshold': 0.8493456840515137, 'precision': 0.7065106815869786, 'recall': 0.732981530343008, 'ap': 0.7873318758247561}, 'max': {'accuracy': 0.8737557370209215, 'f1': 0.7195027195027196, 'ap': 0.7873319647516179}, 'evaluation_time': 4.1}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [10:55<59:33, 132.36s/it]  INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS15 as it already exists
Creating model gte-large$llmrails for task AmazonCounterfactualClassification
Loading gte-large from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 1.63 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7377611940298507, 'f1': 0.6766939857065661, 'ap': 0.36347380485854053, 'accuracy_stderr': 0.0321159211340321, 'f1_stderr': 0.03088198913205242, 'ap_stderr': 0.03306641228549982, 'main_score': 0.7377611940298507}, 'evaluation_time': 1.63}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [42:47<34:32, 207.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [42:57<22:10, 147.82s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [11:24<41:08, 94.96s/it] INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [41:32<26:39, 159.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [41:40<17:10, 114.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [43:16<34:58, 209.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [43:24<22:23, 149.28s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [11:54<30:26, 73.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [45:56<20:31, 153.91s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [12:18<22:47, 56.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [43:53<16:03, 120.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [42:34<12:49, 96.13s/it] INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [46:36<13:59, 119.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [12:43<17:53, 46.68s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [44:42<17:01, 127.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [44:34<11:15, 96.53s/it] INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [43:10<09:08, 78.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [13:08<14:41, 40.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Evaluating the model flag-embedding$llmrails$mixed-bread$voyage...
Creating model flag-embedding$llmrails$mixed-bread$voyage for task ArxivClusteringS2S
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [13:24<11:23, 32.53s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [45:10<11:25, 97.96s/it] INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [47:32<10:04, 100.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [45:09<07:48, 78.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [47:44<06:09, 73.94s/it] INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [45:22<04:52, 58.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [43:59<06:56, 69.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [45:59<08:18, 83.13s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [45:53<03:20, 50.19s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [48:19<04:09, 62.35s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [44:31<04:51, 58.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [14:23<13:36, 40.81s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS22 as it already exists
Creating model gte-large$llmrails for task RedditClustering
Loading gte-large from cache for RedditClustering...
Loading llmrails from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.abstasks.AbsTaskClustering:
Task: RedditClustering, split: test. Running...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [46:22<05:25, 65.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [46:17<02:07, 42.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [48:43<02:32, 50.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:12<05:11, 13.00s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name flag-embedding$voyage
Converting results/flag-embedding$voyage to results/flag-embedding$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model gist$gte-large...
Creating model gist$gte-large for task ArxivClusteringS2S
Loading gist from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:38<07:52, 20.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [45:27<03:49, 57.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [15:21<14:32, 45.90s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [46:56<01:22, 41.40s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [49:25<01:36, 48.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [47:14<04:04, 61.19s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:35<17:59, 35.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [47:09<00:32, 32.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [49:37<00:37, 37.40s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [46:51<03:16, 65.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [02:11<19:34, 53.39s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [01:57<30:16, 62.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [48:29<00:00, 47.06s/it]Clustering: 100%|██████████| 31/31 [48:29<00:00, 93.86s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 2909.71 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4309030946011323, 'v_measure_std': 0.14253470295434098, 'main_score': 0.4309030946011323, 'evaluation_time': 2909.71}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [48:43<03:28, 69.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [02:14<19:28, 41.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Creating model angle$llmrails$mixed-bread for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [02:36<14:44, 42.13s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [17:16<20:00, 66.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [51:30<00:00, 59.99s/it]Clustering: 100%|██████████| 31/31 [51:30<00:00, 99.69s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 3090.38 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4312942554102099, 'v_measure_std': 0.14224079919803123, 'main_score': 0.4312942554102099, 'evaluation_time': 3090.38}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 16.33 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5507500000000001, 'f1': 0.4833538133639137, 'accuracy_stderr': 0.026273798735622536, 'f1_stderr': 0.015380866613735647, 'main_score': 0.5507500000000001, 'evaluation_time': 16.33}
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [03:00<11:52, 35.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [47:48<02:05, 62.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [02:46<17:09, 38.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Creating model angle$flag-embedding$gist for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading flag-embedding from cache for EmotionClassification...
Loading gist from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [49:33<02:07, 63.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [47:58<00:46, 46.99s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$llmrails$mixed-bread for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 11.05 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5612999999999999, 'f1': 0.49634483602235757, 'accuracy_stderr': 0.023001304310842883, 'f1_stderr': 0.013152515096284297, 'main_score': 0.5612999999999999, 'evaluation_time': 11.05}
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [03:23<09:59, 31.54s/it]INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [49:47<00:48, 48.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 11.12 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.87578232103475, 'accuracy_threshold': 0.806734561920166, 'f1': 0.718304528825533, 'f1_threshold': 0.786474347114563, 'precision': 0.6881798404641044, 'recall': 0.7511873350923483, 'ap': 0.7875469627678724}, 'manhattan': {'accuracy': 0.8761399535077785, 'accuracy_threshold': 26.98284149169922, 'f1': 0.7186466547952175, 'f1_threshold': 28.395626068115234, 'precision': 0.693762278978389, 'recall': 0.7453825857519789, 'ap': 0.7878182509902625}, 'euclidean': {'accuracy': 0.87578232103475, 'accuracy_threshold': 0.6217160224914551, 'f1': 0.718304528825533, 'f1_threshold': 0.6534916162490845, 'precision': 0.6881798404641044, 'recall': 0.7511873350923483, 'ap': 0.7875469452047615}, 'dot': {'accuracy': 0.87578232103475, 'accuracy_threshold': 0.8067346811294556, 'f1': 0.718304528825533, 'f1_threshold': 0.7864744067192078, 'precision': 0.6881798404641044, 'recall': 0.7511873350923483, 'ap': 0.7875470305627557}, 'max': {'accuracy': 0.8761399535077785, 'f1': 0.7186466547952175, 'ap': 0.7878182509902625}, 'evaluation_time': 11.12}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [03:18<15:29, 35.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS15 as it already exists
Creating model angle$llmrails$mixed-bread for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [03:37<07:40, 25.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 1.27 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7317910447761193, 'f1': 0.6718807164783187, 'ap': 0.3597064055571532, 'accuracy_stderr': 0.036498870127798816, 'f1_stderr': 0.034826585259903536, 'ap_stderr': 0.03592991702128202, 'main_score': 0.7317910447761193}, 'evaluation_time': 1.27}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [18:25<19:09, 67.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$flag-embedding$gist for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [03:42<13:17, 31.91s/it]INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 10.06 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8748286344400071, 'accuracy_threshold': 0.8164488077163696, 'f1': 0.7195581220185789, 'f1_threshold': 0.7866687774658203, 'precision': 0.6863026819923371, 'recall': 0.7562005277044855, 'ap': 0.7866764274945042}, 'manhattan': {'accuracy': 0.87536508314955, 'accuracy_threshold': 26.822404861450195, 'f1': 0.7201625190452007, 'f1_threshold': 28.318824768066406, 'precision': 0.6940773372491434, 'recall': 0.7482849604221636, 'ap': 0.7867427346011394}, 'euclidean': {'accuracy': 0.8748286344400071, 'accuracy_threshold': 0.6058897972106934, 'f1': 0.7195581220185789, 'f1_threshold': 0.653194010257721, 'precision': 0.6863026819923371, 'recall': 0.7562005277044855, 'ap': 0.7866763526921612}, 'dot': {'accuracy': 0.8748286344400071, 'accuracy_threshold': 0.8164488077163696, 'f1': 0.7195581220185789, 'f1_threshold': 0.7866687774658203, 'precision': 0.6863026819923371, 'recall': 0.7562005277044855, 'ap': 0.7866768035758003}, 'max': {'accuracy': 0.87536508314955, 'f1': 0.7201625190452007, 'ap': 0.7867427346011394}, 'evaluation_time': 10.06}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS15 as it already exists
Creating model angle$flag-embedding$gist for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading flag-embedding from cache for AmazonCounterfactualClassification...
Loading gist from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [48:53<00:00, 49.52s/it]Clustering: 100%|██████████| 31/31 [48:53<00:00, 94.64s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 2933.73 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4302670045547602, 'v_measure_std': 0.14368534042739678, 'main_score': 0.4302670045547602, 'evaluation_time': 2933.73}
INFO:main:Running task: EmotionClassification
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [04:09<07:50, 27.70s/it]Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 2.57 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7417910447761193, 'f1': 0.6809399459606729, 'ap': 0.3685527370435742, 'accuracy_stderr': 0.03436078935289952, 'f1_stderr': 0.0334229885359249, 'ap_stderr': 0.03598634751720272, 'main_score': 0.7417910447761193}, 'evaluation_time': 2.57}
INFO:main:Running task: RedditClustering
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [52:12<00:00, 77.58s/it]Clustering: 100%|██████████| 31/31 [52:12<00:00, 101.04s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 3132.26 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43054642701237517, 'v_measure_std': 0.14319672614990733, 'main_score': 0.43054642701237517, 'evaluation_time': 3132.26}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Creating model flag-embedding$gist$llmrails for task EmotionClassification
Loading flag-embedding from cache for EmotionClassification...
Loading gist from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [05:39<23:51, 59.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [06:09<15:06, 56.67s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 14.43 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.56345, 'f1': 0.4997641915373962, 'accuracy_stderr': 0.023146760032453785, 'f1_stderr': 0.012633450566397173, 'main_score': 0.56345, 'evaluation_time': 14.43}
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [05:59<18:00, 46.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [20:59<24:55, 93.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [06:22<10:48, 43.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [06:16<13:49, 37.69s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [06:38<08:06, 34.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model flag-embedding$gist$llmrails for task TwitterSemEval2015
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [06:45<05:40, 26.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [06:34<11:06, 31.72s/it]INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 7.65 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8760207426834357, 'accuracy_threshold': 0.8155783414840698, 'f1': 0.7239014478028957, 'f1_threshold': 0.784979522228241, 'precision': 0.6978452497551421, 'recall': 0.7519788918205804, 'ap': 0.7921593374311108}, 'manhattan': {'accuracy': 0.8758419264469214, 'accuracy_threshold': 27.267610549926758, 'f1': 0.721836760439006, 'f1_threshold': 28.70547866821289, 'precision': 0.6915639352187576, 'recall': 0.7548812664907651, 'ap': 0.7915620661397461}, 'euclidean': {'accuracy': 0.8760207426834357, 'accuracy_threshold': 0.6073246002197266, 'f1': 0.7239014478028957, 'f1_threshold': 0.6557750701904297, 'precision': 0.6978452497551421, 'recall': 0.7519788918205804, 'ap': 0.7921594138815904}, 'dot': {'accuracy': 0.8760207426834357, 'accuracy_threshold': 0.8155783414840698, 'f1': 0.7239014478028957, 'f1_threshold': 0.784979522228241, 'precision': 0.6978452497551421, 'recall': 0.7519788918205804, 'ap': 0.7921595204174643}, 'max': {'accuracy': 0.8760207426834357, 'f1': 0.7239014478028957, 'ap': 0.7921595204174643}, 'evaluation_time': 7.65}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [06:53<04:08, 20.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [21:31<18:46, 75.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS15 as it already exists
Creating model flag-embedding$gist$llmrails for task AmazonCounterfactualClassification
Loading flag-embedding from cache for AmazonCounterfactualClassification...
Loading gist from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 1.80 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7458208955223881, 'f1': 0.6850313662644371, 'ap': 0.3730275007943437, 'accuracy_stderr': 0.03319377482990193, 'f1_stderr': 0.031451418936360366, 'ap_stderr': 0.03357618386883073, 'main_score': 0.7458208955223881}, 'evaluation_time': 1.8}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [07:11<03:40, 20.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [06:56<09:31, 28.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [07:16<02:34, 15.46s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [22:02<14:24, 61.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [07:35<02:28, 16.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [07:26<09:10, 28.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [07:44<01:53, 14.25s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [22:25<10:51, 50.08s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [07:48<01:18, 11.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [09:03<03:02, 30.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [08:46<13:19, 44.43s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [23:42<11:39, 58.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [09:24<02:18, 27.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [09:07<10:36, 37.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [24:06<08:48, 48.08s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [09:45<01:42, 25.52s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [09:29<08:41, 32.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [24:36<07:05, 42.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [24:39<04:36, 30.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [10:01<01:08, 22.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [10:04<00:33, 16.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [09:59<07:59, 31.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [10:17<00:15, 15.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [24:56<03:31, 26.41s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [10:33<00:00, 15.64s/it]Clustering: 100%|██████████| 25/25 [10:33<00:00, 25.33s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 633.20 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.593476758969473, 'v_measure_std': 0.043958239028194124, 'main_score': 0.593476758969473, 'evaluation_time': 633.2}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [25:12<02:44, 23.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [10:16<06:25, 27.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [25:16<01:44, 17.46s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS13 as it already exists
Creating model gte-large$llmrails for task AskUbuntuDupQuestions
Loading gte-large from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [10:22<04:31, 20.90s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [25:18<01:04, 12.91s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [25:22<00:40, 10.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [10:26<03:10, 15.90s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [26:09<01:03, 21.17s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [11:13<04:36, 25.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 49.27 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.643179072138865, 'mrr': 0.7759937123510531, 'evaluation_time': 49.27}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [26:14<00:32, 16.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [11:18<03:12, 19.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [11:18<02:01, 13.53s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Creating model gte-large$llmrails for task SciFact
Loading gte-large from cache for SciFact...
Loading llmrails from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [26:15<00:11, 11.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 5183 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '4983', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.', 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [26:19<00:00,  9.40s/it]Clustering: 100%|██████████| 31/31 [26:19<00:00, 50.94s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 1579.18 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43090515346633956, 'v_measure_std': 0.14256337326806362, 'main_score': 0.43090515346633956, 'evaluation_time': 1579.18}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [11:23<01:26, 10.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [11:23<00:54,  7.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [11:24<00:34,  5.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [11:25<00:20,  4.18s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [11:26<00:12,  3.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 300 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '1', 'text': '0-dimensional biomaterials show inductive properties.'}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [11:27<00:07,  2.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/mteb/evaluation/evaluators/utils.py:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [11:27<00:03,  1.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [11:28<00:01,  1.53s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.46 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.6433
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.7072
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.7332
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.7594
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.7758
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.7800
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.6143
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.6829
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.6998
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.7131
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.7168
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.7170
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.6143
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.7502
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.8166
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.8932
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9683
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 1.0000
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.6433
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2756
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1827
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.1013
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0110
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6433
INFO:root:MRR@3: 0.6978
INFO:root:MRR@5: 0.7133
INFO:root:MRR@10: 0.7216
INFO:root:MRR@100: 0.7245
INFO:root:MRR@1000: 0.7247
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 1.85 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.64333, 'ndcg_at_3': 0.70724, 'ndcg_at_5': 0.73317, 'ndcg_at_10': 0.75938, 'ndcg_at_100': 0.77578, 'ndcg_at_1000': 0.78001, 'map_at_1': 0.61428, 'map_at_3': 0.68291, 'map_at_5': 0.69976, 'map_at_10': 0.71307, 'map_at_100': 0.71682, 'map_at_1000': 0.71701, 'recall_at_1': 0.61428, 'recall_at_3': 0.75017, 'recall_at_5': 0.81661, 'recall_at_10': 0.89322, 'recall_at_100': 0.96833, 'recall_at_1000': 1.0, 'precision_at_1': 0.64333, 'precision_at_3': 0.27556, 'precision_at_5': 0.18267, 'precision_at_10': 0.10133, 'precision_at_100': 0.01097, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.64333, 'mrr_at_3': 0.69778, 'mrr_at_5': 0.71328, 'mrr_at_10': 0.72156, 'mrr_at_100': 0.72451, 'mrr_at_1000': 0.72467, 'evaluation_time': 1.85}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [11:29<00:00,  1.37s/it]Clustering: 100%|██████████| 31/31 [11:29<00:00, 22.24s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 689.45 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43187640472797334, 'v_measure_std': 0.14318481812398637, 'main_score': 0.43187640472797334, 'evaluation_time': 689.45}
INFO:main:Running task: EmotionClassification
Evaluating the model cohere$flag-embedding$gte-large$llmrails$voyage...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name cohere$flag-embedding$gte-large$llmrails$voyage
Converting results/cohere$flag-embedding$gte-large$llmrails$voyage to results/cohere$flag-embedding$gte-large$llmrails$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$flag-embedding$gte-large$mixed-bread$voyage...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name cohere$flag-embedding$gte-large$mixed-bread$voyage
Converting results/cohere$flag-embedding$gte-large$mixed-bread$voyage to results/cohere$flag-embedding$gte-large$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$flag-embedding$llmrails$mixed-bread$voyage...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name cohere$flag-embedding$llmrails$mixed-bread$voyage
Converting results/cohere$flag-embedding$llmrails$mixed-bread$voyage to results/cohere$flag-embedding$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$gist$gte-large$llmrails$mixed-bread...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name cohere$gist$gte-large$llmrails$mixed-bread
Converting results/cohere$gist$gte-large$llmrails$mixed-bread to results/cohere$gist$gte-large$llmrails$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$gist$gte-large$llmrails$voyage...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name cohere$gist$gte-large$llmrails$voyage
Converting results/cohere$gist$gte-large$llmrails$voyage to results/cohere$gist$gte-large$llmrails$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$gist$gte-large$mixed-bread$voyage...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name cohere$gist$gte-large$mixed-bread$voyage
Converting results/cohere$gist$gte-large$mixed-bread$voyage to results/cohere$gist$gte-large$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Creating model angle$flag-embedding for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading flag-embedding from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Creating model gte-large$llmrails for task Banking77Classification
Loading gte-large from cache for Banking77Classification...
Loading llmrails from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 1.63 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5501, 'f1': 0.4829599744370164, 'accuracy_stderr': 0.027969447616998093, 'f1_stderr': 0.01650263816186874, 'main_score': 0.5501, 'evaluation_time': 1.63}
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Skipping SICK-R as it already exists
Creating model gist$gte-large for task EmotionClassification
Loading gist from cache for EmotionClassification...
Loading gte-large from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 3.56 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8393181818181817, 'f1': 0.8319518690941079, 'accuracy_stderr': 0.0040667447529707905, 'f1_stderr': 0.005374219532478827, 'main_score': 0.8393181818181817, 'evaluation_time': 3.56}
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 3.14 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.567, 'f1': 0.5058103855803056, 'accuracy_stderr': 0.019460215826141297, 'f1_stderr': 0.01199604333638601, 'main_score': 0.567, 'evaluation_time': 3.14}
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model gte-large$llmrails for task ArguAna
Loading gte-large from cache for ArguAna...
Loading llmrails from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 8674 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'test-environment-aeghhgwpe-pro02b', 'title': 'animals environment general health health general weight philosophy ethics', 'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008"}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$flag-embedding for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading flag-embedding from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 1406 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': 'test-environment-aeghhgwpe-pro02a', 'text': "Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004"}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 2.97 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8754246885617214, 'accuracy_threshold': 0.8088423013687134, 'f1': 0.7205825986968188, 'f1_threshold': 0.7910902500152588, 'precision': 0.6985385187020065, 'recall': 0.7440633245382586, 'ap': 0.788749304930897}, 'manhattan': {'accuracy': 0.8756631102104071, 'accuracy_threshold': 22.219772338867188, 'f1': 0.7173122727842548, 'f1_threshold': 23.488601684570312, 'precision': 0.6833054693097683, 'recall': 0.7548812664907651, 'ap': 0.7881773918533914}, 'euclidean': {'accuracy': 0.8754246885617214, 'accuracy_threshold': 0.6183165311813354, 'f1': 0.7205825986968188, 'f1_threshold': 0.6463896036148071, 'precision': 0.6985385187020065, 'recall': 0.7440633245382586, 'ap': 0.7887492709620947}, 'dot': {'accuracy': 0.8754246885617214, 'accuracy_threshold': 0.8088423013687134, 'f1': 0.7205825986968188, 'f1_threshold': 0.7910902500152588, 'precision': 0.6985385187020065, 'recall': 0.7440633245382586, 'ap': 0.7887492370207437}, 'max': {'accuracy': 0.8756631102104071, 'f1': 0.7205825986968188, 'ap': 0.788749304930897}, 'evaluation_time': 2.97}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.08 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.3955
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.5549
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.6046
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.6409
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.6618
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.6626
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.3955
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.5148
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.5427
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.5576
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.5629
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.5629
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.3955
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.6714
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.7909
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.9033
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9908
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 0.9964
Creating model gist$gte-large for task TwitterSemEval2015
Loading gist from cache for TwitterSemEval2015...
Loading gte-large from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

PairClassification
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.3955
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2238
    - TwitterSemEval2015, s2s
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1582


INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.0903
INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0099
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0010
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:root:

INFO:root:MRR@1: 0.4026
INFO:root:MRR@3: 0.5183
INFO:root:MRR@5: 0.5452
INFO:root:MRR@10: 0.5602
INFO:root:MRR@100: 0.5654
INFO:root:MRR@1000: 0.5655
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 2.83 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.39545, 'ndcg_at_3': 0.55494, 'ndcg_at_5': 0.60462, 'ndcg_at_10': 0.64089, 'ndcg_at_100': 0.6618, 'ndcg_at_1000': 0.66257, 'map_at_1': 0.39545, 'map_at_3': 0.51482, 'map_at_5': 0.54266, 'map_at_10': 0.55757, 'map_at_100': 0.56287, 'map_at_1000': 0.5629, 'recall_at_1': 0.39545, 'recall_at_3': 0.67141, 'recall_at_5': 0.7909, 'recall_at_10': 0.90327, 'recall_at_100': 0.99075, 'recall_at_1000': 0.99644, 'precision_at_1': 0.39545, 'precision_at_3': 0.2238, 'precision_at_5': 0.15818, 'precision_at_10': 0.09033, 'precision_at_100': 0.00991, 'precision_at_1000': 0.001, 'mrr_at_1': 0.40256, 'mrr_at_3': 0.51826, 'mrr_at_5': 0.54521, 'mrr_at_10': 0.56021, 'mrr_at_100': 0.56543, 'mrr_at_1000': 0.56547, 'evaluation_time': 2.83}
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS15 as it already exists
Creating model angle$flag-embedding for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading flag-embedding from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 3.27 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.870179412290636, 'accuracy_threshold': 0.8679511547088623, 'f1': 0.7091584158415841, 'f1_threshold': 0.8475695848464966, 'precision': 0.6678321678321678, 'recall': 0.7559366754617414, 'ap': 0.7707531337454235}, 'manhattan': {'accuracy': 0.8688680932228646, 'accuracy_threshold': 18.082210540771484, 'f1': 0.7061337355455003, 'f1_threshold': 19.258281707763672, 'precision': 0.6742678828612578, 'recall': 0.7411609498680739, 'ap': 0.7672470414496269}, 'euclidean': {'accuracy': 0.870179412290636, 'accuracy_threshold': 0.513904333114624, 'f1': 0.7091584158415841, 'f1_threshold': 0.5521420240402222, 'precision': 0.6678321678321678, 'recall': 0.7559366754617414, 'ap': 0.7707531131948018}, 'dot': {'accuracy': 0.870179412290636, 'accuracy_threshold': 0.8679512143135071, 'f1': 0.7091584158415841, 'f1_threshold': 0.8475696444511414, 'precision': 0.6678321678321678, 'recall': 0.7559366754617414, 'ap': 0.7707532254709606}, 'max': {'accuracy': 0.870179412290636, 'f1': 0.7091584158415841, 'ap': 0.7707532254709606}, 'evaluation_time': 3.27}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 0.92 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7355223880597015, 'f1': 0.6755898588953592, 'ap': 0.3635703986434023, 'accuracy_stderr': 0.03378413515137011, 'f1_stderr': 0.032557103713217926, 'ap_stderr': 0.03456062897303755, 'main_score': 0.7355223880597015}, 'evaluation_time': 0.92}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS15 as it already exists
Creating model gist$gte-large for task AmazonCounterfactualClassification
Loading gist from cache for AmazonCounterfactualClassification...
Loading gte-large from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 0.82 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7388059701492538, 'f1': 0.6767375533094266, 'ap': 0.36293797113717274, 'accuracy_stderr': 0.03885760055590609, 'f1_stderr': 0.03656237531442557, 'ap_stderr': 0.03782805649907301, 'main_score': 0.7388059701492538}, 'evaluation_time': 0.82}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS22 as it already exists
Creating model angle$flag-embedding$gist for task RedditClustering
Loading angle from cache for RedditClustering...
Loading flag-embedding from cache for RedditClustering...
Loading gist from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.abstasks.AbsTaskClustering:
Task: RedditClustering, split: test. Running...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:02<00:48,  2.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:03<00:34,  1.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:06<00:48,  2.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:07<00:38,  1.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:08<00:31,  1.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [00:10<00:32,  1.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [00:11<00:25,  1.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [00:13<00:29,  1.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [00:16<00:31,  1.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [00:19<00:33,  2.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [00:21<00:33,  2.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [00:22<00:22,  1.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [00:23<00:18,  1.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [00:25<00:20,  1.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [00:26<00:16,  1.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [00:29<00:18,  2.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [00:31<00:15,  1.90s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [00:32<00:10,  1.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [00:34<00:09,  1.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [00:39<00:14,  2.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS22 as it already exists
Creating model flag-embedding$gist$llmrails for task RedditClustering
Loading flag-embedding from cache for RedditClustering...
Loading gist from cache for RedditClustering...
Loading llmrails from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.abstasks.AbsTaskClustering:
Task: RedditClustering, split: test. Running...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:02<00:56,  2.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:03<00:37,  1.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:06<00:51,  2.35s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:08<00:41,  1.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:09<00:32,  1.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [00:10<00:32,  1.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [00:11<00:26,  1.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [00:14<00:30,  1.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [00:16<00:32,  2.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [00:19<00:32,  2.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [00:21<00:31,  2.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [00:22<00:22,  1.69s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [00:23<00:17,  1.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [00:25<00:18,  1.67s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [00:26<00:13,  1.37s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [00:28<00:15,  1.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [00:29<00:13,  1.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [00:30<00:09,  1.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [00:32<00:08,  1.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [00:35<00:09,  1.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [00:38<00:08,  2.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [00:40<00:07,  2.35s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [00:41<00:03,  1.81s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [00:43<00:01,  1.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [00:45<00:00,  1.98s/it]Clustering: 100%|██████████| 25/25 [00:45<00:00,  1.82s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 45.62 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.5938791567700561, 'v_measure_std': 0.04160593806090911, 'main_score': 0.5938791567700561, 'evaluation_time': 45.62}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS13 as it already exists
Creating model flag-embedding$gist$llmrails for task AskUbuntuDupQuestions
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 5.29 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6483592627318602, 'mrr': 0.7800795849272304, 'evaluation_time': 5.29}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Creating model flag-embedding$gist$llmrails for task SciFact
Loading flag-embedding from cache for SciFact...
Loading gist from cache for SciFact...
Loading llmrails from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 5183 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '4983', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.', 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 300 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '1', 'text': '0-dimensional biomaterials show inductive properties.'}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/mteb/evaluation/evaluators/utils.py:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 75.43 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.6433
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.6984
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.7213
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.7516
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.7723
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.7766
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.6159
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.6771
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.6926
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.7081
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.7131
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.7133
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.6159
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.7324
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.7899
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.8766
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9683
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 1.0000
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.6433
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2689
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1767
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.0997
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0110
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6433
INFO:root:MRR@3: 0.6922
INFO:root:MRR@5: 0.7064
INFO:root:MRR@10: 0.7166
INFO:root:MRR@100: 0.7208
INFO:root:MRR@1000: 0.7209
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 76.61 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.64333, 'ndcg_at_3': 0.69839, 'ndcg_at_5': 0.72134, 'ndcg_at_10': 0.75164, 'ndcg_at_100': 0.77231, 'ndcg_at_1000': 0.77657, 'map_at_1': 0.61594, 'map_at_3': 0.67707, 'map_at_5': 0.69265, 'map_at_10': 0.70814, 'map_at_100': 0.71312, 'map_at_1000': 0.71332, 'recall_at_1': 0.61594, 'recall_at_3': 0.73239, 'recall_at_5': 0.78994, 'recall_at_10': 0.87656, 'recall_at_100': 0.96833, 'recall_at_1000': 1.0, 'precision_at_1': 0.64333, 'precision_at_3': 0.26889, 'precision_at_5': 0.17667, 'precision_at_10': 0.09967, 'precision_at_100': 0.01097, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.64333, 'mrr_at_3': 0.69222, 'mrr_at_5': 0.70639, 'mrr_at_10': 0.71664, 'mrr_at_100': 0.72075, 'mrr_at_1000': 0.72093, 'evaluation_time': 76.61}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS22 as it already exists
Creating model angle$flag-embedding for task RedditClustering
Loading angle from cache for RedditClustering...
Loading flag-embedding from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
Skipping STS22 as it already exists
Creating model gist$gte-large for task RedditClustering
Loading gist from cache for RedditClustering...
Loading gte-large from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
    - RedditClustering, s2s
Clustering


    - RedditClustering, s2s
INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.abstasks.AbsTaskClustering:
Task: RedditClustering, split: test. Running...
INFO:mteb.abstasks.AbsTaskClustering:
Task: RedditClustering, split: test. Running...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:03<01:20,  3.35s/it]Clustering:   4%|▍         | 1/25 [00:03<01:20,  3.35s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:06<01:20,  3.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:07<01:21,  3.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Creating model flag-embedding$gist$llmrails for task ArguAna
Loading flag-embedding from cache for ArguAna...
Loading gist from cache for ArguAna...
Loading llmrails from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:11<01:27,  3.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:11<01:27,  3.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 8674 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'test-environment-aeghhgwpe-pro02b', 'title': 'animals environment general health health general weight philosophy ethics', 'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008"}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:14<01:15,  3.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:14<01:15,  3.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 1406 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': 'test-environment-aeghhgwpe-pro02a', 'text': "Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004"}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:17<01:07,  3.37s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:17<01:07,  3.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [00:21<01:06,  3.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [00:21<01:06,  3.52s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 3.45 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.4118
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.5720
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.6169
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.6533
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.6726
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.6734
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.4118
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.5316
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.5567
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.5718
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.5767
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.5767
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.4118
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.6892
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.7973
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.9097
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9908
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 0.9964
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.4118
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2297
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1595
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.0910
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0099
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.4196
INFO:root:MRR@3: 0.5338
INFO:root:MRR@5: 0.5593
INFO:root:MRR@10: 0.5747
INFO:root:MRR@100: 0.5795
INFO:root:MRR@1000: 0.5795
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 4.72 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.41181, 'ndcg_at_3': 0.57201, 'ndcg_at_5': 0.61685, 'ndcg_at_10': 0.65333, 'ndcg_at_100': 0.67258, 'ndcg_at_1000': 0.67335, 'map_at_1': 0.41181, 'map_at_3': 0.53165, 'map_at_5': 0.55672, 'map_at_10': 0.57185, 'map_at_100': 0.57667, 'map_at_1000': 0.57671, 'recall_at_1': 0.41181, 'recall_at_3': 0.68919, 'recall_at_5': 0.7973, 'recall_at_10': 0.90967, 'recall_at_100': 0.99075, 'recall_at_1000': 0.99644, 'precision_at_1': 0.41181, 'precision_at_3': 0.22973, 'precision_at_5': 0.15946, 'precision_at_10': 0.09097, 'precision_at_100': 0.00991, 'precision_at_1000': 0.001, 'mrr_at_1': 0.41963, 'mrr_at_3': 0.53378, 'mrr_at_5': 0.55928, 'mrr_at_10': 0.57473, 'mrr_at_100': 0.57949, 'mrr_at_1000': 0.57952, 'evaluation_time': 4.72}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [00:24<00:59,  3.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [00:24<00:59,  3.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [00:27<00:58,  3.43s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [00:27<00:58,  3.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [00:32<01:01,  3.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [00:32<01:01,  3.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [00:35<00:55,  3.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [00:36<00:55,  3.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [00:40<00:57,  4.08s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [00:40<00:57,  4.09s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [00:43<00:45,  3.48s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [00:43<00:45,  3.48s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [00:45<00:39,  3.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [00:45<00:39,  3.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [00:49<00:35,  3.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [00:49<00:36,  3.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [00:50<00:28,  2.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [00:51<00:28,  2.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [00:55<00:28,  3.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [00:55<00:29,  3.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [00:57<00:24,  3.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [00:57<00:24,  3.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [00:59<00:18,  2.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [00:59<00:18,  2.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [01:02<00:17,  2.87s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [01:02<00:17,  2.88s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [01:05<00:14,  2.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [01:06<00:14,  2.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [01:09<00:13,  3.28s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [01:09<00:13,  3.28s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [01:14<00:11,  3.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [01:14<00:11,  3.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [01:16<00:06,  3.16s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [01:16<00:06,  3.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [01:20<00:03,  3.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [01:20<00:03,  3.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [01:21<00:00,  2.82s/it]Clustering: 100%|██████████| 25/25 [01:21<00:00,  3.28s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 81.95 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.6187466947955226, 'v_measure_std': 0.0456654658426364, 'main_score': 0.6187466947955226, 'evaluation_time': 81.95}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [01:22<00:00,  2.92s/it]Clustering: 100%|██████████| 25/25 [01:22<00:00,  3.29s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 82.25 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.596849850820976, 'v_measure_std': 0.042315714575724216, 'main_score': 0.596849850820976, 'evaluation_time': 82.25}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS13 as it already exists
Creating model angle$flag-embedding for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Reranking
Skipping STS13 as it already exists
Creating model gist$gte-large for task AskUbuntuDupQuestions
Loading gist from cache for AskUbuntuDupQuestions...
Loading gte-large from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
    - AskUbuntuDupQuestions, s2s
Reranking


    - AskUbuntuDupQuestions, s2s
INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************


INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 2.94 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6430223348463596, 'mrr': 0.7739832036230927, 'evaluation_time': 2.94}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 2.98 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.645142525579911, 'mrr': 0.7773106010640637, 'evaluation_time': 2.98}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Creating model angle$flag-embedding for task SciFact
Loading angle from cache for SciFact...
Loading flag-embedding from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Retrieval
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Creating model gist$gte-large for task SciFact
Loading gist from cache for SciFact...
Loading gte-large from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
    - SciFact, s2p
Retrieval


    - SciFact, s2p
INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************


INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 5183 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 5183 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '4983', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.', 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '4983', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.', 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 300 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 300 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '1', 'text': '0-dimensional biomaterials show inductive properties.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '1', 'text': '0-dimensional biomaterials show inductive properties.'}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/mteb/evaluation/evaluators/utils.py:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.41 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.37 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.6400
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.6932
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.7168
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.7394
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.7673
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.7710
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.6233
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.6126
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.6963
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.6712
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.6876
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.6994
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.7242
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.7066
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.7463
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.7068
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.7649
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.7692
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.5969
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.6674
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.6859
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.6126
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.6977
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.7021
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.7023
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.7279
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.5969
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.7537
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.8224
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.8849
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.7883
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9683
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 1.0000
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.6233
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2744
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1833
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.1003
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.8509
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0110
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0011
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9717
INFO:root:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 1.0000
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.6400
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2667
INFO:root:MRR@1: 0.6233
INFO:root:MRR@3: 0.6844
INFO:root:MRR@5: 0.6994
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1753
INFO:root:MRR@10: 0.7067
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.0967
INFO:root:MRR@100: 0.7101
INFO:root:MRR@1000: 0.7102
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0110
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 1.99 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.62333, 'ndcg_at_3': 0.69625, 'ndcg_at_5': 0.72424, 'ndcg_at_10': 0.74626, 'ndcg_at_100': 0.76487, 'ndcg_at_1000': 0.76916, 'map_at_1': 0.59694, 'map_at_3': 0.66741, 'map_at_5': 0.68592, 'map_at_10': 0.69766, 'map_at_100': 0.70213, 'map_at_1000': 0.70232, 'recall_at_1': 0.59694, 'recall_at_3': 0.75367, 'recall_at_5': 0.82244, 'recall_at_10': 0.88489, 'recall_at_100': 0.96833, 'recall_at_1000': 1.0, 'precision_at_1': 0.62333, 'precision_at_3': 0.27444, 'precision_at_5': 0.18333, 'precision_at_10': 0.10033, 'precision_at_100': 0.01097, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.62333, 'mrr_at_3': 0.68444, 'mrr_at_5': 0.69944, 'mrr_at_10': 0.70666, 'mrr_at_100': 0.71007, 'mrr_at_1000': 0.71024, 'evaluation_time': 1.99}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6400
INFO:root:MRR@3: 0.6878
INFO:root:MRR@5: 0.7009
INFO:root:MRR@10: 0.7090
INFO:main:Running task: Banking77Classification
INFO:root:MRR@100: 0.7149
INFO:root:MRR@1000: 0.7150
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 2.14 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.64, 'ndcg_at_3': 0.6932, 'ndcg_at_5': 0.71679, 'ndcg_at_10': 0.73942, 'ndcg_at_100': 0.76731, 'ndcg_at_1000': 0.77104, 'map_at_1': 0.61261, 'map_at_3': 0.67115, 'map_at_5': 0.68764, 'map_at_10': 0.69937, 'map_at_100': 0.70661, 'map_at_1000': 0.70677, 'recall_at_1': 0.61261, 'recall_at_3': 0.72794, 'recall_at_5': 0.78828, 'recall_at_10': 0.85089, 'recall_at_100': 0.97167, 'recall_at_1000': 1.0, 'precision_at_1': 0.64, 'precision_at_3': 0.26667, 'precision_at_5': 0.17533, 'precision_at_10': 0.09667, 'precision_at_100': 0.011, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.64, 'mrr_at_3': 0.68778, 'mrr_at_5': 0.70094, 'mrr_at_10': 0.70903, 'mrr_at_100': 0.71488, 'mrr_at_1000': 0.71502, 'evaluation_time': 2.14}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Creating model gist$gte-large for task Banking77Classification
Loading gist from cache for Banking77Classification...
Loading gte-large from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Creating model angle$flag-embedding for task Banking77Classification
Loading angle from cache for Banking77Classification...
Loading flag-embedding from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 5.43 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8509740259740258, 'f1': 0.8451397874949418, 'accuracy_stderr': 0.004470627137158066, 'f1_stderr': 0.00553645899395339, 'main_score': 0.8509740259740258, 'evaluation_time': 5.43}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 6.70 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8471753246753246, 'f1': 0.8413718695448752, 'accuracy_stderr': 0.00412235389709478, 'f1_stderr': 0.00538230790178364, 'main_score': 0.8471753246753246, 'evaluation_time': 6.7}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model gist$gte-large for task ArguAna
Loading gist from cache for ArguAna...
Loading gte-large from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$flag-embedding for task ArguAna
Loading angle from cache for ArguAna...
Loading flag-embedding from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 8674 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 8674 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'test-environment-aeghhgwpe-pro02b', 'title': 'animals environment general health health general weight philosophy ethics', 'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008"}
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'test-environment-aeghhgwpe-pro02b', 'title': 'animals environment general health health general weight philosophy ethics', 'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008"}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 1406 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 1406 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': 'test-environment-aeghhgwpe-pro02a', 'text': "Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004"}
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': 'test-environment-aeghhgwpe-pro02a', 'text': "Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004"}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 5.02 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 5.02 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.3741
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.5289
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.5799
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.6226
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.6465
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.6471
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.4196
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.5784
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.6190
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.6567
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.6760
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.6769
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.3741
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.4196
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.5388
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.5612
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.4900
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.5769
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.5817
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.5817
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.4196
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.6935
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.7923
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.5184
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.9083
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9900
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 0.9964
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.5365
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.5428
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.4196
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.5429
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2311
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1585
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.3741
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.0908
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.6415
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.7653
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0099
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.8947
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9922
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 0.9964
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.3741
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2139
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0010
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1531
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.0895
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0099
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0010
INFO:root:

INFO:root:

INFO:root:MRR@1: 0.4260
INFO:root:MRR@3: 0.5408
INFO:root:MRR@5: 0.5639
INFO:root:MRR@10: 0.5795
INFO:root:MRR@100: 0.5842
INFO:root:MRR@1000: 0.5843
INFO:root:MRR@1: 0.3826
INFO:root:MRR@3: 0.4932
INFO:root:MRR@5: 0.5220
INFO:root:MRR@10: 0.5402
INFO:root:MRR@100: 0.5463
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 6.04 seconds
INFO:root:MRR@1000: 0.5464
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.41963, 'ndcg_at_3': 0.57843, 'ndcg_at_5': 0.61904, 'ndcg_at_10': 0.65675, 'ndcg_at_100': 0.67601, 'ndcg_at_1000': 0.67688, 'map_at_1': 0.41963, 'map_at_3': 0.53876, 'map_at_5': 0.56124, 'map_at_10': 0.57693, 'map_at_100': 0.58171, 'map_at_1000': 0.58175, 'recall_at_1': 0.41963, 'recall_at_3': 0.69346, 'recall_at_5': 0.79232, 'recall_at_10': 0.90825, 'recall_at_100': 0.99004, 'recall_at_1000': 0.99644, 'precision_at_1': 0.41963, 'precision_at_3': 0.23115, 'precision_at_5': 0.15846, 'precision_at_10': 0.09083, 'precision_at_100': 0.0099, 'precision_at_1000': 0.001, 'mrr_at_1': 0.42603, 'mrr_at_3': 0.54078, 'mrr_at_5': 0.56386, 'mrr_at_10': 0.5795, 'mrr_at_100': 0.58421, 'mrr_at_1000': 0.58425, 'evaluation_time': 6.04}
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 6.10 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.37411, 'ndcg_at_3': 0.52887, 'ndcg_at_5': 0.57989, 'ndcg_at_10': 0.62262, 'ndcg_at_100': 0.64648, 'ndcg_at_1000': 0.64706, 'map_at_1': 0.37411, 'map_at_3': 0.49004, 'map_at_5': 0.51839, 'map_at_10': 0.53652, 'map_at_100': 0.54284, 'map_at_1000': 0.54286, 'recall_at_1': 0.37411, 'recall_at_3': 0.64154, 'recall_at_5': 0.76529, 'recall_at_10': 0.89474, 'recall_at_100': 0.99218, 'recall_at_1000': 0.99644, 'precision_at_1': 0.37411, 'precision_at_3': 0.21385, 'precision_at_5': 0.15306, 'precision_at_10': 0.08947, 'precision_at_100': 0.00992, 'precision_at_1000': 0.001, 'mrr_at_1': 0.38265, 'mrr_at_3': 0.49324, 'mrr_at_5': 0.52201, 'mrr_at_10': 0.54016, 'mrr_at_100': 0.54634, 'mrr_at_1000': 0.54636, 'evaluation_time': 6.1}
INFO:main:Running task: ArxivClusteringS2S
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Converting the results to a CSV file...
Using model name gte-large$llmrails
Converting results/gte-large$llmrails to results/gte-large$llmrails_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model gte-large$mixed-bread...
Creating model gte-large$mixed-bread for task ArxivClusteringS2S
Loading gte-large from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name angle$gist$llmrails
Converting results/angle$gist$llmrails to results/angle$gist$llmrails_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$gist$mixed-bread...
Creating model angle$gist$mixed-bread for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
Clustering
    - ArxivClusteringS2S, s2s
    - ArxivClusteringS2S, s2s




INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:02<01:13,  2.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:02<01:22,  2.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:03<00:55,  1.90s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:04<01:03,  2.19s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:04<00:41,  1.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [00:10<01:19,  2.94s/it]Clustering:  10%|▉         | 3/31 [00:10<01:44,  3.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [00:11<01:00,  2.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [00:11<01:20,  2.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [00:12<00:49,  1.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [00:17<01:12,  3.02s/it]Clustering:  16%|█▌        | 5/31 [00:17<01:44,  4.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [00:18<00:55,  2.43s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [00:19<01:18,  3.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [00:19<00:43,  1.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [00:23<01:27,  3.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [00:23<00:54,  2.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [00:28<01:33,  4.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [00:29<01:07,  3.37s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [00:31<00:55,  2.93s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [00:31<01:17,  3.54s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [00:32<00:46,  2.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [00:33<01:05,  3.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [00:34<00:40,  2.39s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [00:43<01:10,  4.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [00:44<01:49,  5.48s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [00:46<00:57,  3.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [00:47<01:32,  4.87s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [00:49<00:48,  3.48s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [00:54<00:53,  4.09s/it]Clustering:  42%|████▏     | 13/31 [00:54<01:38,  5.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [01:03<01:06,  5.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [01:03<01:52,  6.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [01:11<01:09,  6.35s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [01:12<01:54,  7.13s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [01:12<00:48,  4.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [01:15<00:37,  4.19s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [01:21<00:36,  4.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [01:21<01:55,  7.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [01:21<00:24,  3.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [01:27<00:24,  4.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [01:27<01:43,  7.40s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [01:28<00:15,  3.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [01:36<00:18,  4.68s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [01:37<01:43,  7.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [01:37<00:10,  3.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [01:45<00:09,  4.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [01:46<01:38,  8.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [01:46<00:03,  3.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [01:55<00:00,  5.27s/it]Clustering: 100%|██████████| 31/31 [01:55<00:00,  3.72s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 115.44 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43203609634371337, 'v_measure_std': 0.143224231502551, 'main_score': 0.43203609634371337, 'evaluation_time': 115.44}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [01:55<01:35,  8.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [01:58<01:08,  6.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [01:58<00:43,  4.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [02:01<00:34,  4.37s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [02:04<00:26,  3.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [02:06<00:20,  3.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [02:08<00:13,  2.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Creating model gte-large$mixed-bread for task EmotionClassification
Loading gte-large from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [02:10<00:11,  2.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 2.60 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.53865, 'f1': 0.4689308625950209, 'accuracy_stderr': 0.028050891251437973, 'f1_stderr': 0.016518116137579524, 'main_score': 0.53865, 'evaluation_time': 2.6}
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [02:14<00:09,  3.09s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [02:17<00:05,  2.91s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [02:19<00:02,  2.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [02:22<00:00,  2.76s/it]Clustering: 100%|██████████| 31/31 [02:22<00:00,  4.59s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 142.29 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4316816461183033, 'v_measure_std': 0.1430119493562686, 'main_score': 0.4316816461183033, 'evaluation_time': 142.29}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model gte-large$mixed-bread for task TwitterSemEval2015
Loading gte-large from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Creating model angle$gist$mixed-bread for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading gist from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 32.88 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8733981045478929, 'accuracy_threshold': 0.8734050393104553, 'f1': 0.7115916519989942, 'f1_threshold': 0.8542459607124329, 'precision': 0.6796349663784822, 'recall': 0.7467018469656992, 'ap': 0.7799820512808664}, 'manhattan': {'accuracy': 0.8723848125409788, 'accuracy_threshold': 18.042158126831055, 'f1': 0.70917225950783, 'f1_threshold': 19.08858871459961, 'precision': 0.6703477443609023, 'recall': 0.7527704485488127, 'ap': 0.7760642292048222}, 'euclidean': {'accuracy': 0.8733981045478929, 'accuracy_threshold': 0.5031797885894775, 'f1': 0.7115916519989942, 'f1_threshold': 0.5399148464202881, 'precision': 0.6796349663784822, 'recall': 0.7467018469656992, 'ap': 0.7799820942216088}, 'dot': {'accuracy': 0.8733981045478929, 'accuracy_threshold': 0.8734050989151001, 'f1': 0.7115916519989942, 'f1_threshold': 0.8542460799217224, 'precision': 0.6796349663784822, 'recall': 0.7467018469656992, 'ap': 0.7799819615255719}, 'max': {'accuracy': 0.8733981045478929, 'f1': 0.7115916519989942, 'ap': 0.7799820942216088}, 'evaluation_time': 32.88}
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
INFO:main:Running task: AmazonCounterfactualClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS15 as it already exists
Creating model gte-large$mixed-bread for task AmazonCounterfactualClassification
Loading gte-large from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 2.35 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.561, 'f1': 0.49560423073127896, 'accuracy_stderr': 0.022319274181747034, 'f1_stderr': 0.013321008525644348, 'main_score': 0.561, 'evaluation_time': 2.35}
INFO:main:Running task: TwitterSemEval2015
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 0.90 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7195522388059701, 'f1': 0.6589022777828194, 'ap': 0.3449250237498666, 'accuracy_stderr': 0.035272228392741335, 'f1_stderr': 0.0333596881097637, 'ap_stderr': 0.03294218420472533, 'main_score': 0.7195522388059701}, 'evaluation_time': 0.9}
INFO:main:Running task: RedditClustering
Evaluating the model cohere$flag-embedding$gist$gte-large$llmrails$voyage...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name cohere$flag-embedding$gist$gte-large$llmrails$voyage
Converting results/cohere$flag-embedding$gist$gte-large$llmrails$voyage to results/cohere$flag-embedding$gist$gte-large$llmrails$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$flag-embedding$gist$gte-large$mixed-bread$voyage...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name cohere$flag-embedding$gist$gte-large$mixed-bread$voyage
Converting results/cohere$flag-embedding$gist$gte-large$mixed-bread$voyage to results/cohere$flag-embedding$gist$gte-large$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$flag-embedding$gist$llmrails$mixed-bread$voyage...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name cohere$flag-embedding$gist$llmrails$mixed-bread$voyage
Converting results/cohere$flag-embedding$gist$llmrails$mixed-bread$voyage to results/cohere$flag-embedding$gist$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage
Converting results/cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage to results/cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$gist$gte-large$llmrails$mixed-bread$voyage...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name cohere$gist$gte-large$llmrails$mixed-bread$voyage
Converting results/cohere$gist$gte-large$llmrails$mixed-bread$voyage to results/cohere$gist$gte-large$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage
Converting results/flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage to results/flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist$mixed-bread for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 1.26 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8747690290278357, 'accuracy_threshold': 0.8135254383087158, 'f1': 0.7149538617115409, 'f1_threshold': 0.7886128425598145, 'precision': 0.6862412035913613, 'recall': 0.7461741424802111, 'ap': 0.7836291945064717}, 'manhattan': {'accuracy': 0.8754842939738928, 'accuracy_threshold': 26.385536193847656, 'f1': 0.7159916926272066, 'f1_threshold': 27.963581085205078, 'precision': 0.7046499744506899, 'recall': 0.7277044854881266, 'ap': 0.7834106380697007}, 'euclidean': {'accuracy': 0.8747690290278357, 'accuracy_threshold': 0.610695481300354, 'f1': 0.7149538617115409, 'f1_threshold': 0.650210976600647, 'precision': 0.6862412035913613, 'recall': 0.7461741424802111, 'ap': 0.7836291685405077}, 'dot': {'accuracy': 0.8747690290278357, 'accuracy_threshold': 0.8135254979133606, 'f1': 0.7149538617115409, 'f1_threshold': 0.7886127233505249, 'precision': 0.6862412035913613, 'recall': 0.7461741424802111, 'ap': 0.7836292580228242}, 'max': {'accuracy': 0.8754842939738928, 'f1': 0.7159916926272066, 'ap': 0.7836292580228242}, 'evaluation_time': 1.26}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS15 as it already exists
Creating model angle$gist$mixed-bread for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading gist from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 1.16 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7349253731343283, 'f1': 0.6744799464114876, 'ap': 0.3619162678878269, 'accuracy_stderr': 0.03650588834915927, 'f1_stderr': 0.03496096093916173, 'ap_stderr': 0.035816676711669757, 'main_score': 0.7349253731343283}, 'evaluation_time': 1.16}
INFO:main:Running task: RedditClustering
Evaluating the model angle$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name angle$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage
Converting results/angle$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage to results/angle$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage
Converting results/cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage to results/cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage
Converting results/angle$cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage to results/angle$cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS22 as it already exists
Creating model gte-large$mixed-bread for task RedditClustering
Loading gte-large from cache for RedditClustering...
Loading mixed-bread from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.abstasks.AbsTaskClustering:
Task: RedditClustering, split: test. Running...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:01<00:42,  1.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:02<00:22,  1.00it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:03<00:20,  1.05it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:03<00:16,  1.31it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:04<00:13,  1.51it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [00:04<00:12,  1.55it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [00:05<00:09,  1.83it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [00:05<00:10,  1.66it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [00:06<00:10,  1.45it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [00:07<00:11,  1.26it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [00:08<00:10,  1.28it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [00:08<00:07,  1.63it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [00:09<00:06,  1.84it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [00:09<00:06,  1.63it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [00:10<00:05,  1.88it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [00:10<00:05,  1.61it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [00:11<00:04,  1.67it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [00:11<00:03,  1.93it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [00:12<00:03,  1.90it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [00:13<00:03,  1.56it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [00:14<00:02,  1.36it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [00:15<00:02,  1.33it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [00:15<00:01,  1.66it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [00:15<00:00,  1.72it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [00:16<00:00,  1.51it/s]Clustering: 100%|██████████| 25/25 [00:16<00:00,  1.50it/s]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 16.75 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.606583048683175, 'v_measure_std': 0.04375684778159731, 'main_score': 0.606583048683175, 'evaluation_time': 16.75}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS13 as it already exists
Creating model gte-large$mixed-bread for task AskUbuntuDupQuestions
Loading gte-large from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
Evaluating the model angle$gist$gte-large$llmrails$mixed-bread...
Creating model angle$gist$gte-large$llmrails$mixed-bread for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 3.29 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6470562523946587, 'mrr': 0.7783383898342345, 'evaluation_time': 3.29}
INFO:main:Running task: SciFact
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Creating model gte-large$mixed-bread for task SciFact
Loading gte-large from cache for SciFact...
Loading mixed-bread from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 5183 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '4983', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.', 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:08<04:25,  8.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:11<02:35,  5.37s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 300 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '1', 'text': '0-dimensional biomaterials show inductive properties.'}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:14<01:57,  4.19s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 1.38 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.6367
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.7037
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.7269
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.7541
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.7708
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.7762
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.6093
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.6782
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.6940
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.7076
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.7117
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.7120
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.6093
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.7495
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.8083
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.8882
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9617
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 1.0000
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.6367
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2744
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1807
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.1007
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0109
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6367
INFO:root:MRR@3: 0.6950
INFO:root:MRR@5: 0.7077
INFO:root:MRR@10: 0.7167
INFO:root:MRR@100: 0.7198
INFO:root:MRR@1000: 0.7201
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 1.94 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.63667, 'ndcg_at_3': 0.70366, 'ndcg_at_5': 0.72688, 'ndcg_at_10': 0.7541, 'ndcg_at_100': 0.77082, 'ndcg_at_1000': 0.77622, 'map_at_1': 0.60928, 'map_at_3': 0.6782, 'map_at_5': 0.69405, 'map_at_10': 0.70761, 'map_at_100': 0.71173, 'map_at_1000': 0.71202, 'recall_at_1': 0.60928, 'recall_at_3': 0.7495, 'recall_at_5': 0.80828, 'recall_at_10': 0.88822, 'recall_at_100': 0.96167, 'recall_at_1000': 1.0, 'precision_at_1': 0.63667, 'precision_at_3': 0.27444, 'precision_at_5': 0.18067, 'precision_at_10': 0.10067, 'precision_at_100': 0.0109, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.63667, 'mrr_at_3': 0.695, 'mrr_at_5': 0.70767, 'mrr_at_10': 0.71674, 'mrr_at_100': 0.71983, 'mrr_at_1000': 0.7201, 'evaluation_time': 1.94}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [00:17<01:44,  3.88s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [00:22<01:47,  4.13s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Creating model gte-large$mixed-bread for task Banking77Classification
Loading gte-large from cache for Banking77Classification...
Loading mixed-bread from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [00:27<01:49,  4.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 4.96 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8379220779220778, 'f1': 0.8304633923800567, 'accuracy_stderr': 0.004744705262891311, 'f1_stderr': 0.005980046633242933, 'main_score': 0.8379220779220778, 'evaluation_time': 4.96}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [00:34<02:04,  5.18s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [00:38<01:50,  4.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model gte-large$mixed-bread for task ArguAna
Loading gte-large from cache for ArguAna...
Loading mixed-bread from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [00:42<01:43,  4.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 8674 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'test-environment-aeghhgwpe-pro02b', 'title': 'animals environment general health health general weight philosophy ethics', 'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008"}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [00:47<01:38,  4.69s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 1406 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': 'test-environment-aeghhgwpe-pro02a', 'text': "Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004"}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.79 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.3990
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.5639
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.6129
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.6473
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.6675
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.6683
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.3990
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.5224
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.5499
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.5642
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.5695
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.5696
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.3990
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.6842
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.8023
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.9083
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9908
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 0.9964
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.3990
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2281
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1605
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.0908
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0099
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.4075
INFO:root:MRR@3: 0.5263
INFO:root:MRR@5: 0.5529
INFO:root:MRR@10: 0.5674
INFO:root:MRR@100: 0.5725
INFO:root:MRR@1000: 0.5726
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 3.77 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.399, 'ndcg_at_3': 0.56386, 'ndcg_at_5': 0.61293, 'ndcg_at_10': 0.64732, 'ndcg_at_100': 0.66754, 'ndcg_at_1000': 0.66834, 'map_at_1': 0.399, 'map_at_3': 0.5224, 'map_at_5': 0.54989, 'map_at_10': 0.56416, 'map_at_100': 0.56951, 'map_at_1000': 0.56955, 'recall_at_1': 0.399, 'recall_at_3': 0.68421, 'recall_at_5': 0.80228, 'recall_at_10': 0.90825, 'recall_at_100': 0.99075, 'recall_at_1000': 0.99644, 'precision_at_1': 0.399, 'precision_at_3': 0.22807, 'precision_at_5': 0.16046, 'precision_at_10': 0.09083, 'precision_at_100': 0.00991, 'precision_at_1000': 0.001, 'mrr_at_1': 0.40754, 'mrr_at_3': 0.52632, 'mrr_at_5': 0.55292, 'mrr_at_10': 0.56737, 'mrr_at_100': 0.57252, 'mrr_at_1000': 0.57256, 'evaluation_time': 3.77}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [00:54<01:47,  5.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [01:00<01:48,  5.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [01:08<01:51,  6.22s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [01:19<02:13,  7.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [01:24<01:51,  6.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [01:28<01:28,  5.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [01:31<01:10,  5.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [01:34<00:58,  4.53s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [01:37<00:48,  4.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS22 as it already exists
Creating model angle$gist$mixed-bread for task RedditClustering
Loading angle from cache for RedditClustering...
Loading gist from cache for RedditClustering...
Loading mixed-bread from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [01:40<00:41,  3.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClustering:
Task: RedditClustering, split: test. Running...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:01<00:35,  1.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [01:44<00:38,  3.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [01:46<00:29,  3.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:03<00:44,  1.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Evaluating the model cohere$gist$llmrails$mixed-bread$voyage...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name cohere$gist$llmrails$mixed-bread$voyage
Converting results/cohere$gist$llmrails$mixed-bread$voyage to results/cohere$gist$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$gte-large$llmrails$mixed-bread$voyage...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name cohere$gte-large$llmrails$mixed-bread$voyage
Converting results/cohere$gte-large$llmrails$mixed-bread$voyage to results/cohere$gte-large$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model flag-embedding$gist$gte-large$llmrails$mixed-bread...
Creating model flag-embedding$gist$gte-large$llmrails$mixed-bread for task ArxivClusteringS2S
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:06<00:54,  2.48s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [01:51<00:31,  3.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:09<00:49,  2.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:09<00:35,  1.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [00:12<00:39,  2.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [01:55<00:26,  3.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [00:13<00:28,  1.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [00:16<00:36,  2.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [01:59<00:23,  3.88s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [02:08<00:27,  5.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:14<07:23, 14.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [00:26<01:13,  4.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [00:28<00:55,  3.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:33<08:14, 17.05s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [02:28<00:38,  9.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  44%|████▍     | 11/25 [00:45<01:51,  7.94s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [00:45<01:13,  5.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [00:46<00:49,  4.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:36<04:57, 10.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [00:48<00:37,  3.40s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [00:52<00:35,  3.52s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [02:35<00:26,  8.82s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [00:41<03:47,  8.41s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [00:54<00:28,  3.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [00:56<00:23,  2.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [02:40<00:15,  7.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [00:59<00:18,  2.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [00:47<03:18,  7.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [01:00<00:13,  2.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [02:43<00:06,  6.48s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [01:02<00:11,  2.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [00:52<02:44,  6.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [01:07<00:12,  3.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [02:50<00:00,  6.61s/it]Clustering: 100%|██████████| 31/31 [02:50<00:00,  5.51s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 170.74 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4319158260384248, 'v_measure_std': 0.14367055447665086, 'main_score': 0.4319158260384248, 'evaluation_time': 170.74}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [00:57<02:24,  6.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [01:09<00:08,  2.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [01:09<00:04,  2.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  96%|█████████▌| 24/25 [01:11<00:01,  1.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [01:00<01:56,  5.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [01:12<00:00,  1.71s/it]Clustering: 100%|██████████| 25/25 [01:12<00:00,  2.91s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 72.74 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.6048096742368911, 'v_measure_std': 0.04444694161057801, 'main_score': 0.6048096742368911, 'evaluation_time': 72.74}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [01:03<01:37,  4.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [01:06<01:25,  4.09s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS13 as it already exists
Creating model angle$gist$mixed-bread for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [01:12<01:30,  4.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 3.26 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6481794339851356, 'mrr': 0.7780251066262147, 'evaluation_time': 3.26}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [01:18<01:35,  5.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Creating model angle$gist$mixed-bread for task SciFact
Loading angle from cache for SciFact...
Loading gist from cache for SciFact...
Loading mixed-bread from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [01:24<01:39,  5.52s/it]INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 5183 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '4983', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.', 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [01:31<01:38,  5.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 300 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '1', 'text': '0-dimensional biomaterials show inductive properties.'}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/mteb/evaluation/evaluators/utils.py:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 3.51 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.6400
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.6977
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.7195
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.7472
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.7700
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.7744
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.6126
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.6750
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.6899
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.7044
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.7100
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.7102
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.6126
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.7351
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.7899
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.8682
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9683
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 1.0000
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.6400
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2689
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1767
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.0987
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0110
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6400
INFO:root:MRR@3: 0.6928
INFO:root:MRR@5: 0.7049
INFO:root:MRR@10: 0.7145
INFO:root:MRR@100: 0.7190
INFO:root:MRR@1000: 0.7192
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 4.12 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.64, 'ndcg_at_3': 0.69771, 'ndcg_at_5': 0.71951, 'ndcg_at_10': 0.74723, 'ndcg_at_100': 0.77004, 'ndcg_at_1000': 0.77438, 'map_at_1': 0.61261, 'map_at_3': 0.67496, 'map_at_5': 0.68992, 'map_at_10': 0.70437, 'map_at_100': 0.71, 'map_at_1000': 0.71021, 'recall_at_1': 0.61261, 'recall_at_3': 0.73506, 'recall_at_5': 0.78994, 'recall_at_10': 0.86822, 'recall_at_100': 0.96833, 'recall_at_1000': 1.0, 'precision_at_1': 0.64, 'precision_at_3': 0.26889, 'precision_at_5': 0.17667, 'precision_at_10': 0.09867, 'precision_at_100': 0.01097, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.64, 'mrr_at_3': 0.69278, 'mrr_at_5': 0.70494, 'mrr_at_10': 0.71445, 'mrr_at_100': 0.71902, 'mrr_at_1000': 0.71922, 'evaluation_time': 4.12}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [01:38<01:39,  6.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [01:56<02:25,  9.67s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [02:00<01:50,  7.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Creating model angle$gist$mixed-bread for task Banking77Classification
Loading angle from cache for Banking77Classification...
Loading gist from cache for Banking77Classification...
Loading mixed-bread from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [02:03<01:25,  6.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 8.48 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8557792207792208, 'f1': 0.8506733126907404, 'accuracy_stderr': 0.004472513079927936, 'f1_stderr': 0.005573699273265814, 'main_score': 0.8557792207792208, 'evaluation_time': 8.48}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [02:13<01:32,  7.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [02:17<01:10,  6.40s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [02:19<00:52,  5.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [02:20<00:34,  3.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist$mixed-bread for task ArguAna
Loading angle from cache for ArguAna...
Loading gist from cache for ArguAna...
Loading mixed-bread from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [02:22<00:27,  3.46s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [02:24<00:20,  2.90s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 8674 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'test-environment-aeghhgwpe-pro02b', 'title': 'animals environment general health health general weight philosophy ethics', 'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008"}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [02:26<00:16,  2.68s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [02:27<00:10,  2.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [02:29<00:08,  2.13s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 1406 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': 'test-environment-aeghhgwpe-pro02a', 'text': "Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004"}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [02:32<00:06,  2.22s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [02:34<00:04,  2.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [02:35<00:02,  2.00s/it]INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 4.48 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.4154
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.5797
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.6251
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.6591
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.6784
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.6790
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.4154
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.5385
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.5639
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.5783
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.5833
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.5833
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.4154
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.6992
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.8087
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.9118
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9922
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 0.9964
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.4154
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2331
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1617
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.0912
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0099
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.4232
INFO:root:MRR@3: 0.5416
INFO:root:MRR@5: 0.5667
INFO:root:MRR@10: 0.5810
INFO:root:MRR@100: 0.5859
INFO:root:MRR@1000: 0.5859
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 5.43 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.41536, 'ndcg_at_3': 0.5797, 'ndcg_at_5': 0.62509, 'ndcg_at_10': 0.65906, 'ndcg_at_100': 0.67842, 'ndcg_at_1000': 0.679, 'map_at_1': 0.41536, 'map_at_3': 0.53853, 'map_at_5': 0.56388, 'map_at_10': 0.57827, 'map_at_100': 0.58326, 'map_at_1000': 0.58329, 'recall_at_1': 0.41536, 'recall_at_3': 0.69915, 'recall_at_5': 0.80868, 'recall_at_10': 0.91181, 'recall_at_100': 0.99218, 'recall_at_1000': 0.99644, 'precision_at_1': 0.41536, 'precision_at_3': 0.23305, 'precision_at_5': 0.16174, 'precision_at_10': 0.09118, 'precision_at_100': 0.00992, 'precision_at_1000': 0.001, 'mrr_at_1': 0.42319, 'mrr_at_3': 0.54161, 'mrr_at_5': 0.56668, 'mrr_at_10': 0.58099, 'mrr_at_100': 0.58591, 'mrr_at_1000': 0.58594, 'evaluation_time': 5.43}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [02:37<00:00,  2.08s/it]Clustering: 100%|██████████| 31/31 [02:37<00:00,  5.10s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 158.00 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4319456870092069, 'v_measure_std': 0.14360323418008958, 'main_score': 0.4319456870092069, 'evaluation_time': 158.0}
INFO:main:Running task: ArxivClusteringS2S
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model flag-embedding$gte-large$llmrails$mixed-bread$voyage...
Creating model flag-embedding$gte-large$llmrails$mixed-bread$voyage for task ArxivClusteringS2S
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:12<06:14, 12.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:19<04:31,  9.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:24<03:29,  7.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [00:30<03:06,  6.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [00:37<02:58,  6.88s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [00:45<03:01,  7.25s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [00:55<03:10,  7.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [01:01<02:52,  7.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [01:05<02:17,  6.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [01:07<01:46,  5.05s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [01:11<01:35,  4.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [01:15<01:23,  4.41s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [01:19<01:17,  4.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [01:23<01:11,  4.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [01:27<01:05,  4.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [01:31<01:03,  4.22s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [01:35<00:57,  4.13s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [01:39<00:52,  4.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [01:43<00:47,  3.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [01:46<00:42,  3.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [01:50<00:37,  3.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [01:50<00:24,  2.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [01:54<00:23,  3.00s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [01:56<00:19,  2.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [01:59<00:16,  2.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [02:00<00:10,  2.18s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [02:03<00:09,  2.48s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [02:06<00:08,  2.82s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [02:11<00:06,  3.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [02:15<00:03,  3.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [02:19<00:00,  3.85s/it]Clustering: 100%|██████████| 31/31 [02:19<00:00,  4.51s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 139.89 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4332938501008272, 'v_measure_std': 0.14286261135536665, 'main_score': 0.4332938501008272, 'evaluation_time': 139.89}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model angle$cohere$flag-embedding$gist$llmrails$voyage...
Creating model angle$cohere$flag-embedding$gist$llmrails$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Evaluating the model angle$flag-embedding$gist$gte-large$llmrails$voyage...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name angle$flag-embedding$gist$gte-large$llmrails$voyage
Converting results/angle$flag-embedding$gist$gte-large$llmrails$voyage to results/angle$flag-embedding$gist$gte-large$llmrails$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$flag-embedding$gist$gte-large$mixed-bread$voyage...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name angle$flag-embedding$gist$gte-large$mixed-bread$voyage
Converting results/angle$flag-embedding$gist$gte-large$mixed-bread$voyage to results/angle$flag-embedding$gist$gte-large$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$flag-embedding$gist$llmrails$mixed-bread$voyage...
Creating model angle$flag-embedding$gist$llmrails$mixed-bread$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
Clustering
    - ArxivClusteringS2S, s2s
    - ArxivClusteringS2S, s2s




INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:09<04:58,  9.95s/it]Clustering:   3%|▎         | 1/31 [00:09<04:58,  9.94s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:14<03:18,  6.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:15<03:28,  7.18s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:18<02:29,  5.35s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:19<02:47,  5.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [00:21<02:07,  4.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [00:24<02:27,  5.46s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [00:26<02:03,  4.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [00:30<02:24,  5.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [00:32<02:05,  5.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [00:36<02:25,  5.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [00:38<02:09,  5.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [00:43<02:29,  6.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [00:45<02:14,  5.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [00:50<02:28,  6.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [00:51<02:09,  5.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [00:56<02:21,  6.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [00:57<02:06,  6.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [01:03<02:13,  6.35s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [01:06<02:18,  6.93s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [01:11<02:21,  7.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Evaluating the model angle$cohere$gist$gte-large$llmrails$mixed-bread...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$gist$gte-large$llmrails$mixed-bread
Converting results/angle$cohere$gist$gte-large$llmrails$mixed-bread to results/angle$cohere$gist$gte-large$llmrails$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$gist$gte-large$llmrails$voyage...
Creating model angle$cohere$gist$gte-large$llmrails$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading cohere from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [01:16<02:26,  7.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [01:28<03:09,  9.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [01:28<02:46,  9.22s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [01:35<02:24,  8.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [01:36<02:47,  9.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [01:43<02:13,  8.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [01:44<02:32,  8.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [01:50<01:57,  7.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [01:50<02:10,  8.18s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [01:57<01:46,  7.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [01:58<02:02,  8.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [02:05<01:42,  7.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [02:07<01:58,  8.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [02:11<01:25,  7.16s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [02:16<01:48,  8.37s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [02:18<01:18,  7.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [02:23<01:38,  8.19s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [02:25<01:10,  7.09s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [02:25<00:46,  5.16s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [02:31<01:26,  7.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [02:32<00:43,  5.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [02:36<00:34,  4.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [02:37<01:13,  7.33s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [02:37<00:48,  5.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [02:39<00:27,  4.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [02:42<00:20,  4.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [02:44<00:45,  5.68s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [02:46<00:16,  4.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [02:47<00:34,  4.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [02:50<00:11,  3.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [02:51<00:28,  4.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [02:54<00:21,  4.25s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [02:55<00:08,  4.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [02:59<00:04,  4.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [02:59<00:18,  4.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [03:02<00:00,  3.88s/it]Clustering: 100%|██████████| 31/31 [03:02<00:00,  5.88s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 182.39 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43145118758601103, 'v_measure_std': 0.14315680714214862, 'main_score': 0.43145118758601103, 'evaluation_time': 182.39}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model angle$cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread
Converting results/angle$cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread to results/angle$cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$gist$gte-large$llmrails$voyage...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gist$gte-large$llmrails$voyage
Converting results/angle$cohere$flag-embedding$gist$gte-large$llmrails$voyage to results/angle$cohere$flag-embedding$gist$gte-large$llmrails$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$gist$gte-large$mixed-bread$voyage...
Skipping ArxivClusteringS2S as it already exists
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gist$gte-large$mixed-bread$voyage
Converting results/angle$cohere$flag-embedding$gist$gte-large$mixed-bread$voyage to results/angle$cohere$flag-embedding$gist$gte-large$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$gist$llmrails$mixed-bread$voyage...
Creating model angle$cohere$flag-embedding$gist$llmrails$mixed-bread$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [03:03<00:12,  4.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [03:06<00:07,  3.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [03:10<00:03,  3.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:07<03:42,  7.43s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [03:15<00:00,  4.20s/it]Clustering: 100%|██████████| 31/31 [03:15<00:00,  6.31s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 195.48 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43577798815128144, 'v_measure_std': 0.14175619943552434, 'main_score': 0.43577798815128144, 'evaluation_time': 195.48}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:11<02:43,  5.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:15<02:16,  4.87s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [00:20<02:05,  4.66s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [00:25<02:10,  5.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [00:30<02:05,  5.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Creating model angle$cohere$flag-embedding$gist$llmrails$voyage for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading cohere from cache for EmotionClassification...
Loading flag-embedding from cache for EmotionClassification...
Loading gist from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 2.64 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.56705, 'f1': 0.5044293043735565, 'accuracy_stderr': 0.02102433114274982, 'f1_stderr': 0.01248665840750702, 'main_score': 0.56705, 'evaluation_time': 2.64}
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [00:38<02:19,  5.82s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [00:44<02:20,  6.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [00:51<02:18,  6.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [00:59<02:19,  6.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [01:10<02:40,  8.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gist$llmrails$voyage for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading cohere from cache for TwitterSemEval2015...
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [01:24<03:06,  9.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 16.52 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8770936401025213, 'accuracy_threshold': 0.8074047099696989, 'f1': 0.7217736767909778, 'f1_threshold': 0.793731608383203, 'precision': 0.7017194119112883, 'recall': 0.7430079155672823, 'ap': 0.7899573220560506}, 'manhattan': {'accuracy': 0.8771532455146928, 'accuracy_threshold': 36.924465060086625, 'f1': 0.7195754134781536, 'f1_threshold': 39.661445356119756, 'precision': 0.6760204081632653, 'recall': 0.7691292875989446, 'ap': 0.7902626977092514}, 'euclidean': {'accuracy': 0.8770936401025213, 'accuracy_threshold': 0.6206372370585622, 'f1': 0.7217736767909778, 'f1_threshold': 0.6422902639991411, 'precision': 0.7017194119112883, 'recall': 0.7430079155672823, 'ap': 0.7899573220560506}, 'dot': {'accuracy': 0.8770936401025213, 'accuracy_threshold': 0.8074047099696988, 'f1': 0.7217736767909778, 'f1_threshold': 0.793731608383203, 'precision': 0.7017194119112883, 'recall': 0.7430079155672823, 'ap': 0.7899573220560506}, 'max': {'accuracy': 0.8771532455146928, 'f1': 0.7217736767909778, 'ap': 0.7902626977092514}, 'evaluation_time': 16.52}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [01:37<03:18, 11.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS15 as it already exists
Creating model angle$cohere$flag-embedding$gist$llmrails$voyage for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading cohere from cache for AmazonCounterfactualClassification...
Loading flag-embedding from cache for AmazonCounterfactualClassification...
Loading gist from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [01:43<02:41,  9.49s/it]INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 0.54 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7597014925373134, 'f1': 0.699034478937351, 'ap': 0.38989321629105067, 'accuracy_stderr': 0.03861606806568532, 'f1_stderr': 0.03710275863430887, 'ap_stderr': 0.04159521686958354, 'main_score': 0.7597014925373134}, 'evaluation_time': 0.54}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [01:50<02:15,  8.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [01:56<01:55,  7.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [02:01<01:39,  7.08s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [02:07<01:27,  6.69s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [02:13<01:17,  6.43s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [02:18<01:06,  6.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [02:23<00:56,  5.67s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [02:23<00:37,  4.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [02:28<00:34,  4.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [02:31<00:27,  3.91s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [02:35<00:23,  3.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [02:36<00:15,  3.16s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [02:40<00:13,  3.40s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [02:44<00:10,  3.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [02:47<00:07,  3.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [02:50<00:03,  3.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [02:54<00:00,  3.47s/it]Clustering: 100%|██████████| 31/31 [02:54<00:00,  5.63s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 174.55 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4340591832762309, 'v_measure_std': 0.142480285438846, 'main_score': 0.4340591832762309, 'evaluation_time': 174.55}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Creating model angle$cohere$flag-embedding$gist$llmrails$mixed-bread$voyage for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading cohere from cache for EmotionClassification...
Loading flag-embedding from cache for EmotionClassification...
Loading gist from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 1.99 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5611, 'f1': 0.4970809036985731, 'accuracy_stderr': 0.023222618284767106, 'f1_stderr': 0.013335680632775208, 'main_score': 0.5611, 'evaluation_time': 1.99}
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gist$llmrails$mixed-bread$voyage for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading cohere from cache for TwitterSemEval2015...
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 4.77 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8773916671633785, 'accuracy_threshold': 0.813828874025301, 'f1': 0.7219042663891779, 'f1_threshold': 0.7977952013278703, 'precision': 0.7119035402770651, 'recall': 0.7321899736147758, 'ap': 0.7912243299718664}, 'manhattan': {'accuracy': 0.8776300888120642, 'accuracy_threshold': 40.11640330204405, 'f1': 0.7204107830551991, 'f1_threshold': 42.28215596275254, 'precision': 0.7015, 'recall': 0.7403693931398417, 'ap': 0.791158936850686}, 'euclidean': {'accuracy': 0.8773916671633785, 'accuracy_threshold': 0.6101985347921357, 'f1': 0.7219042663891779, 'f1_threshold': 0.6359320683290454, 'precision': 0.7119035402770651, 'recall': 0.7321899736147758, 'ap': 0.7912243299718664}, 'dot': {'accuracy': 0.8773916671633785, 'accuracy_threshold': 0.813828874025301, 'f1': 0.7219042663891779, 'f1_threshold': 0.7977952013278702, 'precision': 0.7119035402770651, 'recall': 0.7321899736147758, 'ap': 0.7912243299718665}, 'max': {'accuracy': 0.8776300888120642, 'f1': 0.7219042663891779, 'ap': 0.7912243299718665}, 'evaluation_time': 4.77}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS15 as it already exists
Creating model angle$cohere$flag-embedding$gist$llmrails$mixed-bread$voyage for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading cohere from cache for AmazonCounterfactualClassification...
Loading flag-embedding from cache for AmazonCounterfactualClassification...
Loading gist from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 0.36 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7565671641791045, 'f1': 0.69625487162489, 'ap': 0.3870536663850189, 'accuracy_stderr': 0.03903177701362274, 'f1_stderr': 0.037508948888031884, 'ap_stderr': 0.04174258973260096, 'main_score': 0.7565671641791045}, 'evaluation_time': 0.36}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name angle$flag-embedding$gist$llmrails$mixed-bread$voyage
Converting results/angle$flag-embedding$gist$llmrails$mixed-bread$voyage to results/angle$flag-embedding$gist$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$flag-embedding$gte-large$llmrails$mixed-bread$voyage...
Creating model angle$flag-embedding$gte-large$llmrails$mixed-bread$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:07<03:41,  7.37s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS22 as it already exists
Creating model angle$cohere$flag-embedding$gist$llmrails$mixed-bread$voyage for task RedditClustering
Loading angle from cache for RedditClustering...
Loading cohere from cache for RedditClustering...
Loading flag-embedding from cache for RedditClustering...
Loading gist from cache for RedditClustering...
Loading llmrails from cache for RedditClustering...
Loading mixed-bread from cache for RedditClustering...
Loading voyage from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS22 as it already exists
Creating model angle$cohere$flag-embedding$gist$llmrails$voyage for task RedditClustering
Loading angle from cache for RedditClustering...
Loading cohere from cache for RedditClustering...
Loading flag-embedding from cache for RedditClustering...
Loading gist from cache for RedditClustering...
Loading llmrails from cache for RedditClustering...
Loading voyage from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.abstasks.AbsTaskClustering:
Task: RedditClustering, split: test. Running...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClustering:
Task: RedditClustering, split: test. Running...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:10<02:28,  5.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:03<01:20,  3.37s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:02<01:07,  2.81s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:25<04:18,  9.22s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:15<03:18,  8.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:16<03:25,  8.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [00:28<03:12,  7.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:22<02:48,  7.66s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:24<03:10,  8.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [00:35<03:03,  7.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:26<02:12,  6.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:27<02:17,  6.52s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:28<01:38,  4.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:35<02:18,  6.94s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [00:47<03:34,  8.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [00:37<01:56,  6.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [00:41<02:07,  6.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [00:41<01:38,  5.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [00:52<02:56,  7.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [00:43<01:33,  5.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [00:45<01:25,  5.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [00:56<02:27,  6.39s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [00:49<01:29,  5.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [01:03<02:24,  6.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [00:53<01:36,  6.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [00:56<01:35,  5.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [01:10<02:17,  6.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [01:01<01:39,  6.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [01:03<01:33,  6.22s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [01:07<01:31,  6.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [01:18<02:22,  7.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [01:10<01:07,  5.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [01:11<01:36,  6.87s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [01:17<01:11,  5.93s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [01:20<01:34,  7.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [01:36<03:17, 10.40s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [01:27<01:28,  7.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [01:27<01:18,  7.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [01:28<00:54,  5.40s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [01:33<01:16,  6.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [01:49<03:22, 11.28s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [01:41<01:10,  7.08s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [01:41<01:06,  7.41s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [01:45<00:51,  6.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [01:49<00:41,  5.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [02:01<03:16, 11.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [01:52<01:15,  8.43s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [01:53<00:30,  5.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [01:57<00:59,  7.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [02:03<00:49,  7.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [02:15<03:15, 12.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [02:05<00:36,  7.34s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [02:07<00:36,  6.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [02:12<00:28,  7.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [02:25<02:51, 11.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [02:18<00:37,  7.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [02:18<00:20,  6.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [02:20<00:10,  5.35s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [02:36<02:40, 11.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [02:27<00:05,  5.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [02:29<00:33,  8.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [02:33<00:00,  5.82s/it]Clustering: 100%|██████████| 25/25 [02:33<00:00,  6.13s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 153.29 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.6098960460194328, 'v_measure_std': 0.0480808858466844, 'main_score': 0.6098960460194328, 'evaluation_time': 153.29}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [02:45<02:18, 10.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [02:36<00:24,  8.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [02:38<00:12,  6.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [02:51<01:50,  9.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [02:42<00:05,  5.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS13 as it already exists
Creating model angle$cohere$flag-embedding$gist$llmrails$voyage for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading cohere from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [02:47<00:00,  5.58s/it]Clustering: 100%|██████████| 25/25 [02:47<00:00,  6.72s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 167.88 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.6101236573959328, 'v_measure_std': 0.042978003539157046, 'main_score': 0.6101236573959328, 'evaluation_time': 167.88}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [02:58<01:33,  8.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS13 as it already exists
Creating model angle$cohere$flag-embedding$gist$llmrails$mixed-bread$voyage for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading cohere from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 3.33 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6461744323560255, 'mrr': 0.7794541177505167, 'evaluation_time': 3.33}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 1.20 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6500181223054043, 'mrr': 0.7859792023919447, 'evaluation_time': 1.2}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [03:03<01:14,  7.46s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [03:03<00:48,  5.39s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [03:07<00:39,  4.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [03:10<00:29,  4.19s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [03:13<00:22,  3.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Creating model angle$cohere$flag-embedding$gist$llmrails$mixed-bread$voyage for task SciFact
Loading angle from cache for SciFact...
Loading cohere from cache for SciFact...
Loading flag-embedding from cache for SciFact...
Loading gist from cache for SciFact...
Loading llmrails from cache for SciFact...
Loading mixed-bread from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Creating model angle$cohere$flag-embedding$gist$llmrails$voyage for task SciFact
Loading angle from cache for SciFact...
Loading cohere from cache for SciFact...
Loading flag-embedding from cache for SciFact...
Loading gist from cache for SciFact...
Loading llmrails from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [03:14<00:15,  3.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 5183 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '4983', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.', 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 5183 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '4983', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.', 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [03:17<00:12,  3.05s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 300 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '1', 'text': '0-dimensional biomaterials show inductive properties.'}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [03:20<00:08,  2.93s/it]INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 300 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '1', 'text': '0-dimensional biomaterials show inductive properties.'}
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/mteb/evaluation/evaluators/utils.py:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/mteb/evaluation/evaluators/utils.py:13: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.92 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.6567
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.7061
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.7363
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.7620
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.7803
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.7843
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.6276
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.6850
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.7047
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.7177
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.7222
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.7224
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.6276
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.7401
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.8149
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.8899
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9717
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 1.0000
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.6567
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2711
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1820
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.1010
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0110
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6567
INFO:root:MRR@3: 0.7017
INFO:root:MRR@5: 0.7187
INFO:root:MRR@10: 0.7269
INFO:root:MRR@100: 0.7305
INFO:root:MRR@1000: 0.7307
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 3.11 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.65667, 'ndcg_at_3': 0.70607, 'ndcg_at_5': 0.73632, 'ndcg_at_10': 0.76201, 'ndcg_at_100': 0.78034, 'ndcg_at_1000': 0.78428, 'map_at_1': 0.62761, 'map_at_3': 0.68496, 'map_at_5': 0.7047, 'map_at_10': 0.71772, 'map_at_100': 0.72221, 'map_at_1000': 0.72242, 'recall_at_1': 0.62761, 'recall_at_3': 0.74006, 'recall_at_5': 0.81494, 'recall_at_10': 0.88989, 'recall_at_100': 0.97167, 'recall_at_1000': 1.0, 'precision_at_1': 0.65667, 'precision_at_3': 0.27111, 'precision_at_5': 0.182, 'precision_at_10': 0.101, 'precision_at_100': 0.011, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.65667, 'mrr_at_3': 0.70167, 'mrr_at_5': 0.71867, 'mrr_at_10': 0.72694, 'mrr_at_100': 0.73049, 'mrr_at_1000': 0.73068, 'evaluation_time': 3.11}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [03:23<00:06,  3.05s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 3.03 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.6500
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.7044
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.7321
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.7555
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.7781
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.7821
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.6209
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.6828
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.7008
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.7137
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.7195
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.7197
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.6209
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.7385
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.8083
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.8732
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9717
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 1.0000
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.6500
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2722
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1807
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.0993
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0110
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6500
INFO:root:MRR@3: 0.6983
INFO:root:MRR@5: 0.7155
INFO:root:MRR@10: 0.7228
INFO:root:MRR@100: 0.7276
INFO:root:MRR@1000: 0.7278
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 3.26 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.65, 'ndcg_at_3': 0.70438, 'ndcg_at_5': 0.73211, 'ndcg_at_10': 0.75553, 'ndcg_at_100': 0.77814, 'ndcg_at_1000': 0.78206, 'map_at_1': 0.62094, 'map_at_3': 0.68281, 'map_at_5': 0.70083, 'map_at_10': 0.71375, 'map_at_100': 0.71948, 'map_at_1000': 0.71968, 'recall_at_1': 0.62094, 'recall_at_3': 0.7385, 'recall_at_5': 0.80828, 'recall_at_10': 0.87322, 'recall_at_100': 0.97167, 'recall_at_1000': 1.0, 'precision_at_1': 0.65, 'precision_at_3': 0.27222, 'precision_at_5': 0.18067, 'precision_at_10': 0.09933, 'precision_at_100': 0.011, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.65, 'mrr_at_3': 0.69833, 'mrr_at_5': 0.7155, 'mrr_at_10': 0.72283, 'mrr_at_100': 0.72762, 'mrr_at_1000': 0.7278, 'evaluation_time': 3.26}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [03:25<00:02,  2.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [03:28<00:00,  2.75s/it]Clustering: 100%|██████████| 31/31 [03:28<00:00,  6.72s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 208.30 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43320516442134704, 'v_measure_std': 0.14158330301391, 'main_score': 0.43320516442134704, 'evaluation_time': 208.3}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Creating model angle$cohere$flag-embedding$gist$llmrails$voyage for task Banking77Classification
Loading angle from cache for Banking77Classification...
Loading cohere from cache for Banking77Classification...
Loading flag-embedding from cache for Banking77Classification...
Loading gist from cache for Banking77Classification...
Loading llmrails from cache for Banking77Classification...
Loading voyage from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Creating model angle$cohere$flag-embedding$gist$llmrails$mixed-bread$voyage for task ArguAna
Loading angle from cache for ArguAna...
Loading cohere from cache for ArguAna...
Loading flag-embedding from cache for ArguAna...
Loading gist from cache for ArguAna...
Loading llmrails from cache for ArguAna...
Loading mixed-bread from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
Retrieval
    - ArguAna, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 8674 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'test-environment-aeghhgwpe-pro02b', 'title': 'animals environment general health health general weight philosophy ethics', 'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008"}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Creating model angle$flag-embedding$gte-large$llmrails$mixed-bread$voyage for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading flag-embedding from cache for EmotionClassification...
Loading gte-large from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 1406 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': 'test-environment-aeghhgwpe-pro02a', 'text': "Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004"}
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 7.83 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8549999999999999, 'f1': 0.8498657094001937, 'accuracy_stderr': 0.005129870129870144, 'f1_stderr': 0.006094046927425279, 'main_score': 0.8549999999999999, 'evaluation_time': 7.83}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gist$llmrails$voyage for task ArguAna
Loading angle from cache for ArguAna...
Loading cohere from cache for ArguAna...
Loading flag-embedding from cache for ArguAna...
Loading gist from cache for ArguAna...
Loading llmrails from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 8674 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'test-environment-aeghhgwpe-pro02b', 'title': 'animals environment general health health general weight philosophy ethics', 'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008"}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 2.09 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.54825, 'f1': 0.48083646595619217, 'accuracy_stderr': 0.026873081326859415, 'f1_stderr': 0.01607966552159707, 'main_score': 0.54825, 'evaluation_time': 2.09}
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 1406 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': 'test-environment-aeghhgwpe-pro02a', 'text': "Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004"}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 7.78 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.4026
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.5677
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.6155
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.6527
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.6718
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.6722
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.4026
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.5272
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.5539
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.5695
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.5744
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.5744
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.4026
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.6849
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.8001
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.9139
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9936
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 0.9964
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.4026
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2283
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1600
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.0914
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0099
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.4097
INFO:root:MRR@3: 0.5302
INFO:root:MRR@5: 0.5565
INFO:root:MRR@10: 0.5720
INFO:root:MRR@100: 0.5769
INFO:root:MRR@1000: 0.5769
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 8.42 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.40256, 'ndcg_at_3': 0.56767, 'ndcg_at_5': 0.61552, 'ndcg_at_10': 0.65266, 'ndcg_at_100': 0.67176, 'ndcg_at_1000': 0.67215, 'map_at_1': 0.40256, 'map_at_3': 0.52715, 'map_at_5': 0.55392, 'map_at_10': 0.56945, 'map_at_100': 0.57435, 'map_at_1000': 0.57437, 'recall_at_1': 0.40256, 'recall_at_3': 0.68492, 'recall_at_5': 0.80014, 'recall_at_10': 0.91394, 'recall_at_100': 0.9936, 'recall_at_1000': 0.99644, 'precision_at_1': 0.40256, 'precision_at_3': 0.22831, 'precision_at_5': 0.16003, 'precision_at_10': 0.09139, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.40967, 'mrr_at_3': 0.53023, 'mrr_at_5': 0.55651, 'mrr_at_10': 0.57201, 'mrr_at_100': 0.57691, 'mrr_at_1000': 0.57693, 'evaluation_time': 8.42}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 4.88 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.3969
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.5634
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.6115
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.6489
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.6682
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.6685
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.3969
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.5222
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.5491
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.5647
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.5696
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.5697
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.3969
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.6828
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.7987
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.9132
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9936
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 0.9964
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.3969
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2276
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1597
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.0913
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0099
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.4047
INFO:root:MRR@3: 0.5254
INFO:root:MRR@5: 0.5517
INFO:root:MRR@10: 0.5675
INFO:root:MRR@100: 0.5724
INFO:root:MRR@1000: 0.5724
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 5.56 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.39687, 'ndcg_at_3': 0.56339, 'ndcg_at_5': 0.61154, 'ndcg_at_10': 0.64885, 'ndcg_at_100': 0.66815, 'ndcg_at_1000': 0.66854, 'map_at_1': 0.39687, 'map_at_3': 0.52217, 'map_at_5': 0.54912, 'map_at_10': 0.56469, 'map_at_100': 0.56964, 'map_at_1000': 0.56966, 'recall_at_1': 0.39687, 'recall_at_3': 0.68279, 'recall_at_5': 0.79872, 'recall_at_10': 0.91323, 'recall_at_100': 0.9936, 'recall_at_1000': 0.99644, 'precision_at_1': 0.39687, 'precision_at_3': 0.2276, 'precision_at_5': 0.15974, 'precision_at_10': 0.09132, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.40469, 'mrr_at_3': 0.52537, 'mrr_at_5': 0.55172, 'mrr_at_10': 0.56748, 'mrr_at_100': 0.57236, 'mrr_at_1000': 0.57238, 'evaluation_time': 5.56}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$flag-embedding$gte-large$llmrails$mixed-bread$voyage for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gte-large from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 4.34 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8757227156225785, 'accuracy_threshold': 0.8322031238049414, 'f1': 0.7225411404515881, 'f1_threshold': 0.8163772218226824, 'precision': 0.6994319585082737, 'recall': 0.7472295514511873, 'ap': 0.7895384297821179}, 'manhattan': {'accuracy': 0.8754246885617214, 'accuracy_threshold': 34.75077860484896, 'f1': 0.7193635313743103, 'f1_threshold': 36.15451114620214, 'precision': 0.7002248313764676, 'recall': 0.7395778364116095, 'ap': 0.7878466390159006}, 'euclidean': {'accuracy': 0.8757227156225785, 'accuracy_threshold': 0.5793045402886148, 'f1': 0.7225411404515881, 'f1_threshold': 0.6060078843604011, 'precision': 0.6994319585082737, 'recall': 0.7472295514511873, 'ap': 0.7895384297821179}, 'dot': {'accuracy': 0.8757227156225785, 'accuracy_threshold': 0.8322031238049412, 'f1': 0.7225411404515881, 'f1_threshold': 0.8163772218226826, 'precision': 0.6994319585082737, 'recall': 0.7472295514511873, 'ap': 0.7895384297821179}, 'max': {'accuracy': 0.8757227156225785, 'f1': 0.7225411404515881, 'ap': 0.7895384297821179}, 'evaluation_time': 4.34}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS15 as it already exists
Creating model angle$flag-embedding$gte-large$llmrails$mixed-bread$voyage for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading flag-embedding from cache for AmazonCounterfactualClassification...
Loading gte-large from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 0.44 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7388059701492536, 'f1': 0.6788158430193729, 'ap': 0.36724124036830824, 'accuracy_stderr': 0.036044080831339906, 'f1_stderr': 0.03470844588793234, 'ap_stderr': 0.03686853287792489, 'main_score': 0.7388059701492536}, 'evaluation_time': 0.44}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS22 as it already exists
Creating model angle$flag-embedding$gte-large$llmrails$mixed-bread$voyage for task RedditClustering
Loading angle from cache for RedditClustering...
Loading flag-embedding from cache for RedditClustering...
Loading gte-large from cache for RedditClustering...
Loading llmrails from cache for RedditClustering...
Loading mixed-bread from cache for RedditClustering...
Loading voyage from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.abstasks.AbsTaskClustering:
Task: RedditClustering, split: test. Running...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:02<01:08,  2.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:06<01:11,  3.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:14<02:01,  5.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:18<01:39,  4.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:20<01:17,  3.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [00:24<01:15,  3.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [00:26<00:59,  3.28s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [00:32<01:13,  4.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [00:40<01:27,  5.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [00:48<01:32,  6.18s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [00:55<01:28,  6.35s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [00:56<01:01,  4.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [00:58<00:46,  3.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [01:04<00:49,  4.48s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [01:05<00:35,  3.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [01:12<00:40,  4.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [01:15<00:33,  4.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [01:16<00:22,  3.25s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [01:21<00:21,  3.53s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gist$llmrails$mixed-bread$voyage
Converting results/angle$cohere$flag-embedding$gist$llmrails$mixed-bread$voyage to results/angle$cohere$flag-embedding$gist$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage...
Creating model angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gist$llmrails$voyage
Converting results/angle$cohere$flag-embedding$gist$llmrails$voyage to results/angle$cohere$flag-embedding$gist$llmrails$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$gist$mixed-bread$voyage...
Creating model angle$cohere$flag-embedding$gist$mixed-bread$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
Clustering
    - ArxivClusteringS2S, s2s
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:03<01:52,  3.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:04<02:07,  4.25s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:07<01:45,  3.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:08<01:58,  4.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:10<01:39,  3.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:12<01:55,  4.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [00:14<01:34,  3.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [00:16<01:51,  4.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [00:17<01:32,  3.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [00:22<02:06,  4.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [00:23<01:45,  4.22s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [00:28<02:08,  5.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [00:28<01:50,  4.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [00:35<01:58,  5.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [00:35<02:15,  5.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [00:39<01:49,  4.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [00:40<02:05,  5.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [00:43<01:34,  4.48s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [00:44<01:49,  4.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [00:49<01:47,  5.13s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [00:50<01:47,  5.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [00:57<01:54,  6.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [00:58<02:06,  6.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [01:06<02:03,  6.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [01:07<02:15,  7.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [01:15<02:03,  7.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [01:16<02:17,  7.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [01:23<02:00,  7.54s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  45%|████▌     | 14/31 [01:25<02:17,  8.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [01:28<01:44,  6.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [01:34<02:13,  8.34s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [01:36<01:42,  7.33s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [01:43<02:06,  8.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [01:45<01:39,  7.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [01:52<02:01,  8.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [01:54<01:37,  8.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [02:01<01:53,  8.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [02:02<01:29,  8.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [02:10<01:19,  7.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [02:10<01:45,  8.82s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [02:10<00:51,  5.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [02:18<00:50,  6.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [02:19<01:38,  8.93s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [02:21<00:37,  5.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [02:27<00:32,  5.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [02:27<01:27,  8.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [02:29<00:59,  6.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [02:29<00:23,  4.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [02:35<00:19,  4.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [02:36<00:54,  6.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [02:39<00:13,  4.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [02:40<00:41,  5.88s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  94%|█████████▎| 29/31 [02:43<00:08,  4.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [02:44<00:32,  5.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [02:47<00:04,  4.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [02:47<00:22,  4.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [02:50<00:00,  4.04s/it]Clustering: 100%|██████████| 31/31 [02:50<00:00,  5.51s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 170.78 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4340421065124652, 'v_measure_std': 0.14264175209323873, 'main_score': 0.4340421065124652, 'evaluation_time': 170.78}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [02:51<00:18,  4.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [02:55<00:12,  4.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [02:58<00:08,  4.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [03:01<00:03,  3.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Creating model angle$cohere$flag-embedding$gist$mixed-bread$voyage for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading cohere from cache for EmotionClassification...
Loading flag-embedding from cache for EmotionClassification...
Loading gist from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 4.00 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.56525, 'f1': 0.5021858417987997, 'accuracy_stderr': 0.02018570038418287, 'f1_stderr': 0.010725664984363514, 'main_score': 0.56525, 'evaluation_time': 4.0}
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [03:08<00:00,  4.63s/it]Clustering: 100%|██████████| 31/31 [03:08<00:00,  6.08s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 188.43 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43271732010182723, 'v_measure_std': 0.142885371718433, 'main_score': 0.43271732010182723, 'evaluation_time': 188.43}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Creating model angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading cohere from cache for EmotionClassification...
Loading flag-embedding from cache for EmotionClassification...
Loading gte-large from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 1.63 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5529, 'f1': 0.4875650528771838, 'accuracy_stderr': 0.023507232929462375, 'f1_stderr': 0.013341021793745614, 'main_score': 0.5529, 'evaluation_time': 1.63}
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gist$mixed-bread$voyage for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading cohere from cache for TwitterSemEval2015...
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
PairClassification
Creating model angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading cohere from cache for TwitterSemEval2015...
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gte-large from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
    - TwitterSemEval2015, s2s
PairClassification


    - TwitterSemEval2015, s2s
INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************


INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 4.59 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.876914823866007, 'accuracy_threshold': 0.8117664474644595, 'f1': 0.7203521491455205, 'f1_threshold': 0.7977198220256335, 'precision': 0.7071682765632944, 'recall': 0.7340369393139842, 'ap': 0.7883833840134241}, 'manhattan': {'accuracy': 0.8765571913929785, 'accuracy_threshold': 37.378819053503044, 'f1': 0.7188723570869223, 'f1_threshold': 38.44219416888748, 'precision': 0.7112603305785123, 'recall': 0.7266490765171504, 'ap': 0.7885945370449786}, 'euclidean': {'accuracy': 0.876914823866007, 'accuracy_threshold': 0.613569152569614, 'f1': 0.7203521491455205, 'f1_threshold': 0.6360505922839237, 'precision': 0.7071682765632944, 'recall': 0.7340369393139842, 'ap': 0.7883833840134241}, 'dot': {'accuracy': 0.876914823866007, 'accuracy_threshold': 0.811766447464459, 'f1': 0.7203521491455205, 'f1_threshold': 0.7977198220256332, 'precision': 0.7071682765632944, 'recall': 0.7340369393139842, 'ap': 0.7883833840134241}, 'max': {'accuracy': 0.876914823866007, 'f1': 0.7203521491455205, 'ap': 0.7885945370449786}, 'evaluation_time': 4.59}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 5.11 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8772128509268642, 'accuracy_threshold': 0.8322081593468613, 'f1': 0.7213448802852777, 'f1_threshold': 0.8107593851380099, 'precision': 0.6971935007385525, 'recall': 0.7472295514511873, 'ap': 0.7906697903146007}, 'manhattan': {'accuracy': 0.8769744292781785, 'accuracy_threshold': 37.925735259466435, 'f1': 0.7194244604316546, 'f1_threshold': 40.011106882473925, 'precision': 0.7010515773660491, 'recall': 0.7387862796833773, 'ap': 0.7894964335865745}, 'euclidean': {'accuracy': 0.8772128509268642, 'accuracy_threshold': 0.5792958495501279, 'f1': 0.7213448802852777, 'f1_threshold': 0.6152082809093379, 'precision': 0.6971935007385525, 'recall': 0.7472295514511873, 'ap': 0.7906697903146007}, 'dot': {'accuracy': 0.8772128509268642, 'accuracy_threshold': 0.832208159346861, 'f1': 0.7213448802852777, 'f1_threshold': 0.8107593851380099, 'precision': 0.6971935007385525, 'recall': 0.7472295514511873, 'ap': 0.7906697903146007}, 'max': {'accuracy': 0.8772128509268642, 'f1': 0.7213448802852777, 'ap': 0.7906697903146007}, 'evaluation_time': 5.11}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS15 as it already exists
Creating model angle$cohere$flag-embedding$gist$mixed-bread$voyage for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading cohere from cache for AmazonCounterfactualClassification...
Loading flag-embedding from cache for AmazonCounterfactualClassification...
Loading gist from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Classification
Skipping STS15 as it already exists
Creating model angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading cohere from cache for AmazonCounterfactualClassification...
Loading flag-embedding from cache for AmazonCounterfactualClassification...
Loading gte-large from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs
Classification


    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs
INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************


INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 0.35 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7564179104477613, 'f1': 0.69561533180207, 'ap': 0.3856426896587385, 'accuracy_stderr': 0.0383660483306954, 'f1_stderr': 0.03688932638705256, 'ap_stderr': 0.04073319324038019, 'main_score': 0.7564179104477613}, 'evaluation_time': 0.35}
INFO:main:Running task: RedditClustering
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 0.28 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.752089552238806, 'f1': 0.6920543889221382, 'ap': 0.38223567676659137, 'accuracy_stderr': 0.036714294320338105, 'f1_stderr': 0.03500132922693219, 'ap_stderr': 0.03864961605961511, 'main_score': 0.752089552238806}, 'evaluation_time': 0.28}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS22 as it already exists
Creating model angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage for task RedditClustering
Loading angle from cache for RedditClustering...
Loading cohere from cache for RedditClustering...
Loading flag-embedding from cache for RedditClustering...
Loading gte-large from cache for RedditClustering...
Loading llmrails from cache for RedditClustering...
Loading mixed-bread from cache for RedditClustering...
Loading voyage from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
Skipping STS22 as it already exists
Creating model angle$cohere$flag-embedding$gist$mixed-bread$voyage for task RedditClustering
Loading angle from cache for RedditClustering...
Loading cohere from cache for RedditClustering...
Loading flag-embedding from cache for RedditClustering...
Loading gist from cache for RedditClustering...
Loading mixed-bread from cache for RedditClustering...
Loading voyage from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
    - RedditClustering, s2s
Clustering


    - RedditClustering, s2s
INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************


INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.abstasks.AbsTaskClustering:
Task: RedditClustering, split: test. Running...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.abstasks.AbsTaskClustering:
Task: RedditClustering, split: test. Running...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:02<01:08,  2.87s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:02<01:09,  2.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:06<01:17,  3.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:06<01:19,  3.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:13<01:49,  4.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:14<01:57,  5.34s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:15<01:21,  3.88s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:16<01:29,  4.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:17<01:03,  3.17s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:19<01:09,  3.48s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [00:20<00:57,  3.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [00:23<00:54,  3.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [00:23<01:13,  3.88s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [00:25<00:56,  3.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [00:26<00:53,  3.13s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [00:29<00:57,  3.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [00:31<00:57,  3.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [00:33<00:59,  3.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [00:35<00:55,  3.69s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [00:37<00:56,  3.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [00:39<00:52,  3.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [00:40<00:37,  2.90s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [00:42<00:58,  4.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [00:42<00:34,  2.88s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [00:43<00:41,  3.22s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [00:47<00:40,  3.41s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [00:48<00:39,  3.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [00:49<00:28,  2.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [00:51<00:38,  3.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [00:54<00:34,  3.46s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [00:55<00:33,  3.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [00:57<00:26,  3.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [00:59<00:19,  2.81s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [00:59<00:35,  4.00s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [01:01<00:16,  2.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [01:02<00:28,  3.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [01:03<00:19,  2.81s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [01:08<00:19,  3.90s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [01:08<00:20,  3.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [01:12<00:16,  4.09s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [01:14<00:21,  4.25s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [01:16<00:12,  4.08s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [01:17<00:06,  3.16s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [01:19<00:18,  4.52s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [01:20<00:03,  3.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [01:26<00:15,  5.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [01:27<00:00,  4.08s/it]Clustering: 100%|██████████| 25/25 [01:27<00:00,  3.48s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 87.05 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.6149127148520713, 'v_measure_std': 0.04558166127256731, 'main_score': 0.6149127148520713, 'evaluation_time': 87.05}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [01:27<00:07,  4.00s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [01:29<00:03,  3.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [01:33<00:00,  3.44s/it]Clustering: 100%|██████████| 25/25 [01:33<00:00,  3.73s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 93.36 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.6049580857281116, 'v_measure_std': 0.04722072462632396, 'main_score': 0.6049580857281116, 'evaluation_time': 93.36}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS13 as it already exists
Creating model angle$cohere$flag-embedding$gist$mixed-bread$voyage for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading cohere from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS13 as it already exists
Creating model angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading cohere from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading gte-large from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 1.19 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6473259683211477, 'mrr': 0.7802191883216812, 'evaluation_time': 1.19}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 0.82 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.648822760974188, 'mrr': 0.7829782790309107, 'evaluation_time': 0.82}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Creating model angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage for task SciFact
Loading angle from cache for SciFact...
Loading cohere from cache for SciFact...
Loading flag-embedding from cache for SciFact...
Loading gte-large from cache for SciFact...
Loading llmrails from cache for SciFact...
Loading mixed-bread from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Retrieval
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Creating model angle$cohere$flag-embedding$gist$mixed-bread$voyage for task SciFact
Loading angle from cache for SciFact...
Loading cohere from cache for SciFact...
Loading flag-embedding from cache for SciFact...
Loading gist from cache for SciFact...
Loading mixed-bread from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
    - SciFact, s2p
Retrieval


    - SciFact, s2p
INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************


INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 5183 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '4983', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.', 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 5183 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '4983', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.', 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 300 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '1', 'text': '0-dimensional biomaterials show inductive properties.'}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 300 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '1', 'text': '0-dimensional biomaterials show inductive properties.'}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.78 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.6567
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.7118
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.7351
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.7599
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.7821
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.7856
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.6276
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.6895
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.7055
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.7186
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.7241
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.7243
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.6276
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.7485
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.8074
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.8766
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9750
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 1.0000
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.6567
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2756
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1807
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.0997
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0110
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6567
INFO:root:MRR@3: 0.7050
INFO:root:MRR@5: 0.7192
INFO:root:MRR@10: 0.7275
INFO:root:MRR@100: 0.7321
INFO:root:MRR@1000: 0.7322
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 2.94 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.65667, 'ndcg_at_3': 0.71184, 'ndcg_at_5': 0.73512, 'ndcg_at_10': 0.75992, 'ndcg_at_100': 0.78212, 'ndcg_at_1000': 0.78556, 'map_at_1': 0.62761, 'map_at_3': 0.68948, 'map_at_5': 0.7055, 'map_at_10': 0.71864, 'map_at_100': 0.72408, 'map_at_1000': 0.72426, 'recall_at_1': 0.62761, 'recall_at_3': 0.7485, 'recall_at_5': 0.80744, 'recall_at_10': 0.87656, 'recall_at_100': 0.975, 'recall_at_1000': 1.0, 'precision_at_1': 0.65667, 'precision_at_3': 0.27556, 'precision_at_5': 0.18067, 'precision_at_10': 0.09967, 'precision_at_100': 0.01103, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.65667, 'mrr_at_3': 0.705, 'mrr_at_5': 0.71917, 'mrr_at_10': 0.72754, 'mrr_at_100': 0.73208, 'mrr_at_1000': 0.73224, 'evaluation_time': 2.94}
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.33 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.6467
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.7019
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.7297
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.7578
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.7751
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.7796
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.6176
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.6794
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.6973
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.7117
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.7160
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.7163
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.6176
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.7401
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.8099
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.8916
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9683
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 1.0000
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.6467
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2711
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1807
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.1010
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0110
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6467
INFO:root:MRR@3: 0.6961
INFO:root:MRR@5: 0.7119
INFO:root:MRR@10: 0.7212
INFO:root:MRR@100: 0.7243
INFO:root:MRR@1000: 0.7245
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 2.47 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.64667, 'ndcg_at_3': 0.70195, 'ndcg_at_5': 0.72967, 'ndcg_at_10': 0.75781, 'ndcg_at_100': 0.77511, 'ndcg_at_1000': 0.77956, 'map_at_1': 0.61761, 'map_at_3': 0.67941, 'map_at_5': 0.69731, 'map_at_10': 0.7117, 'map_at_100': 0.71602, 'map_at_1000': 0.71626, 'recall_at_1': 0.61761, 'recall_at_3': 0.74006, 'recall_at_5': 0.80994, 'recall_at_10': 0.89156, 'recall_at_100': 0.96833, 'recall_at_1000': 1.0, 'precision_at_1': 0.64667, 'precision_at_3': 0.27111, 'precision_at_5': 0.18067, 'precision_at_10': 0.101, 'precision_at_100': 0.01097, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.64667, 'mrr_at_3': 0.69611, 'mrr_at_5': 0.71194, 'mrr_at_10': 0.72117, 'mrr_at_100': 0.72428, 'mrr_at_1000': 0.7245, 'evaluation_time': 2.47}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Creating model angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage for task Banking77Classification
Loading angle from cache for Banking77Classification...
Loading cohere from cache for Banking77Classification...
Loading flag-embedding from cache for Banking77Classification...
Loading gte-large from cache for Banking77Classification...
Loading llmrails from cache for Banking77Classification...
Loading mixed-bread from cache for Banking77Classification...
Loading voyage from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Classification
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Creating model angle$cohere$flag-embedding$gist$mixed-bread$voyage for task Banking77Classification
Loading angle from cache for Banking77Classification...
Loading cohere from cache for Banking77Classification...
Loading flag-embedding from cache for Banking77Classification...
Loading gist from cache for Banking77Classification...
Loading mixed-bread from cache for Banking77Classification...
Loading voyage from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
    - Banking77Classification, s2s
Classification


    - Banking77Classification, s2s
INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************


INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 12.47 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8550000000000001, 'f1': 0.8498904581873058, 'accuracy_stderr': 0.0051278148110128945, 'f1_stderr': 0.006097246032730868, 'main_score': 0.8550000000000001, 'evaluation_time': 12.47}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 14.47 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8475974025974026, 'f1': 0.8414521785340767, 'accuracy_stderr': 0.004633197653078766, 'f1_stderr': 0.005360867142313025, 'main_score': 0.8475974025974026, 'evaluation_time': 14.47}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gist$mixed-bread$voyage for task ArguAna
Loading angle from cache for ArguAna...
Loading cohere from cache for ArguAna...
Loading flag-embedding from cache for ArguAna...
Loading gist from cache for ArguAna...
Loading mixed-bread from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage for task ArguAna
Loading angle from cache for ArguAna...
Loading cohere from cache for ArguAna...
Loading flag-embedding from cache for ArguAna...
Loading gte-large from cache for ArguAna...
Loading llmrails from cache for ArguAna...
Loading mixed-bread from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 8674 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 8674 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'test-environment-aeghhgwpe-pro02b', 'title': 'animals environment general health health general weight philosophy ethics', 'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008"}
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'test-environment-aeghhgwpe-pro02b', 'title': 'animals environment general health health general weight philosophy ethics', 'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008"}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 1406 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': 'test-environment-aeghhgwpe-pro02a', 'text': "Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004"}
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 1406 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': 'test-environment-aeghhgwpe-pro02a', 'text': "Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004"}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 5.12 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.3990
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.5638
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.6127
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.6496
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.6691
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.6695
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.3990
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.5232
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.5504
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.5659
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.5709
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.5710
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.3990
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.6814
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.7994
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.9125
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9936
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 0.9964
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.3990
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2271
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1599
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.0912
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0099
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.4075
INFO:root:MRR@3: 0.5270
INFO:root:MRR@5: 0.5536
INFO:root:MRR@10: 0.5690
INFO:root:MRR@100: 0.5740
INFO:root:MRR@1000: 0.5740
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 5.74 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 5.77 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.399, 'ndcg_at_3': 0.56384, 'ndcg_at_5': 0.61266, 'ndcg_at_10': 0.64958, 'ndcg_at_100': 0.66914, 'ndcg_at_1000': 0.66953, 'map_at_1': 0.399, 'map_at_3': 0.52323, 'map_at_5': 0.55044, 'map_at_10': 0.56588, 'map_at_100': 0.57095, 'map_at_1000': 0.57096, 'recall_at_1': 0.399, 'recall_at_3': 0.68137, 'recall_at_5': 0.79943, 'recall_at_10': 0.91252, 'recall_at_100': 0.9936, 'recall_at_1000': 0.99644, 'precision_at_1': 0.399, 'precision_at_3': 0.22712, 'precision_at_5': 0.15989, 'precision_at_10': 0.09125, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.40754, 'mrr_at_3': 0.52703, 'mrr_at_5': 0.55356, 'mrr_at_10': 0.56903, 'mrr_at_100': 0.57404, 'mrr_at_1000': 0.57405, 'evaluation_time': 5.77}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.4018
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.5681
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.6142
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.6507
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.6708
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.6713
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.4018
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.5274
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.5531
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.5683
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.5735
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.5735
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.4018
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.6856
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.7973
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.9097
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9929
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 0.9964
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.4018
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2285
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1595
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.0910
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0099
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.4104
INFO:root:MRR@3: 0.5302
INFO:root:MRR@5: 0.5558
INFO:root:MRR@10: 0.5713
INFO:root:MRR@100: 0.5764
INFO:root:MRR@1000: 0.5765
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 6.35 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.40185, 'ndcg_at_3': 0.56805, 'ndcg_at_5': 0.6142, 'ndcg_at_10': 0.65074, 'ndcg_at_100': 0.67081, 'ndcg_at_1000': 0.6713, 'map_at_1': 0.40185, 'map_at_3': 0.52738, 'map_at_5': 0.55309, 'map_at_10': 0.56828, 'map_at_100': 0.57348, 'map_at_1000': 0.5735, 'recall_at_1': 0.40185, 'recall_at_3': 0.68563, 'recall_at_5': 0.7973, 'recall_at_10': 0.90967, 'recall_at_100': 0.99289, 'recall_at_1000': 0.99644, 'precision_at_1': 0.40185, 'precision_at_3': 0.22854, 'precision_at_5': 0.15946, 'precision_at_10': 0.09097, 'precision_at_100': 0.00993, 'precision_at_1000': 0.001, 'mrr_at_1': 0.41038, 'mrr_at_3': 0.53023, 'mrr_at_5': 0.55583, 'mrr_at_10': 0.57132, 'mrr_at_100': 0.57644, 'mrr_at_1000': 0.57647, 'evaluation_time': 6.35}
INFO:main:Running task: ArxivClusteringS2S
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gist$mixed-bread$voyage
Converting results/angle$cohere$flag-embedding$gist$mixed-bread$voyage to results/angle$cohere$flag-embedding$gist$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread...
Creating model angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:05<02:47,  5.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:08<01:56,  4.00s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:11<01:34,  3.37s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [00:13<01:21,  3.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [00:16<01:14,  2.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [00:18<01:09,  2.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [00:21<01:04,  2.67s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [00:23<00:59,  2.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [00:26<00:56,  2.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [00:28<00:52,  2.52s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [00:33<01:03,  3.16s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [00:37<01:06,  3.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [00:42<01:09,  3.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [00:46<01:09,  4.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [00:51<01:08,  4.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [00:56<01:07,  4.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [01:01<01:03,  4.53s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [01:05<01:00,  4.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage
Converting results/angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage to results/angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$gist$gte-large$llmrails$mixed-bread$voyage...
Creating model angle$cohere$gist$gte-large$llmrails$mixed-bread$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading cohere from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [01:10<00:55,  4.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [01:15<00:52,  4.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:05<02:52,  5.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [01:20<00:47,  4.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [01:21<00:31,  3.53s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:10<02:32,  5.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [01:26<00:31,  3.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:15<02:23,  5.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [01:29<00:25,  3.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [00:19<02:07,  4.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [01:33<00:22,  3.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [01:36<00:18,  3.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [00:25<02:10,  5.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [01:40<00:14,  3.66s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [00:29<02:00,  4.81s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [01:43<00:10,  3.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [00:33<01:49,  4.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [01:47<00:07,  3.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [00:37<01:41,  4.43s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [01:50<00:03,  3.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [00:44<01:54,  5.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [01:56<00:00,  4.38s/it]Clustering: 100%|██████████| 31/31 [01:56<00:00,  3.77s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 116.82 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4349841998851944, 'v_measure_std': 0.14258054541229398, 'main_score': 0.4349841998851944, 'evaluation_time': 116.82}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [00:47<01:36,  4.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [00:54<01:41,  5.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [00:59<01:38,  5.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [01:05<01:36,  5.35s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [01:10<01:32,  5.43s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [01:16<01:27,  5.48s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [01:22<01:21,  5.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [01:27<01:18,  5.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [01:37<01:27,  6.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [01:44<01:23,  6.94s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping EmotionClassification as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping STS15 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping STS22 as it already exists
Skipping RedditClustering as it already exists
Skipping STS13 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Skipping SciFact as it already exists
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread
Converting results/angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread to results/angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$gte-large$llmrails$voyage...
Creating model angle$cohere$flag-embedding$gte-large$llmrails$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [01:51<01:16,  6.94s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:04<02:06,  4.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [01:58<01:09,  6.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [02:00<00:47,  5.33s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:09<02:23,  4.94s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:16<02:38,  5.66s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [02:08<00:50,  6.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [00:19<02:07,  4.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [02:12<00:39,  5.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [00:23<01:54,  4.41s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [02:17<00:32,  5.41s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [00:27<01:46,  4.25s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [02:19<00:22,  4.40s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [00:30<01:35,  3.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [02:24<00:18,  4.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [00:34<01:31,  3.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [02:31<00:16,  5.34s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [00:41<01:44,  4.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [00:45<01:37,  4.67s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [02:37<00:10,  5.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [02:41<00:05,  5.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [00:51<01:42,  5.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [02:50<00:00,  6.20s/it]Clustering: 100%|██████████| 31/31 [02:50<00:00,  5.50s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 170.45 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4338504020432339, 'v_measure_std': 0.14292261289363442, 'main_score': 0.4338504020432339, 'evaluation_time': 170.45}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [01:01<02:03,  6.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [01:06<01:47,  5.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [01:10<01:34,  5.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Creating model angle$cohere$gist$gte-large$llmrails$mixed-bread$voyage for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading cohere from cache for EmotionClassification...
Loading gist from cache for EmotionClassification...
Loading gte-large from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 5.05 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5602999999999999, 'f1': 0.49626018101864294, 'accuracy_stderr': 0.021640471344219855, 'f1_stderr': 0.011994725520753991, 'main_score': 0.5602999999999999, 'evaluation_time': 5.05}
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [01:19<01:46,  6.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [01:24<01:32,  6.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [01:29<01:19,  5.69s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [01:34<01:11,  5.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$gist$gte-large$llmrails$mixed-bread$voyage for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading cohere from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
Loading gte-large from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [01:39<01:03,  5.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [01:45<00:59,  5.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 8.61 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8765571913929785, 'accuracy_threshold': 0.8252997584573061, 'f1': 0.7195753822823203, 'f1_threshold': 0.8083790367624952, 'precision': 0.690516614115935, 'recall': 0.7511873350923483, 'ap': 0.7881722804443927}, 'manhattan': {'accuracy': 0.8757227156225785, 'accuracy_threshold': 38.57380121312458, 'f1': 0.7181418706842435, 'f1_threshold': 40.49865792373035, 'precision': 0.6850299401197605, 'recall': 0.7546174142480211, 'ap': 0.7866740179871742}, 'euclidean': {'accuracy': 0.8765571913929785, 'accuracy_threshold': 0.5911010768622578, 'f1': 0.7195753822823203, 'f1_threshold': 0.6190653652591565, 'precision': 0.690516614115935, 'recall': 0.7511873350923483, 'ap': 0.7881722804443927}, 'dot': {'accuracy': 0.8765571913929785, 'accuracy_threshold': 0.8252997584573061, 'f1': 0.7195753822823203, 'f1_threshold': 0.8083790367624952, 'precision': 0.690516614115935, 'recall': 0.7511873350923483, 'ap': 0.7881722804443928}, 'max': {'accuracy': 0.8765571913929785, 'f1': 0.7195753822823203, 'ap': 0.7881722804443928}, 'evaluation_time': 8.61}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [01:50<00:54,  5.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [01:51<00:35,  3.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS15 as it already exists
Creating model angle$cohere$gist$gte-large$llmrails$mixed-bread$voyage for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading cohere from cache for AmazonCounterfactualClassification...
Loading gist from cache for AmazonCounterfactualClassification...
Loading gte-large from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 0.76 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7550746268656716, 'f1': 0.6946246580186084, 'ap': 0.3849107668042896, 'accuracy_stderr': 0.039145756952307424, 'f1_stderr': 0.03743442561680749, 'ap_stderr': 0.04101811111412398, 'main_score': 0.7550746268656716}, 'evaluation_time': 0.76}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [01:55<00:33,  4.17s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [01:58<00:25,  3.69s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [02:01<00:20,  3.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [02:02<00:14,  2.88s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [02:06<00:11,  3.00s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [02:08<00:08,  2.94s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [02:11<00:05,  2.94s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [02:14<00:02,  2.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [02:16<00:00,  2.75s/it]Clustering: 100%|██████████| 31/31 [02:16<00:00,  4.42s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 136.88 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4354252437839675, 'v_measure_std': 0.14224828174519516, 'main_score': 0.4354252437839675, 'evaluation_time': 136.88}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Creating model angle$cohere$flag-embedding$gte-large$llmrails$voyage for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading cohere from cache for EmotionClassification...
Loading flag-embedding from cache for EmotionClassification...
Loading gte-large from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 1.34 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.55035, 'f1': 0.4851085779631711, 'accuracy_stderr': 0.022648454693422245, 'f1_stderr': 0.01278891486136263, 'main_score': 0.55035, 'evaluation_time': 1.34}
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gte-large$llmrails$voyage for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading cohere from cache for TwitterSemEval2015...
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gte-large from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 4.32 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8764379805686356, 'accuracy_threshold': 0.8400453369345878, 'f1': 0.71886767952214, 'f1_threshold': 0.8288537031677915, 'precision': 0.7077473791869087, 'recall': 0.7303430079155673, 'ap': 0.7884546746672556}, 'manhattan': {'accuracy': 0.8759015318590928, 'accuracy_threshold': 33.731913441483314, 'f1': 0.7179162978884814, 'f1_threshold': 36.0282002233383, 'precision': 0.6892449623695072, 'recall': 0.7490765171503958, 'ap': 0.7871392797824515}, 'euclidean': {'accuracy': 0.8764379805686356, 'accuracy_threshold': 0.5656052741113073, 'f1': 0.71886767952214, 'f1_threshold': 0.5850577695102834, 'precision': 0.7077473791869087, 'recall': 0.7303430079155673, 'ap': 0.7884546746672556}, 'dot': {'accuracy': 0.8764379805686356, 'accuracy_threshold': 0.8400453369345874, 'f1': 0.71886767952214, 'f1_threshold': 0.8288537031677914, 'precision': 0.7077473791869087, 'recall': 0.7303430079155673, 'ap': 0.7884546746672556}, 'max': {'accuracy': 0.8764379805686356, 'f1': 0.71886767952214, 'ap': 0.7884546746672556}, 'evaluation_time': 4.32}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS15 as it already exists
Creating model angle$cohere$flag-embedding$gte-large$llmrails$voyage for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading cohere from cache for AmazonCounterfactualClassification...
Loading flag-embedding from cache for AmazonCounterfactualClassification...
Loading gte-large from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 0.33 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7555223880597015, 'f1': 0.6948434688289178, 'ap': 0.38511119267900695, 'accuracy_stderr': 0.039544071249066066, 'f1_stderr': 0.038434355910841364, 'ap_stderr': 0.04333232442923353, 'main_score': 0.7555223880597015}, 'evaluation_time': 0.33}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS22 as it already exists
Creating model angle$cohere$gist$gte-large$llmrails$mixed-bread$voyage for task RedditClustering
Loading angle from cache for RedditClustering...
Loading cohere from cache for RedditClustering...
Loading gist from cache for RedditClustering...
Loading gte-large from cache for RedditClustering...
Loading llmrails from cache for RedditClustering...
Loading mixed-bread from cache for RedditClustering...
Loading voyage from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS22 as it already exists
Creating model angle$cohere$flag-embedding$gte-large$llmrails$voyage for task RedditClustering
Loading angle from cache for RedditClustering...
Loading cohere from cache for RedditClustering...
Loading flag-embedding from cache for RedditClustering...
Loading gte-large from cache for RedditClustering...
Loading llmrails from cache for RedditClustering...
Loading voyage from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.abstasks.AbsTaskClustering:
Task: RedditClustering, split: test. Running...
INFO:mteb.abstasks.AbsTaskClustering:
Task: RedditClustering, split: test. Running...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:03<01:15,  3.16s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:03<01:22,  3.43s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:06<01:21,  3.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:07<01:26,  3.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:14<01:55,  5.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:15<02:10,  5.91s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:17<01:29,  4.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:18<01:40,  4.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:19<01:11,  3.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:21<01:16,  3.81s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [00:22<01:03,  3.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [00:25<00:57,  3.18s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [00:25<01:16,  4.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [00:27<00:58,  3.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [00:28<00:56,  3.34s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [00:31<00:59,  3.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [00:33<00:59,  3.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [00:36<01:04,  4.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [00:38<01:01,  4.13s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [00:40<01:00,  4.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [00:42<00:56,  4.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [00:43<00:39,  3.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [00:46<00:37,  3.09s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [00:46<01:04,  4.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [00:47<00:45,  3.52s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [00:50<00:42,  3.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [00:51<00:39,  3.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [00:52<00:28,  2.88s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [00:54<00:39,  3.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [00:57<00:32,  3.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [00:57<00:33,  3.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [01:00<00:26,  3.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [01:01<00:19,  2.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [01:02<00:35,  3.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [01:04<00:16,  2.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [01:05<00:28,  3.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [01:06<00:19,  2.81s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [01:08<00:16,  3.28s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [01:10<00:18,  3.09s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [01:12<00:14,  3.52s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [01:16<00:19,  3.93s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [01:18<00:11,  3.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [01:19<00:06,  3.16s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [01:21<00:17,  4.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [01:22<00:03,  3.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [01:29<00:15,  5.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [01:29<00:00,  4.27s/it]Clustering: 100%|██████████| 25/25 [01:29<00:00,  3.57s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 89.24 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.6136316651781369, 'v_measure_std': 0.04988316274788132, 'main_score': 0.6136316651781369, 'evaluation_time': 89.24}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [01:29<00:07,  3.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [01:32<00:03,  3.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [01:35<00:00,  3.44s/it]Clustering: 100%|██████████| 25/25 [01:35<00:00,  3.82s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 95.60 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.6145516847385487, 'v_measure_std': 0.04414320528232587, 'main_score': 0.6145516847385487, 'evaluation_time': 95.6}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS13 as it already exists
Creating model angle$cohere$flag-embedding$gte-large$llmrails$voyage for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading cohere from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading gte-large from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS13 as it already exists
Creating model angle$cohere$gist$gte-large$llmrails$mixed-bread$voyage for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading cohere from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
Loading gte-large from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 1.52 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6472303709387681, 'mrr': 0.7819625818933298, 'evaluation_time': 1.52}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 0.82 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6489370516300157, 'mrr': 0.7831937299388824, 'evaluation_time': 0.82}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Creating model angle$cohere$gist$gte-large$llmrails$mixed-bread$voyage for task SciFact
Loading angle from cache for SciFact...
Loading cohere from cache for SciFact...
Loading gist from cache for SciFact...
Loading gte-large from cache for SciFact...
Loading llmrails from cache for SciFact...
Loading mixed-bread from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Retrieval
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Creating model angle$cohere$flag-embedding$gte-large$llmrails$voyage for task SciFact
Loading angle from cache for SciFact...
Loading cohere from cache for SciFact...
Loading flag-embedding from cache for SciFact...
Loading gte-large from cache for SciFact...
Loading llmrails from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
    - SciFact, s2p
Retrieval


    - SciFact, s2p
INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************


INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 5183 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '4983', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.', 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 5183 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '4983', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.', 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 300 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '1', 'text': '0-dimensional biomaterials show inductive properties.'}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 300 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '1', 'text': '0-dimensional biomaterials show inductive properties.'}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.86 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.42 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.6533
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.7065
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.7332
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.7607
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.7791
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.7835
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.6243
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.6844
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.7020
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.7163
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.7210
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.7212
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.6243
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.7434
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.8099
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.8882
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9683
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 1.0000
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.6533
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2722
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1807
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.1007
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0110
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0011
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.6600
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.7112
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.7376
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.7636
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.7829
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.7868
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.6309
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.6895
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.7067
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.7206
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.7254
INFO:root:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.7256
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.6309
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.7468
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.8133
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.8866
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9717
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 1.0000
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.6600
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2744
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1820
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.1007
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0110
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6533
INFO:root:MRR@3: 0.7011
INFO:root:MRR@5: 0.7166
INFO:root:MRR@10: 0.7259
INFO:root:MRR@100: 0.7294
INFO:root:MRR@1000: 0.7296
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 3.00 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.65333, 'ndcg_at_3': 0.70651, 'ndcg_at_5': 0.73324, 'ndcg_at_10': 0.76073, 'ndcg_at_100': 0.77907, 'ndcg_at_1000': 0.78352, 'map_at_1': 0.62428, 'map_at_3': 0.68441, 'map_at_5': 0.70198, 'map_at_10': 0.71631, 'map_at_100': 0.72102, 'map_at_1000': 0.72125, 'recall_at_1': 0.62428, 'recall_at_3': 0.74339, 'recall_at_5': 0.80994, 'recall_at_10': 0.88822, 'recall_at_100': 0.96833, 'recall_at_1000': 1.0, 'precision_at_1': 0.65333, 'precision_at_3': 0.27222, 'precision_at_5': 0.18067, 'precision_at_10': 0.10067, 'precision_at_100': 0.01097, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.65333, 'mrr_at_3': 0.70111, 'mrr_at_5': 0.71661, 'mrr_at_10': 0.72586, 'mrr_at_100': 0.72935, 'mrr_at_1000': 0.72958, 'evaluation_time': 3.0}
INFO:root:MRR@1: 0.6600
INFO:root:MRR@3: 0.7044
INFO:root:MRR@5: 0.7206
INFO:root:MRR@10: 0.7294
INFO:root:MRR@100: 0.7333
INFO:root:MRR@1000: 0.7335
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 2.56 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.66, 'ndcg_at_3': 0.71118, 'ndcg_at_5': 0.73756, 'ndcg_at_10': 0.76356, 'ndcg_at_100': 0.78285, 'ndcg_at_1000': 0.78683, 'map_at_1': 0.63094, 'map_at_3': 0.68948, 'map_at_5': 0.70675, 'map_at_10': 0.72056, 'map_at_100': 0.72538, 'map_at_1000': 0.72559, 'recall_at_1': 0.63094, 'recall_at_3': 0.74683, 'recall_at_5': 0.81328, 'recall_at_10': 0.88656, 'recall_at_100': 0.97167, 'recall_at_1000': 1.0, 'precision_at_1': 0.66, 'precision_at_3': 0.27444, 'precision_at_5': 0.182, 'precision_at_10': 0.10067, 'precision_at_100': 0.011, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.66, 'mrr_at_3': 0.70444, 'mrr_at_5': 0.72061, 'mrr_at_10': 0.72935, 'mrr_at_100': 0.73328, 'mrr_at_1000': 0.73347, 'evaluation_time': 2.56}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Creating model angle$cohere$gist$gte-large$llmrails$mixed-bread$voyage for task Banking77Classification
Loading angle from cache for Banking77Classification...
Loading cohere from cache for Banking77Classification...
Loading gist from cache for Banking77Classification...
Loading gte-large from cache for Banking77Classification...
Loading llmrails from cache for Banking77Classification...
Loading mixed-bread from cache for Banking77Classification...
Loading voyage from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Classification
    - Banking77Classification, s2s
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Creating model angle$cohere$flag-embedding$gte-large$llmrails$voyage for task Banking77Classification
Loading angle from cache for Banking77Classification...
Loading cohere from cache for Banking77Classification...
Loading flag-embedding from cache for Banking77Classification...
Loading gte-large from cache for Banking77Classification...
Loading llmrails from cache for Banking77Classification...
Loading voyage from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────


Classification
INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
    - Banking77Classification, s2s
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 13.70 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8439935064935064, 'f1': 0.8374675151412474, 'accuracy_stderr': 0.004952230059306306, 'f1_stderr': 0.005930800217487768, 'main_score': 0.8439935064935064, 'evaluation_time': 13.7}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 14.93 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8512337662337662, 'f1': 0.8456562792861579, 'accuracy_stderr': 0.004458349063317364, 'f1_stderr': 0.005363007068579761, 'main_score': 0.8512337662337662, 'evaluation_time': 14.93}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$gist$gte-large$llmrails$mixed-bread$voyage for task ArguAna
Loading angle from cache for ArguAna...
Loading cohere from cache for ArguAna...
Loading gist from cache for ArguAna...
Loading gte-large from cache for ArguAna...
Loading llmrails from cache for ArguAna...
Loading mixed-bread from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Retrieval
    - ArguAna, p2p
Creating model angle$cohere$flag-embedding$gte-large$llmrails$voyage for task ArguAna
Loading angle from cache for ArguAna...
Loading cohere from cache for ArguAna...
Loading flag-embedding from cache for ArguAna...
Loading gte-large from cache for ArguAna...
Loading llmrails from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────


Retrieval
INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
    - ArguAna, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 8674 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'test-environment-aeghhgwpe-pro02b', 'title': 'animals environment general health health general weight philosophy ethics', 'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008"}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 8674 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'test-environment-aeghhgwpe-pro02b', 'title': 'animals environment general health health general weight philosophy ethics', 'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008"}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 1406 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': 'test-environment-aeghhgwpe-pro02a', 'text': "Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004"}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 1406 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': 'test-environment-aeghhgwpe-pro02a', 'text': "Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004"}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 5.78 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 6.27 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.3919
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.5606
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.6068
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.6430
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.6649
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.6654
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.3919
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.5193
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.5451
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.5602
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.5659
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.5659
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.3919
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.6799
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.7916
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.9026
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9929
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 0.9964
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.3919
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2266
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1583
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.0903
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0099
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0010
INFO:root:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.3962
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.5658
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.6106
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.6485
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.6686
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.6690
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.3962
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.5243
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.5492
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.5651
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.5703
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.5703
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.3962
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.6856
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.7944
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.9104
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9936
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 0.9964
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.3962
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2285
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1589
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.0910
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0099
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.3990
INFO:root:MRR@3: 0.5222
INFO:root:MRR@5: 0.5475
INFO:root:MRR@10: 0.5627
INFO:root:MRR@100: 0.5685
INFO:root:MRR@1000: 0.5685
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 6.41 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.39189, 'ndcg_at_3': 0.56059, 'ndcg_at_5': 0.60678, 'ndcg_at_10': 0.64298, 'ndcg_at_100': 0.66489, 'ndcg_at_1000': 0.66539, 'map_at_1': 0.39189, 'map_at_3': 0.51932, 'map_at_5': 0.54507, 'map_at_10': 0.56018, 'map_at_100': 0.56591, 'map_at_1000': 0.56594, 'recall_at_1': 0.39189, 'recall_at_3': 0.67994, 'recall_at_5': 0.79161, 'recall_at_10': 0.90256, 'recall_at_100': 0.99289, 'recall_at_1000': 0.99644, 'precision_at_1': 0.39189, 'precision_at_3': 0.22665, 'precision_at_5': 0.15832, 'precision_at_10': 0.09026, 'precision_at_100': 0.00993, 'precision_at_1000': 0.001, 'mrr_at_1': 0.399, 'mrr_at_3': 0.52217, 'mrr_at_5': 0.54752, 'mrr_at_10': 0.56268, 'mrr_at_100': 0.56847, 'mrr_at_1000': 0.5685, 'evaluation_time': 6.41}
INFO:root:MRR@1: 0.4040
INFO:root:MRR@3: 0.5272
INFO:root:MRR@5: 0.5520
INFO:root:MRR@10: 0.5680
INFO:root:MRR@100: 0.5731
INFO:root:MRR@1000: 0.5731
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 6.89 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.39616, 'ndcg_at_3': 0.56576, 'ndcg_at_5': 0.61063, 'ndcg_at_10': 0.64853, 'ndcg_at_100': 0.66863, 'ndcg_at_1000': 0.66902, 'map_at_1': 0.39616, 'map_at_3': 0.5243, 'map_at_5': 0.54923, 'map_at_10': 0.56511, 'map_at_100': 0.57033, 'map_at_1000': 0.57034, 'recall_at_1': 0.39616, 'recall_at_3': 0.68563, 'recall_at_5': 0.79445, 'recall_at_10': 0.91038, 'recall_at_100': 0.9936, 'recall_at_1000': 0.99644, 'precision_at_1': 0.39616, 'precision_at_3': 0.22854, 'precision_at_5': 0.15889, 'precision_at_10': 0.09104, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.40398, 'mrr_at_3': 0.52715, 'mrr_at_5': 0.55204, 'mrr_at_10': 0.56796, 'mrr_at_100': 0.57311, 'mrr_at_1000': 0.57313, 'evaluation_time': 6.89}
INFO:main:Running task: ArxivClusteringS2S
Converting the results to a CSV file...
Using model name angle$cohere$gist$gte-large$llmrails$mixed-bread$voyage
Converting results/angle$cohere$gist$gte-large$llmrails$mixed-bread$voyage to results/angle$cohere$gist$gte-large$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gte-large$llmrails$voyage
Converting results/angle$cohere$flag-embedding$gte-large$llmrails$voyage to results/angle$cohere$flag-embedding$gte-large$llmrails$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$gte-large$mixed-bread$voyage...
Creating model angle$cohere$flag-embedding$gte-large$mixed-bread$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:02<01:21,  2.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:05<01:19,  2.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:08<01:16,  2.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [00:10<01:12,  2.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [00:13<01:10,  2.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [00:16<01:05,  2.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [00:18<01:03,  2.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [00:21<01:00,  2.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [00:23<00:57,  2.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [00:26<00:54,  2.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [00:31<01:05,  3.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [00:35<01:10,  3.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [00:40<01:12,  4.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [00:45<01:11,  4.22s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [00:50<01:11,  4.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [00:55<01:08,  4.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [01:00<01:06,  4.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [01:04<00:59,  4.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [01:09<00:54,  4.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [01:13<00:49,  4.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [01:17<00:43,  4.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [01:18<00:28,  3.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [01:22<00:28,  3.54s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [01:25<00:23,  3.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [01:28<00:19,  3.25s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [01:29<00:13,  2.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [01:32<00:11,  2.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [01:35<00:08,  2.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [01:38<00:05,  2.82s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [01:40<00:02,  2.66s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [01:43<00:00,  2.69s/it]Clustering: 100%|██████████| 31/31 [01:43<00:00,  3.33s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 103.34 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4349081179090444, 'v_measure_std': 0.1425141112284918, 'main_score': 0.4349081179090444, 'evaluation_time': 103.34}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Creating model angle$cohere$flag-embedding$gte-large$mixed-bread$voyage for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading cohere from cache for EmotionClassification...
Loading flag-embedding from cache for EmotionClassification...
Loading gte-large from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 1.50 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.55, 'f1': 0.4844194360657834, 'accuracy_stderr': 0.0225, 'f1_stderr': 0.013065409393157935, 'main_score': 0.55, 'evaluation_time': 1.5}
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gte-large$mixed-bread$voyage for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading cohere from cache for TwitterSemEval2015...
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gte-large from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 3.10 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8763187697442928, 'accuracy_threshold': 0.8502344815379536, 'f1': 0.7179162978884814, 'f1_threshold': 0.8269578089405795, 'precision': 0.6892449623695072, 'recall': 0.7490765171503958, 'ap': 0.7867959696213684}, 'manhattan': {'accuracy': 0.8756631102104071, 'accuracy_threshold': 33.26440373731719, 'f1': 0.7179812325640376, 'f1_threshold': 35.73244182802552, 'precision': 0.691162109375, 'recall': 0.7469656992084432, 'ap': 0.785620071158732}, 'euclidean': {'accuracy': 0.8763187697442928, 'accuracy_threshold': 0.5472942851192536, 'f1': 0.7179162978884814, 'f1_threshold': 0.5882893685732797, 'precision': 0.6892449623695072, 'recall': 0.7490765171503958, 'ap': 0.7867959696213684}, 'dot': {'accuracy': 0.8763187697442928, 'accuracy_threshold': 0.8502344815379537, 'f1': 0.7179162978884814, 'f1_threshold': 0.8269578089405795, 'precision': 0.6892449623695072, 'recall': 0.7490765171503958, 'ap': 0.7867959696213684}, 'max': {'accuracy': 0.8763187697442928, 'f1': 0.7179812325640376, 'ap': 0.7867959696213684}, 'evaluation_time': 3.1}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS15 as it already exists
Creating model angle$cohere$flag-embedding$gte-large$mixed-bread$voyage for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading cohere from cache for AmazonCounterfactualClassification...
Loading flag-embedding from cache for AmazonCounterfactualClassification...
Loading gte-large from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 0.32 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7507462686567163, 'f1': 0.6903510659362083, 'ap': 0.3800515376319777, 'accuracy_stderr': 0.03901208179750337, 'f1_stderr': 0.037299092099735066, 'ap_stderr': 0.04056676158831498, 'main_score': 0.7507462686567163}, 'evaluation_time': 0.32}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS22 as it already exists
Creating model angle$cohere$flag-embedding$gte-large$mixed-bread$voyage for task RedditClustering
Loading angle from cache for RedditClustering...
Loading cohere from cache for RedditClustering...
Loading flag-embedding from cache for RedditClustering...
Loading gte-large from cache for RedditClustering...
Loading mixed-bread from cache for RedditClustering...
Loading voyage from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.abstasks.AbsTaskClustering:
Task: RedditClustering, split: test. Running...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:01<00:26,  1.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:02<00:33,  1.46s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:06<00:57,  2.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:08<00:48,  2.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:10<00:41,  2.08s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [00:12<00:42,  2.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [00:14<00:34,  1.91s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [00:17<00:39,  2.34s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [00:21<00:44,  2.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [00:24<00:43,  2.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [00:27<00:41,  2.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [00:28<00:30,  2.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [00:29<00:24,  2.05s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [00:32<00:25,  2.33s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [00:33<00:19,  1.93s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [00:37<00:21,  2.40s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [00:39<00:18,  2.28s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [00:39<00:12,  1.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [00:42<00:11,  1.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [00:46<00:13,  2.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [00:50<00:12,  3.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [00:53<00:09,  3.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [00:54<00:05,  2.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [00:57<00:02,  2.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [01:00<00:00,  2.78s/it]Clustering: 100%|██████████| 25/25 [01:00<00:00,  2.43s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 60.69 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.6141969205713153, 'v_measure_std': 0.04683129232306226, 'main_score': 0.6141969205713153, 'evaluation_time': 60.69}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS13 as it already exists
Creating model angle$cohere$flag-embedding$gte-large$mixed-bread$voyage for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading cohere from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading gte-large from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 0.72 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.646236016799641, 'mrr': 0.7794002550235237, 'evaluation_time': 0.72}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Creating model angle$cohere$flag-embedding$gte-large$mixed-bread$voyage for task SciFact
Loading angle from cache for SciFact...
Loading cohere from cache for SciFact...
Loading flag-embedding from cache for SciFact...
Loading gte-large from cache for SciFact...
Loading mixed-bread from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 5183 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '4983', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.', 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 300 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '1', 'text': '0-dimensional biomaterials show inductive properties.'}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.24 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.6467
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.7038
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.7291
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.7607
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.7778
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.7818
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.6176
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.6813
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.6979
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.7142
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.7184
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.7186
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.6176
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.7428
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.8049
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.8949
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9717
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 1.0000
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.6467
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2722
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1800
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.1013
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0110
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6467
INFO:root:MRR@3: 0.6967
INFO:root:MRR@5: 0.7125
INFO:root:MRR@10: 0.7235
INFO:root:MRR@100: 0.7265
INFO:root:MRR@1000: 0.7267
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 2.36 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.64667, 'ndcg_at_3': 0.70381, 'ndcg_at_5': 0.7291, 'ndcg_at_10': 0.76072, 'ndcg_at_100': 0.77779, 'ndcg_at_1000': 0.78177, 'map_at_1': 0.61761, 'map_at_3': 0.68126, 'map_at_5': 0.69786, 'map_at_10': 0.71422, 'map_at_100': 0.71842, 'map_at_1000': 0.71864, 'recall_at_1': 0.61761, 'recall_at_3': 0.74283, 'recall_at_5': 0.80494, 'recall_at_10': 0.89489, 'recall_at_100': 0.97167, 'recall_at_1000': 1.0, 'precision_at_1': 0.64667, 'precision_at_3': 0.27222, 'precision_at_5': 0.18, 'precision_at_10': 0.10133, 'precision_at_100': 0.011, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.64667, 'mrr_at_3': 0.69667, 'mrr_at_5': 0.7125, 'mrr_at_10': 0.72354, 'mrr_at_100': 0.72654, 'mrr_at_1000': 0.72673, 'evaluation_time': 2.36}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Creating model angle$cohere$flag-embedding$gte-large$mixed-bread$voyage for task Banking77Classification
Loading angle from cache for Banking77Classification...
Loading cohere from cache for Banking77Classification...
Loading flag-embedding from cache for Banking77Classification...
Loading gte-large from cache for Banking77Classification...
Loading mixed-bread from cache for Banking77Classification...
Loading voyage from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 6.55 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8436688311688311, 'f1': 0.8371972121231346, 'accuracy_stderr': 0.005107319330510043, 'f1_stderr': 0.006009679246029249, 'main_score': 0.8436688311688311, 'evaluation_time': 6.55}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gte-large$mixed-bread$voyage for task ArguAna
Loading angle from cache for ArguAna...
Loading cohere from cache for ArguAna...
Loading flag-embedding from cache for ArguAna...
Loading gte-large from cache for ArguAna...
Loading mixed-bread from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 8674 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'test-environment-aeghhgwpe-pro02b', 'title': 'animals environment general health health general weight philosophy ethics', 'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008"}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 1406 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': 'test-environment-aeghhgwpe-pro02a', 'text': "Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004"}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 4.60 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.3926
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.5633
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.6080
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.6448
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.6656
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.6661
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.3926
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.5211
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.5459
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.5613
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.5667
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.5667
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.3926
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.6856
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.7937
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.9068
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9929
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 0.9964
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.3926
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2285
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1588
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.0907
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0099
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.3990
INFO:root:MRR@3: 0.5242
INFO:root:MRR@5: 0.5479
INFO:root:MRR@10: 0.5638
INFO:root:MRR@100: 0.5692
INFO:root:MRR@1000: 0.5692
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 5.20 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.3926, 'ndcg_at_3': 0.56333, 'ndcg_at_5': 0.60796, 'ndcg_at_10': 0.64478, 'ndcg_at_100': 0.66563, 'ndcg_at_1000': 0.66612, 'map_at_1': 0.3926, 'map_at_3': 0.5211, 'map_at_5': 0.54592, 'map_at_10': 0.56127, 'map_at_100': 0.56669, 'map_at_1000': 0.56672, 'recall_at_1': 0.3926, 'recall_at_3': 0.68563, 'recall_at_5': 0.79374, 'recall_at_10': 0.90683, 'recall_at_100': 0.99289, 'recall_at_1000': 0.99644, 'precision_at_1': 0.3926, 'precision_at_3': 0.22854, 'precision_at_5': 0.15875, 'precision_at_10': 0.09068, 'precision_at_100': 0.00993, 'precision_at_1000': 0.001, 'mrr_at_1': 0.399, 'mrr_at_3': 0.52418, 'mrr_at_5': 0.5479, 'mrr_at_10': 0.5638, 'mrr_at_100': 0.56916, 'mrr_at_1000': 0.56919, 'evaluation_time': 5.2}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gte-large$mixed-bread$voyage
Converting results/angle$cohere$flag-embedding$gte-large$mixed-bread$voyage to results/angle$cohere$flag-embedding$gte-large$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$llmrails$mixed-bread$voyage...
Creating model angle$cohere$flag-embedding$llmrails$mixed-bread$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.abstasks.AbsTaskClustering:
Task: ArxivClusteringS2S, split: test. Running...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:02<01:19,  2.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:05<01:16,  2.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:07<01:12,  2.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [00:10<01:10,  2.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [00:13<01:08,  2.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [00:15<01:03,  2.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [00:18<01:01,  2.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [00:20<00:59,  2.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [00:23<00:56,  2.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [00:25<00:53,  2.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [00:30<01:02,  3.13s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [00:34<01:08,  3.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [00:39<01:10,  3.94s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [00:44<01:11,  4.18s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [00:48<01:08,  4.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [00:53<01:06,  4.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [00:58<01:03,  4.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [01:03<01:00,  4.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [01:07<00:55,  4.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [01:12<00:49,  4.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [01:16<00:43,  4.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [01:16<00:28,  3.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [01:20<00:27,  3.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [01:22<00:21,  3.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [01:25<00:18,  3.05s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [01:27<00:12,  2.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [01:30<00:10,  2.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [01:33<00:08,  2.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [01:36<00:05,  2.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [01:38<00:02,  2.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [01:41<00:00,  2.66s/it]Clustering: 100%|██████████| 31/31 [01:41<00:00,  3.26s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 101.11 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4326706013910097, 'v_measure_std': 0.14200809039254078, 'main_score': 0.4326706013910097, 'evaluation_time': 101.11}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Creating model angle$cohere$flag-embedding$llmrails$mixed-bread$voyage for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading cohere from cache for EmotionClassification...
Loading flag-embedding from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 1.32 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5543500000000001, 'f1': 0.48916871002766904, 'accuracy_stderr': 0.025044011260179553, 'f1_stderr': 0.01502810008283394, 'main_score': 0.5543500000000001, 'evaluation_time': 1.32}
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$llmrails$mixed-bread$voyage for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading cohere from cache for TwitterSemEval2015...
Loading flag-embedding from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 3.07 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8778685104607499, 'accuracy_threshold': 0.8131575610581476, 'f1': 0.7245593721857712, 'f1_threshold': 0.7948518660932119, 'precision': 0.707004770273663, 'recall': 0.7430079155672823, 'ap': 0.793224329654624}, 'manhattan': {'accuracy': 0.8781069321094356, 'accuracy_threshold': 36.988763307182666, 'f1': 0.7218025860965306, 'f1_threshold': 38.88807204538463, 'precision': 0.701069385724944, 'recall': 0.7437994722955145, 'ap': 0.7926665766726455}, 'euclidean': {'accuracy': 0.8778685104607499, 'accuracy_threshold': 0.6112976997921551, 'f1': 0.7245593721857712, 'f1_threshold': 0.6405437281436859, 'precision': 0.707004770273663, 'recall': 0.7430079155672823, 'ap': 0.793224329654624}, 'dot': {'accuracy': 0.8778685104607499, 'accuracy_threshold': 0.8131575610581482, 'f1': 0.7245593721857712, 'f1_threshold': 0.7948518660932119, 'precision': 0.707004770273663, 'recall': 0.7430079155672823, 'ap': 0.793224329654624}, 'max': {'accuracy': 0.8781069321094356, 'f1': 0.7245593721857712, 'ap': 0.793224329654624}, 'evaluation_time': 3.07}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS15 as it already exists
Creating model angle$cohere$flag-embedding$llmrails$mixed-bread$voyage for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading cohere from cache for AmazonCounterfactualClassification...
Loading flag-embedding from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 0.25 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7544776119402986, 'f1': 0.6941789437016066, 'ap': 0.3843725389455415, 'accuracy_stderr': 0.03602708072795477, 'f1_stderr': 0.03411624428803609, 'ap_stderr': 0.037757470299543044, 'main_score': 0.7544776119402986}, 'evaluation_time': 0.25}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS22 as it already exists
Creating model angle$cohere$flag-embedding$llmrails$mixed-bread$voyage for task RedditClustering
Loading angle from cache for RedditClustering...
Loading cohere from cache for RedditClustering...
Loading flag-embedding from cache for RedditClustering...
Loading llmrails from cache for RedditClustering...
Loading mixed-bread from cache for RedditClustering...
Loading voyage from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.abstasks.AbsTaskClustering:
Task: RedditClustering, split: test. Running...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:00<00:22,  1.06it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:02<00:28,  1.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:05<00:50,  2.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:07<00:42,  2.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:08<00:35,  1.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [00:10<00:35,  1.87s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [00:12<00:29,  1.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [00:14<00:33,  1.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [00:17<00:36,  2.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [00:20<00:36,  2.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [00:23<00:34,  2.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [00:23<00:25,  1.94s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [00:25<00:20,  1.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [00:27<00:20,  1.88s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [00:28<00:16,  1.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [00:31<00:18,  2.00s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [00:32<00:15,  1.90s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [00:33<00:10,  1.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [00:35<00:10,  1.68s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [00:38<00:10,  2.17s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [00:42<00:10,  2.52s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [00:45<00:07,  2.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [00:45<00:04,  2.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [00:47<00:02,  2.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [00:50<00:00,  2.26s/it]Clustering: 100%|██████████| 25/25 [00:50<00:00,  2.02s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 50.62 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.605680178317225, 'v_measure_std': 0.05037599734158438, 'main_score': 0.605680178317225, 'evaluation_time': 50.62}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS13 as it already exists
Creating model angle$cohere$flag-embedding$llmrails$mixed-bread$voyage for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading cohere from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 0.68 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6490473545692006, 'mrr': 0.7828474695510708, 'evaluation_time': 0.68}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping STS14 as it already exists
Creating model angle$cohere$flag-embedding$llmrails$mixed-bread$voyage for task SciFact
Loading angle from cache for SciFact...
Loading cohere from cache for SciFact...
Loading flag-embedding from cache for SciFact...
Loading llmrails from cache for SciFact...
Loading mixed-bread from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 5183 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': '4983', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.', 'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.'}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 300 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': '1', 'text': '0-dimensional biomaterials show inductive properties.'}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 2.23 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.6567
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.7090
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.7347
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.7569
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.7793
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.7832
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.6249
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.6862
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.7036
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.7154
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.7209
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.7211
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.6249
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.7452
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.8108
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.8732
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9717
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 1.0000
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.6567
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2744
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1813
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.0993
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0110
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6567
INFO:root:MRR@3: 0.7033
INFO:root:MRR@5: 0.7188
INFO:root:MRR@10: 0.7259
INFO:root:MRR@100: 0.7306
INFO:root:MRR@1000: 0.7308
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 2.36 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.65667, 'ndcg_at_3': 0.70899, 'ndcg_at_5': 0.73468, 'ndcg_at_10': 0.75694, 'ndcg_at_100': 0.77928, 'ndcg_at_1000': 0.78319, 'map_at_1': 0.62494, 'map_at_3': 0.6862, 'map_at_5': 0.70355, 'map_at_10': 0.71539, 'map_at_100': 0.72088, 'map_at_1000': 0.72108, 'recall_at_1': 0.62494, 'recall_at_3': 0.74517, 'recall_at_5': 0.81078, 'recall_at_10': 0.87322, 'recall_at_100': 0.97167, 'recall_at_1000': 1.0, 'precision_at_1': 0.65667, 'precision_at_3': 0.27444, 'precision_at_5': 0.18133, 'precision_at_10': 0.09933, 'precision_at_100': 0.011, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.65667, 'mrr_at_3': 0.70333, 'mrr_at_5': 0.71883, 'mrr_at_10': 0.72593, 'mrr_at_100': 0.73057, 'mrr_at_1000': 0.73075, 'evaluation_time': 2.36}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS17 as it already exists
Skipping STS16 as it already exists
Creating model angle$cohere$flag-embedding$llmrails$mixed-bread$voyage for task Banking77Classification
Loading angle from cache for Banking77Classification...
Loading cohere from cache for Banking77Classification...
Loading flag-embedding from cache for Banking77Classification...
Loading llmrails from cache for Banking77Classification...
Loading mixed-bread from cache for Banking77Classification...
Loading voyage from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/code/.venv/lib64/python3.9/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 6.95 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8507792207792206, 'f1': 0.8448999036800844, 'accuracy_stderr': 0.0047986090355434715, 'f1_stderr': 0.005545265637452021, 'main_score': 0.8507792207792206, 'evaluation_time': 6.95}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$llmrails$mixed-bread$voyage for task ArguAna
Loading angle from cache for ArguAna...
Loading cohere from cache for ArguAna...
Loading flag-embedding from cache for ArguAna...
Loading llmrails from cache for ArguAna...
Loading mixed-bread from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Corpus...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 8674 TEST Documents.
INFO:mteb.abstasks.AbsTaskRetrieval:Doc Example: {'id': 'test-environment-aeghhgwpe-pro02b', 'title': 'animals environment general health health general weight philosophy ethics', 'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008"}
INFO:mteb.abstasks.AbsTaskRetrieval:Loading Queries...
INFO:mteb.abstasks.AbsTaskRetrieval:Loaded 1406 TEST Queries.
INFO:mteb.abstasks.AbsTaskRetrieval:Query Example: {'id': 'test-environment-aeghhgwpe-pro02a', 'text': "Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004"}
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Queries...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Corpus in batches... Warning: This might take a while!
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Scoring Function: Cosine Similarity (cos_sim)
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Encoding Batch 1/1...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 4.57 seconds
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1: 0.4118
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@3: 0.5756
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@5: 0.6185
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@10: 0.6555
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@100: 0.6754
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:NDCG@1000: 0.6761
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1: 0.4118
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@3: 0.5351
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@5: 0.5592
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@10: 0.5747
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@100: 0.5798
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:MAP@1000: 0.5799
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1: 0.4118
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@3: 0.6927
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@5: 0.7959
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@10: 0.9090
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@100: 0.9915
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:Recall@1000: 0.9964
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:

INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1: 0.4118
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@3: 0.2309
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@5: 0.1592
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@10: 0.0909
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@100: 0.0099
INFO:mteb.evaluation.evaluators.RetrievalEvaluator:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.4182
INFO:root:MRR@3: 0.5375
INFO:root:MRR@5: 0.5614
INFO:root:MRR@10: 0.5768
INFO:root:MRR@100: 0.5819
INFO:root:MRR@1000: 0.5820
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 5.16 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.41181, 'ndcg_at_3': 0.57556, 'ndcg_at_5': 0.61851, 'ndcg_at_10': 0.65546, 'ndcg_at_100': 0.6754, 'ndcg_at_1000': 0.67609, 'map_at_1': 0.41181, 'map_at_3': 0.53509, 'map_at_5': 0.5592, 'map_at_10': 0.57466, 'map_at_100': 0.57983, 'map_at_1000': 0.57987, 'recall_at_1': 0.41181, 'recall_at_3': 0.69275, 'recall_at_5': 0.79587, 'recall_at_10': 0.90896, 'recall_at_100': 0.99147, 'recall_at_1000': 0.99644, 'precision_at_1': 0.41181, 'precision_at_3': 0.23092, 'precision_at_5': 0.15917, 'precision_at_10': 0.0909, 'precision_at_100': 0.00991, 'precision_at_1000': 0.001, 'mrr_at_1': 0.41821, 'mrr_at_3': 0.53746, 'mrr_at_5': 0.56143, 'mrr_at_10': 0.57677, 'mrr_at_100': 0.58194, 'mrr_at_1000': 0.58198, 'evaluation_time': 5.16}
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$llmrails$mixed-bread$voyage
Converting results/angle$cohere$flag-embedding$llmrails$mixed-bread$voyage to results/angle$cohere$flag-embedding$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
