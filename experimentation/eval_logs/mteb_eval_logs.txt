Num models to be evaluated: 255
Models to be evaluated: ['angle', 'cohere', 'flag-embedding', 'gist', 'gte-large', 'llmrails', 'mixed-bread', 'voyage', 'angle$cohere', 'angle$flag-embedding', 'angle$gist', 'angle$gte-large', 'angle$llmrails', 'angle$mixed-bread', 'angle$voyage', 'cohere$flag-embedding', 'cohere$gist', 'cohere$gte-large', 'cohere$llmrails', 'cohere$mixed-bread', 'cohere$voyage', 'flag-embedding$gist', 'flag-embedding$gte-large', 'flag-embedding$llmrails', 'flag-embedding$mixed-bread', 'flag-embedding$voyage', 'gist$gte-large', 'gist$llmrails', 'gist$mixed-bread', 'gist$voyage', 'gte-large$llmrails', 'gte-large$mixed-bread', 'gte-large$voyage', 'llmrails$mixed-bread', 'llmrails$voyage', 'mixed-bread$voyage', 'angle$cohere$flag-embedding', 'angle$cohere$gist', 'angle$cohere$gte-large', 'angle$cohere$llmrails', 'angle$cohere$mixed-bread', 'angle$cohere$voyage', 'angle$flag-embedding$gist', 'angle$flag-embedding$gte-large', 'angle$flag-embedding$llmrails', 'angle$flag-embedding$mixed-bread', 'angle$flag-embedding$voyage', 'angle$gist$gte-large', 'angle$gist$llmrails', 'angle$gist$mixed-bread', 'angle$gist$voyage', 'angle$gte-large$llmrails', 'angle$gte-large$mixed-bread', 'angle$gte-large$voyage', 'angle$llmrails$mixed-bread', 'angle$llmrails$voyage', 'angle$mixed-bread$voyage', 'cohere$flag-embedding$gist', 'cohere$flag-embedding$gte-large', 'cohere$flag-embedding$llmrails', 'cohere$flag-embedding$mixed-bread', 'cohere$flag-embedding$voyage', 'cohere$gist$gte-large', 'cohere$gist$llmrails', 'cohere$gist$mixed-bread', 'cohere$gist$voyage', 'cohere$gte-large$llmrails', 'cohere$gte-large$mixed-bread', 'cohere$gte-large$voyage', 'cohere$llmrails$mixed-bread', 'cohere$llmrails$voyage', 'cohere$mixed-bread$voyage', 'flag-embedding$gist$gte-large', 'flag-embedding$gist$llmrails', 'flag-embedding$gist$mixed-bread', 'flag-embedding$gist$voyage', 'flag-embedding$gte-large$llmrails', 'flag-embedding$gte-large$mixed-bread', 'flag-embedding$gte-large$voyage', 'flag-embedding$llmrails$mixed-bread', 'flag-embedding$llmrails$voyage', 'flag-embedding$mixed-bread$voyage', 'gist$gte-large$llmrails', 'gist$gte-large$mixed-bread', 'gist$gte-large$voyage', 'gist$llmrails$mixed-bread', 'gist$llmrails$voyage', 'gist$mixed-bread$voyage', 'gte-large$llmrails$mixed-bread', 'gte-large$llmrails$voyage', 'gte-large$mixed-bread$voyage', 'llmrails$mixed-bread$voyage', 'angle$cohere$flag-embedding$gist', 'angle$cohere$flag-embedding$gte-large', 'angle$cohere$flag-embedding$llmrails', 'angle$cohere$flag-embedding$mixed-bread', 'angle$cohere$flag-embedding$voyage', 'angle$cohere$gist$gte-large', 'angle$cohere$gist$llmrails', 'angle$cohere$gist$mixed-bread', 'angle$cohere$gist$voyage', 'angle$cohere$gte-large$llmrails', 'angle$cohere$gte-large$mixed-bread', 'angle$cohere$gte-large$voyage', 'angle$cohere$llmrails$mixed-bread', 'angle$cohere$llmrails$voyage', 'angle$cohere$mixed-bread$voyage', 'angle$flag-embedding$gist$gte-large', 'angle$flag-embedding$gist$llmrails', 'angle$flag-embedding$gist$mixed-bread', 'angle$flag-embedding$gist$voyage', 'angle$flag-embedding$gte-large$llmrails', 'angle$flag-embedding$gte-large$mixed-bread', 'angle$flag-embedding$gte-large$voyage', 'angle$flag-embedding$llmrails$mixed-bread', 'angle$flag-embedding$llmrails$voyage', 'angle$flag-embedding$mixed-bread$voyage', 'angle$gist$gte-large$llmrails', 'angle$gist$gte-large$mixed-bread', 'angle$gist$gte-large$voyage', 'angle$gist$llmrails$mixed-bread', 'angle$gist$llmrails$voyage', 'angle$gist$mixed-bread$voyage', 'angle$gte-large$llmrails$mixed-bread', 'angle$gte-large$llmrails$voyage', 'angle$gte-large$mixed-bread$voyage', 'angle$llmrails$mixed-bread$voyage', 'cohere$flag-embedding$gist$gte-large', 'cohere$flag-embedding$gist$llmrails', 'cohere$flag-embedding$gist$mixed-bread', 'cohere$flag-embedding$gist$voyage', 'cohere$flag-embedding$gte-large$llmrails', 'cohere$flag-embedding$gte-large$mixed-bread', 'cohere$flag-embedding$gte-large$voyage', 'cohere$flag-embedding$llmrails$mixed-bread', 'cohere$flag-embedding$llmrails$voyage', 'cohere$flag-embedding$mixed-bread$voyage', 'cohere$gist$gte-large$llmrails', 'cohere$gist$gte-large$mixed-bread', 'cohere$gist$gte-large$voyage', 'cohere$gist$llmrails$mixed-bread', 'cohere$gist$llmrails$voyage', 'cohere$gist$mixed-bread$voyage', 'cohere$gte-large$llmrails$mixed-bread', 'cohere$gte-large$llmrails$voyage', 'cohere$gte-large$mixed-bread$voyage', 'cohere$llmrails$mixed-bread$voyage', 'flag-embedding$gist$gte-large$llmrails', 'flag-embedding$gist$gte-large$mixed-bread', 'flag-embedding$gist$gte-large$voyage', 'flag-embedding$gist$llmrails$mixed-bread', 'flag-embedding$gist$llmrails$voyage', 'flag-embedding$gist$mixed-bread$voyage', 'flag-embedding$gte-large$llmrails$mixed-bread', 'flag-embedding$gte-large$llmrails$voyage', 'flag-embedding$gte-large$mixed-bread$voyage', 'flag-embedding$llmrails$mixed-bread$voyage', 'gist$gte-large$llmrails$mixed-bread', 'gist$gte-large$llmrails$voyage', 'gist$gte-large$mixed-bread$voyage', 'gist$llmrails$mixed-bread$voyage', 'gte-large$llmrails$mixed-bread$voyage', 'angle$cohere$flag-embedding$gist$gte-large', 'angle$cohere$flag-embedding$gist$llmrails', 'angle$cohere$flag-embedding$gist$mixed-bread', 'angle$cohere$flag-embedding$gist$voyage', 'angle$cohere$flag-embedding$gte-large$llmrails', 'angle$cohere$flag-embedding$gte-large$mixed-bread', 'angle$cohere$flag-embedding$gte-large$voyage', 'angle$cohere$flag-embedding$llmrails$mixed-bread', 'angle$cohere$flag-embedding$llmrails$voyage', 'angle$cohere$flag-embedding$mixed-bread$voyage', 'angle$cohere$gist$gte-large$llmrails', 'angle$cohere$gist$gte-large$mixed-bread', 'angle$cohere$gist$gte-large$voyage', 'angle$cohere$gist$llmrails$mixed-bread', 'angle$cohere$gist$llmrails$voyage', 'angle$cohere$gist$mixed-bread$voyage', 'angle$cohere$gte-large$llmrails$mixed-bread', 'angle$cohere$gte-large$llmrails$voyage', 'angle$cohere$gte-large$mixed-bread$voyage', 'angle$cohere$llmrails$mixed-bread$voyage', 'angle$flag-embedding$gist$gte-large$llmrails', 'angle$flag-embedding$gist$gte-large$mixed-bread', 'angle$flag-embedding$gist$gte-large$voyage', 'angle$flag-embedding$gist$llmrails$mixed-bread', 'angle$flag-embedding$gist$llmrails$voyage', 'angle$flag-embedding$gist$mixed-bread$voyage', 'angle$flag-embedding$gte-large$llmrails$mixed-bread', 'angle$flag-embedding$gte-large$llmrails$voyage', 'angle$flag-embedding$gte-large$mixed-bread$voyage', 'angle$flag-embedding$llmrails$mixed-bread$voyage', 'angle$gist$gte-large$llmrails$mixed-bread', 'angle$gist$gte-large$llmrails$voyage', 'angle$gist$gte-large$mixed-bread$voyage', 'angle$gist$llmrails$mixed-bread$voyage', 'angle$gte-large$llmrails$mixed-bread$voyage', 'cohere$flag-embedding$gist$gte-large$llmrails', 'cohere$flag-embedding$gist$gte-large$mixed-bread', 'cohere$flag-embedding$gist$gte-large$voyage', 'cohere$flag-embedding$gist$llmrails$mixed-bread', 'cohere$flag-embedding$gist$llmrails$voyage', 'cohere$flag-embedding$gist$mixed-bread$voyage', 'cohere$flag-embedding$gte-large$llmrails$mixed-bread', 'cohere$flag-embedding$gte-large$llmrails$voyage', 'cohere$flag-embedding$gte-large$mixed-bread$voyage', 'cohere$flag-embedding$llmrails$mixed-bread$voyage', 'cohere$gist$gte-large$llmrails$mixed-bread', 'cohere$gist$gte-large$llmrails$voyage', 'cohere$gist$gte-large$mixed-bread$voyage', 'cohere$gist$llmrails$mixed-bread$voyage', 'cohere$gte-large$llmrails$mixed-bread$voyage', 'flag-embedding$gist$gte-large$llmrails$mixed-bread', 'flag-embedding$gist$gte-large$llmrails$voyage', 'flag-embedding$gist$gte-large$mixed-bread$voyage', 'flag-embedding$gist$llmrails$mixed-bread$voyage', 'flag-embedding$gte-large$llmrails$mixed-bread$voyage', 'gist$gte-large$llmrails$mixed-bread$voyage', 'angle$cohere$flag-embedding$gist$gte-large$llmrails', 'angle$cohere$flag-embedding$gist$gte-large$mixed-bread', 'angle$cohere$flag-embedding$gist$gte-large$voyage', 'angle$cohere$flag-embedding$gist$llmrails$mixed-bread', 'angle$cohere$flag-embedding$gist$llmrails$voyage', 'angle$cohere$flag-embedding$gist$mixed-bread$voyage', 'angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread', 'angle$cohere$flag-embedding$gte-large$llmrails$voyage', 'angle$cohere$flag-embedding$gte-large$mixed-bread$voyage', 'angle$cohere$flag-embedding$llmrails$mixed-bread$voyage', 'angle$cohere$gist$gte-large$llmrails$mixed-bread', 'angle$cohere$gist$gte-large$llmrails$voyage', 'angle$cohere$gist$gte-large$mixed-bread$voyage', 'angle$cohere$gist$llmrails$mixed-bread$voyage', 'angle$cohere$gte-large$llmrails$mixed-bread$voyage', 'angle$flag-embedding$gist$gte-large$llmrails$mixed-bread', 'angle$flag-embedding$gist$gte-large$llmrails$voyage', 'angle$flag-embedding$gist$gte-large$mixed-bread$voyage', 'angle$flag-embedding$gist$llmrails$mixed-bread$voyage', 'angle$flag-embedding$gte-large$llmrails$mixed-bread$voyage', 'angle$gist$gte-large$llmrails$mixed-bread$voyage', 'cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread', 'cohere$flag-embedding$gist$gte-large$llmrails$voyage', 'cohere$flag-embedding$gist$gte-large$mixed-bread$voyage', 'cohere$flag-embedding$gist$llmrails$mixed-bread$voyage', 'cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage', 'cohere$gist$gte-large$llmrails$mixed-bread$voyage', 'flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage', 'angle$cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread', 'angle$cohere$flag-embedding$gist$gte-large$llmrails$voyage', 'angle$cohere$flag-embedding$gist$gte-large$mixed-bread$voyage', 'angle$cohere$flag-embedding$gist$llmrails$mixed-bread$voyage', 'angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage', 'angle$cohere$gist$gte-large$llmrails$mixed-bread$voyage', 'angle$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage', 'cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage', 'angle$cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage']
Number of cores:  16
Running in parallel with 8 processes
INFO:main:Running task: ArxivClusteringS2S
INFO:main:Running task: ArxivClusteringS2S
INFO:main:Running task: ArxivClusteringS2S
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model cohere$gist...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name cohere$gist
Converting results/cohere$gist to results/cohere$gist_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$gte-large...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model cohere$gte-large for task AskUbuntuDupQuestions
Loading cohere from cache for AskUbuntuDupQuestions...
Loading gte-large from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:main:Running task: TwitterSemEval2015
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 7.52 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6249543887775445, 'mrr': 0.7471540693839863, 'evaluation_time': 7.52}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$gte-large for task SciFact
Loading cohere from cache for SciFact...
Loading gte-large from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.util:Downloading scifact.zip ...
/cs/student/ug/2020/damibose/.cache/huggingface/datasets/BeIR/scifact.zip:   0%|          | 0.00/2.69M [00:00<?, ?iB/s]/cs/student/ug/2020/damibose/.cache/huggingface/datasets/BeIR/scifact.zip:  32%|███▏      | 880k/2.69M [00:00<00:00, 9.00MiB/s]/cs/student/ug/2020/damibose/.cache/huggingface/datasets/BeIR/scifact.zip: 100%|██████████| 2.69M/2.69M [00:00<00:00, 15.4MiB/s]
INFO:beir.util:Unzipping scifact.zip ...
INFO:beir.datasets.data_loader:Loading Corpus...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
  0%|          | 0/5183 [00:00<?, ?it/s]INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model angle$cohere...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$cohere
Converting results/angle$cohere to results/angle$cohere_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$flag-embedding...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$flag-embedding
Converting results/angle$flag-embedding to results/angle$flag-embedding_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$gist...
Skipping STS17 as it already exists
Creating model angle$gist for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
  1%|▏         | 72/5183 [00:02<02:27, 34.65it/s] 66%|██████▌   | 3402/5183 [00:02<00:00, 2174.47it/s]100%|██████████| 5183/5183 [00:02<00:00, 2243.37it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
Evaluating the model angle$gist$llmrails...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$gist$llmrails
Converting results/angle$gist$llmrails to results/angle$gist$llmrails_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$gist$mixed-bread...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$gist$mixed-bread
Converting results/angle$gist$mixed-bread to results/angle$gist$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$gist$voyage...
Skipping STS17 as it already exists
Creating model angle$gist$voyage for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
Evaluating the model flag-embedding$mixed-bread...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name flag-embedding$mixed-bread
Converting results/flag-embedding$mixed-bread to results/flag-embedding$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model flag-embedding$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name flag-embedding$voyage
Converting results/flag-embedding$voyage to results/flag-embedding$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model gist$gte-large...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name gist$gte-large
Converting results/gist$gte-large to results/gist$gte-large_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model gist$llmrails...
Skipping STS17 as it already exists
Creating model gist$llmrails for task TwitterSemEval2015
Loading gist from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
PairClassification
    - TwitterSemEval2015, s2s
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:faiss.loader:Loading faiss.
INFO:faiss.loader:Successfully loaded faiss.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 10.68 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:root:

INFO:root:NDCG@1: 0.6467
INFO:root:NDCG@3: 0.7036
INFO:root:NDCG@5: 0.7219
INFO:root:NDCG@10: 0.7458
INFO:root:NDCG@100: 0.7693
INFO:root:NDCG@1000: 0.7735
INFO:root:

INFO:root:MAP@1: 0.6149
INFO:root:MAP@3: 0.6782
INFO:root:MAP@5: 0.6918
INFO:root:MAP@10: 0.7039
INFO:root:MAP@100: 0.7096
INFO:root:MAP@1000: 0.7098
INFO:root:

INFO:root:Recall@1: 0.6149
INFO:root:Recall@3: 0.7456
INFO:root:Recall@5: 0.7937
INFO:root:Recall@10: 0.8632
INFO:root:Recall@100: 0.9683
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6467
INFO:root:P@3: 0.2744
INFO:root:P@5: 0.1773
INFO:root:P@10: 0.0980
INFO:root:P@100: 0.0110
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6467
INFO:root:MRR@3: 0.6967
INFO:root:MRR@5: 0.7075
INFO:root:MRR@10: 0.7153
INFO:root:MRR@100: 0.7200
INFO:root:MRR@1000: 0.7202
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 15.36 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.64667, 'ndcg_at_3': 0.70362, 'ndcg_at_5': 0.7219, 'ndcg_at_10': 0.74578, 'ndcg_at_100': 0.76928, 'ndcg_at_1000': 0.77347, 'map_at_1': 0.61494, 'map_at_3': 0.6782, 'map_at_5': 0.69183, 'map_at_10': 0.70394, 'map_at_100': 0.70958, 'map_at_1000': 0.70976, 'recall_at_1': 0.61494, 'recall_at_3': 0.74556, 'recall_at_5': 0.79372, 'recall_at_10': 0.86322, 'recall_at_100': 0.96833, 'recall_at_1000': 1.0, 'precision_at_1': 0.64667, 'precision_at_3': 0.27444, 'precision_at_5': 0.17733, 'precision_at_10': 0.098, 'precision_at_100': 0.01097, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.64667, 'mrr_at_3': 0.69667, 'mrr_at_5': 0.7075, 'mrr_at_10': 0.7153, 'mrr_at_100': 0.72, 'mrr_at_1000': 0.72017, 'evaluation_time': 15.36}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Creating model cohere$gte-large for task AmazonCounterfactualClassification
Loading cohere from cache for AmazonCounterfactualClassification...
Loading gte-large from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 17.19 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.87369613160875, 'accuracy_threshold': 0.8095630407333374, 'f1': 0.714087876117336, 'f1_threshold': 0.7856805324554443, 'precision': 0.6828798458945341, 'recall': 0.7482849604221636, 'ap': 0.7816538643558175}, 'manhattan': {'accuracy': 0.8740537640817786, 'accuracy_threshold': 22.0153865814209, 'f1': 0.7141377524598652, 'f1_threshold': 23.309104919433594, 'precision': 0.701067615658363, 'recall': 0.7277044854881266, 'ap': 0.7812324874780867}, 'euclidean': {'accuracy': 0.87369613160875, 'accuracy_threshold': 0.6171497106552124, 'f1': 0.714087876117336, 'f1_threshold': 0.6547051668167114, 'precision': 0.6828798458945341, 'recall': 0.7482849604221636, 'ap': 0.7816539616478457}, 'dot': {'accuracy': 0.87369613160875, 'accuracy_threshold': 0.8095631003379822, 'f1': 0.714087876117336, 'f1_threshold': 0.7856805324554443, 'precision': 0.6828798458945341, 'recall': 0.7482849604221636, 'ap': 0.7816536970769716}, 'max': {'accuracy': 0.8740537640817786, 'f1': 0.7141377524598652, 'ap': 0.7816539616478457}, 'evaluation_time': 17.19}
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 17.22 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.87578232103475, 'accuracy_threshold': 0.8041488528251648, 'f1': 0.7223146844194086, 'f1_threshold': 0.7816035747528076, 'precision': 0.7015667744342203, 'recall': 0.7443271767810027, 'ap': 0.79015507295657}, 'manhattan': {'accuracy': 0.8759015318590928, 'accuracy_threshold': 22.64194107055664, 'f1': 0.7218179496999872, 'f1_threshold': 23.85763931274414, 'precision': 0.6992332426416028, 'recall': 0.745910290237467, 'ap': 0.7896418045776331}, 'euclidean': {'accuracy': 0.87578232103475, 'accuracy_threshold': 0.6258611679077148, 'f1': 0.7223146844194086, 'f1_threshold': 0.6609030961990356, 'precision': 0.7015667744342203, 'recall': 0.7443271767810027, 'ap': 0.7901550198318141}, 'dot': {'accuracy': 0.87578232103475, 'accuracy_threshold': 0.8041488528251648, 'f1': 0.7223146844194086, 'f1_threshold': 0.7816035747528076, 'precision': 0.7015667744342203, 'recall': 0.7443271767810027, 'ap': 0.7901548291667504}, 'max': {'accuracy': 0.8759015318590928, 'f1': 0.7223146844194086, 'ap': 0.79015507295657}, 'evaluation_time': 17.22}
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 16.69 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8742325803182929, 'accuracy_threshold': 0.8368275097132731, 'f1': 0.7150695419165497, 'f1_threshold': 0.8146495979014602, 'precision': 0.69236471460341, 'recall': 0.7393139841688654, 'ap': 0.7818055175571372}, 'manhattan': {'accuracy': 0.8742325803182929, 'accuracy_threshold': 24.492419505426255, 'f1': 0.712569435473453, 'f1_threshold': 25.78131781089114, 'precision': 0.69805112629714, 'recall': 0.7277044854881266, 'ap': 0.7795551464246421}, 'euclidean': {'accuracy': 0.8742325803182929, 'accuracy_threshold': 0.5712661205162898, 'f1': 0.7150695419165497, 'f1_threshold': 0.6088520380097715, 'precision': 0.69236471460341, 'recall': 0.7393139841688654, 'ap': 0.7818055175571372}, 'dot': {'accuracy': 0.8742325803182929, 'accuracy_threshold': 0.8368275097132734, 'f1': 0.7150695419165497, 'f1_threshold': 0.8146495979014603, 'precision': 0.69236471460341, 'recall': 0.7393139841688654, 'ap': 0.7818055175571372}, 'max': {'accuracy': 0.8742325803182929, 'f1': 0.7150695419165497, 'ap': 0.7818055175571372}, 'evaluation_time': 16.69}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:main:Running task: AskUbuntuDupQuestions
INFO:main:Running task: AskUbuntuDupQuestions
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model angle$gist for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model gist$llmrails for task AskUbuntuDupQuestions
Loading gist from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model angle$gist$voyage for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 1.93 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7919402985074627, 'f1': 0.7338617499371336, 'ap': 0.4353515642774329, 'accuracy_stderr': 0.03580969974292335, 'f1_stderr': 0.03481104198458447, 'ap_stderr': 0.044144712780751424, 'main_score': 0.7919402985074627}, 'evaluation_time': 1.93}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 7.73 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6482798043863712, 'mrr': 0.7778063580002639, 'evaluation_time': 7.73}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 7.31 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6481081562562732, 'mrr': 0.7764444004748714, 'evaluation_time': 7.31}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 7.26 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6478569402298074, 'mrr': 0.7836543112166381, 'evaluation_time': 7.26}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist for task SciFact
Loading angle from cache for SciFact...
Loading gist from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model gist$llmrails for task SciFact
Loading gist from cache for SciFact...
Loading llmrails from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist$voyage for task SciFact
Loading angle from cache for SciFact...
Loading gist from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:beir.datasets.data_loader:Loading Corpus...
INFO:beir.datasets.data_loader:Loading Corpus...
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s]  0%|          | 0/5183 [00:00<?, ?it/s]  0%|          | 0/5183 [00:00<?, ?it/s] 75%|███████▍  | 3882/5183 [00:00<00:00, 38807.18it/s] 86%|████████▋ | 4480/5183 [00:00<00:00, 44790.65it/s] 50%|████▉     | 2583/5183 [00:00<00:00, 25801.24it/s]100%|██████████| 5183/5183 [00:00<00:00, 44688.59it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
100%|██████████| 5183/5183 [00:00<00:00, 40453.53it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
100%|█████████▉| 5164/5183 [00:00<00:00, 25273.76it/s]100%|██████████| 5183/5183 [00:00<00:00, 25345.84it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:faiss.loader:Loading faiss.
INFO:faiss.loader:Loading faiss.
INFO:faiss.loader:Loading faiss.
INFO:faiss.loader:Successfully loaded faiss.
INFO:faiss.loader:Successfully loaded faiss.
INFO:faiss.loader:Successfully loaded faiss.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
Evaluating the model angle...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle
Converting results/angle to results/angle_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name cohere
Converting results/cohere to results/cohere_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model flag-embedding...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name flag-embedding
Converting results/flag-embedding to results/flag-embedding_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model gist...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name gist
Converting results/gist to results/gist_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model gte-large...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name gte-large
Converting results/gte-large to results/gte-large_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model llmrails...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name llmrails
Converting results/llmrails to results/llmrails_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model mixed-bread...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name mixed-bread
Converting results/mixed-bread to results/mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name voyage
Converting results/voyage to results/voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 152.56 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 152.57 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 152.61 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:

INFO:root:

INFO:root:NDCG@1: 0.6367
INFO:root:NDCG@1: 0.6500
INFO:root:NDCG@1: 0.6467
INFO:root:NDCG@3: 0.6939
INFO:root:NDCG@3: 0.7014
INFO:root:NDCG@3: 0.7011
INFO:root:NDCG@5: 0.7348
INFO:root:NDCG@5: 0.7235
INFO:root:NDCG@5: 0.7278
INFO:root:NDCG@10: 0.7567
INFO:root:NDCG@10: 0.7526
INFO:root:NDCG@10: 0.7461
INFO:root:NDCG@100: 0.7766
INFO:root:NDCG@100: 0.7755
INFO:root:NDCG@1000: 0.7810
INFO:root:NDCG@100: 0.7687
INFO:root:NDCG@1000: 0.7788
INFO:root:

INFO:root:

INFO:root:NDCG@1000: 0.7735
INFO:root:MAP@1: 0.6209
INFO:root:MAP@1: 0.6193
INFO:root:

INFO:root:MAP@3: 0.6802
INFO:root:MAP@3: 0.6786
INFO:root:MAP@5: 0.7009
INFO:root:MAP@5: 0.6967
INFO:root:MAP@1: 0.6119
INFO:root:MAP@10: 0.7128
INFO:root:MAP@10: 0.7099
INFO:root:MAP@3: 0.6716
INFO:root:MAP@100: 0.7180
INFO:root:MAP@100: 0.7156
INFO:root:MAP@5: 0.6910
INFO:root:MAP@1000: 0.7157
INFO:root:MAP@1000: 0.7182
INFO:root:

INFO:root:MAP@10: 0.7031
INFO:root:

INFO:root:Recall@1: 0.6193
INFO:root:Recall@1: 0.6209
INFO:root:MAP@100: 0.7089
INFO:root:Recall@3: 0.7384
INFO:root:Recall@3: 0.7362
INFO:root:Recall@5: 0.8033
INFO:root:MAP@1000: 0.7091
INFO:root:Recall@5: 0.8199
INFO:root:Recall@10: 0.8732
INFO:root:Recall@10: 0.8816
INFO:root:

INFO:root:Recall@100: 0.9750
INFO:root:Recall@100: 0.9683
INFO:root:Recall@1000: 1.0000
INFO:root:Recall@1: 0.6119
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:

INFO:root:Recall@3: 0.7317
INFO:root:P@1: 0.6467
INFO:root:P@1: 0.6500
INFO:root:P@3: 0.2700
INFO:root:Recall@5: 0.8049
INFO:root:P@3: 0.2700
INFO:root:P@5: 0.1800
INFO:root:Recall@10: 0.8682
INFO:root:P@5: 0.1827
INFO:root:P@10: 0.0993
INFO:root:P@10: 0.1000
INFO:root:P@100: 0.0110
INFO:root:Recall@100: 0.9650
INFO:root:P@100: 0.0110
INFO:root:P@1000: 0.0011
INFO:root:Recall@1000: 1.0000
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:P@1: 0.6367
INFO:root:P@3: 0.2678
INFO:root:P@5: 0.1800
INFO:root:P@10: 0.0987
INFO:root:P@100: 0.0109
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:

INFO:root:

INFO:root:MRR@1: 0.6500
INFO:root:MRR@3: 0.6961
INFO:root:MRR@5: 0.7158
INFO:root:MRR@10: 0.7226
INFO:root:MRR@100: 0.7265
INFO:root:MRR@1000: 0.7267
INFO:root:MRR@1: 0.6467
INFO:root:MRR@3: 0.6961
INFO:root:MRR@5: 0.7109
INFO:root:MRR@10: 0.7191
INFO:root:MRR@100: 0.7239
INFO:root:MRR@1000: 0.7240
INFO:root:MRR@1: 0.6367
INFO:root:MRR@3: 0.6878
INFO:root:MRR@5: 0.7038
INFO:root:MRR@10: 0.7114
INFO:root:MRR@100: 0.7161
INFO:root:MRR@1000: 0.7163
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 156.32 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.65, 'ndcg_at_3': 0.70144, 'ndcg_at_5': 0.73482, 'ndcg_at_10': 0.75671, 'ndcg_at_100': 0.77664, 'ndcg_at_1000': 0.78103, 'map_at_1': 0.62094, 'map_at_3': 0.68015, 'map_at_5': 0.70091, 'map_at_10': 0.71285, 'map_at_100': 0.71796, 'map_at_1000': 0.71818, 'recall_at_1': 0.62094, 'recall_at_3': 0.73617, 'recall_at_5': 0.81994, 'recall_at_10': 0.88156, 'recall_at_100': 0.96833, 'recall_at_1000': 1.0, 'precision_at_1': 0.65, 'precision_at_3': 0.27, 'precision_at_5': 0.18267, 'precision_at_10': 0.1, 'precision_at_100': 0.01097, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.65, 'mrr_at_3': 0.69611, 'mrr_at_5': 0.71578, 'mrr_at_10': 0.72255, 'mrr_at_100': 0.72647, 'mrr_at_1000': 0.72667, 'evaluation_time': 156.32}
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 156.37 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.64667, 'ndcg_at_3': 0.70113, 'ndcg_at_5': 0.72778, 'ndcg_at_10': 0.75257, 'ndcg_at_100': 0.77552, 'ndcg_at_1000': 0.77882, 'map_at_1': 0.61928, 'map_at_3': 0.67857, 'map_at_5': 0.69673, 'map_at_10': 0.70991, 'map_at_100': 0.71557, 'map_at_1000': 0.7157, 'recall_at_1': 0.61928, 'recall_at_3': 0.73839, 'recall_at_5': 0.80328, 'recall_at_10': 0.87322, 'recall_at_100': 0.975, 'recall_at_1000': 1.0, 'precision_at_1': 0.64667, 'precision_at_3': 0.27, 'precision_at_5': 0.18, 'precision_at_10': 0.09933, 'precision_at_100': 0.01103, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.64667, 'mrr_at_3': 0.69611, 'mrr_at_5': 0.71094, 'mrr_at_10': 0.71915, 'mrr_at_100': 0.72387, 'mrr_at_1000': 0.72399, 'evaluation_time': 156.37}
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 156.39 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.63667, 'ndcg_at_3': 0.69389, 'ndcg_at_5': 0.72352, 'ndcg_at_10': 0.74611, 'ndcg_at_100': 0.76868, 'ndcg_at_1000': 0.77354, 'map_at_1': 0.61194, 'map_at_3': 0.67157, 'map_at_5': 0.69104, 'map_at_10': 0.70309, 'map_at_100': 0.70886, 'map_at_1000': 0.7091, 'recall_at_1': 0.61194, 'recall_at_3': 0.73172, 'recall_at_5': 0.80494, 'recall_at_10': 0.86822, 'recall_at_100': 0.965, 'recall_at_1000': 1.0, 'precision_at_1': 0.63667, 'precision_at_3': 0.26778, 'precision_at_5': 0.18, 'precision_at_10': 0.09867, 'precision_at_100': 0.01093, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.63667, 'mrr_at_3': 0.68778, 'mrr_at_5': 0.70378, 'mrr_at_10': 0.71139, 'mrr_at_100': 0.71606, 'mrr_at_1000': 0.71629, 'evaluation_time': 156.39}
INFO:main:Running task: EmotionClassification
INFO:main:Running task: EmotionClassification
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model gist$llmrails for task EmotionClassification
Loading gist from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading gist from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist$voyage for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading gist from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 76.29 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5638000000000001, 'f1': 0.49895170636203606, 'accuracy_stderr': 0.019167941986556605, 'f1_stderr': 0.010584857597144972, 'main_score': 0.5638000000000001, 'evaluation_time': 76.29}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 83.71 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5690999999999999, 'f1': 0.5058639309626473, 'accuracy_stderr': 0.017978876494375268, 'f1_stderr': 0.010867014517016124, 'main_score': 0.5690999999999999, 'evaluation_time': 83.71}
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 84.16 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5708, 'f1': 0.5082749451830112, 'accuracy_stderr': 0.01980303007117851, 'f1_stderr': 0.011214649944038802, 'main_score': 0.5708, 'evaluation_time': 84.16}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model angle$gist for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading gist from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model gist$llmrails for task AmazonCounterfactualClassification
Loading gist from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model angle$gist$voyage for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading gist from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 1.74 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.751044776119403, 'f1': 0.6898752085682156, 'ap': 0.3782630882023655, 'accuracy_stderr': 0.03363875815700228, 'f1_stderr': 0.032490516600660796, 'ap_stderr': 0.03629243206262536, 'main_score': 0.751044776119403}, 'evaluation_time': 1.74}
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 2.43 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7428358208955224, 'f1': 0.6816456656584677, 'ap': 0.3690924470329479, 'accuracy_stderr': 0.03608762633282035, 'f1_stderr': 0.034528638956332985, 'ap_stderr': 0.03678575174975547, 'main_score': 0.7428358208955224}, 'evaluation_time': 2.43}
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:main:Running task: Banking77Classification
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 2.97 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7432835820895523, 'f1': 0.6823827132176017, 'ap': 0.37029310324390274, 'accuracy_stderr': 0.037007702713719295, 'f1_stderr': 0.03524300295325699, 'ap_stderr': 0.037354954827993746, 'main_score': 0.7432835820895523}, 'evaluation_time': 2.97}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist for task Banking77Classification
Loading angle from cache for Banking77Classification...
Loading gist from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model gist$llmrails for task Banking77Classification
Loading gist from cache for Banking77Classification...
Loading llmrails from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist$voyage for task Banking77Classification
Loading angle from cache for Banking77Classification...
Loading gist from cache for Banking77Classification...
Loading voyage from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Evaluating the model gte-large$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Creating model gte-large$voyage for task ArxivClusteringS2S
Loading gte-large from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 84.43 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8582467532467533, 'f1': 0.853365005541687, 'accuracy_stderr': 0.004081622111640981, 'f1_stderr': 0.004985490095302935, 'main_score': 0.8582467532467533, 'evaluation_time': 84.43}
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 84.68 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8580844155844154, 'f1': 0.8534801601874383, 'accuracy_stderr': 0.004640586130618527, 'f1_stderr': 0.005669317256323117, 'main_score': 0.8580844155844154, 'evaluation_time': 84.68}
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:main:Running task: ArguAna
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 95.39 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8528246753246753, 'f1': 0.8472836322930226, 'accuracy_stderr': 0.004215906277972152, 'f1_stderr': 0.005097578230231393, 'main_score': 0.8528246753246753, 'evaluation_time': 95.39}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Creating model cohere$gte-large for task ArxivClusteringS2S
Loading cohere from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model angle$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Creating model angle$mixed-bread$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Evaluating the model angle$cohere$mixed-bread...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Creating model angle$cohere$mixed-bread for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading cohere from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s
Clustering


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
    - ArxivClusteringS2S, s2s
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist for task ArguAna
Loading angle from cache for ArguAna...
Loading gist from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.util:Downloading arguana.zip ...
/cs/student/ug/2020/damibose/.cache/huggingface/datasets/BeIR/arguana.zip:   0%|          | 0.00/3.60M [00:00<?, ?iB/s]/cs/student/ug/2020/damibose/.cache/huggingface/datasets/BeIR/arguana.zip:  33%|███▎      | 1.19M/3.60M [00:00<00:00, 12.5MiB/s]INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model gist$llmrails for task ArguAna
Loading gist from cache for ArguAna...
Loading llmrails from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
/cs/student/ug/2020/damibose/.cache/huggingface/datasets/BeIR/arguana.zip:  93%|█████████▎| 3.36M/3.60M [00:00<00:00, 18.5MiB/s]/cs/student/ug/2020/damibose/.cache/huggingface/datasets/BeIR/arguana.zip: 100%|██████████| 3.60M/3.60M [00:00<00:00, 18.0MiB/s]
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:beir.util:Unzipping arguana.zip ...
INFO:beir.util:Unzipping arguana.zip ...
ERROR:mteb.evaluation.MTEB:Error while evaluating ArguAna: [Errno 17] File exists: '/cs/student/ug/2020/damibose/.cache/huggingface/datasets/BeIR/arguana'
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s]INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist$voyage for task ArguAna
Loading angle from cache for ArguAna...
Loading gist from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s] 47%|████▋     | 4036/8674 [00:00<00:00, 40357.15it/s] 51%|█████     | 4388/8674 [00:00<00:00, 43869.48it/s]100%|█████████▉| 8633/8674 [00:00<00:00, 43656.25it/s]100%|██████████| 8674/8674 [00:00<00:00, 43086.67it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
100%|██████████| 8674/8674 [00:00<00:00, 44396.74it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [01:02<31:00, 62.02s/it]Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:05<02:55,  5.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [01:08<14:18, 29.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:11<05:37, 11.26s/it]Clustering:   6%|▋         | 2/31 [00:13<03:19,  6.88s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 14.51 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:13<06:54, 13.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:root:

INFO:root:NDCG@1: 0.4047
INFO:root:NDCG@3: 0.5677
INFO:root:NDCG@5: 0.6176
INFO:root:NDCG@10: 0.6534
INFO:root:NDCG@100: 0.6722
INFO:root:NDCG@1000: 0.6729
INFO:root:

INFO:root:MAP@1: 0.4047
INFO:root:MAP@3: 0.5275
INFO:root:MAP@5: 0.5554
INFO:root:MAP@10: 0.5704
INFO:root:MAP@100: 0.5753
INFO:root:MAP@1000: 0.5754
INFO:root:

INFO:root:Recall@1: 0.4047
INFO:root:Recall@3: 0.6842
INFO:root:Recall@5: 0.8044
INFO:root:Recall@10: 0.9139
INFO:root:Recall@100: 0.9915
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.4047
INFO:root:P@3: 0.2281
INFO:root:P@5: 0.1609
INFO:root:P@10: 0.0914
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
Clustering:  10%|▉         | 3/31 [01:17<09:24, 20.16s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:root:

INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model cohere$gist$mixed-bread...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Creating model cohere$gist$mixed-bread for task ArxivClusteringS2S
Loading cohere from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:root:MRR@1: 0.4090
INFO:root:MRR@3: 0.5287
INFO:root:MRR@5: 0.5565
INFO:root:MRR@10: 0.5720
INFO:root:MRR@100: 0.5767
INFO:root:MRR@1000: 0.5767
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 18.72 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.40469, 'ndcg_at_3': 0.56773, 'ndcg_at_5': 0.6176, 'ndcg_at_10': 0.65342, 'ndcg_at_100': 0.67224, 'ndcg_at_1000': 0.67293, 'map_at_1': 0.40469, 'map_at_3': 0.5275, 'map_at_5': 0.55538, 'map_at_10': 0.5704, 'map_at_100': 0.57531, 'map_at_1000': 0.57535, 'recall_at_1': 0.40469, 'recall_at_3': 0.68421, 'recall_at_5': 0.80441, 'recall_at_10': 0.91394, 'recall_at_100': 0.99147, 'recall_at_1000': 0.99644, 'precision_at_1': 0.40469, 'precision_at_3': 0.22807, 'precision_at_5': 0.16088, 'precision_at_10': 0.09139, 'precision_at_100': 0.00991, 'precision_at_1000': 0.001, 'mrr_at_1': 0.40896, 'mrr_at_3': 0.52869, 'mrr_at_5': 0.5565, 'mrr_at_10': 0.57197, 'mrr_at_100': 0.57667, 'mrr_at_1000': 0.5767, 'evaluation_time': 18.72}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:21<03:28,  7.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 21.28 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:root:

INFO:root:NDCG@1: 0.4147
INFO:root:NDCG@3: 0.5783
INFO:root:NDCG@5: 0.6242
INFO:root:NDCG@10: 0.6607
INFO:root:NDCG@100: 0.6783
INFO:root:NDCG@1000: 0.6787
INFO:root:

INFO:root:MAP@1: 0.4147
INFO:root:MAP@3: 0.5373
INFO:root:MAP@5: 0.5629
INFO:root:MAP@10: 0.5782
INFO:root:MAP@100: 0.5827
INFO:root:MAP@1000: 0.5827
INFO:root:

INFO:root:Recall@1: 0.4147
INFO:root:Recall@3: 0.6970
INFO:root:Recall@5: 0.8080
INFO:root:Recall@10: 0.9196
INFO:root:Recall@100: 0.9929
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.4147
INFO:root:P@3: 0.2323
INFO:root:P@5: 0.1616
INFO:root:P@10: 0.0920
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:   6%|▋         | 2/31 [00:22<05:23, 11.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:25<06:48, 15.11s/it]INFO:root:MRR@1: 0.4225
INFO:root:MRR@3: 0.5405
INFO:root:MRR@5: 0.5657
INFO:root:MRR@10: 0.5811
INFO:root:MRR@100: 0.5856
INFO:root:MRR@1000: 0.5856
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 24.55 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.41465, 'ndcg_at_3': 0.57827, 'ndcg_at_5': 0.62416, 'ndcg_at_10': 0.66069, 'ndcg_at_100': 0.67825, 'ndcg_at_1000': 0.67874, 'map_at_1': 0.41465, 'map_at_3': 0.53734, 'map_at_5': 0.56291, 'map_at_10': 0.57823, 'map_at_100': 0.58272, 'map_at_1000': 0.58275, 'recall_at_1': 0.41465, 'recall_at_3': 0.69701, 'recall_at_5': 0.80797, 'recall_at_10': 0.91963, 'recall_at_100': 0.99289, 'recall_at_1000': 0.99644, 'precision_at_1': 0.41465, 'precision_at_3': 0.23234, 'precision_at_5': 0.16159, 'precision_at_10': 0.09196, 'precision_at_100': 0.00993, 'precision_at_1000': 0.001, 'mrr_at_1': 0.42248, 'mrr_at_3': 0.54054, 'mrr_at_5': 0.56572, 'mrr_at_10': 0.58113, 'mrr_at_100': 0.58562, 'mrr_at_1000': 0.58564, 'evaluation_time': 24.55}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:25<05:57, 12.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [00:29<03:26,  7.66s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [01:32<05:14, 12.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:32<04:56, 10.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [00:35<03:02,  7.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  10%|▉         | 3/31 [00:34<05:03, 10.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [01:39<04:20, 10.41s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [00:41<02:51,  6.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [00:41<04:30, 10.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [00:44<04:43, 10.52s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  23%|██▎       | 7/31 [01:46<03:46,  9.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [00:48<02:40,  6.68s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model flag-embedding$gist$gte-large...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name flag-embedding$gist$gte-large
Converting results/flag-embedding$gist$gte-large to results/flag-embedding$gist$gte-large_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model flag-embedding$gist$llmrails...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name flag-embedding$gist$llmrails
Converting results/flag-embedding$gist$llmrails to results/flag-embedding$gist$llmrails_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model flag-embedding$gist$mixed-bread...
Skipping STS17 as it already exists
Creating model flag-embedding$gist$mixed-bread for task TwitterSemEval2015
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [01:53<03:20,  8.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [00:55<02:40,  6.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [00:56<05:06, 11.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [00:57<05:01, 11.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
Clustering:   3%|▎         | 1/31 [00:14<07:05, 14.19s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [02:02<03:12,  8.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [01:03<02:38,  7.22s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [01:08<04:56, 11.87s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [01:11<02:36,  7.43s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [02:12<03:10,  9.08s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [01:10<05:03, 12.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:26<06:15, 12.94s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [01:23<05:07, 12.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 32.54 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8759611372712642, 'accuracy_threshold': 0.820733368396759, 'f1': 0.7228015964980044, 'f1_threshold': 0.7915694713592529, 'precision': 0.7058083982901685, 'recall': 0.7406332453825858, 'ap': 0.7907548519523809}, 'manhattan': {'accuracy': 0.8761399535077785, 'accuracy_threshold': 26.425193786621094, 'f1': 0.7207389598886498, 'f1_threshold': 28.310937881469727, 'precision': 0.6924386092876246, 'recall': 0.7514511873350923, 'ap': 0.7894999601089618}, 'euclidean': {'accuracy': 0.8759611372712642, 'accuracy_threshold': 0.5987764596939087, 'f1': 0.7228015964980044, 'f1_threshold': 0.6456478238105774, 'precision': 0.7058083982901685, 'recall': 0.7406332453825858, 'ap': 0.7907548645859683}, 'dot': {'accuracy': 0.8759611372712642, 'accuracy_threshold': 0.8207335472106934, 'f1': 0.7228015964980044, 'f1_threshold': 0.7915695905685425, 'precision': 0.7058083982901685, 'recall': 0.7406332453825858, 'ap': 0.7907549133833536}, 'max': {'accuracy': 0.8761399535077785, 'f1': 0.7228015964980044, 'ap': 0.7907549133833536}, 'evaluation_time': 32.54}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [01:28<03:25, 10.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:41<06:33, 14.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  23%|██▎       | 7/31 [01:27<05:22, 13.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model flag-embedding$gist$mixed-bread for task AskUbuntuDupQuestions
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [02:30<03:58, 11.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [01:44<05:54, 15.40s/it]INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 16.28 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6482742169691558, 'mrr': 0.77740293716748, 'evaluation_time': 16.28}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:01<07:22, 16.39s/it]Clustering:  26%|██▌       | 8/31 [01:46<05:55, 15.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [01:51<04:27, 14.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  39%|███▊      | 12/31 [02:54<04:55, 15.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [02:07<06:35, 17.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [02:07<06:18, 17.19s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [01:23<07:55, 18.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [02:14<05:01, 16.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [03:16<05:11, 17.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [01:36<06:50, 16.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [02:24<05:57, 17.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [02:25<06:19, 18.09s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [02:31<04:49, 17.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [03:32<04:52, 17.20s/it]Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model flag-embedding$gist$mixed-bread for task SciFact
Loading flag-embedding from cache for SciFact...
Loading gist from cache for SciFact...
Loading mixed-bread from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
  0%|          | 0/5183 [00:00<?, ?it/s] 28%|██▊       | 1461/5183 [00:00<00:00, 13697.50it/s] 55%|█████▍    | 2831/5183 [00:00<00:00, 11664.68it/s]100%|██████████| 5183/5183 [00:00<00:00, 15916.86it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:faiss.loader:Loading faiss.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:faiss.loader:Successfully loaded faiss.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [01:59<07:27, 18.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:18<09:23, 18.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 19.63 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.6367
INFO:root:NDCG@3: 0.6919
INFO:root:NDCG@5: 0.7178
INFO:root:NDCG@10: 0.7454
INFO:root:NDCG@100: 0.7688
INFO:root:NDCG@1000: 0.7726
INFO:root:

INFO:root:MAP@1: 0.6093
INFO:root:MAP@3: 0.6702
INFO:root:MAP@5: 0.6878
INFO:root:MAP@10: 0.7021
INFO:root:MAP@100: 0.7078
INFO:root:MAP@1000: 0.7080
INFO:root:

INFO:root:Recall@1: 0.6093
INFO:root:Recall@3: 0.7267
INFO:root:Recall@5: 0.7899
INFO:root:Recall@10: 0.8682
INFO:root:Recall@100: 0.9717
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6367
INFO:root:P@3: 0.2656
INFO:root:P@5: 0.1767
INFO:root:P@10: 0.0987
INFO:root:P@100: 0.0110
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6367
INFO:root:MRR@3: 0.6872
INFO:root:MRR@5: 0.7022
INFO:root:MRR@10: 0.7116
INFO:root:MRR@100: 0.7162
INFO:root:MRR@1000: 0.7164
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 22.25 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.63667, 'ndcg_at_3': 0.69186, 'ndcg_at_5': 0.71782, 'ndcg_at_10': 0.74537, 'ndcg_at_100': 0.76879, 'ndcg_at_1000': 0.77263, 'map_at_1': 0.60928, 'map_at_3': 0.67024, 'map_at_5': 0.68781, 'map_at_10': 0.70207, 'map_at_100': 0.70785, 'map_at_1000': 0.70803, 'recall_at_1': 0.60928, 'recall_at_3': 0.72672, 'recall_at_5': 0.78994, 'recall_at_10': 0.86822, 'recall_at_100': 0.97167, 'recall_at_1000': 1.0, 'precision_at_1': 0.63667, 'precision_at_3': 0.26556, 'precision_at_5': 0.17667, 'precision_at_10': 0.09867, 'precision_at_100': 0.011, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.63667, 'mrr_at_3': 0.68722, 'mrr_at_5': 0.70222, 'mrr_at_10': 0.71156, 'mrr_at_100': 0.71619, 'mrr_at_1000': 0.71636, 'evaluation_time': 22.25}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [02:59<05:26, 20.43s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:26<06:03, 12.54s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [02:15<06:50, 17.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  35%|███▌      | 11/31 [03:02<07:52, 23.60s/it]INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model flag-embedding$gist$mixed-bread for task EmotionClassification
Loading flag-embedding from cache for EmotionClassification...
Loading gist from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [04:06<05:53, 22.11s/it]Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
Clustering:  35%|███▌      | 11/31 [03:08<08:29, 25.45s/it]/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Clustering:  10%|▉         | 3/31 [00:36<05:08, 11.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Clustering:  13%|█▎        | 4/31 [00:59<07:10, 15.94s/it]Clustering:  29%|██▉       | 9/31 [02:46<08:03, 21.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  52%|█████▏    | 16/31 [03:48<07:11, 28.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  16%|█▌        | 5/31 [01:27<08:43, 20.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [05:08<08:30, 34.05s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [03:23<09:18, 26.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 64.12 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5613000000000001, 'f1': 0.49700972571367574, 'accuracy_stderr': 0.024828612526679776, 'f1_stderr': 0.015119338390265262, 'main_score': 0.5613000000000001, 'evaluation_time': 64.12}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model flag-embedding$gist$mixed-bread for task AmazonCounterfactualClassification
Loading flag-embedding from cache for AmazonCounterfactualClassification...
Loading gist from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 3.60 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7407462686567164, 'f1': 0.6796322751306014, 'ap': 0.36697233611807323, 'accuracy_stderr': 0.035571582641853984, 'f1_stderr': 0.03465302845300386, 'ap_stderr': 0.03718556373245514, 'main_score': 0.7407462686567164}, 'evaluation_time': 3.6}
INFO:main:Running task: Banking77Classification
Clustering:  32%|███▏      | 10/31 [03:32<07:27, 21.30s/it]
ERROR:mteb.evaluation.MTEB:Error while evaluating ArxivClusteringS2S: Unable to allocate 586. MiB for an array with shape (25000, 3072) and data type float64
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [04:21<12:43, 40.19s/it]INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model flag-embedding$gist$mixed-bread for task Banking77Classification
Loading flag-embedding from cache for Banking77Classification...
Loading gist from cache for Banking77Classification...
Loading mixed-bread from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [01:49<08:45, 21.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:32<16:26, 32.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [04:25<13:03, 41.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [04:28<07:32, 32.35s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [01:58<06:45, 16.91s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [05:34<07:24, 31.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [02:12<06:07, 15.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
Clustering:   6%|▋         | 2/31 [00:56<13:11, 27.30s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [02:30<06:05, 16.62s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [05:06<12:32, 41.81s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Clustering:  58%|█████▊    | 18/31 [05:13<07:50, 36.18s/it]Clustering:  10%|▉         | 3/31 [01:20<11:59, 25.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [06:16<07:32, 34.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [02:45<05:38, 16.10s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [05:18<13:26, 44.81s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:50<12:26, 27.64s/it]INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [05:56<07:38, 38.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [07:02<07:37, 38.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 84.65 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8545454545454545, 'f1': 0.8490263817648913, 'accuracy_stderr': 0.004517539514526246, 'f1_stderr': 0.005493410767588394, 'main_score': 0.8545454545454545, 'evaluation_time': 84.65}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [06:14<14:04, 49.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [03:49<10:16, 30.81s/it]INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [02:30<13:52, 32.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [06:25<14:35, 51.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  65%|██████▍   | 20/31 [06:30<06:44, 36.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [07:31<06:27, 35.25s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [06:37<11:08, 41.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [03:05<13:47, 33.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model flag-embedding$gist$mixed-bread for task ArguAna
Loading flag-embedding from cache for ArguAna...
Loading gist from cache for ArguAna...
Loading mixed-bread from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s] 37%|███▋      | 3173/8674 [00:00<00:00, 31724.89it/s] 73%|███████▎  | 6346/8674 [00:00<00:00, 30192.78it/s]100%|██████████| 8674/8674 [00:00<00:00, 29191.71it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
Clustering:  68%|██████▊   | 21/31 [08:01<05:38, 33.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [07:02<05:54, 35.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
Clustering:  39%|███▊      | 12/31 [04:28<10:33, 33.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [08:03<03:37, 24.13s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [07:04<03:48, 25.34s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [03:32<12:25, 31.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [07:27<14:35, 54.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [08:31<03:24, 25.54s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [07:34<03:34, 26.81s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [05:04<10:11, 33.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  52%|█████▏    | 16/31 [07:39<11:54, 47.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 41.20 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [08:44<02:31, 21.68s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:root:

INFO:root:NDCG@1: 0.4075
INFO:root:NDCG@3: 0.5734
INFO:root:NDCG@5: 0.6175
INFO:root:NDCG@10: 0.6546
INFO:root:NDCG@100: 0.6737
INFO:root:NDCG@1000: 0.6743
INFO:root:

INFO:root:MAP@1: 0.4075
INFO:root:MAP@3: 0.5325
INFO:root:MAP@5: 0.5570
INFO:root:MAP@10: 0.5726
INFO:root:MAP@100: 0.5775
INFO:root:MAP@1000: 0.5775
INFO:root:

INFO:root:Recall@1: 0.4075
INFO:root:Recall@3: 0.6920
INFO:root:Recall@5: 0.7987
INFO:root:Recall@10: 0.9118
INFO:root:Recall@100: 0.9922
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.4075
INFO:root:P@3: 0.2307
INFO:root:P@5: 0.1597
INFO:root:P@10: 0.0912
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.4154
INFO:root:MRR@3: 0.5356
INFO:root:MRR@5: 0.5600
INFO:root:MRR@10: 0.5757
INFO:root:MRR@100: 0.5804
INFO:root:MRR@1000: 0.5805
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [07:49<02:43, 23.32s/it]INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 48.60 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.40754, 'ndcg_at_3': 0.57344, 'ndcg_at_5': 0.61749, 'ndcg_at_10': 0.65461, 'ndcg_at_100': 0.67374, 'ndcg_at_1000': 0.67432, 'map_at_1': 0.40754, 'map_at_3': 0.53248, 'map_at_5': 0.55698, 'map_at_10': 0.57262, 'map_at_100': 0.57745, 'map_at_1000': 0.57748, 'recall_at_1': 0.40754, 'recall_at_3': 0.69203, 'recall_at_5': 0.79872, 'recall_at_10': 0.91181, 'recall_at_100': 0.99218, 'recall_at_1000': 0.99644, 'precision_at_1': 0.40754, 'precision_at_3': 0.23068, 'precision_at_5': 0.15974, 'precision_at_10': 0.09118, 'precision_at_100': 0.00992, 'precision_at_1000': 0.001, 'mrr_at_1': 0.41536, 'mrr_at_3': 0.53556, 'mrr_at_5': 0.55996, 'mrr_at_10': 0.57566, 'mrr_at_100': 0.58043, 'mrr_at_1000': 0.58045, 'evaluation_time': 48.6}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [03:57<11:07, 29.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [05:41<09:57, 35.13s/it]Clustering:  81%|████████  | 25/31 [08:16<02:25, 24.23s/it]Clustering:  81%|████████  | 25/31 [09:16<02:27, 24.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [04:24<10:27, 28.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [08:18<13:22, 53.53s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [08:22<01:33, 18.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [09:22<01:35, 19.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [08:23<10:53, 46.67s/it]Evaluating the model flag-embedding$llmrails$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Creating model flag-embedding$llmrails$voyage for task ArxivClusteringS2S
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [04:54<10:07, 28.94s/it]Clustering:  87%|████████▋ | 27/31 [09:48<01:24, 21.17s/it]Clustering:  87%|████████▋ | 27/31 [08:48<01:24, 21.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  48%|████▊     | 15/31 [06:17<09:26, 35.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [09:05<00:59, 19.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:34<17:19, 34.64s/it]Clustering:  90%|█████████ | 28/31 [10:06<01:00, 20.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [09:16<12:48, 54.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [09:19<10:41, 49.37s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [09:25<00:39, 19.91s/it]Clustering:  94%|█████████▎| 29/31 [10:25<00:39, 19.90s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:56<13:04, 27.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [06:55<09:02, 36.16s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [09:31<00:15, 15.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [10:33<00:16, 16.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [05:43<11:40, 35.05s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [09:47<00:00, 15.86s/it]Clustering: 100%|██████████| 31/31 [09:47<00:00, 18.96s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 587.68 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43104388756804307, 'v_measure_std': 0.14220554083220804, 'evaluation_time': 587.68}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [01:17<11:20, 24.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [10:57<00:00, 18.78s/it]Clustering: 100%|██████████| 31/31 [10:57<00:00, 21.22s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 657.90 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.42211707245136054, 'v_measure_std': 0.1422362234203387, 'evaluation_time': 657.9}
Clustering:  61%|██████▏   | 19/31 [09:55<09:06, 45.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [07:31<08:23, 35.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [10:03<11:22, 52.53s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:34<09:40, 21.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model flag-embedding$gist$mixed-bread for task ArxivClusteringS2S
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: TwitterSemEval2015
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name cohere$gte-large
Converting results/cohere$gte-large to results/cohere$gte-large_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$llmrails...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model cohere$llmrails for task AskUbuntuDupQuestions
Loading cohere from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name gte-large$voyage
Converting results/gte-large$voyage to results/gte-large$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model llmrails$mixed-bread...
Skipping STS17 as it already exists
Creating model llmrails$mixed-bread for task TwitterSemEval2015
Loading llmrails from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [06:29<12:10, 38.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 10.42 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8763187697442928, 'accuracy_threshold': 0.8061760663986206, 'f1': 0.7215206353339408, 'f1_threshold': 0.7896776795387268, 'precision': 0.7121562580313544, 'recall': 0.7311345646437994, 'ap': 0.7917619104739987}, 'manhattan': {'accuracy': 0.8769744292781785, 'accuracy_threshold': 22.39482879638672, 'f1': 0.7191913956200596, 'f1_threshold': 23.42950439453125, 'precision': 0.706646294881589, 'recall': 0.7321899736147758, 'ap': 0.7911670097974817}, 'euclidean': {'accuracy': 0.8763187697442928, 'accuracy_threshold': 0.622613787651062, 'f1': 0.7215206353339408, 'f1_threshold': 0.648571252822876, 'precision': 0.7121562580313544, 'recall': 0.7311345646437994, 'ap': 0.7917618171701085}, 'dot': {'accuracy': 0.8763187697442928, 'accuracy_threshold': 0.8061760663986206, 'f1': 0.7215206353339408, 'f1_threshold': 0.7896777391433716, 'precision': 0.7121562580313544, 'recall': 0.7311345646437994, 'ap': 0.7917615290108778}, 'max': {'accuracy': 0.8769744292781785, 'f1': 0.7215206353339408, 'ap': 0.7917619104739987}, 'evaluation_time': 10.42}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model llmrails$mixed-bread for task AskUbuntuDupQuestions
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [02:02<10:23, 23.98s/it]INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:25<12:53, 25.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [08:07<07:48, 36.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 22.94 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6352677760422898, 'mrr': 0.7572274985709889, 'evaluation_time': 22.94}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$llmrails for task SciFact
Loading cohere from cache for SciFact...
Loading llmrails from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s] 50%|█████     | 2613/5183 [00:00<00:00, 26125.98it/s]100%|██████████| 5183/5183 [00:00<00:00, 26255.84it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [10:44<08:30, 46.43s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 14.01 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6491502886879734, 'mrr': 0.7805038913072154, 'evaluation_time': 14.01}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model llmrails$mixed-bread for task SciFact
Loading llmrails from cache for SciFact...
Loading mixed-bread from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
 17%|█▋        | 907/5183 [00:00<00:00, 8807.91it/s] 51%|█████     | 2650/5183 [00:00<00:00, 12400.09it/s] 75%|███████▍  | 3870/5183 [00:00<00:00, 8881.22it/s]  94%|█████████▎| 4857/5183 [00:00<00:00, 9181.64it/s]100%|██████████| 5183/5183 [00:00<00:00, 9483.29it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:faiss.loader:Loading faiss.
INFO:faiss.loader:Successfully loaded faiss.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 11.44 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.6433
INFO:root:NDCG@3: 0.6989
INFO:root:NDCG@5: 0.7290
INFO:root:NDCG@10: 0.7519
INFO:root:NDCG@100: 0.7712
INFO:root:NDCG@1000: 0.7750
INFO:root:

INFO:root:MAP@1: 0.6116
INFO:root:MAP@3: 0.6750
INFO:root:MAP@5: 0.6956
INFO:root:MAP@10: 0.7066
INFO:root:MAP@100: 0.7110
INFO:root:MAP@1000: 0.7112
INFO:root:

INFO:root:Recall@1: 0.6116
INFO:root:Recall@3: 0.7381
INFO:root:Recall@5: 0.8152
INFO:root:Recall@10: 0.8826
INFO:root:Recall@100: 0.9717
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6433
INFO:root:P@3: 0.2722
INFO:root:P@5: 0.1833
INFO:root:P@10: 0.1000
INFO:root:P@100: 0.0110
INFO:root:P@1000: 0.0011
INFO:root:

INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:root:MRR@1: 0.6433
INFO:root:MRR@3: 0.6917
INFO:root:MRR@5: 0.7082
INFO:root:MRR@10: 0.7162
INFO:root:MRR@100: 0.7195
INFO:root:MRR@1000: 0.7197
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 12.38 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.64333, 'ndcg_at_3': 0.69886, 'ndcg_at_5': 0.72899, 'ndcg_at_10': 0.75186, 'ndcg_at_100': 0.77115, 'ndcg_at_1000': 0.77499, 'map_at_1': 0.61161, 'map_at_3': 0.67496, 'map_at_5': 0.69555, 'map_at_10': 0.70655, 'map_at_100': 0.71102, 'map_at_1000': 0.7112, 'recall_at_1': 0.61161, 'recall_at_3': 0.73806, 'recall_at_5': 0.81522, 'recall_at_10': 0.88256, 'recall_at_100': 0.97167, 'recall_at_1000': 1.0, 'precision_at_1': 0.64333, 'precision_at_3': 0.27222, 'precision_at_5': 0.18333, 'precision_at_10': 0.1, 'precision_at_100': 0.011, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.64333, 'mrr_at_3': 0.69167, 'mrr_at_5': 0.70817, 'mrr_at_10': 0.71621, 'mrr_at_100': 0.7195, 'mrr_at_1000': 0.71967, 'evaluation_time': 12.38}
INFO:main:Running task: Banking77Classification
Clustering:   6%|▋         | 2/31 [00:45<10:46, 22.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Creating model cohere$llmrails for task Banking77Classification
Loading cohere from cache for Banking77Classification...
Loading llmrails from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
Clustering:  19%|█▉        | 6/31 [02:31<10:38, 25.54s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 14.59 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  61%|██████▏   | 19/31 [11:03<10:58, 54.88s/it]INFO:root:

INFO:root:NDCG@1: 0.6333
INFO:root:NDCG@3: 0.6897
INFO:root:NDCG@5: 0.7134
INFO:root:NDCG@10: 0.7409
INFO:root:NDCG@100: 0.7653
INFO:root:NDCG@1000: 0.7696
INFO:root:

INFO:root:MAP@1: 0.6059
INFO:root:MAP@3: 0.6671
INFO:root:MAP@5: 0.6837
INFO:root:MAP@10: 0.6978
INFO:root:MAP@100: 0.7042
INFO:root:MAP@1000: 0.7044
INFO:root:

INFO:root:Recall@1: 0.6059
INFO:root:Recall@3: 0.7246
INFO:root:Recall@5: 0.7849
INFO:root:Recall@10: 0.8626
INFO:root:Recall@100: 0.9683
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6333
INFO:root:P@3: 0.2656
INFO:root:P@5: 0.1753
INFO:root:P@10: 0.0980
INFO:root:P@100: 0.0110
INFO:root:P@1000: 0.0011
INFO:root:

INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:root:MRR@1: 0.6333
INFO:root:MRR@3: 0.6850
INFO:root:MRR@5: 0.6978
INFO:root:MRR@10: 0.7074
INFO:root:MRR@100: 0.7126
INFO:root:MRR@1000: 0.7127
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 17.39 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.63333, 'ndcg_at_3': 0.68971, 'ndcg_at_5': 0.71339, 'ndcg_at_10': 0.74087, 'ndcg_at_100': 0.76535, 'ndcg_at_1000': 0.76958, 'map_at_1': 0.60594, 'map_at_3': 0.66707, 'map_at_5': 0.68373, 'map_at_10': 0.6978, 'map_at_100': 0.70418, 'map_at_1000': 0.70438, 'recall_at_1': 0.60594, 'recall_at_3': 0.72461, 'recall_at_5': 0.78494, 'recall_at_10': 0.86256, 'recall_at_100': 0.96833, 'recall_at_1000': 1.0, 'precision_at_1': 0.63333, 'precision_at_3': 0.26556, 'precision_at_5': 0.17533, 'precision_at_10': 0.098, 'precision_at_100': 0.01097, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.63333, 'mrr_at_3': 0.685, 'mrr_at_5': 0.69783, 'mrr_at_10': 0.70736, 'mrr_at_100': 0.71257, 'mrr_at_1000': 0.71275, 'evaluation_time': 17.39}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model llmrails$mixed-bread for task EmotionClassification
Loading llmrails from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [07:36<14:05, 46.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [01:22<13:36, 29.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [09:15<09:06, 45.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [03:20<13:17, 33.22s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
Clustering:  68%|██████▊   | 21/31 [11:59<09:10, 55.03s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [12:11<06:20, 42.28s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [02:10<16:18, 36.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 85.16 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8449675324675324, 'f1': 0.8397161466848869, 'accuracy_stderr': 0.005203422236226877, 'f1_stderr': 0.00582768485656451, 'main_score': 0.8449675324675324, 'evaluation_time': 85.16}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$llmrails for task ArguAna
Loading cohere from cache for ArguAna...
Loading llmrails from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s] 14%|█▍        | 1235/8674 [00:00<00:00, 12229.42it/s] 28%|██▊       | 2458/8674 [00:00<00:00, 11041.22it/s] 44%|████▍     | 3825/8674 [00:00<00:00, 12171.59it/s] 59%|█████▉    | 5153/8674 [00:00<00:00, 12492.81it/s] 74%|███████▍  | 6410/8674 [00:00<00:00, 9868.10it/s]  87%|████████▋ | 7522/8674 [00:00<00:00, 10088.26it/s]100%|█████████▉| 8654/8674 [00:00<00:00, 10438.11it/s]100%|██████████| 8674/8674 [00:00<00:00, 10790.25it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 78.45 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.54815, 'f1': 0.48054679031519515, 'accuracy_stderr': 0.02827547523915382, 'f1_stderr': 0.01728363126546743, 'main_score': 0.54815, 'evaluation_time': 78.45}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model llmrails$mixed-bread for task AmazonCounterfactualClassification
Loading llmrails from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 2.77 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7323880597014926, 'f1': 0.6726307000414407, 'ap': 0.3607676139964629, 'accuracy_stderr': 0.03706814902429474, 'f1_stderr': 0.035545556753784846, 'ap_stderr': 0.036924585985415086, 'main_score': 0.7323880597014926}, 'evaluation_time': 2.77}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model llmrails$mixed-bread for task Banking77Classification
Loading llmrails from cache for Banking77Classification...
Loading mixed-bread from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [04:08<14:33, 37.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [02:42<15:04, 34.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [12:52<13:00, 70.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [10:25<09:41, 52.88s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [09:12<17:31, 61.87s/it]INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 34.21 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:root:

INFO:root:NDCG@1: 0.3464
INFO:root:NDCG@3: 0.5109
INFO:root:NDCG@5: 0.5606
INFO:root:NDCG@10: 0.6015
INFO:root:NDCG@100: 0.6282
INFO:root:NDCG@1000: 0.6289
INFO:root:

INFO:root:MAP@1: 0.3464
INFO:root:MAP@3: 0.4693
INFO:root:MAP@5: 0.4968
INFO:root:MAP@10: 0.5138
INFO:root:MAP@100: 0.5204
INFO:root:MAP@1000: 0.5205
INFO:root:

INFO:root:Recall@1: 0.3464
INFO:root:Recall@3: 0.6316
INFO:root:Recall@5: 0.7532
INFO:root:Recall@10: 0.8784
INFO:root:Recall@100: 0.9915
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.3464
INFO:root:P@3: 0.2105
INFO:root:P@5: 0.1506
INFO:root:P@10: 0.0878
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:root:MRR@1: 0.3506
INFO:root:MRR@3: 0.4704
INFO:root:MRR@5: 0.4985
INFO:root:MRR@10: 0.5157
INFO:root:MRR@100: 0.5224
INFO:root:MRR@1000: 0.5224
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 44.19 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.34637, 'ndcg_at_3': 0.51086, 'ndcg_at_5': 0.56065, 'ndcg_at_10': 0.60147, 'ndcg_at_100': 0.62824, 'ndcg_at_1000': 0.62891, 'map_at_1': 0.34637, 'map_at_3': 0.4693, 'map_at_5': 0.49675, 'map_at_10': 0.51379, 'map_at_100': 0.52045, 'map_at_1000': 0.52048, 'recall_at_1': 0.34637, 'recall_at_3': 0.63158, 'recall_at_5': 0.7532, 'recall_at_10': 0.87838, 'recall_at_100': 0.99147, 'recall_at_1000': 0.99644, 'precision_at_1': 0.34637, 'precision_at_3': 0.21053, 'precision_at_5': 0.15064, 'precision_at_10': 0.08784, 'precision_at_100': 0.00991, 'precision_at_1000': 0.001, 'mrr_at_1': 0.35064, 'mrr_at_3': 0.47037, 'mrr_at_5': 0.49846, 'mrr_at_10': 0.51572, 'mrr_at_100': 0.52238, 'mrr_at_1000': 0.52241, 'evaluation_time': 44.19}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [04:46<13:51, 37.80s/it]INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [13:21<06:44, 50.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [03:13<13:58, 33.55s/it]/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [11:06<08:14, 49.41s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [05:13<12:03, 34.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [11:14<05:31, 36.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [13:48<11:04, 66.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [03:41<12:39, 31.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [13:53<07:12, 48.06s/it]Clustering:  77%|███████▋  | 24/31 [13:53<05:13, 44.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 78.98 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.850844155844156, 'f1': 0.8448105975125774, 'accuracy_stderr': 0.004261046679616347, 'f1_stderr': 0.0051988062105530995, 'main_score': 0.850844155844156, 'evaluation_time': 78.98}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model llmrails$mixed-bread for task ArguAna
Loading llmrails from cache for ArguAna...
Loading mixed-bread from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s] 13%|█▎        | 1124/8674 [00:00<00:00, 11234.76it/s] 28%|██▊       | 2432/8674 [00:00<00:00, 12319.25it/s] 57%|█████▋    | 4984/8674 [00:00<00:00, 18343.00it/s] 84%|████████▎ | 7253/8674 [00:00<00:00, 20056.30it/s]100%|██████████| 8674/8674 [00:00<00:00, 18318.12it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [04:00<10:34, 27.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  48%|████▊     | 15/31 [10:20<17:01, 63.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [11:44<04:39, 34.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [14:24<04:03, 40.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Creating model cohere$llmrails for task RedditClustering
Loading cohere from cache for RedditClustering...
Loading llmrails from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 24.70 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [11:55<03:14, 27.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [04:18<09:01, 24.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:root:

INFO:root:NDCG@1: 0.4303
INFO:root:NDCG@3: 0.5854
INFO:root:NDCG@5: 0.6264
INFO:root:NDCG@10: 0.6631
INFO:root:NDCG@100: 0.6821
INFO:root:NDCG@1000: 0.6828
INFO:root:

INFO:root:MAP@1: 0.4303
INFO:root:MAP@3: 0.5460
INFO:root:MAP@5: 0.5689
INFO:root:MAP@10: 0.5843
INFO:root:MAP@100: 0.5891
INFO:root:MAP@1000: 0.5891
INFO:root:

INFO:root:Recall@1: 0.4303
INFO:root:Recall@3: 0.6999
INFO:root:Recall@5: 0.7987
INFO:root:Recall@10: 0.9111
INFO:root:Recall@100: 0.9908
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.4303
INFO:root:P@3: 0.2333
INFO:root:P@5: 0.1597
INFO:root:P@10: 0.0911
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.4403
INFO:root:MRR@3: 0.5499
INFO:root:MRR@5: 0.5723
INFO:root:MRR@10: 0.5879
INFO:root:MRR@100: 0.5925
INFO:root:MRR@1000: 0.5926
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 30.89 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.4303, 'ndcg_at_3': 0.58538, 'ndcg_at_5': 0.62637, 'ndcg_at_10': 0.66307, 'ndcg_at_100': 0.68208, 'ndcg_at_1000': 0.68284, 'map_at_1': 0.4303, 'map_at_3': 0.54599, 'map_at_5': 0.5689, 'map_at_10': 0.58425, 'map_at_100': 0.58908, 'map_at_1000': 0.58911, 'recall_at_1': 0.4303, 'recall_at_3': 0.69986, 'recall_at_5': 0.79872, 'recall_at_10': 0.9111, 'recall_at_100': 0.99075, 'recall_at_1000': 0.99644, 'precision_at_1': 0.4303, 'precision_at_3': 0.23329, 'precision_at_5': 0.15974, 'precision_at_10': 0.09111, 'precision_at_100': 0.00991, 'precision_at_1000': 0.001, 'mrr_at_1': 0.44026, 'mrr_at_3': 0.54991, 'mrr_at_5': 0.57234, 'mrr_at_10': 0.58792, 'mrr_at_100': 0.59253, 'mrr_at_1000': 0.59256, 'evaluation_time': 30.89}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [06:05<13:16, 39.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [14:35<02:39, 31.85s/it]Clustering:  74%|███████▍  | 23/31 [14:35<06:11, 46.39s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:08<03:14,  8.09s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:17<03:17,  8.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [04:35<07:53, 22.54s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [12:13<02:29, 24.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [14:52<04:22, 37.53s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [11:04<14:26, 57.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [14:56<01:54, 28.54s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [12:31<01:53, 22.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [06:36<11:48, 37.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:51<07:25, 20.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [15:27<01:27, 29.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [12:58<01:36, 24.12s/it]Clustering:  81%|████████  | 25/31 [15:31<03:47, 37.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [01:05<06:19, 18.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Creating model llmrails$mixed-bread for task ArxivClusteringS2S
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [01:18<05:21, 16.09s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [15:50<02:40, 32.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [13:20<01:09, 23.25s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:16<08:23, 16.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [01:32<04:52, 15.41s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [12:11<14:06, 60.46s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [16:03<01:02, 31.34s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [01:41<03:57, 13.18s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [06:00<13:52, 41.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [13:39<00:44, 22.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:30<07:07, 14.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [07:45<14:03, 46.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [13:44<00:16, 16.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [16:18<00:26, 26.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [16:19<02:05, 31.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [01:51<03:29, 12.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:43<06:29, 13.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [14:02<00:00, 17.20s/it]Clustering: 100%|██████████| 31/31 [14:02<00:00, 27.17s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 842.38 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43048972418326026, 'v_measure_std': 0.1429363561049921, 'evaluation_time': 842.38}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:01<07:01, 15.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [02:17<04:25, 16.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [16:56<00:00, 29.75s/it]Clustering: 100%|██████████| 31/31 [16:56<00:00, 32.78s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 1016.11 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43197138617833225, 'v_measure_std': 0.14269508483300938, 'evaluation_time': 1016.11}
Clustering:  90%|█████████ | 28/31 [16:56<01:38, 32.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [01:17<06:56, 16.02s/it]Clustering:  58%|█████▊    | 18/31 [13:09<12:58, 59.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [02:33<04:06, 16.41s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [06:55<14:23, 45.44s/it]Clustering:  45%|████▌     | 14/31 [08:35<13:33, 47.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [17:08<00:53, 26.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [01:28<05:53, 14.13s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [02:47<03:38, 15.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [02:53<02:46, 12.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$mixed-bread$voyage
Converting results/angle$mixed-bread$voyage to results/angle$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$flag-embedding$gist...
Skipping STS17 as it already exists
Creating model cohere$flag-embedding$gist for task TwitterSemEval2015
Loading cohere from cache for TwitterSemEval2015...
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
Clustering:  97%|█████████▋| 30/31 [17:26<00:23, 23.99s/it]INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Creating model angle$gist for task RedditClustering
Loading angle from cache for RedditClustering...
Loading gist from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [01:44<05:54, 14.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [03:03<02:20, 11.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:05<02:12,  5.52s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [01:55<05:10, 13.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:15<03:06,  8.13s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [07:38<13:29, 44.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [03:20<02:28, 13.55s/it]INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 23.46 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8748286344400071, 'accuracy_threshold': 0.7848579934708249, 'f1': 0.7103096824774598, 'f1_threshold': 0.7668298251553121, 'precision': 0.7035982397100699, 'recall': 0.7171503957783641, 'ap': 0.780875988596831}, 'manhattan': {'accuracy': 0.8764379805686356, 'accuracy_threshold': 27.658787446323274, 'f1': 0.7155140186915887, 'f1_threshold': 29.79075012209587, 'precision': 0.6779220779220779, 'recall': 0.7575197889182058, 'ap': 0.7858865702003076}, 'euclidean': {'accuracy': 0.8748286344400071, 'accuracy_threshold': 0.655960373150263, 'f1': 0.7103096824774598, 'f1_threshold': 0.6828911697182407, 'precision': 0.7035982397100699, 'recall': 0.7171503957783641, 'ap': 0.780875988596831}, 'dot': {'accuracy': 0.8748286344400071, 'accuracy_threshold': 0.784857993470826, 'f1': 0.7103096824774598, 'f1_threshold': 0.7668298251553132, 'precision': 0.7035982397100699, 'recall': 0.7171503957783641, 'ap': 0.780875988596831}, 'max': {'accuracy': 0.8764379805686356, 'f1': 0.7155140186915887, 'ap': 0.7858865702003076}, 'evaluation_time': 23.46}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model cohere$flag-embedding$gist for task AskUbuntuDupQuestions
Loading cohere from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
Clustering:  61%|██████▏   | 19/31 [14:01<11:29, 57.45s/it]Clustering:  29%|██▉       | 9/31 [02:09<05:04, 13.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [03:28<01:57, 11.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [17:57<00:00, 26.27s/it]Clustering: 100%|██████████| 31/31 [17:57<00:00, 34.77s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 1077.81 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43292991570699474, 'v_measure_std': 0.14357875782093946, 'evaluation_time': 1077.81}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
Clustering:  48%|████▊     | 15/31 [09:28<13:09, 49.37s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:37<05:16, 14.37s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 17.11 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.635859811246448, 'mrr': 0.7583773029063887, 'evaluation_time': 17.11}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [02:27<05:14, 14.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist for task SciFact
Loading cohere from cache for SciFact...
Loading flag-embedding from cache for SciFact...
Loading gist from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s] 18%|█▊        | 947/5183 [00:00<00:00, 9467.62it/s] 37%|███▋      | 1894/5183 [00:00<00:00, 9037.31it/s] 54%|█████▍    | 2800/5183 [00:00<00:00, 6290.03it/s] 71%|███████   | 3677/5183 [00:00<00:00, 6886.86it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
 89%|████████▉ | 4614/5183 [00:00<00:00, 7630.26it/s]100%|██████████| 5183/5183 [00:00<00:00, 7582.16it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:faiss.loader:Loading faiss.
INFO:faiss.loader:Successfully loaded faiss.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:49<04:41, 13.41s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [03:50<02:14, 14.99s/it]/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$mixed-bread
Converting results/angle$cohere$mixed-bread to results/angle$cohere$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$voyage...
Skipping STS17 as it already exists
Creating model angle$cohere$voyage for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading cohere from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [01:02<04:29, 13.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [04:08<02:05, 15.66s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 27.95 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [04:12<01:26, 12.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:root:

INFO:root:NDCG@1: 0.6367
INFO:root:NDCG@3: 0.6924
INFO:root:NDCG@5: 0.7240
INFO:root:NDCG@10: 0.7476
INFO:root:NDCG@100: 0.7688
INFO:root:NDCG@1000: 0.7727
INFO:root:

INFO:root:MAP@1: 0.6093
INFO:root:MAP@3: 0.6695
INFO:root:MAP@5: 0.6912
INFO:root:MAP@10: 0.7024
INFO:root:MAP@100: 0.7078
INFO:root:MAP@1000: 0.7080
INFO:root:

INFO:root:Recall@1: 0.6093
INFO:root:Recall@3: 0.7291
INFO:root:Recall@5: 0.8086
INFO:root:Recall@10: 0.8776
INFO:root:Recall@100: 0.9717
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6367
INFO:root:P@3: 0.2678
INFO:root:P@5: 0.1820
INFO:root:P@10: 0.0993
INFO:root:P@100: 0.0110
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6367
INFO:root:MRR@3: 0.6867
INFO:root:MRR@5: 0.7027
INFO:root:MRR@10: 0.7115
INFO:root:MRR@100: 0.7154
INFO:root:MRR@1000: 0.7156
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 29.84 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.63667, 'ndcg_at_3': 0.69239, 'ndcg_at_5': 0.724, 'ndcg_at_10': 0.74757, 'ndcg_at_100': 0.76879, 'ndcg_at_1000': 0.77266, 'map_at_1': 0.60928, 'map_at_3': 0.66952, 'map_at_5': 0.69119, 'map_at_10': 0.70239, 'map_at_100': 0.70781, 'map_at_1000': 0.70799, 'recall_at_1': 0.60928, 'recall_at_3': 0.72906, 'recall_at_5': 0.80856, 'recall_at_10': 0.87756, 'recall_at_100': 0.97167, 'recall_at_1000': 1.0, 'precision_at_1': 0.63667, 'precision_at_3': 0.26778, 'precision_at_5': 0.182, 'precision_at_10': 0.09933, 'precision_at_100': 0.011, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.63667, 'mrr_at_3': 0.68667, 'mrr_at_5': 0.70267, 'mrr_at_10': 0.71147, 'mrr_at_100': 0.71542, 'mrr_at_1000': 0.71559, 'evaluation_time': 29.84}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist for task EmotionClassification
Loading cohere from cache for EmotionClassification...
Loading flag-embedding from cache for EmotionClassification...
Loading gist from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [01:20<04:41, 14.82s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
Clustering:  76%|███████▌  | 19/25 [04:25<01:15, 12.58s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [08:47<14:47, 52.18s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [15:06<10:56, 59.69s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [03:16<08:29, 25.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [01:30<04:00, 13.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 26.65 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.87494784526435, 'accuracy_threshold': 0.8229619726360208, 'f1': 0.7170532755544227, 'f1_threshold': 0.8019074431032251, 'precision': 0.6935404339250493, 'recall': 0.7422163588390501, 'ap': 0.7829032328245334}, 'manhattan': {'accuracy': 0.8736365261965786, 'accuracy_threshold': 25.606093279553985, 'f1': 0.7144462479710326, 'f1_threshold': 26.902739327159786, 'precision': 0.6781227779094572, 'recall': 0.7548812664907651, 'ap': 0.7796179255133766}, 'euclidean': {'accuracy': 0.87494784526435, 'accuracy_threshold': 0.5950429012158953, 'f1': 0.7170532755544227, 'f1_threshold': 0.6294323742705146, 'precision': 0.6935404339250493, 'recall': 0.7422163588390501, 'ap': 0.7829032328245334}, 'dot': {'accuracy': 0.87494784526435, 'accuracy_threshold': 0.8229619726360209, 'f1': 0.7170532755544227, 'f1_threshold': 0.8019074431032253, 'precision': 0.6935404339250493, 'recall': 0.7422163588390501, 'ap': 0.7829032328245334}, 'max': {'accuracy': 0.87494784526435, 'f1': 0.7170532755544227, 'ap': 0.7829032328245334}, 'evaluation_time': 26.65}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model angle$cohere$voyage for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading cohere from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [10:52<14:56, 59.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [01:58<05:03, 17.84s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
Clustering:  80%|████████  | 20/25 [05:01<01:37, 19.40s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 43.62 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6432712649520198, 'mrr': 0.7693685969309239, 'evaluation_time': 43.62}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$voyage for task SciFact
Loading angle from cache for SciFact...
Loading cohere from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s] 12%|█▏        | 599/5183 [00:00<00:00, 5780.92it/s] 23%|██▎       | 1178/5183 [00:00<00:00, 4999.48it/s] 32%|███▏      | 1684/5183 [00:00<00:00, 4425.96it/s] 41%|████      | 2134/5183 [00:00<00:00, 3966.18it/s] 56%|█████▋    | 2916/5183 [00:00<00:00, 5139.87it/s] 72%|███████▏  | 3742/5183 [00:00<00:00, 5949.96it/s] 91%|█████████ | 4700/5183 [00:00<00:00, 6747.07it/s]100%|██████████| 5183/5183 [00:00<00:00, 5912.19it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:faiss.loader:Loading faiss.
INFO:faiss.loader:Successfully loaded faiss.
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 72.02 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5632499999999999, 'f1': 0.5053448937151523, 'accuracy_stderr': 0.019748734136647832, 'f1_stderr': 0.012438522298982959, 'main_score': 0.5632499999999999, 'evaluation_time': 72.02}
INFO:main:Running task: AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model cohere$flag-embedding$gist for task AmazonCounterfactualClassification
Loading cohere from cache for AmazonCounterfactualClassification...
Loading flag-embedding from cache for AmazonCounterfactualClassification...
Loading gist from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Clustering:  36%|███▌      | 9/25 [02:39<06:41, 25.08s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 4.44 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7888059701492537, 'f1': 0.730643958097638, 'ap': 0.4311634704193745, 'accuracy_stderr': 0.03723723563225047, 'f1_stderr': 0.03649331573765331, 'ap_stderr': 0.04614972413681033, 'main_score': 0.7888059701492537}, 'evaluation_time': 4.44}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist for task Banking77Classification
Loading cohere from cache for Banking77Classification...
Loading flag-embedding from cache for Banking77Classification...
Loading gist from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [04:31<12:51, 40.61s/it]Clustering:  68%|██████▊   | 21/31 [16:23<10:49, 64.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [05:47<01:49, 27.43s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 25.88 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.6467
INFO:root:NDCG@3: 0.7079
INFO:root:NDCG@5: 0.7331
INFO:root:NDCG@10: 0.7559
INFO:root:NDCG@100: 0.7757
INFO:root:NDCG@1000: 0.7797
INFO:root:

INFO:root:MAP@1: 0.6149
INFO:root:MAP@3: 0.6818
INFO:root:MAP@5: 0.6992
INFO:root:MAP@10: 0.7114
INFO:root:MAP@100: 0.7160
INFO:root:MAP@1000: 0.7162
INFO:root:

INFO:root:Recall@1: 0.6149
INFO:root:Recall@3: 0.7541
INFO:root:Recall@5: 0.8191
INFO:root:Recall@10: 0.8822
INFO:root:Recall@100: 0.9717
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6467
INFO:root:P@3: 0.2767
INFO:root:P@5: 0.1827
INFO:root:P@10: 0.1003
INFO:root:P@100: 0.0110
INFO:root:P@1000: 0.0011
INFO:root:

INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [16:31<07:08, 47.66s/it]INFO:root:MRR@1: 0.6467
INFO:root:MRR@3: 0.6994
INFO:root:MRR@5: 0.7138
INFO:root:MRR@10: 0.7215
INFO:root:MRR@100: 0.7252
INFO:root:MRR@1000: 0.7254
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 29.42 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.64667, 'ndcg_at_3': 0.70787, 'ndcg_at_5': 0.73311, 'ndcg_at_10': 0.75592, 'ndcg_at_100': 0.77574, 'ndcg_at_1000': 0.7797, 'map_at_1': 0.61494, 'map_at_3': 0.68185, 'map_at_5': 0.69919, 'map_at_10': 0.71142, 'map_at_100': 0.71602, 'map_at_1000': 0.71624, 'recall_at_1': 0.61494, 'recall_at_3': 0.75406, 'recall_at_5': 0.81911, 'recall_at_10': 0.88222, 'recall_at_100': 0.97167, 'recall_at_1000': 1.0, 'precision_at_1': 0.64667, 'precision_at_3': 0.27667, 'precision_at_5': 0.18267, 'precision_at_10': 0.10033, 'precision_at_100': 0.011, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.64667, 'mrr_at_3': 0.69944, 'mrr_at_5': 0.71378, 'mrr_at_10': 0.72151, 'mrr_at_100': 0.72523, 'mrr_at_1000': 0.72542, 'evaluation_time': 29.42}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$voyage for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading cohere from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [03:20<07:31, 30.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [06:30<01:36, 32.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
Clustering:  48%|████▊     | 15/31 [10:57<20:08, 75.55s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [06:42<00:51, 25.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [12:52<18:09, 77.82s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Clustering:  44%|████▍     | 11/25 [04:04<08:02, 34.48s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [07:14<00:27, 27.87s/it]INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [04:17<06:02, 27.90s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [18:04<08:11, 61.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [06:15<17:51, 59.55s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 104.38 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8497402597402598, 'f1': 0.8450103635611168, 'accuracy_stderr': 0.005881554220376242, 'f1_stderr': 0.006602787358211099, 'main_score': 0.8497402597402598, 'evaluation_time': 104.38}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 87.80 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5557, 'f1': 0.4916597753631883, 'accuracy_stderr': 0.021611570974827347, 'f1_stderr': 0.012148586992966894, 'main_score': 0.5557, 'evaluation_time': 87.8}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model angle$cohere$voyage for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading cohere from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist for task ArguAna
Loading cohere from cache for ArguAna...
Loading flag-embedding from cache for ArguAna...
Loading gist from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s] 16%|█▋        | 1411/8674 [00:00<00:00, 14104.94it/s] 34%|███▍      | 2932/8674 [00:00<00:00, 14753.93it/s] 51%|█████     | 4408/8674 [00:00<00:00, 10409.45it/s] 67%|██████▋   | 5835/8674 [00:00<00:00, 11489.62it/s]Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
 82%|████████▏ | 7077/8674 [00:00<00:00, 10897.71it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
 95%|█████████▌| 8256/8674 [00:00<00:00, 11094.12it/s]Clustering:  52%|█████▏    | 13/25 [04:33<04:50, 24.17s/it]100%|██████████| 8674/8674 [00:00<00:00, 11537.80it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 3.82 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.766865671641791, 'f1': 0.7071242557349854, 'ap': 0.40008843626316964, 'accuracy_stderr': 0.03669821172203703, 'f1_stderr': 0.034122377989604956, 'ap_stderr': 0.038030715567153324, 'main_score': 0.766865671641791}, 'evaluation_time': 3.82}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$voyage for task Banking77Classification
Loading angle from cache for Banking77Classification...
Loading cohere from cache for Banking77Classification...
Loading voyage from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [07:51<00:00, 30.79s/it]Clustering: 100%|██████████| 25/25 [07:51<00:00, 18.88s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 471.94 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.5985668519355413, 'v_measure_std': 0.036087903739969826, 'evaluation_time': 471.94}
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Clustering:  56%|█████▌    | 14/25 [04:53<04:12, 22.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [05:03<03:10, 19.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
Clustering:  77%|███████▋  | 24/31 [18:45<06:27, 55.29s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [12:41<21:02, 84.20s/it]INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Converting the results to a CSV file...
Using model name cohere$llmrails
Converting results/cohere$llmrails to results/cohere$llmrails_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$mixed-bread...
Skipping STS17 as it already exists
Creating model cohere$mixed-bread for task TwitterSemEval2015
Loading cohere from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [14:32<18:18, 84.52s/it]INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 60.79 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [05:36<03:30, 23.41s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:root:

INFO:root:NDCG@1: 0.3329
INFO:root:NDCG@3: 0.4995
INFO:root:NDCG@5: 0.5517
INFO:root:NDCG@10: 0.5942
INFO:root:NDCG@100: 0.6215
INFO:root:NDCG@1000: 0.6221
INFO:root:

INFO:root:MAP@1: 0.3329
INFO:root:MAP@3: 0.4580
INFO:root:MAP@5: 0.4868
INFO:root:MAP@10: 0.5045
INFO:root:MAP@100: 0.5114
INFO:root:MAP@1000: 0.5114
INFO:root:

INFO:root:Recall@1: 0.3329
INFO:root:Recall@3: 0.6195
INFO:root:Recall@5: 0.7475
INFO:root:Recall@10: 0.8777
INFO:root:Recall@100: 0.9922
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.3329
INFO:root:P@3: 0.2065
INFO:root:P@5: 0.1495
INFO:root:P@10: 0.0878
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [07:26<17:54, 63.20s/it]INFO:root:MRR@1: 0.3407
INFO:root:MRR@3: 0.4603
INFO:root:MRR@5: 0.4895
INFO:root:MRR@10: 0.5075
INFO:root:MRR@100: 0.5143
INFO:root:MRR@1000: 0.5144
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 68.49 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.33286, 'ndcg_at_3': 0.49945, 'ndcg_at_5': 0.55175, 'ndcg_at_10': 0.59418, 'ndcg_at_100': 0.62151, 'ndcg_at_1000': 0.6221, 'map_at_1': 0.33286, 'map_at_3': 0.45804, 'map_at_5': 0.48681, 'map_at_10': 0.50451, 'map_at_100': 0.51141, 'map_at_1000': 0.51143, 'recall_at_1': 0.33286, 'recall_at_3': 0.61949, 'recall_at_5': 0.74751, 'recall_at_10': 0.87767, 'recall_at_100': 0.99218, 'recall_at_1000': 0.99644, 'precision_at_1': 0.33286, 'precision_at_3': 0.2065, 'precision_at_5': 0.1495, 'precision_at_10': 0.08777, 'precision_at_100': 0.00992, 'precision_at_1000': 0.001, 'mrr_at_1': 0.34068, 'mrr_at_3': 0.46029, 'mrr_at_5': 0.48952, 'mrr_at_10': 0.50752, 'mrr_at_100': 0.51435, 'mrr_at_1000': 0.51438, 'evaluation_time': 68.49}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 25.48 seconds
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8752458723252071, 'accuracy_threshold': 0.7883987348087012, 'f1': 0.7141898241374681, 'f1_threshold': 0.7765408552571736, 'precision': 0.7269745832194588, 'recall': 0.7018469656992085, 'ap': 0.7822864930001602}, 'manhattan': {'accuracy': 0.8759611372712642, 'accuracy_threshold': 23.283814813055827, 'f1': 0.7155987744771546, 'f1_threshold': 23.902570583559076, 'precision': 0.7226257734732311, 'recall': 0.7087071240105541, 'ap': 0.7839507621800462}, 'euclidean': {'accuracy': 0.8752458723252071, 'accuracy_threshold': 0.6505401834284412, 'f1': 0.7141898241374681, 'f1_threshold': 0.6685194722852081, 'precision': 0.7269745832194588, 'recall': 0.7018469656992085, 'ap': 0.7822864930001602}, 'dot': {'accuracy': 0.8752458723252071, 'accuracy_threshold': 0.7883987348087018, 'f1': 0.7141898241374681, 'f1_threshold': 0.7765408552571742, 'precision': 0.7269745832194588, 'recall': 0.7018469656992085, 'ap': 0.7822864930001602}, 'max': {'accuracy': 0.8759611372712642, 'f1': 0.7155987744771546, 'ap': 0.7839507621800462}, 'evaluation_time': 25.48}
Clustering:  68%|██████▊   | 17/25 [05:54<02:52, 21.50s/it]Clustering:  81%|████████  | 25/31 [19:32<05:16, 52.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [06:03<02:04, 17.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 82.24 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8453896103896105, 'f1': 0.8395369227794142, 'accuracy_stderr': 0.005528640222398252, 'f1_stderr': 0.006213265369173485, 'main_score': 0.8453896103896105, 'evaluation_time': 82.24}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [19:55<03:39, 43.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [06:18<01:41, 16.94s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [08:06<14:59, 56.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [13:42<18:00, 77.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [15:24<14:56, 74.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [06:32<01:21, 16.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model cohere$mixed-bread for task AskUbuntuDupQuestions
Loading cohere from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$voyage for task ArguAna
Loading angle from cache for ArguAna...
Loading cohere from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s] 45%|████▍     | 3897/8674 [00:00<00:00, 28345.15it/s] 94%|█████████▍| 8158/8674 [00:00<00:00, 35610.93it/s]100%|██████████| 8674/8674 [00:00<00:00, 34654.99it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  87%|████████▋ | 27/31 [20:19<02:31, 38.00s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [08:34<11:54, 47.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [06:54<01:11, 17.82s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 32.09 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6353928317093646, 'mrr': 0.7581079892714241, 'evaluation_time': 32.09}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$mixed-bread for task SciFact
Loading cohere from cache for SciFact...
Loading mixed-bread from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s] 23%|██▎       | 1175/5183 [00:00<00:00, 11430.03it/s] 45%|████▍     | 2319/5183 [00:00<00:00, 9805.85it/s]  64%|██████▍   | 3313/5183 [00:00<00:00, 9491.90it/s] 91%|█████████ | 4692/5183 [00:00<00:00, 10940.77it/s]100%|██████████| 5183/5183 [00:00<00:00, 10358.28it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [07:21<01:01, 20.53s/it]Clustering:  90%|█████████ | 28/31 [20:59<01:55, 38.39s/it]INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 11.56 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:root:

INFO:root:NDCG@1: 0.6367
INFO:root:NDCG@3: 0.6892
INFO:root:NDCG@5: 0.7202
INFO:root:NDCG@10: 0.7414
INFO:root:NDCG@100: 0.7661
INFO:root:NDCG@1000: 0.7705
INFO:root:

INFO:root:MAP@1: 0.6076
INFO:root:MAP@3: 0.6662
INFO:root:MAP@5: 0.6880
INFO:root:MAP@10: 0.6987
INFO:root:MAP@100: 0.7050
INFO:root:MAP@1000: 0.7052
INFO:root:

INFO:root:Recall@1: 0.6076
INFO:root:Recall@3: 0.7246
INFO:root:Recall@5: 0.8019
INFO:root:Recall@10: 0.8609
INFO:root:Recall@100: 0.9683
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6367
INFO:root:P@3: 0.2656
INFO:root:P@5: 0.1800
INFO:root:P@10: 0.0977
INFO:root:P@100: 0.0110
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6367
INFO:root:MRR@3: 0.6850
INFO:root:MRR@5: 0.7003
INFO:root:MRR@10: 0.7088
INFO:root:MRR@100: 0.7138
INFO:root:MRR@1000: 0.7140
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 12.21 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.63667, 'ndcg_at_3': 0.6892, 'ndcg_at_5': 0.72017, 'ndcg_at_10': 0.74142, 'ndcg_at_100': 0.7661, 'ndcg_at_1000': 0.77049, 'map_at_1': 0.60761, 'map_at_3': 0.66619, 'map_at_5': 0.68802, 'map_at_10': 0.69866, 'map_at_100': 0.70501, 'map_at_1000': 0.70523, 'recall_at_1': 0.60761, 'recall_at_3': 0.72461, 'recall_at_5': 0.80189, 'recall_at_10': 0.86089, 'recall_at_100': 0.96833, 'recall_at_1000': 1.0, 'precision_at_1': 0.63667, 'precision_at_3': 0.26556, 'precision_at_5': 0.18, 'precision_at_10': 0.09767, 'precision_at_100': 0.01097, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.63667, 'mrr_at_3': 0.685, 'mrr_at_5': 0.70033, 'mrr_at_10': 0.70882, 'mrr_at_100': 0.71382, 'mrr_at_1000': 0.71403, 'evaluation_time': 12.21}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 48.21 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [09:11<10:21, 44.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [07:25<00:31, 15.58s/it]INFO:root:

INFO:root:NDCG@1: 0.3755
INFO:root:NDCG@3: 0.5448
INFO:root:NDCG@5: 0.5968
INFO:root:NDCG@10: 0.6326
INFO:root:NDCG@100: 0.6547
INFO:root:NDCG@1000: 0.6551
INFO:root:

INFO:root:MAP@1: 0.3755
INFO:root:MAP@3: 0.5033
INFO:root:MAP@5: 0.5321
INFO:root:MAP@10: 0.5469
INFO:root:MAP@100: 0.5526
INFO:root:MAP@1000: 0.5526
INFO:root:

INFO:root:Recall@1: 0.3755
INFO:root:Recall@3: 0.6650
INFO:root:Recall@5: 0.7916
INFO:root:Recall@10: 0.9019
INFO:root:Recall@100: 0.9936
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.3755
INFO:root:P@3: 0.2217
INFO:root:P@5: 0.1583
INFO:root:P@10: 0.0902
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [16:27<13:03, 71.20s/it]INFO:root:MRR@1: 0.3812
INFO:root:MRR@3: 0.5056
INFO:root:MRR@5: 0.5342
INFO:root:MRR@10: 0.5492
INFO:root:MRR@100: 0.5547
INFO:root:MRR@1000: 0.5548
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 51.31 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.37553, 'ndcg_at_3': 0.54485, 'ndcg_at_5': 0.59682, 'ndcg_at_10': 0.63263, 'ndcg_at_100': 0.65469, 'ndcg_at_1000': 0.65508, 'map_at_1': 0.37553, 'map_at_3': 0.50332, 'map_at_5': 0.53205, 'map_at_10': 0.54693, 'map_at_100': 0.55258, 'map_at_1000': 0.5526, 'recall_at_1': 0.37553, 'recall_at_3': 0.66501, 'recall_at_5': 0.79161, 'recall_at_10': 0.90185, 'recall_at_100': 0.9936, 'recall_at_1000': 0.99644, 'precision_at_1': 0.37553, 'precision_at_3': 0.22167, 'precision_at_5': 0.15832, 'precision_at_10': 0.09018, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.38122, 'mrr_at_3': 0.50557, 'mrr_at_5': 0.5342, 'mrr_at_10': 0.54917, 'mrr_at_100': 0.55475, 'mrr_at_1000': 0.55477, 'evaluation_time': 51.31}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [14:47<15:54, 73.40s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [07:30<00:12, 12.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [21:25<01:09, 34.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [07:50<00:00, 14.82s/it]Clustering: 100%|██████████| 25/25 [07:50<00:00, 18.83s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 470.86 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.6151439413119538, 'v_measure_std': 0.04212180442597037, 'evaluation_time': 470.86}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [09:43<08:48, 40.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [17:00<09:57, 59.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  61%|██████▏   | 19/31 [15:20<12:17, 61.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [17:02<06:22, 42.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$mixed-bread for task EmotionClassification
Loading cohere from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [21:46<00:30, 30.77s/it]Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [09:57<06:31, 32.66s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [22:32<00:00, 35.21s/it]Clustering: 100%|██████████| 31/31 [22:32<00:00, 43.63s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 1352.50 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4318402506895491, 'v_measure_std': 0.14371681869412622, 'evaluation_time': 1352.5}
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [17:58<06:11, 46.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [10:44<06:48, 37.14s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [16:27<11:34, 63.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 64.97 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.55115, 'f1': 0.4898265182479758, 'accuracy_stderr': 0.02229915917697346, 'f1_stderr': 0.01369943849447632, 'main_score': 0.55115, 'evaluation_time': 64.97}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [18:19<04:32, 38.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [11:06<05:23, 32.40s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [11:08<03:30, 23.35s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model cohere$mixed-bread for task AmazonCounterfactualClassification
Loading cohere from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Converting the results to a CSV file...
Using model name angle$gist
Converting results/angle$gist to results/angle$gist_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$gte-large...
Skipping STS17 as it already exists
Creating model angle$gte-large for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading gte-large from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [16:52<08:35, 51.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [16:54<05:30, 36.69s/it]Clustering:  74%|███████▍  | 23/31 [11:21<02:40, 20.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [18:35<03:12, 32.13s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [11:26<01:50, 15.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [18:41<02:00, 24.16s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 3.58 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7780597014925373, 'f1': 0.7196442051673799, 'ap': 0.41724411176614795, 'accuracy_stderr': 0.03862212478691924, 'f1_stderr': 0.03813781911473255, 'ap_stderr': 0.04700114830461119, 'main_score': 0.7780597014925373}, 'evaluation_time': 3.58}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$mixed-bread for task Banking77Classification
Loading cohere from cache for Banking77Classification...
Loading mixed-bread from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 11.89 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8724444179531502, 'accuracy_threshold': 0.8641130924224854, 'f1': 0.7097329888027563, 'f1_threshold': 0.8495388031005859, 'precision': 0.6649757897163938, 'recall': 0.7609498680738787, 'ap': 0.7764866875861152}, 'manhattan': {'accuracy': 0.8713715205340645, 'accuracy_threshold': 18.171894073486328, 'f1': 0.7070935342121781, 'f1_threshold': 19.097209930419922, 'precision': 0.6744910179640718, 'recall': 0.7430079155672823, 'ap': 0.7726673933505451}, 'euclidean': {'accuracy': 0.8724444179531502, 'accuracy_threshold': 0.5213192701339722, 'f1': 0.7097329888027563, 'f1_threshold': 0.548564076423645, 'precision': 0.6649757897163938, 'recall': 0.7609498680738787, 'ap': 0.776486653938979}, 'dot': {'accuracy': 0.8724444179531502, 'accuracy_threshold': 0.8641130924224854, 'f1': 0.7097329888027563, 'f1_threshold': 0.8495388031005859, 'precision': 0.6649757897163938, 'recall': 0.7609498680738787, 'ap': 0.7764863187250178}, 'max': {'accuracy': 0.8724444179531502, 'f1': 0.7097329888027563, 'ap': 0.7764866875861152}, 'evaluation_time': 11.89}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
Clustering:  81%|████████  | 25/31 [11:39<01:28, 14.75s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model angle$gte-large for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading gte-large from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [17:28<04:46, 35.86s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
Clustering:  84%|████████▍ | 26/31 [11:55<01:16, 15.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [19:20<01:54, 28.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist for task ArxivClusteringS2S
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 22.89 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6435629115754511, 'mrr': 0.7735171261487052, 'evaluation_time': 22.89}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [12:24<01:17, 19.46s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [17:58<03:59, 34.20s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:18<09:01, 18.05s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [19:45<01:22, 27.48s/it]INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [12:43<00:57, 19.19s/it]/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [18:24<03:09, 31.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
Clustering:   6%|▋         | 2/31 [00:38<09:25, 19.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gte-large for task SciFact
Loading angle from cache for SciFact...
Loading gte-large from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s] 20%|██        | 1042/5183 [00:00<00:00, 10384.28it/s]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
 40%|████      | 2081/5183 [00:00<00:00, 7411.80it/s]  56%|█████▋    | 2925/5183 [00:00<00:00, 7484.05it/s]INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 78.36 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8457467532467533, 'f1': 0.8405726658221159, 'accuracy_stderr': 0.005630004941539641, 'f1_stderr': 0.006317889215668904, 'main_score': 0.8457467532467533, 'evaluation_time': 78.36}
 71%|███████▏  | 3702/5183 [00:00<00:00, 7147.01it/s] 88%|████████▊ | 4572/5183 [00:00<00:00, 7633.87it/s]100%|██████████| 5183/5183 [00:00<00:00, 8008.03it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:main:Running task: ArguAna
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [20:14<00:55, 27.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$mixed-bread for task ArguAna
Loading cohere from cache for ArguAna...
Loading mixed-bread from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [18:35<02:07, 25.41s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:beir.datasets.data_loader:Loading Corpus...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [13:02<00:38, 19.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
  0%|          | 0/8674 [00:00<?, ?it/s] 42%|████▏     | 3632/8674 [00:00<00:00, 36308.61it/s] 97%|█████████▋| 8380/8674 [00:00<00:00, 42876.85it/s]100%|██████████| 8674/8674 [00:00<00:00, 41983.60it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 9.01 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:root:

INFO:root:NDCG@1: 0.6500
INFO:root:NDCG@3: 0.7076
INFO:root:NDCG@5: 0.7336
INFO:root:NDCG@10: 0.7588
INFO:root:NDCG@100: 0.7766
INFO:root:NDCG@1000: 0.7815
INFO:root:

INFO:root:MAP@1: 0.6226
INFO:root:MAP@3: 0.6847
INFO:root:MAP@5: 0.7021
INFO:root:MAP@10: 0.7149
INFO:root:MAP@100: 0.7191
INFO:root:MAP@1000: 0.7194
INFO:root:

INFO:root:Recall@1: 0.6226
INFO:root:Recall@3: 0.7467
INFO:root:Recall@5: 0.8116
INFO:root:Recall@10: 0.8849
INFO:root:Recall@100: 0.9650
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6500
INFO:root:P@3: 0.2733
INFO:root:P@5: 0.1813
INFO:root:P@10: 0.1003
INFO:root:P@100: 0.0109
INFO:root:P@1000: 0.0011
INFO:root:

INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [13:06<00:14, 14.56s/it]INFO:root:MRR@1: 0.6500
INFO:root:MRR@3: 0.7011
INFO:root:MRR@5: 0.7156
INFO:root:MRR@10: 0.7239
INFO:root:MRR@100: 0.7271
INFO:root:MRR@1000: 0.7274
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 9.74 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.65, 'ndcg_at_3': 0.70759, 'ndcg_at_5': 0.73362, 'ndcg_at_10': 0.75879, 'ndcg_at_100': 0.77664, 'ndcg_at_1000': 0.78155, 'map_at_1': 0.62261, 'map_at_3': 0.68469, 'map_at_5': 0.70209, 'map_at_10': 0.7149, 'map_at_100': 0.7191, 'map_at_1000': 0.71936, 'recall_at_1': 0.62261, 'recall_at_3': 0.74672, 'recall_at_5': 0.81161, 'recall_at_10': 0.88489, 'recall_at_100': 0.965, 'recall_at_1000': 1.0, 'precision_at_1': 0.65, 'precision_at_3': 0.27333, 'precision_at_5': 0.18133, 'precision_at_10': 0.10033, 'precision_at_100': 0.01093, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.65, 'mrr_at_3': 0.70111, 'mrr_at_5': 0.71561, 'mrr_at_10': 0.72386, 'mrr_at_100': 0.72711, 'mrr_at_1000': 0.72735, 'evaluation_time': 9.74}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:54<08:23, 17.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [20:24<00:22, 22.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gte-large for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading gte-large from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [18:47<01:25, 21.41s/it]Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [13:14<00:00, 12.66s/it]Clustering: 100%|██████████| 31/31 [13:14<00:00, 25.63s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 794.47 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43203592605092334, 'v_measure_std': 0.1422711062597549, 'evaluation_time': 794.47}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:07<07:14, 16.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [18:56<00:53, 17.72s/it]INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 20.81 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [20:38<00:00, 20.01s/it]Clustering: 100%|██████████| 31/31 [20:38<00:00, 39.95s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 1238.54 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4313673496881791, 'v_measure_std': 0.14222484864547916, 'evaluation_time': 1238.54}
INFO:root:

INFO:root:NDCG@1: 0.3336
INFO:root:NDCG@3: 0.5002
INFO:root:NDCG@5: 0.5534
INFO:root:NDCG@10: 0.5962
INFO:root:NDCG@100: 0.6231
INFO:root:NDCG@1000: 0.6237
INFO:root:

INFO:root:MAP@1: 0.3336
INFO:root:MAP@3: 0.4587
INFO:root:MAP@5: 0.4883
INFO:root:MAP@10: 0.5062
INFO:root:MAP@100: 0.5131
INFO:root:MAP@1000: 0.5131
INFO:root:

INFO:root:Recall@1: 0.3336
INFO:root:Recall@3: 0.6202
INFO:root:Recall@5: 0.7496
INFO:root:Recall@10: 0.8805
INFO:root:Recall@100: 0.9922
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.3336
INFO:root:P@3: 0.2067
INFO:root:P@5: 0.1499
INFO:root:P@10: 0.0881
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.3386
INFO:root:MRR@3: 0.4602
INFO:root:MRR@5: 0.4903
INFO:root:MRR@10: 0.5082
INFO:root:MRR@100: 0.5152
INFO:root:MRR@1000: 0.5152
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 23.27 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.33357, 'ndcg_at_3': 0.50017, 'ndcg_at_5': 0.55345, 'ndcg_at_10': 0.59619, 'ndcg_at_100': 0.62307, 'ndcg_at_1000': 0.62365, 'map_at_1': 0.33357, 'map_at_3': 0.45875, 'map_at_5': 0.4883, 'map_at_10': 0.50619, 'map_at_100': 0.51307, 'map_at_1000': 0.5131, 'recall_at_1': 0.33357, 'recall_at_3': 0.6202, 'recall_at_5': 0.74964, 'recall_at_10': 0.88051, 'recall_at_100': 0.99218, 'recall_at_1000': 0.99644, 'precision_at_1': 0.33357, 'precision_at_3': 0.20673, 'precision_at_5': 0.14993, 'precision_at_10': 0.08805, 'precision_at_100': 0.00992, 'precision_at_1000': 0.001, 'mrr_at_1': 0.33855, 'mrr_at_3': 0.46017, 'mrr_at_5': 0.49029, 'mrr_at_10': 0.50822, 'mrr_at_100': 0.51517, 'mrr_at_1000': 0.5152, 'evaluation_time': 23.27}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [19:22<00:40, 20.37s/it]Clustering:  16%|█▌        | 5/31 [01:37<09:03, 20.90s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [19:34<00:17, 17.75s/it]/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [02:01<09:12, 22.09s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 56.24 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.54195, 'f1': 0.47404932396539434, 'accuracy_stderr': 0.026680001874062893, 'f1_stderr': 0.015642235867231426, 'main_score': 0.54195, 'evaluation_time': 56.24}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [20:00<00:00, 20.07s/it]Clustering: 100%|██████████| 31/31 [20:00<00:00, 38.71s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 1200.07 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4322624998056175, 'v_measure_std': 0.143067215553738, 'evaluation_time': 1200.07}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [02:19<08:18, 20.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: AmazonCounterfactualClassification
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [02:30<06:42, 17.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [02:56<07:21, 20.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [03:06<05:56, 16.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model angle$gte-large for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading gte-large from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
Clustering:  35%|███▌      | 11/31 [03:26<05:58, 17.94s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 4.96 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7271641791044776, 'f1': 0.666261311874062, 'ap': 0.3526489745874022, 'accuracy_stderr': 0.03463715750294991, 'f1_stderr': 0.03438653880352475, 'ap_stderr': 0.03638600908145221, 'main_score': 0.7271641791044776}, 'evaluation_time': 4.96}
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name flag-embedding$llmrails$voyage
Converting results/flag-embedding$llmrails$voyage to results/flag-embedding$llmrails$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model flag-embedding$mixed-bread$voyage...
Skipping STS17 as it already exists
Creating model flag-embedding$mixed-bread$voyage for task TwitterSemEval2015
Loading flag-embedding from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:main:Running task: Banking77Classification
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gte-large for task Banking77Classification
Loading angle from cache for Banking77Classification...
Loading gte-large from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [03:46<05:53, 18.61s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 20.42 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8764379805686356, 'accuracy_threshold': 0.8352849579418742, 'f1': 0.719450101832994, 'f1_threshold': 0.8163271647849555, 'precision': 0.6950319724545008, 'recall': 0.745646437994723, 'ap': 0.790963714947929}, 'manhattan': {'accuracy': 0.8757227156225785, 'accuracy_threshold': 24.330033750361363, 'f1': 0.7164760914760915, 'f1_threshold': 25.52775586753886, 'precision': 0.705837173579109, 'recall': 0.7274406332453826, 'ap': 0.7887976528527849}, 'euclidean': {'accuracy': 0.8764379805686356, 'accuracy_threshold': 0.5739600010316381, 'f1': 0.719450101832994, 'f1_threshold': 0.6060904802772287, 'precision': 0.6950319724545008, 'recall': 0.745646437994723, 'ap': 0.790963714947929}, 'dot': {'accuracy': 0.8764379805686356, 'accuracy_threshold': 0.8352849579418744, 'f1': 0.719450101832994, 'f1_threshold': 0.8163271647849555, 'precision': 0.6950319724545008, 'recall': 0.745646437994723, 'ap': 0.790963714947929}, 'max': {'accuracy': 0.8764379805686356, 'f1': 0.719450101832994, 'ap': 0.790963714947929}, 'evaluation_time': 20.42}
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model flag-embedding$mixed-bread$voyage for task AskUbuntuDupQuestions
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 41.68 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8396103896103897, 'f1': 0.8327472193097172, 'accuracy_stderr': 0.004758459989756171, 'f1_stderr': 0.006063874301577356, 'main_score': 0.8396103896103897, 'evaluation_time': 41.68}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [04:27<07:39, 25.52s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Creating model angle$gist$voyage for task RedditClustering
Loading angle from cache for RedditClustering...
Loading gist from cache for RedditClustering...
Loading voyage from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 7.77 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6520724132736216, 'mrr': 0.7853559336938838, 'evaluation_time': 7.77}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gte-large for task ArguAna
Loading angle from cache for ArguAna...
Loading gte-large from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s] 51%|█████     | 4416/8674 [00:00<00:00, 44148.46it/s]100%|██████████| 8674/8674 [00:00<00:00, 47985.86it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:02<01:10,  2.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model flag-embedding$mixed-bread$voyage for task SciFact
Loading flag-embedding from cache for SciFact...
Loading mixed-bread from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
  0%|          | 0/5183 [00:00<?, ?it/s]  0%|          | 22/5183 [00:00<00:29, 175.33it/s] 38%|███▊      | 1960/5183 [00:00<00:00, 10228.57it/s] 59%|█████▉    | 3073/5183 [00:00<00:00, 9887.08it/s]  79%|███████▉  | 4112/5183 [00:00<00:00, 8631.25it/s] 98%|█████████▊| 5084/5183 [00:00<00:00, 8960.30it/s]100%|██████████| 5183/5183 [00:00<00:00, 8457.75it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [04:46<06:40, 23.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:09<01:51,  4.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 13.85 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.4018
INFO:root:NDCG@3: 0.5665
INFO:root:NDCG@5: 0.6107
INFO:root:NDCG@10: 0.6479
INFO:root:NDCG@100: 0.6678
INFO:root:NDCG@1000: 0.6688
INFO:root:

INFO:root:MAP@1: 0.4018
INFO:root:MAP@3: 0.5250
INFO:root:MAP@5: 0.5496
INFO:root:MAP@10: 0.5652
INFO:root:MAP@100: 0.5704
INFO:root:MAP@1000: 0.5705
INFO:root:

INFO:root:Recall@1: 0.4018
INFO:root:Recall@3: 0.6871
INFO:root:Recall@5: 0.7937
INFO:root:Recall@10: 0.9075
INFO:root:Recall@100: 0.9893
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.4018
INFO:root:P@3: 0.2290
INFO:root:P@5: 0.1588
INFO:root:P@10: 0.0907
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.4083
INFO:root:MRR@3: 0.5275
INFO:root:MRR@5: 0.5518
INFO:root:MRR@10: 0.5674
INFO:root:MRR@100: 0.5726
INFO:root:MRR@1000: 0.5727
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 16.67 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.40185, 'ndcg_at_3': 0.56652, 'ndcg_at_5': 0.61066, 'ndcg_at_10': 0.64787, 'ndcg_at_100': 0.66783, 'ndcg_at_1000': 0.66883, 'map_at_1': 0.40185, 'map_at_3': 0.52501, 'map_at_5': 0.54962, 'map_at_10': 0.56522, 'map_at_100': 0.57044, 'map_at_1000': 0.5705, 'recall_at_1': 0.40185, 'recall_at_3': 0.68706, 'recall_at_5': 0.79374, 'recall_at_10': 0.90754, 'recall_at_100': 0.98933, 'recall_at_1000': 0.99644, 'precision_at_1': 0.40185, 'precision_at_3': 0.22902, 'precision_at_5': 0.15875, 'precision_at_10': 0.09075, 'precision_at_100': 0.00989, 'precision_at_1000': 0.001, 'mrr_at_1': 0.40825, 'mrr_at_3': 0.5275, 'mrr_at_5': 0.55183, 'mrr_at_10': 0.56741, 'mrr_at_100': 0.57264, 'mrr_at_1000': 0.57269, 'evaluation_time': 16.67}
INFO:main:Running task: ArxivClusteringS2S
INFO:faiss.loader:Loading faiss.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:22<03:15,  8.87s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [05:05<05:54, 22.17s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:faiss.loader:Successfully loaded faiss.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:31<03:07,  8.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:36<02:31,  7.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 9.29 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.6433
INFO:root:NDCG@3: 0.7021
INFO:root:NDCG@5: 0.7255
INFO:root:NDCG@10: 0.7521
INFO:root:NDCG@100: 0.7746
INFO:root:NDCG@1000: 0.7784
INFO:root:

INFO:root:MAP@1: 0.6143
INFO:root:MAP@3: 0.6799
INFO:root:MAP@5: 0.6954
INFO:root:MAP@10: 0.7094
INFO:root:MAP@100: 0.7150
INFO:root:MAP@1000: 0.7152
INFO:root:

INFO:root:Recall@1: 0.6143
INFO:root:Recall@3: 0.7395
INFO:root:Recall@5: 0.7983
INFO:root:Recall@10: 0.8732
INFO:root:Recall@100: 0.9717
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6433
INFO:root:P@3: 0.2711
INFO:root:P@5: 0.1780
INFO:root:P@10: 0.0993
INFO:root:P@100: 0.0110
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6433
INFO:root:MRR@3: 0.6956
INFO:root:MRR@5: 0.7096
INFO:root:MRR@10: 0.7184
INFO:root:MRR@100: 0.7231
INFO:root:MRR@1000: 0.7233
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 35.92 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.64333, 'ndcg_at_3': 0.70212, 'ndcg_at_5': 0.72545, 'ndcg_at_10': 0.75208, 'ndcg_at_100': 0.77459, 'ndcg_at_1000': 0.77837, 'map_at_1': 0.61428, 'map_at_3': 0.67987, 'map_at_5': 0.69539, 'map_at_10': 0.70938, 'map_at_100': 0.71501, 'map_at_1000': 0.71519, 'recall_at_1': 0.61428, 'recall_at_3': 0.7395, 'recall_at_5': 0.79828, 'recall_at_10': 0.87322, 'recall_at_100': 0.97167, 'recall_at_1000': 1.0, 'precision_at_1': 0.64333, 'precision_at_3': 0.27111, 'precision_at_5': 0.178, 'precision_at_10': 0.09933, 'precision_at_100': 0.011, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.64333, 'mrr_at_3': 0.69556, 'mrr_at_5': 0.70956, 'mrr_at_10': 0.7184, 'mrr_at_100': 0.72314, 'mrr_at_1000': 0.72329, 'evaluation_time': 35.92}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [00:44<02:26,  7.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [05:27<05:30, 22.00s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  28%|██▊       | 7/25 [00:49<02:02,  6.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model flag-embedding$mixed-bread$voyage for task EmotionClassification
Loading flag-embedding from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Creating model llmrails$mixed-bread for task RedditClustering
Loading llmrails from cache for RedditClustering...
Loading mixed-bread from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [01:02<02:29,  8.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
Clustering:  32%|███▏      | 8/25 [01:08<02:24,  8.53s/it]
ERROR:mteb.evaluation.MTEB:Error while evaluating RedditClustering: Unable to allocate 587. MiB for an array with shape (25026, 3072) and data type float64
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
Clustering:   4%|▍         | 1/25 [00:02<01:01,  2.57s/it]/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
Clustering:  55%|█████▍    | 17/31 [05:52<05:22, 23.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:08<01:47,  4.65s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:29<04:26, 12.13s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:40<04:04, 11.66s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:49<03:31, 10.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 49.34 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5461500000000001, 'f1': 0.47853098106967834, 'accuracy_stderr': 0.02587764479236858, 'f1_stderr': 0.014848492288620735, 'main_score': 0.5461500000000001, 'evaluation_time': 49.34}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [00:55<02:50,  8.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model flag-embedding$mixed-bread$voyage for task AmazonCounterfactualClassification
Loading flag-embedding from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [06:41<06:40, 30.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  28%|██▊       | 7/25 [00:57<02:02,  6.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [01:01<01:43,  6.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [01:07<01:37,  6.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [06:57<05:16, 26.39s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [01:16<01:41,  6.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [01:23<01:37,  6.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [01:24<01:07,  5.18s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [01:26<00:50,  4.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [01:31<00:48,  4.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
Clustering:  65%|██████▍   | 20/31 [07:16<04:23, 24.00s/it]INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 1.81 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7385074626865672, 'f1': 0.6781513165222517, 'ap': 0.36611126634188157, 'accuracy_stderr': 0.03653394775250429, 'f1_stderr': 0.03431041378248172, 'ap_stderr': 0.03564930483204528, 'main_score': 0.7385074626865672}, 'evaluation_time': 1.81}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [01:34<00:38,  3.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [01:38<00:37,  4.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [07:30<03:32, 21.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [07:33<02:21, 15.74s/it]INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gte-large for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [01:50<00:51,  6.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [01:52<00:34,  4.90s/it]Evaluating the model gte-large$llmrails$mixed-bread...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name gte-large$llmrails$mixed-bread
Converting results/gte-large$llmrails$mixed-bread to results/gte-large$llmrails$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model gte-large$llmrails$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model gte-large$llmrails$voyage for task AskUbuntuDupQuestions
Loading gte-large from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model flag-embedding$mixed-bread$voyage for task Banking77Classification
Loading flag-embedding from cache for Banking77Classification...
Loading mixed-bread from cache for Banking77Classification...
Loading voyage from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [01:55<00:27,  4.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Creating model flag-embedding$gist$mixed-bread for task RedditClustering
Loading flag-embedding from cache for RedditClustering...
Loading gist from cache for RedditClustering...
Loading mixed-bread from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:12<06:25, 12.85s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:13<05:31, 13.81s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [02:23<00:57, 11.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:35<08:51, 18.34s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 29.26 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6438484070392545, 'mrr': 0.7803741810667019, 'evaluation_time': 29.26}
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:29<05:39, 14.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  74%|███████▍  | 23/31 [08:15<03:08, 23.53s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model gte-large$llmrails$voyage for task SciFact
Loading gte-large from cache for SciFact...
Loading llmrails from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
  0%|          | 0/5183 [00:00<?, ?it/s] 23%|██▎       | 1170/5183 [00:00<00:00, 11697.75it/s] 45%|████▌     | 2340/5183 [00:00<00:00, 10301.47it/s] 72%|███████▏  | 3715/5183 [00:00<00:00, 11767.43it/s]100%|██████████| 5183/5183 [00:00<00:00, 12390.74it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:faiss.loader:Loading faiss.
INFO:faiss.loader:Successfully loaded faiss.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
Clustering:  10%|▉         | 3/31 [00:52<08:22, 17.93s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  84%|████████▍ | 21/25 [02:47<01:00, 15.17s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading cohere from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [08:50<03:08, 26.90s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:18<09:28, 21.05s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 73.60 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8477922077922079, 'f1': 0.8411727213768494, 'accuracy_stderr': 0.004878348044413751, 'f1_stderr': 0.005881525402548287, 'main_score': 0.8477922077922079, 'evaluation_time': 73.6}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$mixed-bread for task ArxivClusteringS2S
Loading cohere from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 27.14 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
Clustering:  12%|█▏        | 3/25 [01:12<10:10, 27.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:root:

INFO:root:NDCG@1: 0.6600
INFO:root:NDCG@3: 0.7280
INFO:root:NDCG@5: 0.7530
INFO:root:NDCG@10: 0.7753
INFO:root:NDCG@100: 0.7900
INFO:root:NDCG@1000: 0.7945
INFO:root:

INFO:root:MAP@1: 0.6309
INFO:root:MAP@3: 0.7025
INFO:root:MAP@5: 0.7189
INFO:root:MAP@10: 0.7312
INFO:root:MAP@100: 0.7347
INFO:root:MAP@1000: 0.7349
INFO:root:

INFO:root:Recall@1: 0.6309
INFO:root:Recall@3: 0.7753
INFO:root:Recall@5: 0.8383
INFO:root:Recall@10: 0.8999
INFO:root:Recall@100: 0.9667
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6600
INFO:root:P@3: 0.2822
INFO:root:P@5: 0.1867
INFO:root:P@10: 0.1020
INFO:root:P@100: 0.0110
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6600
INFO:root:MRR@3: 0.7189
INFO:root:MRR@5: 0.7327
INFO:root:MRR@10: 0.7400
INFO:root:MRR@100: 0.7425
INFO:root:MRR@1000: 0.7427
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 28.62 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.66, 'ndcg_at_3': 0.72804, 'ndcg_at_5': 0.753, 'ndcg_at_10': 0.77532, 'ndcg_at_100': 0.79002, 'ndcg_at_1000': 0.79454, 'map_at_1': 0.63094, 'map_at_3': 0.70246, 'map_at_5': 0.71894, 'map_at_10': 0.73123, 'map_at_100': 0.73465, 'map_at_1000': 0.73486, 'recall_at_1': 0.63094, 'recall_at_3': 0.77533, 'recall_at_5': 0.83828, 'recall_at_10': 0.89989, 'recall_at_100': 0.96667, 'recall_at_1000': 1.0, 'precision_at_1': 0.66, 'precision_at_3': 0.28222, 'precision_at_5': 0.18667, 'precision_at_10': 0.102, 'precision_at_100': 0.01097, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.66, 'mrr_at_3': 0.71889, 'mrr_at_5': 0.73272, 'mrr_at_10': 0.74001, 'mrr_at_100': 0.74251, 'mrr_at_1000': 0.74272, 'evaluation_time': 28.62}
INFO:main:Running task: AmazonCounterfactualClassification
Clustering:  88%|████████▊ | 22/25 [03:13<00:55, 18.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model flag-embedding$mixed-bread$voyage for task ArguAna
Loading flag-embedding from cache for ArguAna...
Loading mixed-bread from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [03:15<00:26, 13.47s/it] 45%|████▌     | 3905/8674 [00:00<00:00, 39042.59it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Creating model gte-large$llmrails$voyage for task AmazonCounterfactualClassification
Loading gte-large from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
 97%|█████████▋| 8390/8674 [00:00<00:00, 42455.32it/s]100%|██████████| 8674/8674 [00:00<00:00, 42182.84it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 3.81 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7367164179104477, 'f1': 0.6742242259378598, 'ap': 0.35996733484803994, 'accuracy_stderr': 0.03730268501925566, 'f1_stderr': 0.03608843252449148, 'ap_stderr': 0.03853822475880909, 'main_score': 0.7367164179104477}, 'evaluation_time': 3.81}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [03:25<00:12, 12.49s/it]Clustering:  16%|█▌        | 5/31 [01:31<07:57, 18.37s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [01:25<07:40, 21.94s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:27<13:51, 27.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:   3%|▎         | 1/31 [00:13<06:31, 13.05s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [09:19<02:46, 27.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [01:35<05:52, 17.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
Clustering:  19%|█▉        | 6/31 [01:43<06:42, 16.09s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [03:37<00:00, 12.37s/it]Clustering: 100%|██████████| 25/25 [03:37<00:00,  8.70s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 217.58 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.5934559163044998, 'v_measure_std': 0.051219545609975485, 'evaluation_time': 217.58}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:24<05:44, 11.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 31.64 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
Clustering:   6%|▋         | 2/31 [00:47<11:07, 23.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [01:55<05:55, 14.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:root:

INFO:root:NDCG@1: 0.4175
INFO:root:NDCG@3: 0.5801
INFO:root:NDCG@5: 0.6224
INFO:root:NDCG@10: 0.6594
INFO:root:NDCG@100: 0.6782
INFO:root:NDCG@1000: 0.6789
INFO:root:

INFO:root:MAP@1: 0.4175
INFO:root:MAP@3: 0.5394
INFO:root:MAP@5: 0.5630
INFO:root:MAP@10: 0.5785
INFO:root:MAP@100: 0.5834
INFO:root:MAP@1000: 0.5834
INFO:root:

INFO:root:Recall@1: 0.4175
INFO:root:Recall@3: 0.6984
INFO:root:Recall@5: 0.8001
INFO:root:Recall@10: 0.9132
INFO:root:Recall@100: 0.9915
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.4175
INFO:root:P@3: 0.2328
INFO:root:P@5: 0.1600
INFO:root:P@10: 0.0913
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [09:34<01:59, 23.84s/it]INFO:root:MRR@1: 0.4232
INFO:root:MRR@3: 0.5416
INFO:root:MRR@5: 0.5653
INFO:root:MRR@10: 0.5807
INFO:root:MRR@100: 0.5855
INFO:root:MRR@1000: 0.5856
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 35.53 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.4175, 'ndcg_at_3': 0.58013, 'ndcg_at_5': 0.6224, 'ndcg_at_10': 0.65939, 'ndcg_at_100': 0.67819, 'ndcg_at_1000': 0.67887, 'map_at_1': 0.4175, 'map_at_3': 0.53936, 'map_at_5': 0.56304, 'map_at_10': 0.57853, 'map_at_100': 0.58338, 'map_at_1000': 0.58342, 'recall_at_1': 0.4175, 'recall_at_3': 0.69844, 'recall_at_5': 0.80014, 'recall_at_10': 0.91323, 'recall_at_100': 0.99147, 'recall_at_1000': 0.99644, 'precision_at_1': 0.4175, 'precision_at_3': 0.23281, 'precision_at_5': 0.16003, 'precision_at_10': 0.09132, 'precision_at_100': 0.00991, 'precision_at_1000': 0.001, 'mrr_at_1': 0.42319, 'mrr_at_3': 0.54161, 'mrr_at_5': 0.56529, 'mrr_at_10': 0.58073, 'mrr_at_100': 0.58551, 'mrr_at_1000': 0.58555, 'evaluation_time': 35.53}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [01:50<05:20, 16.87s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:37<05:51, 12.54s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [02:02<04:39, 12.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  28%|██▊       | 7/25 [01:55<03:51, 12.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [01:00<08:40, 18.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [00:48<05:26, 12.09s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [02:10<03:59, 10.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [09:49<01:24, 21.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [02:15<03:12,  9.18s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [02:09<03:45, 13.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [00:57<04:38, 10.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  13%|█▎        | 4/31 [01:12<07:05, 15.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [01:08<04:32, 10.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Converting the results to a CSV file...
Using model name llmrails$mixed-bread
Converting results/llmrails$mixed-bread to results/llmrails$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model llmrails$voyage...
Skipping STS17 as it already exists
Creating model llmrails$voyage for task TwitterSemEval2015
Loading llmrails from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
Clustering:  90%|█████████ | 28/31 [10:13<01:05, 21.80s/it]INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [02:31<04:16, 16.03s/it]Clustering:  16%|█▌        | 5/31 [01:32<07:33, 17.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [01:19<04:23, 10.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [02:41<04:45, 14.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 10.24 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8733981045478929, 'accuracy_threshold': 0.8555854032235097, 'f1': 0.7124741200828159, 'f1_threshold': 0.837054565932235, 'precision': 0.6990858303707466, 'recall': 0.7263852242744063, 'ap': 0.7852267680816493}, 'manhattan': {'accuracy': 0.8711927042975502, 'accuracy_threshold': 19.198592409909992, 'f1': 0.7092819614711033, 'f1_threshold': 20.49105875502427, 'precision': 0.6743577545195052, 'recall': 0.7480211081794196, 'ap': 0.7798910360594031}, 'euclidean': {'accuracy': 0.8733981045478929, 'accuracy_threshold': 0.5374283146607235, 'f1': 0.7124741200828159, 'f1_threshold': 0.5708685203021793, 'precision': 0.6990858303707466, 'recall': 0.7263852242744063, 'ap': 0.7852267680816493}, 'dot': {'accuracy': 0.8733981045478929, 'accuracy_threshold': 0.8555854032235101, 'f1': 0.7124741200828159, 'f1_threshold': 0.8370545659322352, 'precision': 0.6990858303707466, 'recall': 0.7263852242744063, 'ap': 0.7852267680816494}, 'max': {'accuracy': 0.8733981045478929, 'f1': 0.7124741200828159, 'ap': 0.7852267680816494}, 'evaluation_time': 10.24}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model llmrails$voyage for task AskUbuntuDupQuestions
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [01:34<04:38, 12.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [10:39<00:46, 23.10s/it]Clustering:  26%|██▌       | 8/31 [01:40<04:48, 12.54s/it]
ERROR:mteb.evaluation.MTEB:Error while evaluating ArxivClusteringS2S: Unable to allocate 391. MiB for an array with shape (25000, 2048) and data type float64
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [02:54<04:33, 18.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [01:58<08:27, 20.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 11.79 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6446816746547547, 'mrr': 0.7775458382799103, 'evaluation_time': 11.79}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [03:07<05:40, 17.91s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model llmrails$voyage for task SciFact
Loading llmrails from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s] 36%|███▋      | 1881/5183 [00:00<00:00, 18795.50it/s] 73%|███████▎  | 3761/5183 [00:00<00:00, 18208.84it/s]100%|██████████| 5183/5183 [00:00<00:00, 17649.60it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [10:51<00:19, 19.77s/it]INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Evaluating the model angle$cohere$flag-embedding$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model angle$cohere$flag-embedding$voyage for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading cohere from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [02:15<07:38, 19.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 10.55 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [03:15<04:23, 18.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:root:

INFO:root:NDCG@1: 0.6700
INFO:root:NDCG@3: 0.7279
INFO:root:NDCG@5: 0.7476
INFO:root:NDCG@10: 0.7710
INFO:root:NDCG@100: 0.7892
INFO:root:NDCG@1000: 0.7945
INFO:root:

INFO:root:MAP@1: 0.6383
INFO:root:MAP@3: 0.7042
INFO:root:MAP@5: 0.7179
INFO:root:MAP@10: 0.7308
INFO:root:MAP@100: 0.7355
INFO:root:MAP@1000: 0.7357
INFO:root:

INFO:root:Recall@1: 0.6383
INFO:root:Recall@3: 0.7687
INFO:root:Recall@5: 0.8183
INFO:root:Recall@10: 0.8832
INFO:root:Recall@100: 0.9600
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6700
INFO:root:P@3: 0.2800
INFO:root:P@5: 0.1827
INFO:root:P@10: 0.1003
INFO:root:P@100: 0.0109
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6700
INFO:root:MRR@3: 0.7217
INFO:root:MRR@5: 0.7330
INFO:root:MRR@10: 0.7408
INFO:root:MRR@100: 0.7446
INFO:root:MRR@1000: 0.7448
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 11.09 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.67, 'ndcg_at_3': 0.72792, 'ndcg_at_5': 0.74756, 'ndcg_at_10': 0.77104, 'ndcg_at_100': 0.78919, 'ndcg_at_1000': 0.79451, 'map_at_1': 0.63828, 'map_at_3': 0.70419, 'map_at_5': 0.71791, 'map_at_10': 0.73076, 'map_at_100': 0.73546, 'map_at_1000': 0.73571, 'recall_at_1': 0.63828, 'recall_at_3': 0.76867, 'recall_at_5': 0.81828, 'recall_at_10': 0.88322, 'recall_at_100': 0.96, 'recall_at_1000': 1.0, 'precision_at_1': 0.67, 'precision_at_3': 0.28, 'precision_at_5': 0.18267, 'precision_at_10': 0.10033, 'precision_at_100': 0.0109, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.67, 'mrr_at_3': 0.72167, 'mrr_at_5': 0.733, 'mrr_at_10': 0.74078, 'mrr_at_100': 0.74456, 'mrr_at_1000': 0.74481, 'evaluation_time': 11.09}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [03:17<02:58, 13.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [03:25<05:22, 17.93s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model llmrails$voyage for task EmotionClassification
Loading llmrails from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [11:06<00:00, 18.57s/it]Clustering: 100%|██████████| 31/31 [11:06<00:00, 21.51s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 666.91 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43393011152242345, 'v_measure_std': 0.14193919173266287, 'evaluation_time': 666.91}
Clustering:  52%|█████▏    | 13/25 [03:22<02:13, 11.09s/it]INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [02:32<07:03, 18.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 19.94 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6431237560691526, 'mrr': 0.7721397792727432, 'evaluation_time': 19.94}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [03:39<02:23, 13.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [03:49<05:34, 19.69s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [02:46<06:17, 17.17s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [03:56<02:22, 14.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [03:15<07:20, 20.97s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [04:32<07:07, 26.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [04:25<02:48, 18.69s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [04:37<02:12, 16.56s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 75.95 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.54495, 'f1': 0.48028917905224466, 'accuracy_stderr': 0.02174563174524943, 'f1_stderr': 0.014216099961367542, 'main_score': 0.54495, 'evaluation_time': 75.95}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [04:54<06:21, 25.43s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
Clustering:  35%|███▌      | 11/31 [03:51<08:26, 25.35s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [04:52<01:52, 16.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [05:01<01:23, 13.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [05:08<05:06, 21.91s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [05:16<01:12, 14.41s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [05:24<04:22, 20.23s/it]INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model llmrails$voyage for task AmazonCounterfactualClassification
Loading llmrails from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  39%|███▊      | 12/31 [04:21<08:27, 26.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [05:30<00:56, 14.18s/it]/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [05:40<03:46, 18.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [05:48<00:45, 15.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [04:50<08:14, 27.48s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [05:57<03:20, 18.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [05:58<00:27, 13.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 2.75 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7459701492537314, 'f1': 0.6848485784822265, 'ap': 0.372951359837293, 'accuracy_stderr': 0.03857451064451209, 'f1_stderr': 0.03603024246379233, 'ap_stderr': 0.03791422919222126, 'main_score': 0.7459701492537314}, 'evaluation_time': 2.75}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [06:06<00:12, 12.09s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model llmrails$voyage for task Banking77Classification
Loading llmrails from cache for Banking77Classification...
Loading voyage from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [06:15<03:01, 18.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [06:18<02:01, 13.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [06:31<00:00, 16.09s/it]Clustering: 100%|██████████| 25/25 [06:31<00:00, 15.68s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 391.94 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.6022732820520961, 'v_measure_std': 0.0412957060355128, 'evaluation_time': 391.94}
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [06:42<02:14, 16.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [05:46<10:17, 36.31s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [06:54<01:47, 15.29s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [07:05<01:24, 14.09s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 63.55 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8425974025974027, 'f1': 0.8352965247861668, 'accuracy_stderr': 0.005172027987464915, 'f1_stderr': 0.005668986484755456, 'main_score': 0.8425974025974027, 'evaluation_time': 63.55}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:main:Running task: ArguAna
Clustering:  84%|████████▍ | 26/31 [07:22<01:15, 15.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model llmrails$voyage for task ArguAna
Loading llmrails from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [07:28<00:49, 12.36s/it]INFO:beir.datasets.data_loader:Loading Corpus...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  48%|████▊     | 15/31 [06:23<09:41, 36.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
  0%|          | 0/8674 [00:00<?, ?it/s] 54%|█████▍    | 4672/8674 [00:00<00:00, 46709.02it/s]100%|██████████| 8674/8674 [00:00<00:00, 34279.35it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [07:34<00:30, 10.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [07:39<00:17,  8.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Converting the results to a CSV file...
Using model name flag-embedding$gist$mixed-bread
Converting results/flag-embedding$gist$mixed-bread to results/flag-embedding$gist$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model flag-embedding$gist$voyage...
Skipping STS17 as it already exists
Creating model flag-embedding$gist$voyage for task TwitterSemEval2015
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [07:46<00:08,  8.28s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 17.97 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:root:

INFO:root:NDCG@1: 0.4132
INFO:root:NDCG@3: 0.5684
INFO:root:NDCG@5: 0.6174
INFO:root:NDCG@10: 0.6548
INFO:root:NDCG@100: 0.6737
INFO:root:NDCG@1000: 0.6743
INFO:root:

INFO:root:MAP@1: 0.4132
INFO:root:MAP@3: 0.5299
INFO:root:MAP@5: 0.5571
INFO:root:MAP@10: 0.5727
INFO:root:MAP@100: 0.5776
INFO:root:MAP@1000: 0.5776
INFO:root:

INFO:root:Recall@1: 0.4132
INFO:root:Recall@3: 0.6799
INFO:root:Recall@5: 0.7987
INFO:root:Recall@10: 0.9132
INFO:root:Recall@100: 0.9922
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.4132
INFO:root:P@3: 0.2266
INFO:root:P@5: 0.1597
INFO:root:P@10: 0.0913
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [06:46<08:05, 32.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:root:MRR@1: 0.4203
INFO:root:MRR@3: 0.5331
INFO:root:MRR@5: 0.5593
INFO:root:MRR@10: 0.5753
INFO:root:MRR@100: 0.5802
INFO:root:MRR@1000: 0.5802
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 21.86 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.41323, 'ndcg_at_3': 0.56838, 'ndcg_at_5': 0.61738, 'ndcg_at_10': 0.65475, 'ndcg_at_100': 0.67372, 'ndcg_at_1000': 0.6743, 'map_at_1': 0.41323, 'map_at_3': 0.52987, 'map_at_5': 0.55711, 'map_at_10': 0.57272, 'map_at_100': 0.57761, 'map_at_1000': 0.57763, 'recall_at_1': 0.41323, 'recall_at_3': 0.67994, 'recall_at_5': 0.79872, 'recall_at_10': 0.91323, 'recall_at_100': 0.99218, 'recall_at_1000': 0.99644, 'precision_at_1': 0.41323, 'precision_at_3': 0.22665, 'precision_at_5': 0.15974, 'precision_at_10': 0.09132, 'precision_at_100': 0.00992, 'precision_at_1000': 0.001, 'mrr_at_1': 0.42034, 'mrr_at_3': 0.53307, 'mrr_at_5': 0.55928, 'mrr_at_10': 0.57527, 'mrr_at_100': 0.58015, 'mrr_at_1000': 0.58017, 'evaluation_time': 21.86}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [07:53<00:00,  7.99s/it]Clustering: 100%|██████████| 31/31 [07:53<00:00, 15.29s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 473.95 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43244317628546647, 'v_measure_std': 0.14255791546337324, 'evaluation_time': 473.95}
INFO:main:Running task: ArxivClusteringS2S
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Creating model cohere$flag-embedding$gist for task RedditClustering
Loading cohere from cache for RedditClustering...
Loading flag-embedding from cache for RedditClustering...
Loading gist from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
ERROR:mteb.evaluation.MTEB:Error while evaluating TwitterSemEval2015: Unable to allocate 393. MiB for an array with shape (16777, 3072) and data type float64
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:04<01:39,  4.13s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:08<01:37,  4.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [07:04<06:32, 28.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:18<02:29,  6.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:24<02:18,  6.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:28<01:55,  5.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [07:26<05:39, 26.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [00:34<01:49,  5.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [00:37<01:26,  4.82s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [00:46<01:46,  6.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [07:43<04:41, 23.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Creating model angle$gte-large for task RedditClustering
Loading angle from cache for RedditClustering...
Loading gte-large from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [00:55<01:53,  7.08s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [07:59<03:52, 21.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [01:06<02:03,  8.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Evaluating the model angle$cohere$llmrails$mixed-bread...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model angle$cohere$llmrails$mixed-bread for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading cohere from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [01:14<01:53,  8.13s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [01:16<01:22,  6.33s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [01:19<01:04,  5.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [08:13<03:11, 19.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [08:14<02:04, 13.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [01:26<01:05,  5.91s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [01:29<00:48,  4.81s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [08:29<01:52, 14.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [01:39<00:57,  6.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:01<00:45,  1.90s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [01:44<00:47,  5.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:06<01:17,  3.35s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [01:47<00:36,  5.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [08:41<01:33, 13.34s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:23<03:30,  9.58s/it]Clustering:  76%|███████▌  | 19/25 [02:04<00:52,  8.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [09:03<01:36, 16.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:31<03:10,  9.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:35<02:22,  7.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [09:10<01:06, 13.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [00:39<01:54,  6.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [00:41<01:24,  4.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [02:23<00:59, 11.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [00:46<01:21,  4.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [00:53<01:31,  5.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [09:29<01:00, 15.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [02:38<00:51, 12.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [01:02<01:37,  6.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [01:06<01:21,  5.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [01:07<00:58,  4.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [01:10<00:46,  3.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [09:45<00:46, 15.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [02:53<00:39, 13.22s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [02:56<00:20, 10.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [01:15<00:48,  4.41s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [01:17<00:36,  3.61s/it]INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [03:05<00:09,  9.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Creating model gte-large$llmrails$voyage for task ArxivClusteringS2S
Loading gte-large from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [01:26<00:47,  5.24s/it]INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 9.64 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6457543438625225, 'mrr': 0.7766576529041903, 'evaluation_time': 9.64}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [10:02<00:31, 15.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [01:30<00:38,  4.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [01:31<00:26,  3.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [03:16<00:00, 10.37s/it]Clustering: 100%|██████████| 25/25 [03:16<00:00,  7.88s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 196.89 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.6182554731330415, 'v_measure_std': 0.05103302498739851, 'evaluation_time': 196.89}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [10:11<00:13, 13.84s/it]Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [01:45<00:41,  6.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [01:53<00:35,  7.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [10:28<00:00, 14.74s/it]Clustering: 100%|██████████| 31/31 [10:28<00:00, 20.28s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 628.73 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43297312740432925, 'v_measure_std': 0.14267634632870016, 'evaluation_time': 628.73}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [02:03<00:31,  7.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [02:08<00:21,  7.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [02:09<00:10,  5.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [02:13<00:04,  4.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [02:18<00:00,  5.12s/it]Clustering: 100%|██████████| 25/25 [02:18<00:00,  5.56s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 139.01 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.610302484418323, 'v_measure_std': 0.045126450475529115, 'evaluation_time': 139.01}
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Converting the results to a CSV file...
Using model name cohere$flag-embedding$gist
Converting results/cohere$flag-embedding$gist to results/cohere$flag-embedding$gist_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$flag-embedding$gte-large...
Skipping STS17 as it already exists
Creating model cohere$flag-embedding$gte-large for task TwitterSemEval2015
Loading cohere from cache for TwitterSemEval2015...
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gte-large from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 12.33 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8729808666626929, 'accuracy_threshold': 0.8174706563748915, 'f1': 0.7063883617963315, 'f1_threshold': 0.7943064982460346, 'precision': 0.6784933171324423, 'recall': 0.7366754617414248, 'ap': 0.7745534993858528}, 'manhattan': {'accuracy': 0.87369613160875, 'accuracy_threshold': 25.071901363766568, 'f1': 0.7114077369917192, 'f1_threshold': 26.62083282222996, 'precision': 0.6691467100674262, 'recall': 0.7593667546174142, 'ap': 0.7791598972712296}, 'euclidean': {'accuracy': 0.8729808666626929, 'accuracy_threshold': 0.6042008665819399, 'f1': 0.7063883617963315, 'f1_threshold': 0.6413945767165214, 'precision': 0.6784933171324423, 'recall': 0.7366754617414248, 'ap': 0.7745534993858528}, 'dot': {'accuracy': 0.8729808666626929, 'accuracy_threshold': 0.8174706563748919, 'f1': 0.7063883617963315, 'f1_threshold': 0.7943064982460355, 'precision': 0.6784933171324423, 'recall': 0.7366754617414248, 'ap': 0.7745534993858528}, 'max': {'accuracy': 0.87369613160875, 'f1': 0.7114077369917192, 'ap': 0.7791598972712296}, 'evaluation_time': 12.33}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [01:41<50:39, 101.33s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [01:52<23:16, 48.15s/it] INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model cohere$flag-embedding$gte-large for task AskUbuntuDupQuestions
Loading cohere from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading gte-large from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Converting the results to a CSV file...
Using model name angle$gte-large
Converting results/angle$gte-large to results/angle$gte-large_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$llmrails...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$llmrails
Converting results/angle$llmrails to results/angle$llmrails_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$mixed-bread...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$mixed-bread
Converting results/angle$mixed-bread to results/angle$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model angle$voyage for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [02:40<22:28, 48.17s/it]INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 2.22 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6459568120753706, 'mrr': 0.7800993712351052, 'evaluation_time': 2.22}
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 4.80 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6295844302981927, 'mrr': 0.7520863562414809, 'evaluation_time': 4.8}
INFO:main:Running task: SciFact
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [02:56<15:59, 35.53s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$voyage for task SciFact
Loading angle from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s]  0%|          | 1/5183 [00:00<10:02,  8.60it/s]  0%|          | 22/5183 [00:00<00:47, 109.47it/s]  5%|▌         | 272/5183 [00:00<00:04, 1008.45it/s] 10%|▉         | 499/5183 [00:00<00:03, 1383.69it/s] 33%|███▎      | 1734/5183 [00:00<00:00, 4935.40it/s] 90%|█████████ | 4673/5183 [00:00<00:00, 11239.57it/s]INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gte-large for task SciFact
Loading cohere from cache for SciFact...
Loading flag-embedding from cache for SciFact...
Loading gte-large from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
100%|██████████| 5183/5183 [00:00<00:00, 5837.82it/s] 
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
  0%|          | 0/5183 [00:00<?, ?it/s]  5%|▌         | 272/5183 [00:00<00:02, 2338.08it/s] 30%|███       | 1573/5183 [00:00<00:00, 8218.74it/s] 48%|████▊     | 2488/5183 [00:00<00:00, 8367.23it/s] 72%|███████▏  | 3740/5183 [00:00<00:00, 9333.00it/s] 96%|█████████▋| 5001/5183 [00:00<00:00, 9967.59it/s]100%|██████████| 5183/5183 [00:00<00:00, 9206.25it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [03:11<12:13, 28.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 10.55 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 11.88 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.6467
INFO:root:NDCG@3: 0.7173
INFO:root:NDCG@5: 0.7344
INFO:root:NDCG@10: 0.7616
INFO:root:NDCG@100: 0.7774
INFO:root:NDCG@1000: 0.7826
INFO:root:

INFO:root:MAP@1: 0.6159
INFO:root:MAP@3: 0.6897
INFO:root:MAP@5: 0.7017
INFO:root:MAP@10: 0.7159
INFO:root:MAP@100: 0.7198
INFO:root:MAP@1000: 0.7200
INFO:root:

INFO:root:Recall@1: 0.6159
INFO:root:Recall@3: 0.7703
INFO:root:Recall@5: 0.8149
INFO:root:Recall@10: 0.8916
INFO:root:Recall@100: 0.9617
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6467
INFO:root:P@3: 0.2811
INFO:root:P@5: 0.1813
INFO:root:P@10: 0.1010
INFO:root:P@100: 0.0109
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:

INFO:root:NDCG@1: 0.6333
INFO:root:NDCG@3: 0.6875
INFO:root:NDCG@5: 0.7262
INFO:root:NDCG@10: 0.7429
INFO:root:NDCG@100: 0.7660
INFO:root:NDCG@1000: 0.7703
INFO:root:

INFO:root:MAP@1: 0.6043
INFO:root:MAP@3: 0.6657
INFO:root:MAP@5: 0.6910
INFO:root:MAP@10: 0.6992
INFO:root:MAP@100: 0.7052
INFO:root:MAP@1000: 0.7055
INFO:root:

INFO:root:Recall@1: 0.6043
INFO:root:Recall@3: 0.7214
INFO:root:Recall@5: 0.8196
INFO:root:Recall@10: 0.8676
INFO:root:Recall@100: 0.9683
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6333
INFO:root:P@3: 0.2667
INFO:root:P@5: 0.1833
INFO:root:P@10: 0.0983
INFO:root:P@100: 0.0110
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6467
INFO:root:MRR@3: 0.7067
INFO:root:MRR@5: 0.7162
INFO:root:MRR@10: 0.7256
INFO:root:MRR@100: 0.7283
INFO:root:MRR@1000: 0.7285
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 12.36 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.64667, 'ndcg_at_3': 0.71728, 'ndcg_at_5': 0.73439, 'ndcg_at_10': 0.76156, 'ndcg_at_100': 0.77736, 'ndcg_at_1000': 0.78264, 'map_at_1': 0.61594, 'map_at_3': 0.68969, 'map_at_5': 0.70174, 'map_at_10': 0.71591, 'map_at_100': 0.71978, 'map_at_1000': 0.72005, 'recall_at_1': 0.61594, 'recall_at_3': 0.77033, 'recall_at_5': 0.81494, 'recall_at_10': 0.89156, 'recall_at_100': 0.96167, 'recall_at_1000': 1.0, 'precision_at_1': 0.64667, 'precision_at_3': 0.28111, 'precision_at_5': 0.18133, 'precision_at_10': 0.101, 'precision_at_100': 0.0109, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.64667, 'mrr_at_3': 0.70667, 'mrr_at_5': 0.71617, 'mrr_at_10': 0.72556, 'mrr_at_100': 0.72827, 'mrr_at_1000': 0.72851, 'evaluation_time': 12.36}
INFO:root:MRR@1: 0.6333
INFO:root:MRR@3: 0.6811
INFO:root:MRR@5: 0.7021
INFO:root:MRR@10: 0.7078
INFO:root:MRR@100: 0.7124
INFO:root:MRR@1000: 0.7125
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 11.13 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.63333, 'ndcg_at_3': 0.68749, 'ndcg_at_5': 0.72625, 'ndcg_at_10': 0.74288, 'ndcg_at_100': 0.76599, 'ndcg_at_1000': 0.77031, 'map_at_1': 0.60428, 'map_at_3': 0.66574, 'map_at_5': 0.69096, 'map_at_10': 0.69922, 'map_at_100': 0.70524, 'map_at_1000': 0.70545, 'recall_at_1': 0.60428, 'recall_at_3': 0.72139, 'recall_at_5': 0.81956, 'recall_at_10': 0.86756, 'recall_at_100': 0.96833, 'recall_at_1000': 1.0, 'precision_at_1': 0.63333, 'precision_at_3': 0.26667, 'precision_at_5': 0.18333, 'precision_at_10': 0.09833, 'precision_at_100': 0.01097, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.63333, 'mrr_at_3': 0.68111, 'mrr_at_5': 0.70211, 'mrr_at_10': 0.70781, 'mrr_at_100': 0.71235, 'mrr_at_1000': 0.71254, 'evaluation_time': 11.13}
INFO:main:Running task: EmotionClassification
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [03:22<09:12, 22.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Creating model angle$voyage for task ArguAna
Loading angle from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s] 43%|████▎     | 3718/8674 [00:00<00:00, 37170.73it/s]100%|██████████| 8674/8674 [00:00<00:00, 44556.54it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gte-large for task EmotionClassification
Loading cohere from cache for EmotionClassification...
Loading flag-embedding from cache for EmotionClassification...
Loading gte-large from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [03:32<07:18, 18.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 10.43 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.4218
INFO:root:NDCG@3: 0.5831
INFO:root:NDCG@5: 0.6265
INFO:root:NDCG@10: 0.6618
INFO:root:NDCG@100: 0.6814
INFO:root:NDCG@1000: 0.6818
INFO:root:

INFO:root:MAP@1: 0.4218
INFO:root:MAP@3: 0.5427
INFO:root:MAP@5: 0.5669
INFO:root:MAP@10: 0.5818
INFO:root:MAP@100: 0.5869
INFO:root:MAP@1000: 0.5870
INFO:root:

INFO:root:Recall@1: 0.4218
INFO:root:Recall@3: 0.7006
INFO:root:Recall@5: 0.8051
INFO:root:Recall@10: 0.9125
INFO:root:Recall@100: 0.9936
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.4218
INFO:root:P@3: 0.2335
INFO:root:P@5: 0.1610
INFO:root:P@10: 0.0912
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:root:MRR@1: 0.4274
INFO:root:MRR@3: 0.5453
INFO:root:MRR@5: 0.5691
INFO:root:MRR@10: 0.5841
INFO:root:MRR@100: 0.5891
INFO:root:MRR@1000: 0.5891
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 15.23 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.42176, 'ndcg_at_3': 0.58314, 'ndcg_at_5': 0.62652, 'ndcg_at_10': 0.66183, 'ndcg_at_100': 0.68142, 'ndcg_at_1000': 0.68181, 'map_at_1': 0.42176, 'map_at_3': 0.54267, 'map_at_5': 0.56693, 'map_at_10': 0.58184, 'map_at_100': 0.58694, 'map_at_1000': 0.58696, 'recall_at_1': 0.42176, 'recall_at_3': 0.70057, 'recall_at_5': 0.80512, 'recall_at_10': 0.91252, 'recall_at_100': 0.9936, 'recall_at_1000': 0.99644, 'precision_at_1': 0.42176, 'precision_at_3': 0.23352, 'precision_at_5': 0.16102, 'precision_at_10': 0.09125, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.42745, 'mrr_at_3': 0.54528, 'mrr_at_5': 0.56907, 'mrr_at_10': 0.58412, 'mrr_at_100': 0.58909, 'mrr_at_1000': 0.5891, 'evaluation_time': 15.23}
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [03:53<07:17, 19.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 34.14 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5465, 'f1': 0.4860175854264502, 'accuracy_stderr': 0.022777181564012698, 'f1_stderr': 0.014248553647267738, 'main_score': 0.5465, 'evaluation_time': 34.14}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [04:10<06:47, 18.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model cohere$flag-embedding$gte-large for task AmazonCounterfactualClassification
Loading cohere from cache for AmazonCounterfactualClassification...
Loading flag-embedding from cache for AmazonCounterfactualClassification...
Loading gte-large from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [04:21<05:38, 16.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [04:55<07:12, 21.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [05:34<08:31, 26.95s/it]INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 12.26 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.792089552238806, 'f1': 0.734277058521941, 'ap': 0.4361994372631738, 'accuracy_stderr': 0.03595156515030346, 'f1_stderr': 0.03526356490033567, 'ap_stderr': 0.04486881946591926, 'main_score': 0.792089552238806}, 'evaluation_time': 12.26}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gte-large for task Banking77Classification
Loading cohere from cache for Banking77Classification...
Loading flag-embedding from cache for Banking77Classification...
Loading gte-large from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [06:01<08:07, 27.06s/it]INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [06:30<07:48, 27.54s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 61.93 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8322077922077922, 'f1': 0.825962349832342, 'accuracy_stderr': 0.006602654111969948, 'f1_stderr': 0.007230304500997852, 'main_score': 0.8322077922077922, 'evaluation_time': 61.93}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [07:08<08:13, 30.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model llmrails$voyage for task ArxivClusteringS2S
Loading llmrails from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gte-large for task ArguAna
Loading cohere from cache for ArguAna...
Loading flag-embedding from cache for ArguAna...
Loading gte-large from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s]  5%|▌         | 467/8674 [00:00<00:02, 3823.01it/s] 55%|█████▌    | 4811/8674 [00:00<00:00, 25174.45it/s]100%|██████████| 8674/8674 [00:00<00:00, 28864.32it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [07:28<06:49, 27.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:08<04:19,  8.66s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:   6%|▋         | 2/31 [00:16<03:55,  8.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [07:46<05:46, 24.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:33<05:44, 12.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [08:15<05:35, 25.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [00:57<07:37, 16.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [01:24<08:56, 20.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [01:32<06:44, 16.17s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [08:55<06:01, 30.16s/it]INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 99.72 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:root:

INFO:root:NDCG@1: 0.3044
INFO:root:NDCG@3: 0.4652
INFO:root:NDCG@5: 0.5172
INFO:root:NDCG@10: 0.5668
INFO:root:NDCG@100: 0.5965
INFO:root:NDCG@1000: 0.5975
INFO:root:

INFO:root:MAP@1: 0.3044
INFO:root:MAP@3: 0.4244
INFO:root:MAP@5: 0.4532
INFO:root:MAP@10: 0.4737
INFO:root:MAP@100: 0.4810
INFO:root:MAP@1000: 0.4811
INFO:root:

INFO:root:Recall@1: 0.3044
INFO:root:Recall@3: 0.5839
INFO:root:Recall@5: 0.7105
INFO:root:Recall@10: 0.8634
INFO:root:Recall@100: 0.9893
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.3044
INFO:root:P@3: 0.1946
INFO:root:P@5: 0.1421
INFO:root:P@10: 0.0863
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:root:MRR@1: 0.3101
INFO:root:MRR@3: 0.4260
INFO:root:MRR@5: 0.4553
INFO:root:MRR@10: 0.4759
INFO:root:MRR@100: 0.4832
INFO:root:MRR@1000: 0.4833
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 102.36 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.30441, 'ndcg_at_3': 0.46521, 'ndcg_at_5': 0.51724, 'ndcg_at_10': 0.56685, 'ndcg_at_100': 0.59654, 'ndcg_at_1000': 0.59752, 'map_at_1': 0.30441, 'map_at_3': 0.42437, 'map_at_5': 0.45318, 'map_at_10': 0.47374, 'map_at_100': 0.48105, 'map_at_1000': 0.4811, 'recall_at_1': 0.30441, 'recall_at_3': 0.58393, 'recall_at_5': 0.71053, 'recall_at_10': 0.86344, 'recall_at_100': 0.98933, 'recall_at_1000': 0.99644, 'precision_at_1': 0.30441, 'precision_at_3': 0.19464, 'precision_at_5': 0.14211, 'precision_at_10': 0.08634, 'precision_at_100': 0.00989, 'precision_at_1000': 0.001, 'mrr_at_1': 0.3101, 'mrr_at_3': 0.42603, 'mrr_at_5': 0.45526, 'mrr_at_10': 0.47592, 'mrr_at_100': 0.48323, 'mrr_at_1000': 0.48328, 'evaluation_time': 102.36}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [01:37<05:03, 12.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [01:42<03:55, 10.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [09:14<04:53, 26.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [02:01<04:42, 12.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  68%|██████▊   | 21/31 [09:34<04:08, 24.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [02:14<04:29, 12.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [09:44<03:03, 20.40s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [02:31<04:42, 14.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [10:05<02:43, 20.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [02:44<04:24, 13.91s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [10:15<02:01, 17.40s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [02:55<03:52, 12.94s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model flag-embedding$mixed-bread$voyage for task ArxivClusteringS2S
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [03:07<03:33, 12.54s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [10:29<01:39, 16.53s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [10:41<01:15, 15.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [03:27<03:59, 14.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  84%|████████▍ | 26/31 [10:53<02:05, 25.14s/it]
ERROR:mteb.evaluation.MTEB:Error while evaluating ArxivClusteringS2S: Unable to allocate 586. MiB for an array with shape (25000, 3072) and data type float64
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:09<04:43,  9.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [03:41<03:37, 14.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:19<04:50, 10.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [03:52<03:09, 13.53s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:30<04:44, 10.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [04:03<02:45, 12.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [00:48<05:56, 13.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [04:17<02:38, 13.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [00:58<05:17, 12.22s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [04:28<02:18, 12.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [04:42<02:09, 12.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [04:43<01:24,  9.37s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  19%|█▉        | 6/31 [01:14<05:36, 13.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [04:51<01:12,  9.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [01:24<04:58, 12.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [04:58<00:57,  8.25s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Creating model angle$voyage for task RedditClustering
Loading angle from cache for RedditClustering...
Loading voyage from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [01:35<04:32, 11.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [05:05<00:47,  7.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [05:07<00:30,  6.16s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:01<00:44,  1.87s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:05<01:10,  3.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [01:46<04:13, 11.54s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [05:16<00:27,  6.93s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:13<01:54,  5.19s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [05:22<00:20,  6.90s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [01:55<03:48, 10.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:18<01:45,  5.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:21<01:28,  4.43s/it]Clustering:  94%|█████████▎| 29/31 [05:30<00:14,  7.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [05:36<00:06,  6.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [00:28<01:40,  5.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [00:31<01:22,  4.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [05:48<00:00,  8.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [02:19<04:54, 14.73s/it]Clustering: 100%|██████████| 31/31 [05:48<00:00, 11.26s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 348.98 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4284638300020989, 'v_measure_std': 0.14110921136453858, 'evaluation_time': 348.98}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [00:40<01:42,  6.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  35%|███▌      | 11/31 [02:28<04:29, 13.46s/it]
ERROR:mteb.evaluation.MTEB:Error while evaluating ArxivClusteringS2S: Unable to allocate 586. MiB for an array with shape (25000, 3072) and data type float64
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [00:50<01:52,  7.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [00:57<01:45,  7.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [01:02<01:30,  6.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [01:03<01:03,  4.87s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [01:05<00:48,  4.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [01:10<00:46,  4.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [01:11<00:34,  3.41s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [01:18<00:38,  4.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [01:21<00:32,  4.08s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [01:24<00:25,  3.69s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [01:29<00:25,  4.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [01:42<00:34,  6.81s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [01:49<00:27,  6.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [01:55<00:19,  6.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [01:56<00:09,  4.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [02:02<00:05,  5.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [02:08<00:00,  5.34s/it]Clustering: 100%|██████████| 25/25 [02:08<00:00,  5.13s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 128.14 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.6131960867811137, 'v_measure_std': 0.04341136973525503, 'evaluation_time': 128.14}
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Creating model llmrails$voyage for task RedditClustering
Loading llmrails from cache for RedditClustering...
Loading voyage from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:01<00:47,  1.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:05<01:07,  2.93s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:12<01:45,  4.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:16<01:34,  4.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:19<01:16,  3.82s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [00:23<01:18,  4.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [00:25<01:02,  3.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [00:31<01:10,  4.17s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [00:38<01:17,  4.87s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Converting the results to a CSV file...
Using model name angle$voyage
Converting results/angle$voyage to results/angle$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$flag-embedding...
Skipping STS17 as it already exists
Creating model cohere$flag-embedding for task TwitterSemEval2015
Loading cohere from cache for TwitterSemEval2015...
Loading flag-embedding from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [00:52<01:56,  7.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [01:01<01:56,  8.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [01:06<01:34,  7.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [01:09<01:09,  5.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [01:14<01:03,  5.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [01:16<00:45,  4.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [01:23<00:46,  5.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 9.10 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8755438993860643, 'accuracy_threshold': 0.7830729544897748, 'f1': 0.7118233234581202, 'f1_threshold': 0.7746036747436671, 'precision': 0.726897689768977, 'recall': 0.6973614775725594, 'ap': 0.785365263254808}, 'manhattan': {'accuracy': 0.8762591643321214, 'accuracy_threshold': 23.060955366532276, 'f1': 0.714997378080755, 'f1_threshold': 24.186523334675766, 'precision': 0.7105263157894737, 'recall': 0.7195250659630607, 'ap': 0.7869452612093851}, 'euclidean': {'accuracy': 0.8755438993860643, 'accuracy_threshold': 0.6586760135675969, 'f1': 0.7118233234581202, 'f1_threshold': 0.6714109398234096, 'precision': 0.726897689768977, 'recall': 0.6973614775725594, 'ap': 0.785365263254808}, 'dot': {'accuracy': 0.8755438993860643, 'accuracy_threshold': 0.7830729544897752, 'f1': 0.7118233234581202, 'f1_threshold': 0.7746036747436678, 'precision': 0.726897689768977, 'recall': 0.6973614775725594, 'ap': 0.785365263254808}, 'max': {'accuracy': 0.8762591643321214, 'f1': 0.714997378080755, 'ap': 0.7869452612093851}, 'evaluation_time': 9.1}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [01:26<00:37,  4.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [01:28<00:26,  3.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model cohere$flag-embedding for task AskUbuntuDupQuestions
Loading cohere from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [01:32<00:22,  3.81s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [01:39<00:24,  4.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 6.26 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6343297479330053, 'mrr': 0.7541946972694894, 'evaluation_time': 6.26}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [01:47<00:22,  5.71s/it]INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [02:04<00:27,  9.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [02:05<00:13,  6.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding for task SciFact
Loading cohere from cache for SciFact...
Loading flag-embedding from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [02:09<00:05,  5.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
  0%|          | 0/5183 [00:00<?, ?it/s] 60%|█████▉    | 3098/5183 [00:00<00:00, 30967.70it/s]100%|██████████| 5183/5183 [00:00<00:00, 35813.91it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [02:17<00:00,  6.66s/it]Clustering: 100%|██████████| 25/25 [02:17<00:00,  5.52s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 137.90 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.5983063910204365, 'v_measure_std': 0.04324366136438714, 'evaluation_time': 137.9}
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 28.53 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.6367
INFO:root:NDCG@3: 0.6888
INFO:root:NDCG@5: 0.7231
INFO:root:NDCG@10: 0.7477
INFO:root:NDCG@100: 0.7687
INFO:root:NDCG@1000: 0.7716
INFO:root:

INFO:root:MAP@1: 0.6093
INFO:root:MAP@3: 0.6677
INFO:root:MAP@5: 0.6905
INFO:root:MAP@10: 0.7025
INFO:root:MAP@100: 0.7071
INFO:root:MAP@1000: 0.7073
INFO:root:

INFO:root:Recall@1: 0.6093
INFO:root:Recall@3: 0.7214
INFO:root:Recall@5: 0.8086
INFO:root:Recall@10: 0.8799
INFO:root:Recall@100: 0.9783
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6367
INFO:root:P@3: 0.2667
INFO:root:P@5: 0.1813
INFO:root:P@10: 0.1000
INFO:root:P@100: 0.0111
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6367
INFO:root:MRR@3: 0.6822
INFO:root:MRR@5: 0.7012
INFO:root:MRR@10: 0.7097
INFO:root:MRR@100: 0.7135
INFO:root:MRR@1000: 0.7137
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 29.78 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.63667, 'ndcg_at_3': 0.68876, 'ndcg_at_5': 0.72312, 'ndcg_at_10': 0.74765, 'ndcg_at_100': 0.76867, 'ndcg_at_1000': 0.77157, 'map_at_1': 0.60928, 'map_at_3': 0.66769, 'map_at_5': 0.69052, 'map_at_10': 0.70248, 'map_at_100': 0.70714, 'map_at_1000': 0.70727, 'recall_at_1': 0.60928, 'recall_at_3': 0.72139, 'recall_at_5': 0.80856, 'recall_at_10': 0.87989, 'recall_at_100': 0.97833, 'recall_at_1000': 1.0, 'precision_at_1': 0.63667, 'precision_at_3': 0.26667, 'precision_at_5': 0.18133, 'precision_at_10': 0.1, 'precision_at_100': 0.01107, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.63667, 'mrr_at_3': 0.68222, 'mrr_at_5': 0.70122, 'mrr_at_10': 0.70975, 'mrr_at_100': 0.71354, 'mrr_at_1000': 0.71365, 'evaluation_time': 29.78}
INFO:main:Running task: EmotionClassification
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding for task EmotionClassification
Loading cohere from cache for EmotionClassification...
Loading flag-embedding from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Converting the results to a CSV file...
Using model name llmrails$voyage
Converting results/llmrails$voyage to results/llmrails$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model mixed-bread$voyage...
Skipping STS17 as it already exists
Creating model mixed-bread$voyage for task TwitterSemEval2015
Loading mixed-bread from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 10.97 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8731596828992072, 'accuracy_threshold': 0.8597895885855689, 'f1': 0.7079028925619835, 'f1_threshold': 0.8453345637762872, 'precision': 0.6932220536165908, 'recall': 0.7232189973614775, 'ap': 0.7784050915909814}, 'manhattan': {'accuracy': 0.8716099421827502, 'accuracy_threshold': 18.93850979153713, 'f1': 0.7028880390346829, 'f1_threshold': 19.611365119029404, 'precision': 0.7026100711837595, 'recall': 0.7031662269129287, 'ap': 0.7743460741316711}, 'euclidean': {'accuracy': 0.8731596828992072, 'accuracy_threshold': 0.5295477511165865, 'f1': 0.7079028925619835, 'f1_threshold': 0.5561752173574515, 'precision': 0.6932220536165908, 'recall': 0.7232189973614775, 'ap': 0.7784050915909814}, 'dot': {'accuracy': 0.8731596828992072, 'accuracy_threshold': 0.859789588585569, 'f1': 0.7079028925619835, 'f1_threshold': 0.8453345637762872, 'precision': 0.6932220536165908, 'recall': 0.7232189973614775, 'ap': 0.7784050915909814}, 'max': {'accuracy': 0.8731596828992072, 'f1': 0.7079028925619835, 'ap': 0.7784050915909814}, 'evaluation_time': 10.97}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model mixed-bread$voyage for task AskUbuntuDupQuestions
Loading mixed-bread from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 34.32 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.55115, 'f1': 0.49105498740843495, 'accuracy_stderr': 0.02370975537621593, 'f1_stderr': 0.013846771453206846, 'main_score': 0.55115, 'evaluation_time': 34.32}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model cohere$flag-embedding for task AmazonCounterfactualClassification
Loading cohere from cache for AmazonCounterfactualClassification...
Loading flag-embedding from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 6.33 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.643976484406209, 'mrr': 0.7809281976872005, 'evaluation_time': 6.33}
INFO:main:Running task: SciFact
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model mixed-bread$voyage for task SciFact
Loading mixed-bread from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s] 95%|█████████▌| 4933/5183 [00:00<00:00, 49323.34it/s]100%|██████████| 5183/5183 [00:00<00:00, 49236.35it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 2.30 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7877611940298508, 'f1': 0.7299469663331373, 'ap': 0.43046812520841266, 'accuracy_stderr': 0.03515424434577406, 'f1_stderr': 0.034122672411453926, 'ap_stderr': 0.04255447048703795, 'main_score': 0.7877611940298508}, 'evaluation_time': 2.3}
INFO:main:Running task: Banking77Classification
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 6.45 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.6400
INFO:root:NDCG@3: 0.7134
INFO:root:NDCG@5: 0.7320
INFO:root:NDCG@10: 0.7563
INFO:root:NDCG@100: 0.7752
INFO:root:NDCG@1000: 0.7800
INFO:root:

INFO:root:MAP@1: 0.6109
INFO:root:MAP@3: 0.6855
INFO:root:MAP@5: 0.6986
INFO:root:MAP@10: 0.7117
INFO:root:MAP@100: 0.7164
INFO:root:MAP@1000: 0.7166
INFO:root:

INFO:root:Recall@1: 0.6109
INFO:root:Recall@3: 0.7670
INFO:root:Recall@5: 0.8149
INFO:root:Recall@10: 0.8816
INFO:root:Recall@100: 0.9650
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6400
INFO:root:P@3: 0.2800
INFO:root:P@5: 0.1813
INFO:root:P@10: 0.1000
INFO:root:P@100: 0.0109
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6400
INFO:root:MRR@3: 0.7022
INFO:root:MRR@5: 0.7127
INFO:root:MRR@10: 0.7211
INFO:root:MRR@100: 0.7246
INFO:root:MRR@1000: 0.7248
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 7.08 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.64, 'ndcg_at_3': 0.71336, 'ndcg_at_5': 0.73205, 'ndcg_at_10': 0.75627, 'ndcg_at_100': 0.77515, 'ndcg_at_1000': 0.77995, 'map_at_1': 0.61094, 'map_at_3': 0.68552, 'map_at_5': 0.69858, 'map_at_10': 0.71171, 'map_at_100': 0.7164, 'map_at_1000': 0.71664, 'recall_at_1': 0.61094, 'recall_at_3': 0.767, 'recall_at_5': 0.81494, 'recall_at_10': 0.88156, 'recall_at_100': 0.965, 'recall_at_1000': 1.0, 'precision_at_1': 0.64, 'precision_at_3': 0.28, 'precision_at_5': 0.18133, 'precision_at_10': 0.1, 'precision_at_100': 0.01093, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.64, 'mrr_at_3': 0.70222, 'mrr_at_5': 0.71272, 'mrr_at_10': 0.72107, 'mrr_at_100': 0.72457, 'mrr_at_1000': 0.72478, 'evaluation_time': 7.08}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding for task Banking77Classification
Loading cohere from cache for Banking77Classification...
Loading flag-embedding from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model mixed-bread$voyage for task EmotionClassification
Loading mixed-bread from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Creating model angle$cohere$flag-embedding$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Evaluating the model angle$flag-embedding$gte-large$mixed-bread...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Creating model angle$flag-embedding$gte-large$mixed-bread for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 47.92 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.53905, 'f1': 0.4709805069368346, 'accuracy_stderr': 0.02210141398191528, 'f1_stderr': 0.01290870563337623, 'main_score': 0.53905, 'evaluation_time': 47.92}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model mixed-bread$voyage for task AmazonCounterfactualClassification
Loading mixed-bread from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 61.02 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8427272727272725, 'f1': 0.8373012140418629, 'accuracy_stderr': 0.005755459689911779, 'f1_stderr': 0.006417924508954521, 'main_score': 0.8427272727272725, 'evaluation_time': 61.02}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:56<28:25, 56.84s/it]INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [01:13<16:03, 33.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding for task ArguAna
Loading cohere from cache for ArguAna...
Loading flag-embedding from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
  0%|          | 0/8674 [00:00<?, ?it/s]INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
 16%|█▋        | 1413/8674 [00:00<00:00, 13845.82it/s]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
 32%|███▏      | 2798/8674 [00:00<00:00, 11806.03it/s]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
 75%|███████▌  | 6526/8674 [00:00<00:00, 22383.81it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
100%|██████████| 8674/8674 [00:00<00:00, 21463.25it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 2.40 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7279104477611941, 'f1': 0.6669476298727156, 'ap': 0.35335877116367725, 'accuracy_stderr': 0.038140388571242134, 'f1_stderr': 0.035605252840773274, 'ap_stderr': 0.03569577081875606, 'main_score': 0.7279104477611941}, 'evaluation_time': 2.4}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Creating model angle$cohere$llmrails$mixed-bread for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading cohere from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Creating model mixed-bread$voyage for task Banking77Classification
Loading mixed-bread from cache for Banking77Classification...
Loading voyage from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
Clustering:  10%|▉         | 3/31 [01:28<11:35, 24.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 22.46 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:24<12:20, 24.70s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:root:

INFO:root:NDCG@1: 0.3386
INFO:root:NDCG@3: 0.5053
INFO:root:NDCG@5: 0.5535
INFO:root:NDCG@10: 0.5963
INFO:root:NDCG@100: 0.6236
INFO:root:NDCG@1000: 0.6243
INFO:root:

INFO:root:MAP@1: 0.3386
INFO:root:MAP@3: 0.4632
INFO:root:MAP@5: 0.4899
INFO:root:MAP@10: 0.5079
INFO:root:MAP@100: 0.5147
INFO:root:MAP@1000: 0.5147
INFO:root:

INFO:root:Recall@1: 0.3386
INFO:root:Recall@3: 0.6273
INFO:root:Recall@5: 0.7447
INFO:root:Recall@10: 0.8755
INFO:root:Recall@100: 0.9908
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.3386
INFO:root:P@3: 0.2091
INFO:root:P@5: 0.1489
INFO:root:P@10: 0.0876
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.3421
INFO:root:MRR@3: 0.4646
INFO:root:MRR@5: 0.4916
INFO:root:MRR@10: 0.5098
INFO:root:MRR@100: 0.5166
INFO:root:MRR@1000: 0.5166
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 27.88 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.33855, 'ndcg_at_3': 0.50528, 'ndcg_at_5': 0.55348, 'ndcg_at_10': 0.59633, 'ndcg_at_100': 0.62358, 'ndcg_at_1000': 0.62435, 'map_at_1': 0.33855, 'map_at_3': 0.46325, 'map_at_5': 0.48992, 'map_at_10': 0.50791, 'map_at_100': 0.51467, 'map_at_1000': 0.51471, 'recall_at_1': 0.33855, 'recall_at_3': 0.62731, 'recall_at_5': 0.74467, 'recall_at_10': 0.87553, 'recall_at_100': 0.99075, 'recall_at_1000': 0.99644, 'precision_at_1': 0.33855, 'precision_at_3': 0.2091, 'precision_at_5': 0.14893, 'precision_at_10': 0.08755, 'precision_at_100': 0.00991, 'precision_at_1000': 0.001, 'mrr_at_1': 0.34211, 'mrr_at_3': 0.46456, 'mrr_at_5': 0.49158, 'mrr_at_10': 0.50981, 'mrr_at_100': 0.51658, 'mrr_at_1000': 0.51662, 'evaluation_time': 27.88}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:58<12:12, 27.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:46<23:25, 46.85s/it]INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 49.49 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8415909090909091, 'f1': 0.8343564975357459, 'accuracy_stderr': 0.005339798763519053, 'f1_stderr': 0.006157367866247257, 'main_score': 0.8415909090909091, 'evaluation_time': 49.49}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:58<14:38, 30.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [02:23<11:22, 26.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [01:12<10:33, 22.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [01:11<16:11, 33.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [02:41<09:46, 23.46s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:27<08:50, 19.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [01:25<11:30, 24.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model mixed-bread$voyage for task ArguAna
Loading mixed-bread from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s] 54%|█████▎    | 4650/8674 [00:00<00:00, 46483.31it/s]100%|██████████| 8674/8674 [00:00<00:00, 42638.26it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
Evaluating the model angle$gist$llmrails$mixed-bread...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Creating model angle$gist$llmrails$mixed-bread for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [01:45<08:11, 18.89s/it]Clustering:  23%|██▎       | 7/31 [03:07<09:43, 24.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:39<09:17, 20.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [02:03<07:46, 18.67s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [01:57<08:34, 19.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [03:30<09:09, 23.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [02:13<06:21, 15.90s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [02:11<07:20, 17.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 45.76 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:root:

INFO:root:NDCG@1: 0.4168
INFO:root:NDCG@3: 0.5795
INFO:root:NDCG@5: 0.6245
INFO:root:NDCG@10: 0.6612
INFO:root:NDCG@100: 0.6795
INFO:root:NDCG@1000: 0.6798
INFO:root:

INFO:root:MAP@1: 0.4168
INFO:root:MAP@3: 0.5388
INFO:root:MAP@5: 0.5638
INFO:root:MAP@10: 0.5793
INFO:root:MAP@100: 0.5840
INFO:root:MAP@1000: 0.5840
INFO:root:

INFO:root:Recall@1: 0.4168
INFO:root:Recall@3: 0.6977
INFO:root:Recall@5: 0.8065
INFO:root:Recall@10: 0.9182
INFO:root:Recall@100: 0.9943
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.4168
INFO:root:P@3: 0.2326
INFO:root:P@5: 0.1613
INFO:root:P@10: 0.0918
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [02:23<05:20, 13.93s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:root:MRR@1: 0.4274
INFO:root:MRR@3: 0.5424
INFO:root:MRR@5: 0.5675
INFO:root:MRR@10: 0.5831
INFO:root:MRR@100: 0.5879
INFO:root:MRR@1000: 0.5879
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 49.13 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.41679, 'ndcg_at_3': 0.57951, 'ndcg_at_5': 0.62451, 'ndcg_at_10': 0.66115, 'ndcg_at_100': 0.67949, 'ndcg_at_1000': 0.67978, 'map_at_1': 0.41679, 'map_at_3': 0.53876, 'map_at_5': 0.56383, 'map_at_10': 0.57927, 'map_at_100': 0.58404, 'map_at_1000': 0.58405, 'recall_at_1': 0.41679, 'recall_at_3': 0.69772, 'recall_at_5': 0.80654, 'recall_at_10': 0.91821, 'recall_at_100': 0.99431, 'recall_at_1000': 0.99644, 'precision_at_1': 0.41679, 'precision_at_3': 0.23257, 'precision_at_5': 0.16131, 'precision_at_10': 0.09182, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.42745, 'mrr_at_3': 0.54244, 'mrr_at_5': 0.56754, 'mrr_at_10': 0.58311, 'mrr_at_100': 0.58786, 'mrr_at_1000': 0.58788, 'evaluation_time': 49.13}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [03:49<08:06, 22.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [02:23<06:20, 15.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [02:32<04:36, 12.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [02:52<05:11, 14.85s/it]Clustering:  26%|██▌       | 8/31 [02:45<06:51, 17.90s/it]Clustering:  32%|███▏      | 10/31 [04:15<08:12, 23.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [03:17<08:09, 22.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [03:31<07:24, 22.22s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [05:00<10:02, 30.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [03:32<06:57, 19.87s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:45<22:55, 45.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [03:52<06:55, 21.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [01:01<13:37, 28.19s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [04:14<08:52, 26.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [05:45<10:54, 34.43s/it]Clustering:  10%|▉         | 3/31 [01:21<11:19, 24.28s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [04:25<07:32, 25.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:37<09:30, 21.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [04:55<09:52, 31.18s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [02:03<09:50, 22.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [06:28<11:08, 37.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [05:09<08:44, 30.87s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [02:25<09:27, 22.68s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [05:33<09:57, 33.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [05:41<08:19, 31.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  45%|████▌     | 14/31 [07:08<10:48, 38.17s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [02:46<08:52, 22.19s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [03:09<08:34, 22.39s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [06:14<10:03, 35.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [03:27<07:39, 20.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  52%|█████▏    | 16/31 [06:29<09:05, 36.39s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  48%|████▊     | 15/31 [07:55<10:49, 40.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [03:46<07:04, 20.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [06:50<09:32, 35.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [07:01<08:07, 34.82s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [08:30<09:46, 39.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [07:38<07:41, 35.54s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [04:40<10:11, 30.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [07:37<09:43, 38.93s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [09:21<09:54, 42.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [08:19<07:27, 37.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [05:24<10:58, 34.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [08:25<09:43, 41.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [10:30<10:56, 50.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [09:07<07:25, 40.52s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [06:13<11:41, 38.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [09:12<09:24, 43.40s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  68%|██████▊   | 21/31 [09:38<06:14, 37.48s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [09:42<04:09, 27.68s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [11:22<10:13, 51.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [06:59<11:43, 41.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [09:59<08:53, 44.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [10:09<03:39, 27.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
Evaluating the model cohere$flag-embedding$gist$llmrails...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Creating model cohere$flag-embedding$gist$llmrails for task ArxivClusteringS2S
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]Clustering:  48%|████▊     | 15/31 [07:31<10:17, 38.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model cohere$flag-embedding$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Creating model cohere$flag-embedding$mixed-bread$voyage for task ArxivClusteringS2S
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [11:59<08:35, 46.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [10:40<03:19, 28.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [10:37<07:47, 42.48s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [11:06<02:46, 27.67s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Evaluating the model cohere$gte-large$llmrails$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Creating model cohere$gte-large$llmrails$voyage for task ArxivClusteringS2S
Loading cohere from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:46<23:05, 46.18s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:41<20:44, 41.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [12:45<07:46, 46.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [08:26<10:49, 43.28s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [12:50<05:06, 34.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [11:29<02:10, 26.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [11:25<07:22, 44.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [11:28<04:46, 31.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [01:15<17:32, 36.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [01:16<18:10, 37.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [12:02<01:52, 28.19s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:52<26:12, 52.43s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [13:49<05:31, 41.45s/it]Clustering:  10%|▉         | 3/31 [01:53<17:21, 37.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [09:28<11:24, 48.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [12:24<05:11, 39.00s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
Clustering:  10%|▉         | 3/31 [01:53<17:23, 37.28s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [12:32<01:26, 28.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [01:23<19:15, 39.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [02:12<13:24, 29.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [14:08<04:02, 34.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [12:40<03:45, 32.16s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [02:20<14:58, 33.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [01:53<16:27, 35.25s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [13:05<01:00, 30.28s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [13:22<00:26, 26.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [02:49<14:06, 32.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [13:20<03:26, 34.37s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [14:52<03:44, 37.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
Clustering:  58%|█████▊    | 18/31 [10:28<11:20, 52.37s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [02:19<14:12, 31.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  16%|█▌        | 5/31 [02:52<14:11, 32.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [13:31<02:17, 27.48s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [15:05<02:31, 30.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [13:48<00:00, 26.09s/it]Clustering: 100%|██████████| 31/31 [13:48<00:00, 26.72s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 828.36 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43074378836004074, 'v_measure_std': 0.14373678653846314, 'evaluation_time': 828.36}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [03:18<13:03, 31.33s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  84%|████████▍ | 26/31 [15:18<02:56, 35.33s/it]
ERROR:mteb.evaluation.MTEB:Error while evaluating ArxivClusteringS2S: Unable to allocate 195. MiB for an array with shape (25000, 1024) and data type float64
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [02:54<14:12, 32.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [03:29<14:19, 34.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [14:09<02:02, 30.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [03:43<11:41, 29.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [11:20<10:25, 52.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [03:11<11:31, 27.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [03:47<11:30, 28.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [03:55<09:03, 23.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [14:31<01:24, 28.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  23%|██▎       | 7/31 [03:29<09:42, 24.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [04:11<10:28, 27.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [04:17<08:33, 23.33s/it]INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$flag-embedding$gte-large$mixed-bread
Converting results/angle$flag-embedding$gte-large$mixed-bread to results/angle$flag-embedding$gte-large$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$flag-embedding$gte-large$voyage...
Skipping STS17 as it already exists
Creating model angle$flag-embedding$gte-large$voyage for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gte-large from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [03:52<09:07, 23.82s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [14:58<00:55, 27.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  65%|██████▍   | 20/31 [12:06<09:15, 50.52s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  32%|███▏      | 10/31 [04:37<07:43, 22.05s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [04:33<09:26, 25.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 21.18 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.87536508314955, 'accuracy_threshold': 0.8632884082891383, 'f1': 0.7183652747810636, 'f1_threshold': 0.8469582254600186, 'precision': 0.6921007581315725, 'recall': 0.7467018469656992, 'ap': 0.7841895660223807}, 'manhattan': {'accuracy': 0.8739941586696072, 'accuracy_threshold': 26.181019090340815, 'f1': 0.7137153895685769, 'f1_threshold': 27.48384087680003, 'precision': 0.6971069182389937, 'recall': 0.7311345646437994, 'ap': 0.7811159661052564}, 'euclidean': {'accuracy': 0.87536508314955, 'accuracy_threshold': 0.522898826454947, 'f1': 0.7183652747810636, 'f1_threshold': 0.5532481802219955, 'precision': 0.6921007581315725, 'recall': 0.7467018469656992, 'ap': 0.7841895660223807}, 'dot': {'accuracy': 0.87536508314955, 'accuracy_threshold': 0.8632884082891386, 'f1': 0.7183652747810636, 'f1_threshold': 0.8469582254600188, 'precision': 0.6921007581315725, 'recall': 0.7467018469656992, 'ap': 0.7841895660223807}, 'max': {'accuracy': 0.87536508314955, 'f1': 0.7183652747810636, 'ap': 0.7841895660223807}, 'evaluation_time': 21.18}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [04:06<07:38, 20.82s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [15:11<00:23, 23.39s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model flag-embedding$gist$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Creating model flag-embedding$gist$mixed-bread$voyage for task ArxivClusteringS2S
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model angle$flag-embedding$gte-large$voyage for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading gte-large from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  32%|███▏      | 10/31 [04:58<08:54, 25.43s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [04:34<08:04, 23.07s/it]INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 18.13 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6509886533423839, 'mrr': 0.7906806489908982, 'evaluation_time': 18.13}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [15:43<00:00, 25.82s/it]Clustering: 100%|██████████| 31/31 [15:43<00:00, 30.44s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 943.74 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4329511583564989, 'v_measure_std': 0.1425499755425137, 'evaluation_time': 943.74}
Clustering:  68%|██████▊   | 21/31 [12:49<08:01, 48.19s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [05:22<09:45, 29.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [12:56<05:20, 35.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$flag-embedding$gte-large$voyage for task SciFact
Loading angle from cache for SciFact...
Loading flag-embedding from cache for SciFact...
Loading gte-large from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s] 31%|███       | 1584/5183 [00:00<00:00, 15836.28it/s] 61%|██████    | 3168/5183 [00:00<00:00, 12320.25it/s] 86%|████████▌ | 4448/5183 [00:00<00:00, 9723.67it/s] 100%|██████████| 5183/5183 [00:00<00:00, 10564.13it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:faiss.loader:Loading faiss.
INFO:faiss.loader:Successfully loaded faiss.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [05:42<10:25, 31.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:55<27:43, 55.46s/it]/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [13:36<04:56, 37.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [05:29<10:56, 32.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [01:18<17:42, 36.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [06:14<11:27, 36.17s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [06:18<10:17, 32.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [14:05<04:01, 34.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [01:48<15:38, 33.52s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 74.81 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.6567
INFO:root:NDCG@3: 0.7195
INFO:root:NDCG@5: 0.7376
INFO:root:NDCG@10: 0.7669
INFO:root:NDCG@100: 0.7825
INFO:root:NDCG@1000: 0.7873
INFO:root:

INFO:root:MAP@1: 0.6276
INFO:root:MAP@3: 0.6947
INFO:root:MAP@5: 0.7073
INFO:root:MAP@10: 0.7224
INFO:root:MAP@100: 0.7260
INFO:root:MAP@1000: 0.7262
INFO:root:

INFO:root:Recall@1: 0.6276
INFO:root:Recall@3: 0.7645
INFO:root:Recall@5: 0.8116
INFO:root:Recall@10: 0.8949
INFO:root:Recall@100: 0.9650
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6567
INFO:root:P@3: 0.2800
INFO:root:P@5: 0.1807
INFO:root:P@10: 0.1017
INFO:root:P@100: 0.0109
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6567
INFO:root:MRR@3: 0.7106
INFO:root:MRR@5: 0.7212
INFO:root:MRR@10: 0.7309
INFO:root:MRR@100: 0.7339
INFO:root:MRR@1000: 0.7341
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 76.65 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.65667, 'ndcg_at_3': 0.7195, 'ndcg_at_5': 0.73764, 'ndcg_at_10': 0.76694, 'ndcg_at_100': 0.78246, 'ndcg_at_1000': 0.78733, 'map_at_1': 0.62761, 'map_at_3': 0.69469, 'map_at_5': 0.70729, 'map_at_10': 0.72242, 'map_at_100': 0.72599, 'map_at_1000': 0.72625, 'recall_at_1': 0.62761, 'recall_at_3': 0.7645, 'recall_at_5': 0.81161, 'recall_at_10': 0.89489, 'recall_at_100': 0.965, 'recall_at_1000': 1.0, 'precision_at_1': 0.65667, 'precision_at_3': 0.28, 'precision_at_5': 0.18067, 'precision_at_10': 0.10167, 'precision_at_100': 0.01093, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.65667, 'mrr_at_3': 0.71056, 'mrr_at_5': 0.72122, 'mrr_at_10': 0.73095, 'mrr_at_100': 0.73391, 'mrr_at_1000': 0.73413, 'evaluation_time': 76.65}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:main:Running task: EmotionClassification
Clustering:  39%|███▊      | 12/31 [06:19<12:02, 38.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$llmrails$mixed-bread
Converting results/angle$cohere$llmrails$mixed-bread to results/angle$cohere$llmrails$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$llmrails$voyage...
Skipping STS17 as it already exists
Creating model angle$cohere$llmrails$voyage for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading cohere from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$flag-embedding$gte-large$voyage for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading flag-embedding from cache for EmotionClassification...
Loading gte-large from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Clustering:  42%|████▏     | 13/31 [07:03<12:01, 40.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
Clustering:  42%|████▏     | 13/31 [06:59<10:34, 35.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [14:37<03:23, 33.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [07:19<10:07, 33.77s/it]
ERROR:mteb.evaluation.MTEB:Error while evaluating ArxivClusteringS2S: Unable to allocate 391. MiB for an array with shape (25000, 2048) and data type float64
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Clustering:  13%|█▎        | 4/31 [02:31<16:44, 37.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [15:03<02:37, 31.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
Evaluating the model angle$cohere$flag-embedding$gte-large$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model angle$cohere$flag-embedding$gte-large$voyage for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading cohere from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading gte-large from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 38.95 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8775704833998927, 'accuracy_threshold': 0.8156132620275637, 'f1': 0.719061876247505, 'f1_threshold': 0.7942005827973524, 'precision': 0.6819687647893989, 'recall': 0.7604221635883905, 'ap': 0.7878627657683244}, 'manhattan': {'accuracy': 0.8767360076294928, 'accuracy_threshold': 30.33182087160771, 'f1': 0.7182539682539684, 'f1_threshold': 32.141895230408394, 'precision': 0.6775854000935891, 'recall': 0.7641160949868074, 'ap': 0.7873339168998379}, 'euclidean': {'accuracy': 0.8775704833998927, 'accuracy_threshold': 0.6072672195210504, 'f1': 0.719061876247505, 'f1_threshold': 0.6415596888435253, 'precision': 0.6819687647893989, 'recall': 0.7604221635883905, 'ap': 0.7878627657683244}, 'dot': {'accuracy': 0.8775704833998927, 'accuracy_threshold': 0.8156132620275639, 'f1': 0.719061876247505, 'f1_threshold': 0.7942005827973521, 'precision': 0.6819687647893989, 'recall': 0.7604221635883905, 'ap': 0.7878627657683244}, 'max': {'accuracy': 0.8775704833998927, 'f1': 0.719061876247505, 'ap': 0.7878627657683244}, 'evaluation_time': 38.95}
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model angle$cohere$llmrails$voyage for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading cohere from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 56.30 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.54355, 'f1': 0.47569924536013514, 'accuracy_stderr': 0.024004634969105446, 'f1_stderr': 0.014129232763700731, 'main_score': 0.54355, 'evaluation_time': 56.3}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model angle$flag-embedding$gte-large$voyage for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading flag-embedding from cache for AmazonCounterfactualClassification...
Loading gte-large from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
Evaluating the model gist$llmrails$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Creating model gist$llmrails$mixed-bread$voyage for task ArxivClusteringS2S
Loading gist from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [03:15<17:12, 39.72s/it]INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 4.22 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7371641791044776, 'f1': 0.6764892341980934, 'ap': 0.3641282282765707, 'accuracy_stderr': 0.03812519971353202, 'f1_stderr': 0.03637085398381435, 'ap_stderr': 0.03770229135411954, 'main_score': 0.7371641791044776}, 'evaluation_time': 4.22}
INFO:main:Running task: Banking77Classification
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$flag-embedding$gte-large$voyage for task Banking77Classification
Loading angle from cache for Banking77Classification...
Loading flag-embedding from cache for Banking77Classification...
Loading gte-large from cache for Banking77Classification...
Loading voyage from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 34.13 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6401147264029066, 'mrr': 0.7683660906652597, 'evaluation_time': 34.13}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 32.36 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6438273095046593, 'mrr': 0.7738018291342391, 'evaluation_time': 32.36}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$llmrails$voyage for task SciFact
Loading angle from cache for SciFact...
Loading cohere from cache for SciFact...
Loading llmrails from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s] 27%|██▋       | 1417/5183 [00:00<00:00, 14162.11it/s] 66%|██████▌   | 3395/5183 [00:00<00:00, 17463.36it/s] 99%|█████████▉| 5142/5183 [00:00<00:00, 13323.58it/s]100%|██████████| 5183/5183 [00:00<00:00, 14001.72it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:faiss.loader:Loading faiss.
INFO:faiss.loader:Successfully loaded faiss.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Creating model angle$cohere$flag-embedding$gte-large$voyage for task ArguAna
Loading angle from cache for ArguAna...
Loading cohere from cache for ArguAna...
Loading flag-embedding from cache for ArguAna...
Loading gte-large from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s] 27%|██▋       | 2339/8674 [00:00<00:00, 23159.99it/s] 54%|█████▎    | 4655/8674 [00:00<00:00, 15677.63it/s] 73%|███████▎  | 6360/8674 [00:00<00:00, 13702.36it/s] 97%|█████████▋| 8430/8674 [00:00<00:00, 15819.54it/s]100%|██████████| 8674/8674 [00:00<00:00, 15930.31it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:faiss.loader:Loading faiss.
INFO:faiss.loader:Successfully loaded faiss.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [15:59<02:35, 38.93s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [07:54<16:39, 55.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  45%|████▌     | 14/31 [08:33<15:35, 55.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [03:46<15:16, 36.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:   3%|▎         | 1/31 [00:34<17:26, 34.87s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 27.09 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.6500
INFO:root:NDCG@3: 0.7124
INFO:root:NDCG@5: 0.7390
INFO:root:NDCG@10: 0.7601
INFO:root:NDCG@100: 0.7786
INFO:root:NDCG@1000: 0.7825
INFO:root:

INFO:root:MAP@1: 0.6183
INFO:root:MAP@3: 0.6865
INFO:root:MAP@5: 0.7040
INFO:root:MAP@10: 0.7155
INFO:root:MAP@100: 0.7196
INFO:root:MAP@1000: 0.7198
INFO:root:

INFO:root:Recall@1: 0.6183
INFO:root:Recall@3: 0.7585
INFO:root:Recall@5: 0.8274
INFO:root:Recall@10: 0.8872
INFO:root:Recall@100: 0.9717
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6500
INFO:root:P@3: 0.2789
INFO:root:P@5: 0.1847
INFO:root:P@10: 0.1010
INFO:root:P@100: 0.0110
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6500
INFO:root:MRR@3: 0.7033
INFO:root:MRR@5: 0.7190
INFO:root:MRR@10: 0.7253
INFO:root:MRR@100: 0.7288
INFO:root:MRR@1000: 0.7290
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 30.10 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.65, 'ndcg_at_3': 0.71242, 'ndcg_at_5': 0.73896, 'ndcg_at_10': 0.76015, 'ndcg_at_100': 0.77857, 'ndcg_at_1000': 0.78253, 'map_at_1': 0.61828, 'map_at_3': 0.68648, 'map_at_5': 0.70401, 'map_at_10': 0.71545, 'map_at_100': 0.71958, 'map_at_1000': 0.71979, 'recall_at_1': 0.61828, 'recall_at_3': 0.7585, 'recall_at_5': 0.82744, 'recall_at_10': 0.88722, 'recall_at_100': 0.97167, 'recall_at_1000': 1.0, 'precision_at_1': 0.65, 'precision_at_3': 0.27889, 'precision_at_5': 0.18467, 'precision_at_10': 0.101, 'precision_at_100': 0.011, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.65, 'mrr_at_3': 0.70333, 'mrr_at_5': 0.719, 'mrr_at_10': 0.72533, 'mrr_at_100': 0.72881, 'mrr_at_1000': 0.729, 'evaluation_time': 30.1}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$llmrails$voyage for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading cohere from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [16:43<02:00, 40.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [04:33<15:59, 39.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 88.90 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8421753246753247, 'f1': 0.8350496905622331, 'accuracy_stderr': 0.004330370455437867, 'f1_stderr': 0.005326907826877614, 'main_score': 0.8421753246753247, 'evaluation_time': 88.9}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$flag-embedding$gte-large$voyage for task ArguAna
Loading angle from cache for ArguAna...
Loading flag-embedding from cache for ArguAna...
Loading gte-large from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s] 13%|█▎        | 1128/8674 [00:00<00:00, 11277.83it/s] 26%|██▌       | 2256/8674 [00:00<00:00, 11187.43it/s] 39%|███▉      | 3375/8674 [00:00<00:00, 10922.32it/s] 52%|█████▏    | 4468/8674 [00:00<00:00, 10625.14it/s] 64%|██████▍   | 5532/8674 [00:00<00:00, 10027.10it/s] 75%|███████▌  | 6540/8674 [00:00<00:00, 9479.96it/s]  87%|████████▋ | 7535/8674 [00:00<00:00, 9435.88it/s]100%|██████████| 8674/8674 [00:00<00:00, 10276.17it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 91.31 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
Clustering:   6%|▋         | 2/31 [01:44<26:44, 55.33s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:root:

INFO:root:NDCG@1: 0.3734
INFO:root:NDCG@3: 0.5419
INFO:root:NDCG@5: 0.5918
INFO:root:NDCG@10: 0.6292
INFO:root:NDCG@100: 0.6523
INFO:root:NDCG@1000: 0.6527
INFO:root:

INFO:root:MAP@1: 0.3734
INFO:root:MAP@3: 0.5006
INFO:root:MAP@5: 0.5283
INFO:root:MAP@10: 0.5440
INFO:root:MAP@100: 0.5498
INFO:root:MAP@1000: 0.5499
INFO:root:

INFO:root:Recall@1: 0.3734
INFO:root:Recall@3: 0.6614
INFO:root:Recall@5: 0.7824
INFO:root:Recall@10: 0.8969
INFO:root:Recall@100: 0.9936
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.3734
INFO:root:P@3: 0.2205
INFO:root:P@5: 0.1565
INFO:root:P@10: 0.0897
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:root:MRR@1: 0.3841
INFO:root:MRR@3: 0.5040
INFO:root:MRR@5: 0.5317
INFO:root:MRR@10: 0.5478
INFO:root:MRR@100: 0.5536
INFO:root:MRR@1000: 0.5536
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 101.56 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.3734, 'ndcg_at_3': 0.54192, 'ndcg_at_5': 0.59178, 'ndcg_at_10': 0.62924, 'ndcg_at_100': 0.65234, 'ndcg_at_1000': 0.65273, 'map_at_1': 0.3734, 'map_at_3': 0.50059, 'map_at_5': 0.5283, 'map_at_10': 0.54401, 'map_at_100': 0.54985, 'map_at_1000': 0.54987, 'recall_at_1': 0.3734, 'recall_at_3': 0.66145, 'recall_at_5': 0.78236, 'recall_at_10': 0.89687, 'recall_at_100': 0.9936, 'recall_at_1000': 0.99644, 'precision_at_1': 0.3734, 'precision_at_3': 0.22048, 'precision_at_5': 0.15647, 'precision_at_10': 0.08969, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.38407, 'mrr_at_3': 0.50403, 'mrr_at_5': 0.5317, 'mrr_at_10': 0.54783, 'mrr_at_100': 0.55361, 'mrr_at_1000': 0.55363, 'evaluation_time': 101.56}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
Clustering:  45%|████▌     | 14/31 [09:37<19:45, 69.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [10:17<18:37, 69.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [05:23<16:36, 43.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [17:50<01:36, 48.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 79.77 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5559000000000001, 'f1': 0.49282350993904256, 'accuracy_stderr': 0.02062983276713604, 'f1_stderr': 0.011750935107449909, 'main_score': 0.5559000000000001, 'evaluation_time': 79.77}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [02:13<20:17, 43.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  97%|█████████▋| 30/31 [18:04<00:38, 38.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model angle$cohere$llmrails$voyage for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading cohere from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 5.36 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7713432835820895, 'f1': 0.7126172801369215, 'ap': 0.40820499637835067, 'accuracy_stderr': 0.03918187623457752, 'f1_stderr': 0.03713509022813519, 'ap_stderr': 0.042952452537346905, 'main_score': 0.7713432835820895}, 'evaluation_time': 5.36}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [05:49<13:54, 37.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 53.22 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$llmrails$voyage for task Banking77Classification
Loading angle from cache for Banking77Classification...
Loading cohere from cache for Banking77Classification...
Loading llmrails from cache for Banking77Classification...
Loading voyage from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:root:

INFO:root:NDCG@1: 0.4097
INFO:root:NDCG@3: 0.5755
INFO:root:NDCG@5: 0.6197
INFO:root:NDCG@10: 0.6565
INFO:root:NDCG@100: 0.6752
INFO:root:NDCG@1000: 0.6756
INFO:root:

INFO:root:MAP@1: 0.4097
INFO:root:MAP@3: 0.5341
INFO:root:MAP@5: 0.5587
INFO:root:MAP@10: 0.5741
INFO:root:MAP@100: 0.5789
INFO:root:MAP@1000: 0.5789
INFO:root:

INFO:root:Recall@1: 0.4097
INFO:root:Recall@3: 0.6956
INFO:root:Recall@5: 0.8023
INFO:root:Recall@10: 0.9154
INFO:root:Recall@100: 0.9936
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.4097
INFO:root:P@3: 0.2319
INFO:root:P@5: 0.1605
INFO:root:P@10: 0.0915
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:root:MRR@1: 0.4161
INFO:root:MRR@3: 0.5369
INFO:root:MRR@5: 0.5610
INFO:root:MRR@10: 0.5763
INFO:root:MRR@100: 0.5812
INFO:root:MRR@1000: 0.5812
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 55.82 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.40967, 'ndcg_at_3': 0.57554, 'ndcg_at_5': 0.61965, 'ndcg_at_10': 0.65653, 'ndcg_at_100': 0.67523, 'ndcg_at_1000': 0.67562, 'map_at_1': 0.40967, 'map_at_3': 0.53414, 'map_at_5': 0.55871, 'map_at_10': 0.57412, 'map_at_100': 0.57891, 'map_at_1000': 0.57893, 'recall_at_1': 0.40967, 'recall_at_3': 0.69559, 'recall_at_5': 0.80228, 'recall_at_10': 0.91536, 'recall_at_100': 0.9936, 'recall_at_1000': 0.99644, 'precision_at_1': 0.40967, 'precision_at_3': 0.23186, 'precision_at_5': 0.16046, 'precision_at_10': 0.09154, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.41607, 'mrr_at_3': 0.53687, 'mrr_at_5': 0.56098, 'mrr_at_10': 0.57626, 'mrr_at_100': 0.58118, 'mrr_at_1000': 0.58119, 'evaluation_time': 55.82}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [02:51<18:28, 41.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [06:21<12:33, 35.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [18:47<00:00, 39.59s/it]Clustering: 100%|██████████| 31/31 [18:47<00:00, 36.37s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 1127.42 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43176410867375514, 'v_measure_std': 0.14354740480139125, 'evaluation_time': 1127.42}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [10:38<17:53, 67.08s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [11:17<16:42, 66.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [03:09<14:13, 32.84s/it]/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
Clustering:  19%|█▉        | 6/31 [03:52<15:06, 36.27s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 92.60 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8457467532467533, 'f1': 0.8397197540574934, 'accuracy_stderr': 0.004864607258355003, 'f1_stderr': 0.005457730576375278, 'main_score': 0.8457467532467533, 'evaluation_time': 92.6}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [07:25<14:54, 44.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [12:20<15:19, 65.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [11:42<16:34, 66.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [04:12<12:25, 31.05s/it]INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$llmrails$voyage for task ArguAna
Loading angle from cache for ArguAna...
Loading cohere from cache for ArguAna...
Loading llmrails from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s] 41%|████      | 3577/8674 [00:00<00:00, 35759.55it/s] 84%|████████▍ | 7291/8674 [00:00<00:00, 36568.78it/s]100%|██████████| 8674/8674 [00:00<00:00, 36419.82it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$gist$llmrails$mixed-bread
Converting results/angle$gist$llmrails$mixed-bread to results/angle$gist$llmrails$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$gist$llmrails$voyage...
Skipping STS17 as it already exists
Creating model angle$gist$llmrails$voyage for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [04:34<10:48, 28.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 27.73 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8756035047982357, 'accuracy_threshold': 0.8307224058422029, 'f1': 0.7196098049024513, 'f1_threshold': 0.8078009721171096, 'precision': 0.6840228245363766, 'recall': 0.7591029023746702, 'ap': 0.7873200758568923}, 'manhattan': {'accuracy': 0.87536508314955, 'accuracy_threshold': 29.284511717514263, 'f1': 0.7177898909811695, 'f1_threshold': 31.39858898524723, 'precision': 0.6765530126109295, 'recall': 0.7643799472295515, 'ap': 0.7861494491964558}, 'euclidean': {'accuracy': 0.8756035047982357, 'accuracy_threshold': 0.5818549545762195, 'f1': 0.7196098049024513, 'f1_threshold': 0.6199984320052573, 'precision': 0.6840228245363766, 'recall': 0.7591029023746702, 'ap': 0.7873200758568923}, 'dot': {'accuracy': 0.8756035047982357, 'accuracy_threshold': 0.8307224058422029, 'f1': 0.7196098049024513, 'f1_threshold': 0.80780097211711, 'precision': 0.6840228245363766, 'recall': 0.7591029023746702, 'ap': 0.7873200758568923}, 'max': {'accuracy': 0.8756035047982357, 'f1': 0.7196098049024513, 'ap': 0.7873200758568923}, 'evaluation_time': 27.73}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [08:06<13:44, 43.40s/it]Clustering:  55%|█████▍    | 17/31 [12:22<13:34, 58.18s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 32.90 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  58%|█████▊    | 18/31 [13:02<12:40, 58.46s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:root:

INFO:root:NDCG@1: 0.3762
INFO:root:NDCG@3: 0.5466
INFO:root:NDCG@5: 0.5958
INFO:root:NDCG@10: 0.6335
INFO:root:NDCG@100: 0.6555
INFO:root:NDCG@1000: 0.6558
INFO:root:

INFO:root:MAP@1: 0.3762
INFO:root:MAP@3: 0.5051
INFO:root:MAP@5: 0.5325
INFO:root:MAP@10: 0.5481
INFO:root:MAP@100: 0.5537
INFO:root:MAP@1000: 0.5537
INFO:root:

INFO:root:Recall@1: 0.3762
INFO:root:Recall@3: 0.6664
INFO:root:Recall@5: 0.7859
INFO:root:Recall@10: 0.9019
INFO:root:Recall@100: 0.9936
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.3762
INFO:root:P@3: 0.2221
INFO:root:P@5: 0.1572
INFO:root:P@10: 0.0902
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.3848
INFO:root:MRR@3: 0.5083
INFO:root:MRR@5: 0.5360
INFO:root:MRR@10: 0.5515
INFO:root:MRR@100: 0.5571
INFO:root:MRR@1000: 0.5571
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 36.17 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.37624, 'ndcg_at_3': 0.54657, 'ndcg_at_5': 0.59585, 'ndcg_at_10': 0.63349, 'ndcg_at_100': 0.65546, 'ndcg_at_1000': 0.65584, 'map_at_1': 0.37624, 'map_at_3': 0.5051, 'map_at_5': 0.53248, 'map_at_10': 0.54811, 'map_at_100': 0.5537, 'map_at_1000': 0.55371, 'recall_at_1': 0.37624, 'recall_at_3': 0.66643, 'recall_at_5': 0.78592, 'recall_at_10': 0.90185, 'recall_at_100': 0.9936, 'recall_at_1000': 0.99644, 'precision_at_1': 0.37624, 'precision_at_3': 0.22214, 'precision_at_5': 0.15718, 'precision_at_10': 0.09018, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.38478, 'mrr_at_3': 0.5083, 'mrr_at_5': 0.53604, 'mrr_at_10': 0.55154, 'mrr_at_100': 0.55713, 'mrr_at_1000': 0.55714, 'evaluation_time': 36.17}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [04:52<09:06, 24.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model angle$gist$llmrails$voyage for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [05:17<08:44, 24.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [08:38<12:00, 40.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [13:32<10:00, 50.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [12:54<10:56, 50.48s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 7.32 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6506870694448598, 'mrr': 0.7868333113485468, 'evaluation_time': 7.32}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [14:07<08:18, 45.35s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [09:15<11:06, 39.19s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  61%|██████▏   | 19/31 [13:31<09:17, 46.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [05:57<09:53, 29.67s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist$llmrails$voyage for task SciFact
Loading angle from cache for SciFact...
Loading gist from cache for SciFact...
Loading llmrails from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s] 76%|███████▋  | 3964/5183 [00:00<00:00, 39631.06it/s]100%|██████████| 5183/5183 [00:00<00:00, 40827.63it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:faiss.loader:Loading faiss.
INFO:faiss.loader:Successfully loaded faiss.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 18.81 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.6500
INFO:root:NDCG@3: 0.7096
INFO:root:NDCG@5: 0.7390
INFO:root:NDCG@10: 0.7621
INFO:root:NDCG@100: 0.7785
INFO:root:NDCG@1000: 0.7839
INFO:root:

INFO:root:MAP@1: 0.6209
INFO:root:MAP@3: 0.6866
INFO:root:MAP@5: 0.7052
INFO:root:MAP@10: 0.7174
INFO:root:MAP@100: 0.7215
INFO:root:MAP@1000: 0.7218
INFO:root:

INFO:root:Recall@1: 0.6209
INFO:root:Recall@3: 0.7495
INFO:root:Recall@5: 0.8233
INFO:root:Recall@10: 0.8899
INFO:root:Recall@100: 0.9617
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6500
INFO:root:P@3: 0.2744
INFO:root:P@5: 0.1840
INFO:root:P@10: 0.1010
INFO:root:P@100: 0.0109
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6500
INFO:root:MRR@3: 0.7022
INFO:root:MRR@5: 0.7194
INFO:root:MRR@10: 0.7265
INFO:root:MRR@100: 0.7297
INFO:root:MRR@1000: 0.7299
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 24.16 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.65, 'ndcg_at_3': 0.70962, 'ndcg_at_5': 0.73899, 'ndcg_at_10': 0.76208, 'ndcg_at_100': 0.77855, 'ndcg_at_1000': 0.78389, 'map_at_1': 0.62094, 'map_at_3': 0.68663, 'map_at_5': 0.70523, 'map_at_10': 0.71737, 'map_at_100': 0.7215, 'map_at_1000': 0.72178, 'recall_at_1': 0.62094, 'recall_at_3': 0.7495, 'recall_at_5': 0.82328, 'recall_at_10': 0.88989, 'recall_at_100': 0.96167, 'recall_at_1000': 1.0, 'precision_at_1': 0.65, 'precision_at_3': 0.27444, 'precision_at_5': 0.184, 'precision_at_10': 0.101, 'precision_at_100': 0.0109, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.65, 'mrr_at_3': 0.70222, 'mrr_at_5': 0.71939, 'mrr_at_10': 0.72649, 'mrr_at_100': 0.72969, 'mrr_at_1000': 0.72995, 'evaluation_time': 24.16}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [14:41<07:01, 42.16s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [14:44<04:33, 30.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [06:34<10:03, 31.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [14:09<08:03, 43.94s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist$llmrails$voyage for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading gist from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [09:57<10:38, 39.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  48%|████▊     | 15/31 [10:07<10:48, 40.53s/it]
ERROR:mteb.evaluation.MTEB:Error while evaluating ArxivClusteringS2S: Unable to allocate 781. MiB for an array with shape (25000, 4096) and data type float64
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Evaluating the model angle$cohere$gist$llmrails$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model angle$cohere$gist$llmrails$voyage for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading cohere from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [15:35<04:52, 36.54s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 51.88 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5643499999999999, 'f1': 0.5001107408432021, 'accuracy_stderr': 0.021686458908729198, 'f1_stderr': 0.012849197394554406, 'main_score': 0.5643499999999999, 'evaluation_time': 51.88}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [15:10<08:09, 48.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [07:37<12:21, 41.20s/it]INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 23.27 seconds
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6452673355860397, 'mrr': 0.776491667765906, 'evaluation_time': 23.27}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [15:18<05:29, 36.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [15:57<03:44, 32.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [15:38<04:13, 31.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [08:08<10:49, 38.18s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [16:25<03:05, 30.94s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [15:53<03:05, 26.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [16:31<01:57, 23.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [16:12<02:26, 24.40s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [16:51<01:29, 22.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [08:39<09:36, 36.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [16:28<01:48, 21.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model angle$gist$llmrails$voyage for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading gist from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [17:24<01:16, 25.41s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [16:48<01:25, 21.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [09:20<09:21, 37.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [17:12<01:06, 22.25s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [17:51<00:52, 26.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [09:47<08:00, 34.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Creating model angle$cohere$gist$llmrails$voyage for task ArguAna
Loading angle from cache for ArguAna...
Loading cohere from cache for ArguAna...
Loading gist from cache for ArguAna...
Loading llmrails from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [18:04<00:22, 22.04s/it]INFO:beir.datasets.data_loader:Loading Corpus...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
  0%|          | 0/8674 [00:00<?, ?it/s] 58%|█████▊    | 5062/8674 [00:00<00:00, 50611.60it/s]100%|██████████| 8674/8674 [00:00<00:00, 51417.59it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:faiss.loader:Loading faiss.
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:faiss.loader:Successfully loaded faiss.
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [17:29<00:41, 20.62s/it]INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 2.23 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7464179104477612, 'f1': 0.6854341448102096, 'ap': 0.3736367123498472, 'accuracy_stderr': 0.036962227774076636, 'f1_stderr': 0.035319377926169473, 'ap_stderr': 0.03788184463910396, 'main_score': 0.7464179104477612}, 'evaluation_time': 2.23}
INFO:main:Running task: Banking77Classification
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist$llmrails$voyage for task Banking77Classification
Loading angle from cache for Banking77Classification...
Loading gist from cache for Banking77Classification...
Loading llmrails from cache for Banking77Classification...
Loading voyage from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [18:21<00:00, 20.66s/it]Clustering: 100%|██████████| 31/31 [18:21<00:00, 35.54s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 1101.72 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4351016376091143, 'v_measure_std': 0.14309233570950916, 'evaluation_time': 1101.72}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [17:43<00:18, 18.69s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [18:11<00:00, 21.40s/it]Clustering: 100%|██████████| 31/31 [18:11<00:00, 35.21s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 1091.56 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4335792417136098, 'v_measure_std': 0.14233887447224736, 'evaluation_time': 1091.56}
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
Clustering:  58%|█████▊    | 18/31 [10:40<08:40, 40.05s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 52.92 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.3720
INFO:root:NDCG@3: 0.5431
INFO:root:NDCG@5: 0.5936
INFO:root:NDCG@10: 0.6313
INFO:root:NDCG@100: 0.6531
INFO:root:NDCG@1000: 0.6534
INFO:root:

INFO:root:MAP@1: 0.3720
INFO:root:MAP@3: 0.5014
INFO:root:MAP@5: 0.5293
INFO:root:MAP@10: 0.5449
INFO:root:MAP@100: 0.5505
INFO:root:MAP@1000: 0.5505
INFO:root:

INFO:root:Recall@1: 0.3720
INFO:root:Recall@3: 0.6636
INFO:root:Recall@5: 0.7866
INFO:root:Recall@10: 0.9033
INFO:root:Recall@100: 0.9936
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.3720
INFO:root:P@3: 0.2212
INFO:root:P@5: 0.1573
INFO:root:P@10: 0.0903
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:root:MRR@1: 0.3770
INFO:root:MRR@3: 0.5036
INFO:root:MRR@5: 0.5310
INFO:root:MRR@10: 0.5470
INFO:root:MRR@100: 0.5525
INFO:root:MRR@1000: 0.5525
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 60.41 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.37198, 'ndcg_at_3': 0.54311, 'ndcg_at_5': 0.59355, 'ndcg_at_10': 0.6313, 'ndcg_at_100': 0.65306, 'ndcg_at_1000': 0.65345, 'map_at_1': 0.37198, 'map_at_3': 0.50142, 'map_at_5': 0.52927, 'map_at_10': 0.54487, 'map_at_100': 0.55046, 'map_at_1000': 0.55048, 'recall_at_1': 0.37198, 'recall_at_3': 0.66358, 'recall_at_5': 0.78663, 'recall_at_10': 0.90327, 'recall_at_100': 0.9936, 'recall_at_1000': 0.99644, 'precision_at_1': 0.37198, 'precision_at_3': 0.22119, 'precision_at_5': 0.15733, 'precision_at_10': 0.09033, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.37696, 'mrr_at_3': 0.50356, 'mrr_at_5': 0.53097, 'mrr_at_10': 0.54701, 'mrr_at_100': 0.55253, 'mrr_at_1000': 0.55255, 'evaluation_time': 60.41}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name cohere$flag-embedding$gist$llmrails
Converting results/cohere$flag-embedding$gist$llmrails to results/cohere$flag-embedding$gist$llmrails_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$flag-embedding$gist$mixed-bread...
Skipping STS17 as it already exists
Creating model cohere$flag-embedding$gist$mixed-bread for task TwitterSemEval2015
Loading cohere from cache for TwitterSemEval2015...
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 66.25 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8533116883116882, 'f1': 0.8476104037697894, 'accuracy_stderr': 0.004304367121864049, 'f1_stderr': 0.005137677740018005, 'main_score': 0.8533116883116882, 'evaluation_time': 66.25}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [11:21<08:04, 40.39s/it]INFO:main:Running task: ArguAna
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist$llmrails$voyage for task ArguAna
Loading angle from cache for ArguAna...
Loading gist from cache for ArguAna...
Loading llmrails from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 19.42 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8780473266972642, 'accuracy_threshold': 0.8007781507806246, 'f1': 0.7205257054503286, 'f1_threshold': 0.7781674541261407, 'precision': 0.7041047595064216, 'recall': 0.7377308707124011, 'ap': 0.7908088057616695}, 'manhattan': {'accuracy': 0.8774512725755499, 'accuracy_threshold': 31.638295673741176, 'f1': 0.7201412536259302, 'f1_threshold': 34.06340735359464, 'precision': 0.6897801401304663, 'recall': 0.7532981530343008, 'ap': 0.7910517472432184}, 'euclidean': {'accuracy': 0.8780473266972642, 'accuracy_threshold': 0.6312239684994152, 'f1': 0.7205257054503286, 'f1_threshold': 0.6660818956723191, 'precision': 0.7041047595064216, 'recall': 0.7377308707124011, 'ap': 0.7908088057616695}, 'dot': {'accuracy': 0.8780473266972642, 'accuracy_threshold': 0.8007781507806253, 'f1': 0.7205257054503286, 'f1_threshold': 0.7781674541261416, 'precision': 0.7041047595064216, 'recall': 0.7377308707124011, 'ap': 0.7908088057616695}, 'max': {'accuracy': 0.8780473266972642, 'f1': 0.7205257054503286, 'ap': 0.7910517472432184}, 'evaluation_time': 19.42}
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s] 56%|█████▋    | 4885/8674 [00:00<00:00, 48840.38it/s]100%|██████████| 8674/8674 [00:00<00:00, 48173.56it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:main:Running task: AskUbuntuDupQuestions
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name cohere$gte-large$llmrails$voyage
Converting results/cohere$gte-large$llmrails$voyage to results/cohere$gte-large$llmrails$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$gte-large$mixed-bread$voyage...
Skipping STS17 as it already exists
Creating model cohere$gte-large$mixed-bread$voyage for task TwitterSemEval2015
Loading cohere from cache for TwitterSemEval2015...
Loading gte-large from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [11:50<06:44, 36.81s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model cohere$flag-embedding$gist$mixed-bread for task AskUbuntuDupQuestions
Loading cohere from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 30.97 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8728020504261786, 'accuracy_threshold': 0.8497252487456664, 'f1': 0.7121231395496757, 'f1_threshold': 0.8345637265868484, 'precision': 0.6875460574797347, 'recall': 0.7385224274406332, 'ap': 0.7775257107023761}, 'manhattan': {'accuracy': 0.8723252071288073, 'accuracy_threshold': 26.986549891840145, 'f1': 0.7107354610823766, 'f1_threshold': 28.467833106208893, 'precision': 0.6809282088469906, 'recall': 0.7432717678100264, 'ap': 0.7759768996497266}, 'euclidean': {'accuracy': 0.8728020504261786, 'accuracy_threshold': 0.5482239527134366, 'f1': 0.7121231395496757, 'f1_threshold': 0.5752152172462894, 'precision': 0.6875460574797347, 'recall': 0.7385224274406332, 'ap': 0.7775257107023761}, 'dot': {'accuracy': 0.8728020504261786, 'accuracy_threshold': 0.8497252487456665, 'f1': 0.7121231395496757, 'f1_threshold': 0.8345637265868484, 'precision': 0.6875460574797347, 'recall': 0.7385224274406332, 'ap': 0.7775257107023761}, 'max': {'accuracy': 0.8728020504261786, 'f1': 0.7121231395496757, 'ap': 0.7775257107023761}, 'evaluation_time': 30.97}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 56.56 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 46.17 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6460103563528662, 'mrr': 0.7785351536736578, 'evaluation_time': 46.17}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:root:

INFO:root:NDCG@1: 0.4147
INFO:root:NDCG@3: 0.5788
INFO:root:NDCG@5: 0.6243
INFO:root:NDCG@10: 0.6615
INFO:root:NDCG@100: 0.6783
INFO:root:NDCG@1000: 0.6787
INFO:root:

INFO:root:MAP@1: 0.4147
INFO:root:MAP@3: 0.5376
INFO:root:MAP@5: 0.5629
INFO:root:MAP@10: 0.5785
INFO:root:MAP@100: 0.5827
INFO:root:MAP@1000: 0.5827
INFO:root:

INFO:root:Recall@1: 0.4147
INFO:root:Recall@3: 0.6984
INFO:root:Recall@5: 0.8087
INFO:root:Recall@10: 0.9225
INFO:root:Recall@100: 0.9936
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.4147
INFO:root:P@3: 0.2328
INFO:root:P@5: 0.1617
INFO:root:P@10: 0.0922
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:main:Running task: ArxivClusteringS2S
INFO:root:MRR@1: 0.4232
INFO:root:MRR@3: 0.5411
INFO:root:MRR@5: 0.5657
INFO:root:MRR@10: 0.5814
INFO:root:MRR@100: 0.5856
INFO:root:MRR@1000: 0.5856
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 61.79 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.41465, 'ndcg_at_3': 0.5788, 'ndcg_at_5': 0.62435, 'ndcg_at_10': 0.66148, 'ndcg_at_100': 0.6783, 'ndcg_at_1000': 0.67868, 'map_at_1': 0.41465, 'map_at_3': 0.53758, 'map_at_5': 0.56293, 'map_at_10': 0.57846, 'map_at_100': 0.58266, 'map_at_1000': 0.58267, 'recall_at_1': 0.41465, 'recall_at_3': 0.69844, 'recall_at_5': 0.80868, 'recall_at_10': 0.92248, 'recall_at_100': 0.9936, 'recall_at_1000': 0.99644, 'precision_at_1': 0.41465, 'precision_at_3': 0.23281, 'precision_at_5': 0.16174, 'precision_at_10': 0.09225, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.42319, 'mrr_at_3': 0.54113, 'mrr_at_5': 0.56574, 'mrr_at_10': 0.58139, 'mrr_at_100': 0.58559, 'mrr_at_1000': 0.5856, 'evaluation_time': 61.79}
Clustering:  68%|██████▊   | 21/31 [12:47<07:10, 43.01s/it]INFO:main:Running task: SciFact
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [12:53<04:46, 31.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model cohere$gte-large$mixed-bread$voyage for task AskUbuntuDupQuestions
Loading cohere from cache for AskUbuntuDupQuestions...
Loading gte-large from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
Creating model cohere$flag-embedding$gist$mixed-bread for task SciFact
Loading cohere from cache for SciFact...
Loading flag-embedding from cache for SciFact...
Loading gist from cache for SciFact...
Loading mixed-bread from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s] 68%|██████▊   | 3524/5183 [00:00<00:00, 35233.57it/s]100%|██████████| 5183/5183 [00:00<00:00, 37435.21it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:faiss.loader:Loading faiss.
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:faiss.loader:Successfully loaded faiss.
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 4.32 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6399290327284006, 'mrr': 0.7706470122675109, 'evaluation_time': 4.32}
INFO:main:Running task: SciFact
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$gte-large$mixed-bread$voyage for task SciFact
Loading cohere from cache for SciFact...
Loading gte-large from cache for SciFact...
Loading mixed-bread from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [13:12<03:42, 27.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s] 82%|████████▏ | 4228/5183 [00:00<00:00, 42270.77it/s]100%|██████████| 5183/5183 [00:00<00:00, 43996.08it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:faiss.loader:Loading faiss.
INFO:faiss.loader:Successfully loaded faiss.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 15.54 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.6400
INFO:root:NDCG@3: 0.6995
INFO:root:NDCG@5: 0.7264
INFO:root:NDCG@10: 0.7515
INFO:root:NDCG@100: 0.7740
INFO:root:NDCG@1000: 0.7770
INFO:root:

INFO:root:MAP@1: 0.6136
INFO:root:MAP@3: 0.6770
INFO:root:MAP@5: 0.6946
INFO:root:MAP@10: 0.7075
INFO:root:MAP@100: 0.7131
INFO:root:MAP@1000: 0.7133
INFO:root:

INFO:root:Recall@1: 0.6136
INFO:root:Recall@3: 0.7374
INFO:root:Recall@5: 0.8058
INFO:root:Recall@10: 0.8776
INFO:root:Recall@100: 0.9783
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6400
INFO:root:P@3: 0.2711
INFO:root:P@5: 0.1807
INFO:root:P@10: 0.0993
INFO:root:P@100: 0.0111
INFO:root:P@1000: 0.0011
INFO:root:

INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:root:MRR@1: 0.6400
INFO:root:MRR@3: 0.6922
INFO:root:MRR@5: 0.7077
INFO:root:MRR@10: 0.7161
INFO:root:MRR@100: 0.7203
INFO:root:MRR@1000: 0.7204
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 23.38 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.64, 'ndcg_at_3': 0.69952, 'ndcg_at_5': 0.72642, 'ndcg_at_10': 0.75147, 'ndcg_at_100': 0.77403, 'ndcg_at_1000': 0.77699, 'map_at_1': 0.61361, 'map_at_3': 0.67702, 'map_at_5': 0.69459, 'map_at_10': 0.70746, 'map_at_100': 0.71314, 'map_at_1000': 0.71328, 'recall_at_1': 0.61361, 'recall_at_3': 0.73739, 'recall_at_5': 0.80578, 'recall_at_10': 0.87756, 'recall_at_100': 0.97833, 'recall_at_1000': 1.0, 'precision_at_1': 0.64, 'precision_at_3': 0.27111, 'precision_at_5': 0.18067, 'precision_at_10': 0.09933, 'precision_at_100': 0.01107, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.64, 'mrr_at_3': 0.69222, 'mrr_at_5': 0.70772, 'mrr_at_10': 0.71611, 'mrr_at_100': 0.72029, 'mrr_at_1000': 0.72042, 'evaluation_time': 23.38}
Clustering:  77%|███████▋  | 24/31 [13:23<02:40, 22.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:main:Running task: EmotionClassification
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 8.64 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.6400
INFO:root:NDCG@3: 0.7056
INFO:root:NDCG@5: 0.7360
INFO:root:NDCG@10: 0.7572
INFO:root:NDCG@100: 0.7748
INFO:root:NDCG@1000: 0.7787
INFO:root:

INFO:root:MAP@1: 0.6109
INFO:root:MAP@3: 0.6789
INFO:root:MAP@5: 0.7001
INFO:root:MAP@10: 0.7103
INFO:root:MAP@100: 0.7146
INFO:root:MAP@1000: 0.7148
INFO:root:

INFO:root:Recall@1: 0.6109
INFO:root:Recall@3: 0.7535
INFO:root:Recall@5: 0.8286
INFO:root:Recall@10: 0.8916
INFO:root:Recall@100: 0.9717
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6400
INFO:root:P@3: 0.2767
INFO:root:P@5: 0.1860
INFO:root:P@10: 0.1010
INFO:root:P@100: 0.0110
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6400
INFO:root:MRR@3: 0.6961
INFO:root:MRR@5: 0.7124
INFO:root:MRR@10: 0.7197
INFO:root:MRR@100: 0.7227
INFO:root:MRR@1000: 0.7229
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 12.13 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.64, 'ndcg_at_3': 0.70556, 'ndcg_at_5': 0.736, 'ndcg_at_10': 0.75716, 'ndcg_at_100': 0.77482, 'ndcg_at_1000': 0.77873, 'map_at_1': 0.61094, 'map_at_3': 0.67893, 'map_at_5': 0.70011, 'map_at_10': 0.71027, 'map_at_100': 0.71459, 'map_at_1000': 0.71478, 'recall_at_1': 0.61094, 'recall_at_3': 0.7535, 'recall_at_5': 0.82856, 'recall_at_10': 0.89156, 'recall_at_100': 0.97167, 'recall_at_1000': 1.0, 'precision_at_1': 0.64, 'precision_at_3': 0.27667, 'precision_at_5': 0.186, 'precision_at_10': 0.101, 'precision_at_100': 0.011, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.64, 'mrr_at_3': 0.69611, 'mrr_at_5': 0.71244, 'mrr_at_10': 0.71965, 'mrr_at_100': 0.72269, 'mrr_at_1000': 0.72287, 'evaluation_time': 12.13}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [13:39<02:04, 20.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [13:44<01:20, 16.08s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist$mixed-bread for task EmotionClassification
Loading cohere from cache for EmotionClassification...
Loading flag-embedding from cache for EmotionClassification...
Loading gist from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$gte-large$mixed-bread$voyage for task EmotionClassification
Loading cohere from cache for EmotionClassification...
Loading gte-large from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [13:58<01:01, 15.49s/it]Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [14:29<01:00, 20.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
Clustering:  94%|█████████▎| 29/31 [14:47<00:39, 19.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [15:01<00:17, 17.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [15:46<00:00, 25.98s/it]Clustering: 100%|██████████| 31/31 [15:46<00:00, 30.54s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 946.64 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4339139607350199, 'v_measure_std': 0.14184829026697435, 'evaluation_time': 946.64}
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 110.91 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.56645, 'f1': 0.5049183008608981, 'accuracy_stderr': 0.02089312087745629, 'f1_stderr': 0.012184263530740131, 'main_score': 0.56645, 'evaluation_time': 110.91}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 112.22 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.54545, 'f1': 0.4812285705768472, 'accuracy_stderr': 0.022937360353798338, 'f1_stderr': 0.013327654294347659, 'main_score': 0.54545, 'evaluation_time': 112.22}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model cohere$flag-embedding$gist$mixed-bread for task AmazonCounterfactualClassification
Loading cohere from cache for AmazonCounterfactualClassification...
Loading flag-embedding from cache for AmazonCounterfactualClassification...
Loading gist from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model cohere$gte-large$mixed-bread$voyage for task AmazonCounterfactualClassification
Loading cohere from cache for AmazonCounterfactualClassification...
Loading gte-large from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name gist$llmrails$mixed-bread$voyage
Converting results/gist$llmrails$mixed-bread$voyage to results/gist$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model gte-large$llmrails$mixed-bread$voyage...
Skipping STS17 as it already exists
Creating model gte-large$llmrails$mixed-bread$voyage for task TwitterSemEval2015
Loading gte-large from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
Repo card metadata block was not found. Setting CardData to empty.
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 3.71 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7638805970149254, 'f1': 0.7043437838552438, 'ap': 0.3974324949310566, 'accuracy_stderr': 0.041602988394470075, 'f1_stderr': 0.03890786359347167, 'ap_stderr': 0.0430831406054141, 'main_score': 0.7638805970149254}, 'evaluation_time': 3.71}
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 3.96 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7685074626865671, 'f1': 0.7086261285789709, 'ap': 0.4021972116604851, 'accuracy_stderr': 0.03963775604352167, 'f1_stderr': 0.0387681640167775, 'ap_stderr': 0.045373191484373285, 'main_score': 0.7685074626865671}, 'evaluation_time': 3.96}
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 22.35 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8758419264469214, 'accuracy_threshold': 0.8615376518960087, 'f1': 0.7188857653973934, 'f1_threshold': 0.8454362653182504, 'precision': 0.6969772051536175, 'recall': 0.7422163588390501, 'ap': 0.7868597793471329}, 'manhattan': {'accuracy': 0.8747690290278357, 'accuracy_threshold': 26.19794473996937, 'f1': 0.7158108795119472, 'f1_threshold': 27.81344374863849, 'precision': 0.6905345757724375, 'recall': 0.7430079155672823, 'ap': 0.7834409653502518}, 'euclidean': {'accuracy': 0.8758419264469214, 'accuracy_threshold': 0.5262363499032776, 'f1': 0.7188857653973934, 'f1_threshold': 0.555992328096389, 'precision': 0.6969772051536175, 'recall': 0.7422163588390501, 'ap': 0.7868597793471329}, 'dot': {'accuracy': 0.8758419264469214, 'accuracy_threshold': 0.8615376518960092, 'f1': 0.7188857653973934, 'f1_threshold': 0.8454362653182507, 'precision': 0.6969772051536175, 'recall': 0.7422163588390501, 'ap': 0.7868597793471329}, 'max': {'accuracy': 0.8758419264469214, 'f1': 0.7188857653973934, 'ap': 0.7868597793471329}, 'evaluation_time': 22.35}
INFO:main:Running task: Banking77Classification
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model gte-large$llmrails$mixed-bread$voyage for task AskUbuntuDupQuestions
Loading gte-large from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist$mixed-bread for task Banking77Classification
Loading cohere from cache for Banking77Classification...
Loading flag-embedding from cache for Banking77Classification...
Loading gist from cache for Banking77Classification...
Loading mixed-bread from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$gte-large$mixed-bread$voyage for task Banking77Classification
Loading cohere from cache for Banking77Classification...
Loading gte-large from cache for Banking77Classification...
Loading mixed-bread from cache for Banking77Classification...
Loading voyage from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 10.50 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6507414519189565, 'mrr': 0.7880600624367938, 'evaluation_time': 10.5}
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model gte-large$llmrails$mixed-bread$voyage for task SciFact
Loading gte-large from cache for SciFact...
Loading llmrails from cache for SciFact...
Loading mixed-bread from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
  0%|          | 0/5183 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
 33%|███▎      | 1729/5183 [00:00<00:00, 17282.60it/s]INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
 80%|████████  | 4169/5183 [00:00<00:00, 21463.49it/s]100%|██████████| 5183/5183 [00:00<00:00, 23476.91it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:faiss.loader:Loading faiss.
INFO:faiss.loader:Successfully loaded faiss.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 43.53 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:root:

INFO:root:NDCG@1: 0.6533
INFO:root:NDCG@3: 0.7156
INFO:root:NDCG@5: 0.7368
INFO:root:NDCG@10: 0.7657
INFO:root:NDCG@100: 0.7810
INFO:root:NDCG@1000: 0.7863
INFO:root:

INFO:root:MAP@1: 0.6243
INFO:root:MAP@3: 0.6914
INFO:root:MAP@5: 0.7055
INFO:root:MAP@10: 0.7207
INFO:root:MAP@100: 0.7245
INFO:root:MAP@1000: 0.7248
INFO:root:

INFO:root:Recall@1: 0.6243
INFO:root:Recall@3: 0.7595
INFO:root:Recall@5: 0.8133
INFO:root:Recall@10: 0.8949
INFO:root:Recall@100: 0.9617
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6533
INFO:root:P@3: 0.2778
INFO:root:P@5: 0.1813
INFO:root:P@10: 0.1017
INFO:root:P@100: 0.0109
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6533
INFO:root:MRR@3: 0.7067
INFO:root:MRR@5: 0.7197
INFO:root:MRR@10: 0.7293
INFO:root:MRR@100: 0.7324
INFO:root:MRR@1000: 0.7327
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 53.84 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.65333, 'ndcg_at_3': 0.71558, 'ndcg_at_5': 0.73677, 'ndcg_at_10': 0.76574, 'ndcg_at_100': 0.78101, 'ndcg_at_1000': 0.78635, 'map_at_1': 0.62428, 'map_at_3': 0.69135, 'map_at_5': 0.70545, 'map_at_10': 0.72073, 'map_at_100': 0.72449, 'map_at_1000': 0.72477, 'recall_at_1': 0.62428, 'recall_at_3': 0.7595, 'recall_at_5': 0.81328, 'recall_at_10': 0.89489, 'recall_at_100': 0.96167, 'recall_at_1000': 1.0, 'precision_at_1': 0.65333, 'precision_at_3': 0.27778, 'precision_at_5': 0.18133, 'precision_at_10': 0.10167, 'precision_at_100': 0.0109, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.65333, 'mrr_at_3': 0.70667, 'mrr_at_5': 0.71967, 'mrr_at_10': 0.72927, 'mrr_at_100': 0.7324, 'mrr_at_1000': 0.73265, 'evaluation_time': 53.84}
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 111.14 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8342207792207793, 'f1': 0.8271270108472818, 'accuracy_stderr': 0.006311073670035212, 'f1_stderr': 0.00694399349547197, 'main_score': 0.8342207792207793, 'evaluation_time': 111.14}
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 111.41 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8547402597402597, 'f1': 0.8497805746187218, 'accuracy_stderr': 0.004932928450729533, 'f1_stderr': 0.005785791435438063, 'main_score': 0.8547402597402597, 'evaluation_time': 111.41}
INFO:main:Running task: ArguAna
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model gte-large$llmrails$mixed-bread$voyage for task EmotionClassification
Loading gte-large from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist$mixed-bread for task ArguAna
Loading cohere from cache for ArguAna...
Loading flag-embedding from cache for ArguAna...
Loading gist from cache for ArguAna...
Loading mixed-bread from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 32.14 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5429499999999999, 'f1': 0.4746760424706026, 'accuracy_stderr': 0.024474936159263015, 'f1_stderr': 0.014144974206431805, 'main_score': 0.5429499999999999, 'evaluation_time': 32.14}
INFO:beir.datasets.data_loader:Loading Corpus...
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$gte-large$mixed-bread$voyage for task ArguAna
Loading cohere from cache for ArguAna...
Loading gte-large from cache for ArguAna...
Loading mixed-bread from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s]  0%|          | 0/8674 [00:00<?, ?it/s] 53%|█████▎    | 4637/8674 [00:00<00:00, 46359.43it/s] 13%|█▎        | 1170/8674 [00:00<00:00, 11695.86it/s] 66%|██████▌   | 5687/8674 [00:00<00:00, 31381.56it/s]100%|██████████| 8674/8674 [00:00<00:00, 41829.91it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
100%|██████████| 8674/8674 [00:00<00:00, 32814.22it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model gte-large$llmrails$mixed-bread$voyage for task AmazonCounterfactualClassification
Loading gte-large from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
INFO:main:Running task: TwitterSemEval2015
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 59.05 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 59.14 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.3428
INFO:root:NDCG@3: 0.5100
INFO:root:NDCG@5: 0.5643
INFO:root:NDCG@10: 0.6053
INFO:root:NDCG@100: 0.6302
INFO:root:NDCG@1000: 0.6306
INFO:root:

INFO:root:MAP@1: 0.3428
INFO:root:MAP@3: 0.4687
INFO:root:MAP@5: 0.4985
INFO:root:MAP@10: 0.5154
INFO:root:MAP@100: 0.5218
INFO:root:MAP@1000: 0.5218
INFO:root:

INFO:root:Recall@1: 0.3428
INFO:root:Recall@3: 0.6294
INFO:root:Recall@5: 0.7624
INFO:root:Recall@10: 0.8898
INFO:root:Recall@100: 0.9936
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.3428
INFO:root:P@3: 0.2098
INFO:root:P@5: 0.1525
INFO:root:P@10: 0.0890
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:root:NDCG@1: 0.3805
INFO:root:NDCG@3: 0.5498
INFO:root:NDCG@5: 0.5984
INFO:root:NDCG@10: 0.6368
INFO:root:NDCG@100: 0.6576
INFO:root:NDCG@1000: 0.6580
INFO:root:

INFO:root:MAP@1: 0.3805
INFO:root:MAP@3: 0.5081
INFO:root:MAP@5: 0.5352
INFO:root:MAP@10: 0.5511
INFO:root:MAP@100: 0.5564
INFO:root:MAP@1000: 0.5564
INFO:root:

INFO:root:Recall@1: 0.3805
INFO:root:Recall@3: 0.6707
INFO:root:Recall@5: 0.7881
INFO:root:Recall@10: 0.9061
INFO:root:Recall@100: 0.9936
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.3805
INFO:root:P@3: 0.2236
INFO:root:P@5: 0.1576
INFO:root:P@10: 0.0906
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:root:

INFO:root:MRR@1: 0.3876
INFO:root:MRR@3: 0.5105
INFO:root:MRR@5: 0.5377
INFO:root:MRR@10: 0.5540
INFO:root:MRR@100: 0.5592
INFO:root:MRR@1000: 0.5592
INFO:root:MRR@1: 0.3513
INFO:root:MRR@3: 0.4719
INFO:root:MRR@5: 0.5015
INFO:root:MRR@10: 0.5185
INFO:root:MRR@100: 0.5249
INFO:root:MRR@1000: 0.5249
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 62.07 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.38051, 'ndcg_at_3': 0.54982, 'ndcg_at_5': 0.59843, 'ndcg_at_10': 0.63675, 'ndcg_at_100': 0.65765, 'ndcg_at_1000': 0.65803, 'map_at_1': 0.38051, 'map_at_3': 0.50806, 'map_at_5': 0.53519, 'map_at_10': 0.55109, 'map_at_100': 0.55638, 'map_at_1000': 0.5564, 'recall_at_1': 0.38051, 'recall_at_3': 0.6707, 'recall_at_5': 0.78805, 'recall_at_10': 0.90612, 'recall_at_100': 0.9936, 'recall_at_1000': 0.99644, 'precision_at_1': 0.38051, 'precision_at_3': 0.22357, 'precision_at_5': 0.15761, 'precision_at_10': 0.09061, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.38762, 'mrr_at_3': 0.51055, 'mrr_at_5': 0.53775, 'mrr_at_10': 0.55397, 'mrr_at_100': 0.55919, 'mrr_at_1000': 0.55921, 'evaluation_time': 62.07}
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 62.11 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.34282, 'ndcg_at_3': 0.50997, 'ndcg_at_5': 0.56426, 'ndcg_at_10': 0.60532, 'ndcg_at_100': 0.63022, 'ndcg_at_1000': 0.6306, 'map_at_1': 0.34282, 'map_at_3': 0.46871, 'map_at_5': 0.49854, 'map_at_10': 0.51544, 'map_at_100': 0.52176, 'map_at_1000': 0.52178, 'recall_at_1': 0.34282, 'recall_at_3': 0.62945, 'recall_at_5': 0.76245, 'recall_at_10': 0.88976, 'recall_at_100': 0.9936, 'recall_at_1000': 0.99644, 'precision_at_1': 0.34282, 'precision_at_3': 0.20982, 'precision_at_5': 0.15249, 'precision_at_10': 0.08898, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.35135, 'mrr_at_3': 0.47191, 'mrr_at_5': 0.50153, 'mrr_at_10': 0.51849, 'mrr_at_100': 0.52488, 'mrr_at_1000': 0.5249, 'evaluation_time': 62.11}
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gte-large$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist$llmrails$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 4.44 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7347761194029852, 'f1': 0.6744538766110573, 'ap': 0.3622896016469557, 'accuracy_stderr': 0.03832102268577485, 'f1_stderr': 0.03617967233857537, 'ap_stderr': 0.037480321599414515, 'main_score': 0.7347761194029852}, 'evaluation_time': 4.44}
INFO:main:Running task: Banking77Classification
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:37<18:49, 37.66s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:53<12:04, 25.00s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [01:06<09:03, 19.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model gte-large$llmrails$mixed-bread$voyage for task Banking77Classification
Loading gte-large from cache for Banking77Classification...
Loading llmrails from cache for Banking77Classification...
Loading mixed-bread from cache for Banking77Classification...
Loading voyage from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
Evaluating the model angle$gist$gte-large$llmrails$mixed-bread...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$gist$gte-large$llmrails$mixed-bread
Converting results/angle$gist$gte-large$llmrails$mixed-bread to results/angle$gist$gte-large$llmrails$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$gist$gte-large$llmrails$voyage...
Skipping STS17 as it already exists
Creating model angle$gist$gte-large$llmrails$voyage for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
Loading gte-large from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:30<09:32, 21.20s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [01:43<51:32, 103.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
Clustering:   3%|▎         | 1/31 [02:07<1:03:34, 127.15s/it]
ERROR:mteb.evaluation.MTEB:Error while evaluating ArxivClusteringS2S: Unable to allocate 977. MiB for an array with shape (25000, 5120) and data type float64
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
Clustering:  16%|█▌        | 5/31 [02:08<11:47, 27.21s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 51.41 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.87453060737915, 'accuracy_threshold': 0.8497544251698781, 'f1': 0.7165966118965736, 'f1_threshold': 0.8317715188142989, 'precision': 0.6926865304112287, 'recall': 0.7422163588390501, 'ap': 0.7829279350191634}, 'manhattan': {'accuracy': 0.8744113965548072, 'accuracy_threshold': 30.574479261672355, 'f1': 0.7165561256413465, 'f1_threshold': 32.258775256504364, 'precision': 0.6815044037134016, 'recall': 0.7554089709762533, 'ap': 0.7816264246926737}, 'euclidean': {'accuracy': 0.87453060737915, 'accuracy_threshold': 0.5481707303903531, 'f1': 0.7165966118965736, 'f1_threshold': 0.5800491028243104, 'precision': 0.6926865304112287, 'recall': 0.7422163588390501, 'ap': 0.7829279350191634}, 'dot': {'accuracy': 0.87453060737915, 'accuracy_threshold': 0.8497544251698783, 'f1': 0.7165966118965736, 'f1_threshold': 0.8317715188142994, 'precision': 0.6926865304112287, 'recall': 0.7422163588390501, 'ap': 0.7829279350191634}, 'max': {'accuracy': 0.87453060737915, 'f1': 0.7165966118965736, 'ap': 0.7829279350191634}, 'evaluation_time': 51.41}
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model angle$gist$gte-large$llmrails$voyage for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
Loading gte-large from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
Evaluating the model cohere$flag-embedding$gist$llmrails$mixed-bread...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model cohere$flag-embedding$gist$llmrails$mixed-bread for task AskUbuntuDupQuestions
Loading cohere from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 78.11 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8425649350649351, 'f1': 0.8353641525751299, 'accuracy_stderr': 0.004588042603333699, 'f1_stderr': 0.0054932376368843515, 'main_score': 0.8425649350649351, 'evaluation_time': 78.11}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [02:35<11:19, 27.19s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 10.50 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6466936999580202, 'mrr': 0.7812656641604011, 'evaluation_time': 10.5}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 5.01 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6460346638975122, 'mrr': 0.7771501121224113, 'evaluation_time': 5.01}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model gte-large$llmrails$mixed-bread$voyage for task ArguAna
Loading gte-large from cache for ArguAna...
Loading llmrails from cache for ArguAna...
Loading mixed-bread from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s] 16%|█▋        | 1424/8674 [00:00<00:00, 10709.96it/s] 65%|██████▌   | 5655/8674 [00:00<00:00, 27074.59it/s]100%|██████████| 8674/8674 [00:00<00:00, 29221.16it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [02:48<09:01, 22.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist$gte-large$llmrails$voyage for task SciFact
Loading angle from cache for SciFact...
Loading gist from cache for SciFact...
Loading gte-large from cache for SciFact...
Loading llmrails from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s] 68%|██████▊   | 3545/5183 [00:00<00:00, 35437.87it/s]100%|██████████| 5183/5183 [00:00<00:00, 37836.64it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:faiss.loader:Loading faiss.
INFO:faiss.loader:Successfully loaded faiss.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [03:00<07:23, 19.30s/it]/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 24.89 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.4132
INFO:root:NDCG@3: 0.5789
INFO:root:NDCG@5: 0.6240
INFO:root:NDCG@10: 0.6592
INFO:root:NDCG@100: 0.6776
INFO:root:NDCG@1000: 0.6780
INFO:root:

INFO:root:MAP@1: 0.4132
INFO:root:MAP@3: 0.5375
INFO:root:MAP@5: 0.5626
INFO:root:MAP@10: 0.5772
INFO:root:MAP@100: 0.5819
INFO:root:MAP@1000: 0.5819
INFO:root:

INFO:root:Recall@1: 0.4132
INFO:root:Recall@3: 0.6992
INFO:root:Recall@5: 0.8080
INFO:root:Recall@10: 0.9168
INFO:root:Recall@100: 0.9936
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.4132
INFO:root:P@3: 0.2331
INFO:root:P@5: 0.1616
INFO:root:P@10: 0.0917
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.4210
INFO:root:MRR@3: 0.5407
INFO:root:MRR@5: 0.5652
INFO:root:MRR@10: 0.5799
INFO:root:MRR@100: 0.5846
INFO:root:MRR@1000: 0.5846
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 27.35 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.41323, 'ndcg_at_3': 0.57891, 'ndcg_at_5': 0.62397, 'ndcg_at_10': 0.65922, 'ndcg_at_100': 0.67761, 'ndcg_at_1000': 0.678, 'map_at_1': 0.41323, 'map_at_3': 0.53746, 'map_at_5': 0.5626, 'map_at_10': 0.57719, 'map_at_100': 0.58191, 'map_at_1000': 0.58193, 'recall_at_1': 0.41323, 'recall_at_3': 0.69915, 'recall_at_5': 0.80797, 'recall_at_10': 0.91679, 'recall_at_100': 0.9936, 'recall_at_1000': 0.99644, 'precision_at_1': 0.41323, 'precision_at_3': 0.23305, 'precision_at_5': 0.16159, 'precision_at_10': 0.09168, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.42105, 'mrr_at_3': 0.54066, 'mrr_at_5': 0.56523, 'mrr_at_10': 0.5799, 'mrr_at_100': 0.58455, 'mrr_at_1000': 0.58456, 'evaluation_time': 27.35}
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 16.49 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.6467
INFO:root:NDCG@3: 0.7079
INFO:root:NDCG@5: 0.7334
INFO:root:NDCG@10: 0.7586
INFO:root:NDCG@100: 0.7762
INFO:root:NDCG@1000: 0.7810
INFO:root:

INFO:root:MAP@1: 0.6176
INFO:root:MAP@3: 0.6833
INFO:root:MAP@5: 0.6999
INFO:root:MAP@10: 0.7132
INFO:root:MAP@100: 0.7177
INFO:root:MAP@1000: 0.7179
INFO:root:

INFO:root:Recall@1: 0.6176
INFO:root:Recall@3: 0.7528
INFO:root:Recall@5: 0.8166
INFO:root:Recall@10: 0.8882
INFO:root:Recall@100: 0.9650
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6467
INFO:root:P@3: 0.2756
INFO:root:P@5: 0.1827
INFO:root:P@10: 0.1007
INFO:root:P@100: 0.0109
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6467
INFO:root:MRR@3: 0.6989
INFO:root:MRR@5: 0.7141
INFO:root:MRR@10: 0.7226
INFO:root:MRR@100: 0.7259
INFO:root:MRR@1000: 0.7261
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 22.97 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.64667, 'ndcg_at_3': 0.70787, 'ndcg_at_5': 0.73337, 'ndcg_at_10': 0.75856, 'ndcg_at_100': 0.77618, 'ndcg_at_1000': 0.78104, 'map_at_1': 0.61761, 'map_at_3': 0.6833, 'map_at_5': 0.6999, 'map_at_10': 0.71316, 'map_at_100': 0.71767, 'map_at_1000': 0.71792, 'recall_at_1': 0.61761, 'recall_at_3': 0.75283, 'recall_at_5': 0.81661, 'recall_at_10': 0.88822, 'recall_at_100': 0.965, 'recall_at_1000': 1.0, 'precision_at_1': 0.64667, 'precision_at_3': 0.27556, 'precision_at_5': 0.18267, 'precision_at_10': 0.10067, 'precision_at_100': 0.01093, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.64667, 'mrr_at_3': 0.69889, 'mrr_at_5': 0.71406, 'mrr_at_10': 0.72256, 'mrr_at_100': 0.72587, 'mrr_at_1000': 0.7261, 'evaluation_time': 22.97}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [03:20<07:08, 19.49s/it]INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [03:36<06:23, 18.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [04:25<09:13, 27.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [04:51<08:36, 27.17s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist$gte-large$llmrails$voyage for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading gist from cache for EmotionClassification...
Loading gte-large from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
Clustering:  42%|████▏     | 13/31 [05:47<10:48, 36.04s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 76.08 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5620499999999999, 'f1': 0.4983485389079053, 'accuracy_stderr': 0.02016612258219216, 'f1_stderr': 0.011533505552037956, 'main_score': 0.5620499999999999, 'evaluation_time': 76.08}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [06:55<12:54, 45.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model angle$gist$gte-large$llmrails$voyage for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading gist from cache for AmazonCounterfactualClassification...
Loading gte-large from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 3.13 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7443283582089553, 'f1': 0.682817350153285, 'ap': 0.3700913510591428, 'accuracy_stderr': 0.03669365876347925, 'f1_stderr': 0.034929293409798445, 'ap_stderr': 0.036860053352686536, 'main_score': 0.7443283582089553}, 'evaluation_time': 3.13}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [07:24<10:48, 40.54s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist$gte-large$llmrails$voyage for task Banking77Classification
Loading angle from cache for Banking77Classification...
Loading gist from cache for Banking77Classification...
Loading gte-large from cache for Banking77Classification...
Loading llmrails from cache for Banking77Classification...
Loading voyage from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [07:51<09:08, 36.58s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Clustering:  52%|█████▏    | 16/31 [08:02<07:32, 30.14s/it]
ERROR:mteb.evaluation.MTEB:Error while evaluating ArxivClusteringS2S: Unable to allocate 781. MiB for an array with shape (25000, 4096) and data type float64
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 59.68 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8493831168831167, 'f1': 0.8432975654095826, 'accuracy_stderr': 0.0036079887841128843, 'f1_stderr': 0.004731079245713634, 'main_score': 0.8493831168831167, 'evaluation_time': 59.68}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist$gte-large$llmrails$voyage for task ArguAna
Loading angle from cache for ArguAna...
Loading gist from cache for ArguAna...
Loading gte-large from cache for ArguAna...
Loading llmrails from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s] 54%|█████▍    | 4671/8674 [00:00<00:00, 46696.91it/s]100%|██████████| 8674/8674 [00:00<00:00, 40594.54it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 31.04 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.4018
INFO:root:NDCG@3: 0.5668
INFO:root:NDCG@5: 0.6153
INFO:root:NDCG@10: 0.6506
INFO:root:NDCG@100: 0.6698
INFO:root:NDCG@1000: 0.6703
INFO:root:

INFO:root:MAP@1: 0.4018
INFO:root:MAP@3: 0.5251
INFO:root:MAP@5: 0.5522
INFO:root:MAP@10: 0.5669
INFO:root:MAP@100: 0.5719
INFO:root:MAP@1000: 0.5719
INFO:root:

INFO:root:Recall@1: 0.4018
INFO:root:Recall@3: 0.6878
INFO:root:Recall@5: 0.8051
INFO:root:Recall@10: 0.9132
INFO:root:Recall@100: 0.9929
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.4018
INFO:root:P@3: 0.2293
INFO:root:P@5: 0.1610
INFO:root:P@10: 0.0913
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.4097
INFO:root:MRR@3: 0.5284
INFO:root:MRR@5: 0.5549
INFO:root:MRR@10: 0.5699
INFO:root:MRR@100: 0.5747
INFO:root:MRR@1000: 0.5748
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 33.81 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.40185, 'ndcg_at_3': 0.56678, 'ndcg_at_5': 0.6153, 'ndcg_at_10': 0.65058, 'ndcg_at_100': 0.66981, 'ndcg_at_1000': 0.6703, 'map_at_1': 0.40185, 'map_at_3': 0.52513, 'map_at_5': 0.55216, 'map_at_10': 0.5669, 'map_at_100': 0.57188, 'map_at_1000': 0.57191, 'recall_at_1': 0.40185, 'recall_at_3': 0.68777, 'recall_at_5': 0.80512, 'recall_at_10': 0.91323, 'recall_at_100': 0.99289, 'recall_at_1000': 0.99644, 'precision_at_1': 0.40185, 'precision_at_3': 0.22926, 'precision_at_5': 0.16102, 'precision_at_10': 0.09132, 'precision_at_100': 0.00993, 'precision_at_1000': 0.001, 'mrr_at_1': 0.40967, 'mrr_at_3': 0.52845, 'mrr_at_5': 0.55491, 'mrr_at_10': 0.5699, 'mrr_at_100': 0.57474, 'mrr_at_1000': 0.57477, 'evaluation_time': 33.81}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model cohere$gist$gte-large$llmrails$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name cohere$gist$gte-large$llmrails$voyage
Converting results/cohere$gist$gte-large$llmrails$voyage to results/cohere$gist$gte-large$llmrails$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$gist$gte-large$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name cohere$gist$gte-large$mixed-bread$voyage
Converting results/cohere$gist$gte-large$mixed-bread$voyage to results/cohere$gist$gte-large$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$gist$llmrails$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name cohere$gist$llmrails$mixed-bread$voyage
Converting results/cohere$gist$llmrails$mixed-bread$voyage to results/cohere$gist$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$gte-large$llmrails$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name cohere$gte-large$llmrails$mixed-bread$voyage
Converting results/cohere$gte-large$llmrails$mixed-bread$voyage to results/cohere$gte-large$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model flag-embedding$gist$gte-large$llmrails$mixed-bread...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name flag-embedding$gist$gte-large$llmrails$mixed-bread
Converting results/flag-embedding$gist$gte-large$llmrails$mixed-bread to results/flag-embedding$gist$gte-large$llmrails$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model flag-embedding$gist$gte-large$llmrails$voyage...
Skipping STS17 as it already exists
Creating model flag-embedding$gist$gte-large$llmrails$voyage for task TwitterSemEval2015
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
Loading gte-large from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
ERROR:mteb.evaluation.MTEB:Error while evaluating TwitterSemEval2015: Unable to allocate 655. MiB for an array with shape (16777, 5120) and data type float64
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$gist$llmrails$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading cohere from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:   0%|          | 0/31 [00:06<?, ?it/s]
ERROR:mteb.evaluation.MTEB:Error while evaluating ArxivClusteringS2S: Unable to allocate 391. MiB for an array with shape (25000, 2048) and data type float64
Evaluating the model angle$flag-embedding$gist$gte-large$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Creating model angle$flag-embedding$gist$gte-large$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist$mixed-bread for task ArxivClusteringS2S
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
Evaluating the model flag-embedding$gte-large$llmrails$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name flag-embedding$gte-large$llmrails$mixed-bread$voyage
Converting results/flag-embedding$gte-large$llmrails$mixed-bread$voyage to results/flag-embedding$gte-large$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model gist$gte-large$llmrails$mixed-bread$voyage...
Skipping STS17 as it already exists
Creating model gist$gte-large$llmrails$mixed-bread$voyage for task TwitterSemEval2015
Loading gist from cache for TwitterSemEval2015...
Loading gte-large from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Creating model cohere$flag-embedding$gist$llmrails$mixed-bread for task ArxivClusteringS2S
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:46<23:12, 46.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [01:01<13:36, 28.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [01:14<09:48, 21.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$gte-large$mixed-bread$voyage for task ArxivClusteringS2S
Loading cohere from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 26.50 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.87494784526435, 'accuracy_threshold': 0.8477876435309786, 'f1': 0.7203411734298267, 'f1_threshold': 0.8324247791820718, 'precision': 0.7059270516717325, 'recall': 0.7353562005277045, 'ap': 0.78653486100707}, 'manhattan': {'accuracy': 0.8742921857304643, 'accuracy_threshold': 30.113270931917423, 'f1': 0.7171615500754907, 'f1_threshold': 32.21401090437323, 'precision': 0.6854256854256854, 'recall': 0.7519788918205804, 'ap': 0.7840175759144388}, 'euclidean': {'accuracy': 0.87494784526435, 'accuracy_threshold': 0.5517469645931163, 'f1': 0.7203411734298267, 'f1_threshold': 0.5789217903848553, 'precision': 0.7059270516717325, 'recall': 0.7353562005277045, 'ap': 0.78653486100707}, 'dot': {'accuracy': 0.87494784526435, 'accuracy_threshold': 0.8477876435309795, 'f1': 0.7203411734298267, 'f1_threshold': 0.8324247791820722, 'precision': 0.7059270516717325, 'recall': 0.7353562005277045, 'ap': 0.78653486100707}, 'max': {'accuracy': 0.87494784526435, 'f1': 0.7203411734298267, 'ap': 0.78653486100707}, 'evaluation_time': 26.5}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model gte-large$llmrails$mixed-bread$voyage for task ArxivClusteringS2S
Loading gte-large from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:30<15:05, 30.17s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:31<15:36, 31.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:28<08:13, 18.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:48<11:10, 23.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [01:41<07:10, 16.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:51<12:03, 24.96s/it]Clustering:   0%|          | 0/31 [00:00<?, ?it/s]Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model gist$gte-large$llmrails$mixed-bread$voyage for task AskUbuntuDupQuestions
Loading gist from cache for AskUbuntuDupQuestions...
Loading gte-large from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread
Converting results/angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread to results/angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$gte-large$llmrails$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gte-large$llmrails$voyage
Converting results/angle$cohere$flag-embedding$gte-large$llmrails$voyage to results/angle$cohere$flag-embedding$gte-large$llmrails$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$gte-large$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gte-large$mixed-bread$voyage
Converting results/angle$cohere$flag-embedding$gte-large$mixed-bread$voyage to results/angle$cohere$flag-embedding$gte-large$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$llmrails$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$llmrails$mixed-bread$voyage
Converting results/angle$cohere$flag-embedding$llmrails$mixed-bread$voyage to results/angle$cohere$flag-embedding$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$gist$gte-large$llmrails$mixed-bread...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$gist$gte-large$llmrails$mixed-bread
Converting results/angle$cohere$gist$gte-large$llmrails$mixed-bread to results/angle$cohere$gist$gte-large$llmrails$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$gist$gte-large$llmrails$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model angle$cohere$gist$gte-large$llmrails$voyage for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading cohere from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
Loading gte-large from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [02:02<07:25, 17.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:20<10:18, 20.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:23<11:56, 23.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [01:18<11:55, 25.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 19.64 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.647615265869929, 'mrr': 0.7794794002550235, 'evaluation_time': 19.64}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 18.60 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6460342327799892, 'mrr': 0.7806544870949303, 'evaluation_time': 18.6}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [01:20<12:39, 27.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [02:18<06:55, 17.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:35<08:27, 17.52s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:38<09:01, 18.66s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:37<10:26, 23.19s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:40<10:53, 24.22s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [02:33<06:19, 16.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:50<07:35, 16.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model gist$gte-large$llmrails$mixed-bread$voyage for task SciFact
Loading gist from cache for SciFact...
Loading gte-large from cache for SciFact...
Loading llmrails from cache for SciFact...
Loading mixed-bread from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
Clustering:  10%|▉         | 3/31 [00:53<07:53, 16.90s/it]INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
  0%|          | 0/5183 [00:00<?, ?it/s] 78%|███████▊  | 4029/5183 [00:00<00:00, 40277.75it/s]100%|██████████| 5183/5183 [00:00<00:00, 41471.20it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$gist$gte-large$llmrails$voyage for task SciFact
Loading angle from cache for SciFact...
Loading cohere from cache for SciFact...
Loading gist from cache for SciFact...
Loading gte-large from cache for SciFact...
Loading llmrails from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s] 87%|████████▋ | 4525/5183 [00:00<00:00, 45234.41it/s]100%|██████████| 5183/5183 [00:00<00:00, 44960.97it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:faiss.loader:Loading faiss.
INFO:faiss.loader:Loading faiss.
INFO:faiss.loader:Successfully loaded faiss.
INFO:faiss.loader:Successfully loaded faiss.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [02:54<06:33, 17.88s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:09<07:44, 17.19s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [02:04<10:32, 24.34s/it]Clustering:  16%|█▌        | 5/31 [02:03<10:26, 24.09s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 19.36 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 19.36 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.6433
INFO:root:NDCG@3: 0.7050
INFO:root:NDCG@5: 0.7342
INFO:root:NDCG@10: 0.7613
INFO:root:NDCG@100: 0.7775
INFO:root:NDCG@1000: 0.7815
INFO:root:

INFO:root:MAP@1: 0.6143
INFO:root:MAP@3: 0.6811
INFO:root:MAP@5: 0.7001
INFO:root:MAP@10: 0.7140
INFO:root:MAP@100: 0.7179
INFO:root:MAP@1000: 0.7182
INFO:root:

INFO:root:Recall@1: 0.6143
INFO:root:Recall@3: 0.7478
INFO:root:Recall@5: 0.8199
INFO:root:Recall@10: 0.8982
INFO:root:Recall@100: 0.9717
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6433
INFO:root:P@3: 0.2744
INFO:root:P@5: 0.1833
INFO:root:P@10: 0.1017
INFO:root:P@100: 0.0110
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:

INFO:root:NDCG@1: 0.6600
INFO:root:NDCG@3: 0.7120
INFO:root:NDCG@5: 0.7365
INFO:root:NDCG@10: 0.7670
INFO:root:NDCG@100: 0.7820
INFO:root:NDCG@1000: 0.7868
INFO:root:

INFO:root:MAP@1: 0.6309
INFO:root:MAP@3: 0.6900
INFO:root:MAP@5: 0.7063
INFO:root:MAP@10: 0.7216
INFO:root:MAP@100: 0.7254
INFO:root:MAP@1000: 0.7256
INFO:root:

INFO:root:Recall@1: 0.6309
INFO:root:Recall@3: 0.7495
INFO:root:Recall@5: 0.8099
INFO:root:Recall@10: 0.8982
INFO:root:Recall@100: 0.9650
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6600
INFO:root:P@3: 0.2744
INFO:root:P@5: 0.1813
INFO:root:P@10: 0.1017
INFO:root:P@100: 0.0109
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6433
INFO:root:MRR@3: 0.6967
INFO:root:MRR@5: 0.7137
INFO:root:MRR@10: 0.7229
INFO:root:MRR@100: 0.7256
INFO:root:MRR@1000: 0.7258
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 20.42 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.64333, 'ndcg_at_3': 0.70504, 'ndcg_at_5': 0.7342, 'ndcg_at_10': 0.76135, 'ndcg_at_100': 0.77754, 'ndcg_at_1000': 0.7815, 'map_at_1': 0.61428, 'map_at_3': 0.68107, 'map_at_5': 0.70009, 'map_at_10': 0.71403, 'map_at_100': 0.71795, 'map_at_1000': 0.71816, 'recall_at_1': 0.61428, 'recall_at_3': 0.74783, 'recall_at_5': 0.81994, 'recall_at_10': 0.89822, 'recall_at_100': 0.97167, 'recall_at_1000': 1.0, 'precision_at_1': 0.64333, 'precision_at_3': 0.27444, 'precision_at_5': 0.18333, 'precision_at_10': 0.10167, 'precision_at_100': 0.011, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.64333, 'mrr_at_3': 0.69667, 'mrr_at_5': 0.71367, 'mrr_at_10': 0.7229, 'mrr_at_100': 0.72563, 'mrr_at_1000': 0.72582, 'evaluation_time': 20.42}
INFO:root:MRR@1: 0.6600
INFO:root:MRR@3: 0.7056
INFO:root:MRR@5: 0.7204
INFO:root:MRR@10: 0.7310
INFO:root:MRR@100: 0.7335
INFO:root:MRR@1000: 0.7338
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 20.91 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.66, 'ndcg_at_3': 0.712, 'ndcg_at_5': 0.73653, 'ndcg_at_10': 0.76695, 'ndcg_at_100': 0.78197, 'ndcg_at_1000': 0.78682, 'map_at_1': 0.63094, 'map_at_3': 0.68996, 'map_at_5': 0.70631, 'map_at_10': 0.72163, 'map_at_100': 0.72539, 'map_at_1000': 0.72563, 'recall_at_1': 0.63094, 'recall_at_3': 0.7495, 'recall_at_5': 0.80994, 'recall_at_10': 0.89822, 'recall_at_100': 0.965, 'recall_at_1000': 1.0, 'precision_at_1': 0.66, 'precision_at_3': 0.27444, 'precision_at_5': 0.18133, 'precision_at_10': 0.10167, 'precision_at_100': 0.01093, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.66, 'mrr_at_3': 0.70556, 'mrr_at_5': 0.72039, 'mrr_at_10': 0.731, 'mrr_at_100': 0.73353, 'mrr_at_1000': 0.73376, 'evaluation_time': 20.91}
INFO:main:Running task: EmotionClassification
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [03:06<05:37, 16.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [01:22<06:50, 15.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$gist$gte-large$llmrails$voyage for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading cohere from cache for EmotionClassification...
Loading gist from cache for EmotionClassification...
Loading gte-large from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model gist$gte-large$llmrails$mixed-bread$voyage for task EmotionClassification
Loading gist from cache for EmotionClassification...
Loading gte-large from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [02:20<09:03, 21.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Clustering:  19%|█▉        | 6/31 [02:23<09:20, 22.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [01:55<08:58, 21.54s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Clustering:  23%|██▎       | 7/31 [03:28<14:43, 36.82s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 67.57 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.56125, 'f1': 0.49727542614770204, 'accuracy_stderr': 0.020676375407696592, 'f1_stderr': 0.011422236276600009, 'main_score': 0.56125, 'evaluation_time': 67.57}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 70.68 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5596, 'f1': 0.4962707728064208, 'accuracy_stderr': 0.021504418150696373, 'f1_stderr': 0.011892087381825666, 'main_score': 0.5596, 'evaluation_time': 70.68}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [03:32<15:08, 37.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [02:41<11:47, 29.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [04:27<12:01, 36.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: AmazonCounterfactualClassification
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [03:51<12:24, 32.37s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [02:58<09:49, 25.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [03:53<12:28, 32.54s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [04:54<10:33, 33.33s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [03:13<08:06, 22.13s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [04:07<10:00, 27.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [04:10<10:07, 27.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model gist$gte-large$llmrails$mixed-bread$voyage for task AmazonCounterfactualClassification
Loading gist from cache for AmazonCounterfactualClassification...
Loading gte-large from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model angle$cohere$gist$gte-large$llmrails$voyage for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading cohere from cache for AmazonCounterfactualClassification...
Loading gist from cache for AmazonCounterfactualClassification...
Loading gte-large from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 3.04 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7446268656716417, 'f1': 0.6832512358839302, 'ap': 0.3707802691680967, 'accuracy_stderr': 0.036391291960320975, 'f1_stderr': 0.03501241893372471, 'ap_stderr': 0.03747055047706082, 'main_score': 0.7446268656716417}, 'evaluation_time': 3.04}
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 3.18 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7594029850746268, 'f1': 0.6986409630893481, 'ap': 0.38947137782101826, 'accuracy_stderr': 0.039863880668543704, 'f1_stderr': 0.038825668569054575, 'ap_stderr': 0.04382441214901738, 'main_score': 0.7594029850746268}, 'evaluation_time': 3.18}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [03:37<08:01, 22.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [04:33<09:23, 26.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist$gte-large$llmrails$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
Clustering:  32%|███▏      | 10/31 [04:33<09:11, 26.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [05:32<10:23, 34.67s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model gist$gte-large$llmrails$mixed-bread$voyage for task Banking77Classification
Loading gist from cache for Banking77Classification...
Loading gte-large from cache for Banking77Classification...
Loading llmrails from cache for Banking77Classification...
Loading mixed-bread from cache for Banking77Classification...
Loading voyage from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Evaluating the model angle$cohere$gte-large$llmrails$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$gte-large$llmrails$mixed-bread$voyage
Converting results/angle$cohere$gte-large$llmrails$mixed-bread$voyage to results/angle$cohere$gte-large$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$flag-embedding$gist$gte-large$llmrails$mixed-bread...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$flag-embedding$gist$gte-large$llmrails$mixed-bread
Converting results/angle$flag-embedding$gist$gte-large$llmrails$mixed-bread to results/angle$flag-embedding$gist$gte-large$llmrails$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$flag-embedding$gist$gte-large$llmrails$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$flag-embedding$gist$gte-large$llmrails$voyage
Converting results/angle$flag-embedding$gist$gte-large$llmrails$voyage to results/angle$flag-embedding$gist$gte-large$llmrails$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$flag-embedding$gist$gte-large$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$flag-embedding$gist$gte-large$mixed-bread$voyage
Converting results/angle$flag-embedding$gist$gte-large$mixed-bread$voyage to results/angle$flag-embedding$gist$gte-large$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$flag-embedding$gist$llmrails$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$flag-embedding$gist$llmrails$mixed-bread$voyage
Converting results/angle$flag-embedding$gist$llmrails$mixed-bread$voyage to results/angle$flag-embedding$gist$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$flag-embedding$gte-large$llmrails$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model angle$flag-embedding$gte-large$llmrails$mixed-bread$voyage for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading gte-large from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 26.27 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6488645426027941, 'mrr': 0.7813799850503451, 'evaluation_time': 26.27}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [04:31<10:45, 32.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [06:23<11:16, 39.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [05:32<12:15, 36.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [05:36<12:26, 37.33s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$flag-embedding$gte-large$llmrails$mixed-bread$voyage for task SciFact
Loading angle from cache for SciFact...
Loading flag-embedding from cache for SciFact...
Loading gte-large from cache for SciFact...
Loading llmrails from cache for SciFact...
Loading mixed-bread from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s] 20%|██        | 1053/5183 [00:00<00:00, 10524.51it/s] 41%|████      | 2106/5183 [00:00<00:00, 7735.67it/s]  56%|█████▋    | 2924/5183 [00:00<00:00, 7247.61it/s] 71%|███████   | 3670/5183 [00:00<00:00, 7229.02it/s] 85%|████████▌ | 4406/5183 [00:00<00:00, 7024.64it/s] 99%|█████████▊| 5116/5183 [00:00<00:00, 6643.85it/s]100%|██████████| 5183/5183 [00:00<00:00, 7171.62it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:faiss.loader:Loading faiss.
INFO:faiss.loader:Successfully loaded faiss.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [01:33<46:44, 93.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [05:43<14:04, 44.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 110.34 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8487987012987013, 'f1': 0.8426018239068551, 'accuracy_stderr': 0.00463740484507037, 'f1_stderr': 0.005685423100046674, 'main_score': 0.8487987012987013, 'evaluation_time': 110.34}
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 36.99 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.6500
INFO:root:NDCG@3: 0.7031
INFO:root:NDCG@5: 0.7265
INFO:root:NDCG@10: 0.7557
INFO:root:NDCG@100: 0.7762
INFO:root:NDCG@1000: 0.7800
INFO:root:

INFO:root:MAP@1: 0.6209
INFO:root:MAP@3: 0.6812
INFO:root:MAP@5: 0.6972
INFO:root:MAP@10: 0.7122
INFO:root:MAP@100: 0.7171
INFO:root:MAP@1000: 0.7173
INFO:root:

INFO:root:Recall@1: 0.6209
INFO:root:Recall@3: 0.7374
INFO:root:Recall@5: 0.7966
INFO:root:Recall@10: 0.8799
INFO:root:Recall@100: 0.9717
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6500
INFO:root:P@3: 0.2711
INFO:root:P@5: 0.1780
INFO:root:P@10: 0.1000
INFO:root:P@100: 0.0110
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6500
INFO:root:MRR@3: 0.6978
INFO:root:MRR@5: 0.7119
INFO:root:MRR@10: 0.7217
INFO:root:MRR@100: 0.7258
INFO:root:MRR@1000: 0.7259
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 38.21 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.65, 'ndcg_at_3': 0.70307, 'ndcg_at_5': 0.72651, 'ndcg_at_10': 0.75568, 'ndcg_at_100': 0.77618, 'ndcg_at_1000': 0.77998, 'map_at_1': 0.62094, 'map_at_3': 0.68124, 'map_at_5': 0.69715, 'map_at_10': 0.71217, 'map_at_100': 0.71708, 'map_at_1000': 0.71725, 'recall_at_1': 0.62094, 'recall_at_3': 0.73739, 'recall_at_5': 0.79661, 'recall_at_10': 0.87989, 'recall_at_100': 0.97167, 'recall_at_1000': 1.0, 'precision_at_1': 0.65, 'precision_at_3': 0.27111, 'precision_at_5': 0.178, 'precision_at_10': 0.1, 'precision_at_100': 0.011, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.65, 'mrr_at_3': 0.69778, 'mrr_at_5': 0.71194, 'mrr_at_10': 0.72172, 'mrr_at_100': 0.72579, 'mrr_at_1000': 0.72594, 'evaluation_time': 38.21}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [07:40<13:33, 50.87s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [06:52<15:34, 49.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [06:57<16:14, 51.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [02:12<29:41, 61.43s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model gist$gte-large$llmrails$mixed-bread$voyage for task ArguAna
Loading gist from cache for ArguAna...
Loading gte-large from cache for ArguAna...
Loading llmrails from cache for ArguAna...
Loading mixed-bread from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s] 23%|██▎       | 1973/8674 [00:00<00:00, 19721.60it/s]INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Creating model angle$flag-embedding$gte-large$llmrails$mixed-bread$voyage for task Banking77Classification
Loading angle from cache for Banking77Classification...
Loading flag-embedding from cache for Banking77Classification...
Loading gte-large from cache for Banking77Classification...
Loading llmrails from cache for Banking77Classification...
Loading mixed-bread from cache for Banking77Classification...
Loading voyage from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
 50%|█████     | 4337/8674 [00:00<00:00, 22018.22it/s] 77%|███████▋  | 6656/8674 [00:00<00:00, 22549.33it/s]100%|██████████| 8674/8674 [00:00<00:00, 22589.58it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [06:27<13:19, 44.41s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [02:56<24:51, 53.27s/it]INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [08:39<13:20, 53.36s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [08:09<17:16, 57.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [08:27<18:55, 63.09s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [03:52<24:34, 54.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [07:46<15:31, 54.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 86.12 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:root:

INFO:root:NDCG@1: 0.3990
INFO:root:NDCG@3: 0.5666
INFO:root:NDCG@5: 0.6153
INFO:root:NDCG@10: 0.6496
INFO:root:NDCG@100: 0.6691
INFO:root:NDCG@1000: 0.6696
INFO:root:

INFO:root:MAP@1: 0.3990
INFO:root:MAP@3: 0.5244
INFO:root:MAP@5: 0.5514
INFO:root:MAP@10: 0.5658
INFO:root:MAP@100: 0.5709
INFO:root:MAP@1000: 0.5709
INFO:root:

INFO:root:Recall@1: 0.3990
INFO:root:Recall@3: 0.6892
INFO:root:Recall@5: 0.8073
INFO:root:Recall@10: 0.9125
INFO:root:Recall@100: 0.9929
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.3990
INFO:root:P@3: 0.2297
INFO:root:P@5: 0.1615
INFO:root:P@10: 0.0912
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.4075
INFO:root:MRR@3: 0.5274
INFO:root:MRR@5: 0.5542
INFO:root:MRR@10: 0.5689
INFO:root:MRR@100: 0.5739
INFO:root:MRR@1000: 0.5740
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 91.39 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.399, 'ndcg_at_3': 0.56663, 'ndcg_at_5': 0.61527, 'ndcg_at_10': 0.64965, 'ndcg_at_100': 0.66913, 'ndcg_at_1000': 0.66962, 'map_at_1': 0.399, 'map_at_3': 0.52442, 'map_at_5': 0.55141, 'map_at_10': 0.5658, 'map_at_100': 0.57089, 'map_at_1000': 0.57091, 'recall_at_1': 0.399, 'recall_at_3': 0.68919, 'recall_at_5': 0.80725, 'recall_at_10': 0.91252, 'recall_at_100': 0.99289, 'recall_at_1000': 0.99644, 'precision_at_1': 0.399, 'precision_at_3': 0.22973, 'precision_at_5': 0.16145, 'precision_at_10': 0.09125, 'precision_at_100': 0.00993, 'precision_at_1000': 0.001, 'mrr_at_1': 0.40754, 'mrr_at_3': 0.52738, 'mrr_at_5': 0.55423, 'mrr_at_10': 0.56893, 'mrr_at_100': 0.57395, 'mrr_at_1000': 0.57398, 'evaluation_time': 91.39}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:main:Running task: ArxivClusteringS2S
Clustering:  45%|████▌     | 14/31 [08:02<09:45, 34.44s/it]
ERROR:mteb.evaluation.MTEB:Error while evaluating ArxivClusteringS2S: Unable to allocate 781. MiB for an array with shape (25000, 4096) and data type float64
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [10:02<14:31, 62.28s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 118.54 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8471103896103896, 'f1': 0.8405572462653005, 'accuracy_stderr': 0.004617814580814507, 'f1_stderr': 0.005661967608526045, 'main_score': 0.8471103896103896, 'evaluation_time': 118.54}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [04:30<21:01, 48.52s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [09:22<17:40, 62.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [09:27<17:36, 62.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$flag-embedding$gte-large$llmrails$mixed-bread$voyage for task ArguAna
Loading angle from cache for ArguAna...
Loading flag-embedding from cache for ArguAna...
Loading gte-large from cache for ArguAna...
Loading llmrails from cache for ArguAna...
Loading mixed-bread from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s] 14%|█▎        | 1179/8674 [00:00<00:00, 8104.82it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
 29%|██▊       | 2491/8674 [00:00<00:00, 10499.80it/s] 49%|████▊     | 4211/8674 [00:00<00:00, 13258.18it/s]Clustering:  58%|█████▊    | 18/31 [10:33<11:27, 52.91s/it] 74%|███████▍  | 6414/8674 [00:00<00:00, 16505.40it/s]100%|██████████| 8674/8674 [00:00<00:00, 16049.53it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [05:03<17:58, 43.13s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [10:04<14:57, 56.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [10:10<15:01, 56.37s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [05:25<14:35, 36.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [11:06<09:21, 46.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [05:50<12:32, 32.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [11:35<07:36, 41.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [10:51<13:20, 53.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [10:56<13:19, 53.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [06:12<10:47, 29.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 81.11 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.4260
INFO:root:NDCG@3: 0.5837
INFO:root:NDCG@5: 0.6264
INFO:root:NDCG@10: 0.6630
INFO:root:NDCG@100: 0.6816
INFO:root:NDCG@1000: 0.6824
INFO:root:

INFO:root:MAP@1: 0.4260
INFO:root:MAP@3: 0.5441
INFO:root:MAP@5: 0.5680
INFO:root:MAP@10: 0.5834
INFO:root:MAP@100: 0.5881
INFO:root:MAP@1000: 0.5882
INFO:root:

INFO:root:Recall@1: 0.4260
INFO:root:Recall@3: 0.6984
INFO:root:Recall@5: 0.8016
INFO:root:Recall@10: 0.9132
INFO:root:Recall@100: 0.9908
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.4260
INFO:root:P@3: 0.2328
INFO:root:P@5: 0.1603
INFO:root:P@10: 0.0913
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:root:MRR@1: 0.4317
INFO:root:MRR@3: 0.5466
INFO:root:MRR@5: 0.5702
INFO:root:MRR@10: 0.5856
INFO:root:MRR@100: 0.5903
INFO:root:MRR@1000: 0.5903
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 84.15 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.42603, 'ndcg_at_3': 0.58365, 'ndcg_at_5': 0.62645, 'ndcg_at_10': 0.66299, 'ndcg_at_100': 0.6816, 'ndcg_at_1000': 0.68238, 'map_at_1': 0.42603, 'map_at_3': 0.5441, 'map_at_5': 0.56803, 'map_at_10': 0.58335, 'map_at_100': 0.58812, 'map_at_1000': 0.58816, 'recall_at_1': 0.42603, 'recall_at_3': 0.69844, 'recall_at_5': 0.80156, 'recall_at_10': 0.91323, 'recall_at_100': 0.99075, 'recall_at_1000': 0.99644, 'precision_at_1': 0.42603, 'precision_at_3': 0.23281, 'precision_at_5': 0.16031, 'precision_at_10': 0.09132, 'precision_at_100': 0.00991, 'precision_at_1000': 0.001, 'mrr_at_1': 0.43172, 'mrr_at_3': 0.54659, 'mrr_at_5': 0.5702, 'mrr_at_10': 0.58559, 'mrr_at_100': 0.59029, 'mrr_at_1000': 0.59032, 'evaluation_time': 84.15}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [12:11<06:38, 39.88s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [06:37<09:50, 28.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [12:20<04:34, 30.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [11:36<11:51, 50.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [11:48<12:21, 52.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Creating model angle$cohere$gist$gte-large$llmrails$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading cohere from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [12:50<04:04, 30.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [07:34<12:17, 36.87s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [13:15<03:20, 28.68s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [12:35<11:32, 53.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Evaluating the model cohere$flag-embedding$gist$gte-large$llmrails$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name cohere$flag-embedding$gist$gte-large$llmrails$voyage
Converting results/cohere$flag-embedding$gist$gte-large$llmrails$voyage to results/cohere$flag-embedding$gist$gte-large$llmrails$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$flag-embedding$gist$gte-large$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name cohere$flag-embedding$gist$gte-large$mixed-bread$voyage
Converting results/cohere$flag-embedding$gist$gte-large$mixed-bread$voyage to results/cohere$flag-embedding$gist$gte-large$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$flag-embedding$gist$llmrails$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name cohere$flag-embedding$gist$llmrails$mixed-bread$voyage
Converting results/cohere$flag-embedding$gist$llmrails$mixed-bread$voyage to results/cohere$flag-embedding$gist$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage
Converting results/cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage to results/cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$gist$gte-large$llmrails$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name cohere$gist$gte-large$llmrails$mixed-bread$voyage
Converting results/cohere$gist$gte-large$llmrails$mixed-bread$voyage to results/cohere$gist$gte-large$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage
Converting results/flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage to results/flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread
Converting results/angle$cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread to results/angle$cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$gist$gte-large$llmrails$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gist$gte-large$llmrails$voyage
Converting results/angle$cohere$flag-embedding$gist$gte-large$llmrails$voyage to results/angle$cohere$flag-embedding$gist$gte-large$llmrails$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [13:36<02:39, 26.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [12:45<11:45, 54.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:53<26:52, 53.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [13:49<01:51, 22.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [08:19<12:26, 39.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:   3%|▎         | 1/31 [01:18<39:20, 78.67s/it]
ERROR:mteb.evaluation.MTEB:Error while evaluating ArxivClusteringS2S: Unable to allocate 1.14 GiB for an array with shape (25000, 6144) and data type float64
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [13:17<09:59, 49.93s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  87%|████████▋ | 27/31 [14:12<01:29, 22.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [13:32<10:22, 51.90s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [14:33<01:06, 22.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [09:02<12:05, 40.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [13:52<08:18, 45.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [14:51<00:41, 20.90s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [14:16<09:05, 49.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [15:14<00:21, 21.43s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [14:26<07:01, 42.17s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [09:42<11:23, 40.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [14:30<04:35, 30.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [15:30<00:00, 19.83s/it]Clustering: 100%|██████████| 31/31 [15:30<00:00, 30.01s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 930.25 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4343251226397419, 'v_measure_std': 0.14270622712289166, 'evaluation_time': 930.25}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [14:48<07:24, 44.43s/it]INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [14:57<05:01, 33.54s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [15:01<04:06, 30.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [10:17<10:18, 38.66s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [15:22<04:09, 31.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [15:27<03:24, 29.18s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [15:43<03:16, 28.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [11:00<10:00, 40.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [15:49<02:42, 27.16s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [16:02<01:53, 22.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [16:03<02:34, 25.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [16:18<01:51, 22.34s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Creating model angle$flag-embedding$gte-large$llmrails$mixed-bread$voyage for task RedditClustering
Loading angle from cache for RedditClustering...
Loading flag-embedding from cache for RedditClustering...
Loading gte-large from cache for RedditClustering...
Loading llmrails from cache for RedditClustering...
Loading mixed-bread from cache for RedditClustering...
Loading voyage from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
Evaluating the model angle$cohere$flag-embedding$gist$gte-large$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gist$gte-large$mixed-bread$voyage
Converting results/angle$cohere$flag-embedding$gist$gte-large$mixed-bread$voyage to results/angle$cohere$flag-embedding$gist$gte-large$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$gist$llmrails$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gist$llmrails$mixed-bread$voyage
Converting results/angle$cohere$flag-embedding$gist$llmrails$mixed-bread$voyage to results/angle$cohere$flag-embedding$gist$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage
Converting results/angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage to results/angle$cohere$flag-embedding$gte-large$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$gist$gte-large$llmrails$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$gist$gte-large$llmrails$mixed-bread$voyage
Converting results/angle$cohere$gist$gte-large$llmrails$mixed-bread$voyage to results/angle$cohere$gist$gte-large$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage
Converting results/angle$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage to results/angle$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage
Converting results/cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage to results/cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage
Converting results/angle$cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage to results/angle$cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [11:38<09:14, 39.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [16:28<01:35, 23.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [16:39<01:27, 21.90s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [16:47<01:07, 22.33s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:24<09:51, 24.66s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [17:01<01:05, 21.93s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [12:15<08:22, 38.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [17:10<00:45, 22.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:38<06:57, 18.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Creating model cohere$flag-embedding$gist$mixed-bread for task RedditClustering
Loading cohere from cache for RedditClustering...
Loading flag-embedding from cache for RedditClustering...
Loading gist from cache for RedditClustering...
Loading mixed-bread from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
Clustering:  94%|█████████▎| 29/31 [17:26<00:45, 22.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [17:30<00:21, 21.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:04<01:50,  4.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model gist$gte-large$llmrails$mixed-bread$voyage for task ArxivClusteringS2S
Loading gist from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:12<02:33,  6.68s/it]Clustering:  61%|██████▏   | 19/31 [12:52<07:36, 38.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [17:43<00:21, 21.19s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [01:14<09:41, 26.43s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
Clustering: 100%|██████████| 31/31 [17:50<00:00, 21.19s/it]Clustering: 100%|██████████| 31/31 [17:50<00:00, 34.52s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 1070.24 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.433965787648559, 'v_measure_std': 0.141837371789794, 'evaluation_time': 1070.24}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:38<05:34, 15.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [01:32<08:05, 23.13s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [18:10<00:00, 22.83s/it]Clustering: 100%|██████████| 31/31 [18:10<00:00, 35.17s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 1090.27 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43314548192572816, 'v_measure_std': 0.14395026987662957, 'evaluation_time': 1090.27}
Clustering:   3%|▎         | 1/31 [00:29<14:47, 29.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name cohere$flag-embedding$gist$llmrails$mixed-bread
Converting results/cohere$flag-embedding$gist$llmrails$mixed-bread to results/cohere$flag-embedding$gist$llmrails$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$flag-embedding$gist$llmrails$voyage...
Skipping STS17 as it already exists
Creating model cohere$flag-embedding$gist$llmrails$voyage for task TwitterSemEval2015
Loading cohere from cache for TwitterSemEval2015...
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
Clustering:  16%|█▌        | 4/25 [00:48<04:43, 13.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:main:Running task: TwitterSemEval2015
Clustering:  20%|██        | 5/25 [01:44<06:18, 18.91s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [13:35<07:16, 39.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:57<03:51, 11.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$flag-embedding$gist$gte-large$voyage
Converting results/angle$flag-embedding$gist$gte-large$voyage to results/angle$flag-embedding$gist$gte-large$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$flag-embedding$gist$llmrails$mixed-bread...
Skipping STS17 as it already exists
Creating model angle$flag-embedding$gist$llmrails$mixed-bread for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:52<12:21, 25.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [01:07<03:34, 11.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [02:05<06:14, 19.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [01:16<03:10, 10.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 17.88 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8761995589199499, 'accuracy_threshold': 0.8169969320297241, 'f1': 0.7211623499684144, 'f1_threshold': 0.7862043380737305, 'precision': 0.6918787878787879, 'recall': 0.7530343007915568, 'ap': 0.7892350275866621}, 'manhattan': {'accuracy': 0.87578232103475, 'accuracy_threshold': 34.18781280517578, 'f1': 0.7208802327051979, 'f1_threshold': 36.78717803955078, 'precision': 0.6922516395433568, 'recall': 0.7519788918205804, 'ap': 0.7890722980296415}, 'euclidean': {'accuracy': 0.8761995589199499, 'accuracy_threshold': 0.6049843430519104, 'f1': 0.7211623499684144, 'f1_threshold': 0.6539046764373779, 'precision': 0.6918787878787879, 'recall': 0.7530343007915568, 'ap': 0.7892350057872041}, 'dot': {'accuracy': 0.8761995589199499, 'accuracy_threshold': 0.8169969320297241, 'f1': 0.7211623499684144, 'f1_threshold': 0.78620445728302, 'precision': 0.6918787878787879, 'recall': 0.7530343007915568, 'ap': 0.7892351681445458}, 'max': {'accuracy': 0.8761995589199499, 'f1': 0.7211623499684144, 'ap': 0.7892351681445458}, 'evaluation_time': 17.88}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 27.96 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8776300888120642, 'accuracy_threshold': 0.8059306681784116, 'f1': 0.7187227142322563, 'f1_threshold': 0.7811095705979191, 'precision': 0.6815708540335935, 'recall': 0.7601583113456465, 'ap': 0.7901011752060647}, 'manhattan': {'accuracy': 0.8779281158729213, 'accuracy_threshold': 34.05362925079987, 'f1': 0.7202476780185758, 'f1_threshold': 36.42545313472668, 'precision': 0.6786464410735122, 'recall': 0.7672823218997361, 'ap': 0.7905670801091059}, 'euclidean': {'accuracy': 0.8776300888120642, 'accuracy_threshold': 0.623007755003792, 'f1': 0.7187227142322563, 'f1_threshold': 0.6616501027052815, 'precision': 0.6815708540335935, 'recall': 0.7601583113456465, 'ap': 0.7901011752060647}, 'dot': {'accuracy': 0.8776300888120642, 'accuracy_threshold': 0.8059306681784115, 'f1': 0.7187227142322563, 'f1_threshold': 0.7811095705979191, 'precision': 0.6815708540335935, 'recall': 0.7601583113456465, 'ap': 0.7901011752060647}, 'max': {'accuracy': 0.8779281158729213, 'f1': 0.7202476780185758, 'ap': 0.7905670801091059}, 'evaluation_time': 27.96}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model angle$flag-embedding$gist$llmrails$mixed-bread for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model cohere$flag-embedding$gist$llmrails$voyage for task AskUbuntuDupQuestions
Loading cohere from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [02:14<04:53, 16.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [14:10<06:21, 38.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [01:21<12:38, 27.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [14:15<04:14, 28.32s/it]INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 13.26 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6484523248045964, 'mrr': 0.7785835202040189, 'evaluation_time': 13.26}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 13.35 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6445781297943284, 'mrr': 0.7769610429582727, 'evaluation_time': 13.35}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [01:37<03:52, 13.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$flag-embedding$gist$llmrails$mixed-bread for task SciFact
Loading angle from cache for SciFact...
Loading flag-embedding from cache for SciFact...
Loading gist from cache for SciFact...
Loading llmrails from cache for SciFact...
Loading mixed-bread from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s]INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist$llmrails$voyage for task SciFact
Loading cohere from cache for SciFact...
Loading flag-embedding from cache for SciFact...
Loading gist from cache for SciFact...
Loading llmrails from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s] 76%|███████▌  | 3932/5183 [00:00<00:00, 39295.40it/s]100%|██████████| 5183/5183 [00:00<00:00, 41338.55it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
 67%|██████▋   | 3450/5183 [00:00<00:00, 34483.26it/s]100%|██████████| 5183/5183 [00:00<00:00, 37580.30it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:faiss.loader:Loading faiss.
INFO:faiss.loader:Loading faiss.
INFO:faiss.loader:Successfully loaded faiss.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:faiss.loader:Successfully loaded faiss.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/beir/retrieval/search/dense/util.py:11: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:275.)
  a = torch.tensor(a)
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [02:38<05:19, 18.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 16.15 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.6433
INFO:root:NDCG@3: 0.6943
INFO:root:NDCG@5: 0.7217
INFO:root:NDCG@10: 0.7491
INFO:root:NDCG@100: 0.7711
INFO:root:NDCG@1000: 0.7754
INFO:root:

INFO:root:MAP@1: 0.6159
INFO:root:MAP@3: 0.6736
INFO:root:MAP@5: 0.6919
INFO:root:MAP@10: 0.7061
INFO:root:MAP@100: 0.7116
INFO:root:MAP@1000: 0.7118
INFO:root:

INFO:root:Recall@1: 0.6159
INFO:root:Recall@3: 0.7267
INFO:root:Recall@5: 0.7933
INFO:root:Recall@10: 0.8716
INFO:root:Recall@100: 0.9683
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6433
INFO:root:P@3: 0.2656
INFO:root:P@5: 0.1773
INFO:root:P@10: 0.0990
INFO:root:P@100: 0.0110
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6433
INFO:root:MRR@3: 0.6906
INFO:root:MRR@5: 0.7064
INFO:root:MRR@10: 0.7156
INFO:root:MRR@100: 0.7199
INFO:root:MRR@1000: 0.7201
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 17.73 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.64333, 'ndcg_at_3': 0.69432, 'ndcg_at_5': 0.72166, 'ndcg_at_10': 0.7491, 'ndcg_at_100': 0.77109, 'ndcg_at_1000': 0.77543, 'map_at_1': 0.61594, 'map_at_3': 0.67357, 'map_at_5': 0.6919, 'map_at_10': 0.70611, 'map_at_100': 0.71155, 'map_at_1000': 0.71176, 'recall_at_1': 0.61594, 'recall_at_3': 0.72672, 'recall_at_5': 0.79328, 'recall_at_10': 0.87156, 'recall_at_100': 0.96833, 'recall_at_1000': 1.0, 'precision_at_1': 0.64333, 'precision_at_3': 0.26556, 'precision_at_5': 0.17733, 'precision_at_10': 0.099, 'precision_at_100': 0.01097, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.64333, 'mrr_at_3': 0.69056, 'mrr_at_5': 0.70639, 'mrr_at_10': 0.71558, 'mrr_at_100': 0.71988, 'mrr_at_1000': 0.72008, 'evaluation_time': 17.73}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [01:58<04:15, 15.94s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 18.63 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:45<11:37, 25.82s/it]INFO:root:

INFO:root:NDCG@1: 0.6433
INFO:root:NDCG@3: 0.7000
INFO:root:NDCG@5: 0.7345
INFO:root:NDCG@10: 0.7556
INFO:root:NDCG@100: 0.7752
INFO:root:NDCG@1000: 0.7787
INFO:root:

INFO:root:MAP@1: 0.6116
INFO:root:MAP@3: 0.6765
INFO:root:MAP@5: 0.6982
INFO:root:MAP@10: 0.7096
INFO:root:MAP@100: 0.7144
INFO:root:MAP@1000: 0.7146
INFO:root:

INFO:root:Recall@1: 0.6116
INFO:root:Recall@3: 0.7385
INFO:root:Recall@5: 0.8266
INFO:root:Recall@10: 0.8866
INFO:root:Recall@100: 0.9750
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6433
INFO:root:P@3: 0.2722
INFO:root:P@5: 0.1847
INFO:root:P@10: 0.1007
INFO:root:P@100: 0.0110
INFO:root:P@1000: 0.0011
INFO:root:

INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:root:MRR@1: 0.6433
INFO:root:MRR@3: 0.6933
INFO:root:MRR@5: 0.7135
INFO:root:MRR@10: 0.7198
INFO:root:MRR@100: 0.7236
INFO:root:MRR@1000: 0.7238
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 20.64 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.64333, 'ndcg_at_3': 0.69996, 'ndcg_at_5': 0.73447, 'ndcg_at_10': 0.75557, 'ndcg_at_100': 0.77525, 'ndcg_at_1000': 0.7787, 'map_at_1': 0.61161, 'map_at_3': 0.67648, 'map_at_5': 0.69816, 'map_at_10': 0.70961, 'map_at_100': 0.71437, 'map_at_1000': 0.71455, 'recall_at_1': 0.61161, 'recall_at_3': 0.7385, 'recall_at_5': 0.82661, 'recall_at_10': 0.88656, 'recall_at_100': 0.975, 'recall_at_1000': 1.0, 'precision_at_1': 0.64333, 'precision_at_3': 0.27222, 'precision_at_5': 0.18467, 'precision_at_10': 0.10067, 'precision_at_100': 0.01103, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.64333, 'mrr_at_3': 0.69333, 'mrr_at_5': 0.7135, 'mrr_at_10': 0.71985, 'mrr_at_100': 0.72364, 'mrr_at_1000': 0.72379, 'evaluation_time': 20.64}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$flag-embedding$gist$llmrails$mixed-bread for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading flag-embedding from cache for EmotionClassification...
Loading gist from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist$llmrails$voyage for task EmotionClassification
Loading cohere from cache for EmotionClassification...
Loading flag-embedding from cache for EmotionClassification...
Loading gist from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [14:45<03:50, 28.81s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
Clustering:  40%|████      | 10/25 [02:36<05:42, 22.81s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Clustering:  16%|█▌        | 5/31 [02:45<16:33, 38.19s/it]Clustering:  36%|███▌      | 9/25 [03:50<09:25, 35.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [15:58<04:53, 41.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 74.79 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5616, 'f1': 0.4969232663635178, 'accuracy_stderr': 0.023388886249669952, 'f1_stderr': 0.013423911723135859, 'main_score': 0.5616, 'evaluation_time': 74.79}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 76.19 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5685, 'f1': 0.5078030736630202, 'accuracy_stderr': 0.020134547424762242, 'f1_stderr': 0.01065031193394586, 'main_score': 0.5685, 'evaluation_time': 76.19}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model angle$flag-embedding$gist$llmrails$mixed-bread for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading flag-embedding from cache for AmazonCounterfactualClassification...
Loading gist from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model cohere$flag-embedding$gist$llmrails$voyage for task AmazonCounterfactualClassification
Loading cohere from cache for AmazonCounterfactualClassification...
Loading flag-embedding from cache for AmazonCounterfactualClassification...
Loading gist from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [03:25<07:11, 30.79s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 1.97 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7417910447761195, 'f1': 0.680919172697389, 'ap': 0.36864503009832034, 'accuracy_stderr': 0.036142831922782837, 'f1_stderr': 0.03497769900683466, 'ap_stderr': 0.0374724424711012, 'main_score': 0.7417910447761195}, 'evaluation_time': 1.97}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 2.72 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7765671641791044, 'f1': 0.7172263104678583, 'ap': 0.4131031105099205, 'accuracy_stderr': 0.03814038857124212, 'f1_stderr': 0.0369759912036016, 'ap_stderr': 0.04434979765214015, 'main_score': 0.7765671641791044}, 'evaluation_time': 2.72}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [03:29<04:53, 22.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist$llmrails$voyage for task Banking77Classification
Loading cohere from cache for Banking77Classification...
Loading flag-embedding from cache for Banking77Classification...
Loading gist from cache for Banking77Classification...
Loading llmrails from cache for Banking77Classification...
Loading voyage from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$flag-embedding$gist$llmrails$mixed-bread for task Banking77Classification
Loading angle from cache for Banking77Classification...
Loading flag-embedding from cache for Banking77Classification...
Loading gist from cache for Banking77Classification...
Loading llmrails from cache for Banking77Classification...
Loading mixed-bread from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [03:37<03:37, 18.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [03:26<16:22, 39.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Clustering:  40%|████      | 10/25 [04:49<10:42, 42.81s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [17:07<05:01, 50.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [04:31<05:21, 29.25s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
Clustering:  23%|██▎       | 7/31 [04:27<18:30, 46.29s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [04:46<04:09, 24.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [17:33<03:34, 43.00s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [06:02<12:04, 51.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 110.83 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8536688311688311, 'f1': 0.8485754945942574, 'accuracy_stderr': 0.005156208073780382, 'f1_stderr': 0.0060831420401210356, 'main_score': 0.8536688311688311, 'evaluation_time': 110.83}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 111.38 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8552597402597403, 'f1': 0.84992124735322, 'accuracy_stderr': 0.0040831714083798725, 'f1_stderr': 0.005174814633312873, 'main_score': 0.8552597402597403, 'evaluation_time': 111.38}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [06:17<08:49, 40.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$flag-embedding$gist$llmrails$mixed-bread for task ArguAna
Loading angle from cache for ArguAna...
Loading flag-embedding from cache for ArguAna...
Loading gist from cache for ArguAna...
Loading llmrails from cache for ArguAna...
Loading mixed-bread from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
Clustering:  64%|██████▍   | 16/25 [05:29<04:32, 30.25s/it]  0%|          | 0/8674 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
 23%|██▎       | 1965/8674 [00:00<00:00, 19646.22it/s]INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist$llmrails$voyage for task ArguAna
Loading cohere from cache for ArguAna...
Loading flag-embedding from cache for ArguAna...
Loading gist from cache for ArguAna...
Loading llmrails from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s] 77%|███████▋  | 6656/8674 [00:00<00:00, 35676.64it/s]100%|██████████| 8674/8674 [00:00<00:00, 36093.48it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
 19%|█▊        | 1625/8674 [00:00<00:00, 16246.14it/s]INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
 69%|██████▉   | 6023/8674 [00:00<00:00, 32556.64it/s]100%|██████████| 8674/8674 [00:00<00:00, 33245.91it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [05:16<18:07, 47.30s/it]INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [06:28<06:19, 31.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [18:18<02:53, 43.46s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [05:40<03:14, 24.33s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [05:43<02:05, 17.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [05:38<14:23, 39.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  76%|███████▌  | 19/25 [05:53<01:33, 15.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 31.14 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.4147
INFO:root:NDCG@3: 0.5797
INFO:root:NDCG@5: 0.6228
INFO:root:NDCG@10: 0.6581
INFO:root:NDCG@100: 0.6776
INFO:root:NDCG@1000: 0.6782
INFO:root:

INFO:root:MAP@1: 0.4147
INFO:root:MAP@3: 0.5385
INFO:root:MAP@5: 0.5625
INFO:root:MAP@10: 0.5774
INFO:root:MAP@100: 0.5824
INFO:root:MAP@1000: 0.5824
INFO:root:

INFO:root:Recall@1: 0.4147
INFO:root:Recall@3: 0.6992
INFO:root:Recall@5: 0.8037
INFO:root:Recall@10: 0.9111
INFO:root:Recall@100: 0.9922
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.4147
INFO:root:P@3: 0.2331
INFO:root:P@5: 0.1607
INFO:root:P@10: 0.0911
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:root:MRR@1: 0.4218
INFO:root:MRR@3: 0.5414
INFO:root:MRR@5: 0.5653
INFO:root:MRR@10: 0.5802
INFO:root:MRR@100: 0.5852
INFO:root:MRR@1000: 0.5852
Clustering:  90%|█████████ | 28/31 [18:42<01:53, 37.80s/it]INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 33.83 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.41465, 'ndcg_at_3': 0.57971, 'ndcg_at_5': 0.62284, 'ndcg_at_10': 0.65814, 'ndcg_at_100': 0.67763, 'ndcg_at_1000': 0.67821, 'map_at_1': 0.41465, 'map_at_3': 0.53853, 'map_at_5': 0.56249, 'map_at_10': 0.57739, 'map_at_100': 0.58241, 'map_at_1000': 0.58244, 'recall_at_1': 0.41465, 'recall_at_3': 0.69915, 'recall_at_5': 0.8037, 'recall_at_10': 0.9111, 'recall_at_100': 0.99218, 'recall_at_1000': 0.99644, 'precision_at_1': 0.41465, 'precision_at_3': 0.23305, 'precision_at_5': 0.16074, 'precision_at_10': 0.09111, 'precision_at_100': 0.00992, 'precision_at_1000': 0.001, 'mrr_at_1': 0.42176, 'mrr_at_3': 0.54137, 'mrr_at_5': 0.56527, 'mrr_at_10': 0.58016, 'mrr_at_100': 0.58518, 'mrr_at_1000': 0.58521, 'evaluation_time': 33.83}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 34.71 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [06:56<05:36, 30.63s/it]INFO:root:

INFO:root:NDCG@1: 0.3748
INFO:root:NDCG@3: 0.5442
INFO:root:NDCG@5: 0.5915
INFO:root:NDCG@10: 0.6316
INFO:root:NDCG@100: 0.6535
INFO:root:NDCG@1000: 0.6539
INFO:root:

INFO:root:MAP@1: 0.3748
INFO:root:MAP@3: 0.5027
INFO:root:MAP@5: 0.5290
INFO:root:MAP@10: 0.5457
INFO:root:MAP@100: 0.5513
INFO:root:MAP@1000: 0.5513
INFO:root:

INFO:root:Recall@1: 0.3748
INFO:root:Recall@3: 0.6643
INFO:root:Recall@5: 0.7788
INFO:root:Recall@10: 0.9019
INFO:root:Recall@100: 0.9936
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.3748
INFO:root:P@3: 0.2214
INFO:root:P@5: 0.1558
INFO:root:P@10: 0.0902
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.3834
INFO:root:MRR@3: 0.5052
INFO:root:MRR@5: 0.5317
INFO:root:MRR@10: 0.5490
INFO:root:MRR@100: 0.5545
INFO:root:MRR@1000: 0.5545
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 37.20 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.37482, 'ndcg_at_3': 0.54424, 'ndcg_at_5': 0.59146, 'ndcg_at_10': 0.63156, 'ndcg_at_100': 0.65349, 'ndcg_at_1000': 0.65388, 'map_at_1': 0.37482, 'map_at_3': 0.50273, 'map_at_5': 0.52897, 'map_at_10': 0.5457, 'map_at_100': 0.55126, 'map_at_1000': 0.55127, 'recall_at_1': 0.37482, 'recall_at_3': 0.6643, 'recall_at_5': 0.77881, 'recall_at_10': 0.90185, 'recall_at_100': 0.9936, 'recall_at_1000': 0.99644, 'precision_at_1': 0.37482, 'precision_at_3': 0.22143, 'precision_at_5': 0.15576, 'precision_at_10': 0.09018, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.38336, 'mrr_at_3': 0.50522, 'mrr_at_5': 0.53171, 'mrr_at_10': 0.54898, 'mrr_at_100': 0.55447, 'mrr_at_1000': 0.55449, 'evaluation_time': 37.2}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [06:16<01:29, 17.82s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [07:07<04:06, 24.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [06:02<12:07, 34.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [19:03<01:04, 32.48s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [06:33<01:10, 17.52s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [19:21<00:28, 28.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [07:35<03:50, 25.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [06:56<00:58, 19.35s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  35%|███▌      | 11/31 [06:43<12:11, 36.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [19:41<00:00, 25.65s/it]Clustering: 100%|██████████| 31/31 [19:41<00:00, 38.10s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 1181.16 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4322513818876214, 'v_measure_std': 0.14423865480617776, 'evaluation_time': 1181.16}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [07:55<03:11, 23.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [07:11<00:36, 18.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [08:04<02:15, 19.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [07:19<00:14, 14.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [08:21<01:53, 18.94s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [07:35<00:00, 15.28s/it]Clustering: 100%|██████████| 25/25 [07:35<00:00, 18.22s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 455.48 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.6101713898851012, 'v_measure_std': 0.0419072322776442, 'evaluation_time': 455.48}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [07:32<12:44, 40.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [08:51<01:49, 22.00s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [08:13<12:09, 40.54s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Converting the results to a CSV file...
Using model name cohere$flag-embedding$gist$mixed-bread
Converting results/cohere$flag-embedding$gist$mixed-bread to results/cohere$flag-embedding$gist$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$flag-embedding$gist$voyage...
Skipping STS17 as it already exists
Creating model cohere$flag-embedding$gist$voyage for task TwitterSemEval2015
Loading cohere from cache for TwitterSemEval2015...
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [09:27<01:45, 26.34s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [09:56<01:21, 27.22s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [08:52<11:20, 40.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [10:03<00:42, 21.18s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [10:19<00:19, 19.41s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [09:27<10:15, 38.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [10:42<00:00, 20.59s/it]Clustering: 100%|██████████| 25/25 [10:42<00:00, 25.70s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 642.51 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.6000907630058407, 'v_measure_std': 0.04525502422186853, 'evaluation_time': 642.51}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [09:54<08:46, 35.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [10:33<08:28, 36.34s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Creating model angle$gist$gte-large$llmrails$voyage for task RedditClustering
Loading angle from cache for RedditClustering...
Loading gist from cache for RedditClustering...
Loading gte-large from cache for RedditClustering...
Loading llmrails from cache for RedditClustering...
Loading voyage from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [11:08<07:47, 35.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:05<02:07,  5.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:15<03:09,  8.22s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Converting the results to a CSV file...
Using model name angle$flag-embedding$gte-large$llmrails$mixed-bread$voyage
Converting results/angle$flag-embedding$gte-large$llmrails$mixed-bread$voyage to results/angle$flag-embedding$gte-large$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$gist$gte-large$llmrails$mixed-bread$voyage...
Skipping STS17 as it already exists
Creating model angle$gist$gte-large$llmrails$mixed-bread$voyage for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
Loading gte-large from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [11:41<07:00, 35.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
Clustering:  12%|█▏        | 3/25 [00:35<05:00, 13.66s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:46<04:20, 12.39s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:56<03:51, 11.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 30.13 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8756035047982357, 'accuracy_threshold': 0.829866296923565, 'f1': 0.7204164550533266, 'f1_threshold': 0.8147147857205309, 'precision': 0.6943220753793441, 'recall': 0.7485488126649077, 'ap': 0.7879871464540138}, 'manhattan': {'accuracy': 0.8754842939738928, 'accuracy_threshold': 34.43803295395233, 'f1': 0.7188062773347055, 'f1_threshold': 36.163927196954305, 'precision': 0.7013052208835341, 'recall': 0.737203166226913, 'ap': 0.7856619892470639}, 'euclidean': {'accuracy': 0.8756035047982357, 'accuracy_threshold': 0.5833244431773463, 'f1': 0.7204164550533266, 'f1_threshold': 0.6087449612035338, 'precision': 0.6943220753793441, 'recall': 0.7485488126649077, 'ap': 0.7879871464540138}, 'dot': {'accuracy': 0.8756035047982357, 'accuracy_threshold': 0.8298662969235652, 'f1': 0.7204164550533266, 'f1_threshold': 0.8147147857205317, 'precision': 0.6943220753793441, 'recall': 0.7485488126649077, 'ap': 0.7879871464540138}, 'max': {'accuracy': 0.8756035047982357, 'f1': 0.7204164550533266, 'ap': 0.7879871464540138}, 'evaluation_time': 30.13}
Clustering:  65%|██████▍   | 20/31 [12:19<06:36, 36.01s/it]INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [01:12<04:12, 13.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [01:18<03:15, 10.88s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [12:45<05:29, 32.93s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [12:49<03:37, 24.13s/it]INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model angle$gist$gte-large$llmrails$mixed-bread$voyage for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
Loading gte-large from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
Clustering:  32%|███▏      | 8/25 [01:36<03:43, 13.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$flag-embedding$gist$llmrails$mixed-bread for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 9.71 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6496457837678897, 'mrr': 0.7843853053686849, 'evaluation_time': 9.71}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist$gte-large$llmrails$mixed-bread$voyage for task SciFact
Loading angle from cache for SciFact...
Loading gist from cache for SciFact...
Loading gte-large from cache for SciFact...
Loading llmrails from cache for SciFact...
Loading mixed-bread from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s] 82%|████████▏ | 4227/5183 [00:00<00:00, 38645.34it/s]100%|██████████| 5183/5183 [00:00<00:00, 38755.56it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [01:57<04:08, 15.53s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [13:14<03:16, 24.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 20.43 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:25<12:49, 25.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:root:

INFO:root:NDCG@1: 0.6467
INFO:root:NDCG@3: 0.7028
INFO:root:NDCG@5: 0.7298
INFO:root:NDCG@10: 0.7568
INFO:root:NDCG@100: 0.7747
INFO:root:NDCG@1000: 0.7795
INFO:root:

INFO:root:MAP@1: 0.6176
INFO:root:MAP@3: 0.6800
INFO:root:MAP@5: 0.6975
INFO:root:MAP@10: 0.7115
INFO:root:MAP@100: 0.7159
INFO:root:MAP@1000: 0.7162
INFO:root:

INFO:root:Recall@1: 0.6176
INFO:root:Recall@3: 0.7417
INFO:root:Recall@5: 0.8083
INFO:root:Recall@10: 0.8866
INFO:root:Recall@100: 0.9650
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6467
INFO:root:P@3: 0.2711
INFO:root:P@5: 0.1807
INFO:root:P@10: 0.1007
INFO:root:P@100: 0.0109
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6467
INFO:root:MRR@3: 0.6967
INFO:root:MRR@5: 0.7130
INFO:root:MRR@10: 0.7214
INFO:root:MRR@100: 0.7249
INFO:root:MRR@1000: 0.7251
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 23.39 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.64667, 'ndcg_at_3': 0.70276, 'ndcg_at_5': 0.72981, 'ndcg_at_10': 0.75679, 'ndcg_at_100': 0.77466, 'ndcg_at_1000': 0.77952, 'map_at_1': 0.61761, 'map_at_3': 0.67996, 'map_at_5': 0.69754, 'map_at_10': 0.71148, 'map_at_100': 0.71592, 'map_at_1000': 0.71617, 'recall_at_1': 0.61761, 'recall_at_3': 0.74172, 'recall_at_5': 0.80828, 'recall_at_10': 0.88656, 'recall_at_100': 0.965, 'recall_at_1000': 1.0, 'precision_at_1': 0.64667, 'precision_at_3': 0.27111, 'precision_at_5': 0.18067, 'precision_at_10': 0.10067, 'precision_at_100': 0.01093, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.64667, 'mrr_at_3': 0.69667, 'mrr_at_5': 0.713, 'mrr_at_10': 0.72135, 'mrr_at_100': 0.7249, 'mrr_at_1000': 0.72513, 'evaluation_time': 23.39}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:40<09:16, 19.19s/it]Clustering:  77%|███████▋  | 24/31 [13:39<02:51, 24.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [02:25<04:49, 19.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:57<08:36, 18.46s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [14:08<02:34, 25.81s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist$gte-large$llmrails$mixed-bread$voyage for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading gist from cache for EmotionClassification...
Loading gte-large from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Clustering:  44%|████▍     | 11/25 [02:54<05:11, 22.25s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [02:57<03:35, 16.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist$llmrails$voyage for task ArxivClusteringS2S
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [14:31<02:05, 25.08s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Clustering:  13%|█▎        | 4/31 [01:34<11:35, 25.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [03:20<03:40, 18.34s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 50.55 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.55635, 'f1': 0.49069313374798523, 'accuracy_stderr': 0.024557127274988818, 'f1_stderr': 0.014145363225080048, 'main_score': 0.55635, 'evaluation_time': 50.55}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model angle$gist$gte-large$llmrails$mixed-bread$voyage for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading gist from cache for AmazonCounterfactualClassification...
Loading gte-large from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
Clustering:  16%|█▌        | 5/31 [02:06<12:02, 27.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
Clustering:   3%|▎         | 1/31 [00:36<18:15, 36.51s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 2.77 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7407462686567163, 'f1': 0.6800439341551926, 'ap': 0.36790040741015123, 'accuracy_stderr': 0.03611847784679275, 'f1_stderr': 0.034861311324609505, 'ap_stderr': 0.0372002362934119, 'main_score': 0.7407462686567163}, 'evaluation_time': 2.77}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [03:55<04:16, 23.34s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [15:12<01:58, 29.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist$gte-large$llmrails$mixed-bread$voyage for task Banking77Classification
Loading angle from cache for Banking77Classification...
Loading gist from cache for Banking77Classification...
Loading gte-large from cache for Banking77Classification...
Loading llmrails from cache for Banking77Classification...
Loading mixed-bread from cache for Banking77Classification...
Loading voyage from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [04:01<03:00, 18.09s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Clustering:  19%|█▉        | 6/31 [02:25<10:24, 25.00s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [01:06<15:54, 32.90s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [15:54<01:40, 33.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [02:57<10:50, 27.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [04:46<03:57, 26.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [01:50<17:40, 37.86s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [03:28<10:52, 28.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [05:13<03:31, 26.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [05:22<02:28, 21.19s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 83.99 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8503246753246753, 'f1': 0.8442411401970629, 'accuracy_stderr': 0.003960506670643361, 'f1_stderr': 0.005040468617057918, 'main_score': 0.8503246753246753, 'evaluation_time': 83.99}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [16:39<01:13, 36.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist$gte-large$llmrails$mixed-bread$voyage for task ArguAna
Loading angle from cache for ArguAna...
Loading gist from cache for ArguAna...
Loading gte-large from cache for ArguAna...
Loading llmrails from cache for ArguAna...
Loading mixed-bread from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s] 24%|██▍       | 2109/8674 [00:00<00:00, 16883.50it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
 79%|███████▊  | 6810/8674 [00:00<00:00, 32953.20it/s]100%|██████████| 8674/8674 [00:00<00:00, 33117.62it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [03:46<09:11, 25.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [02:20<15:36, 34.69s/it]Clustering:  76%|███████▌  | 19/25 [05:36<01:55, 19.17s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [03:59<07:28, 21.35s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [16:58<00:31, 31.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [02:50<14:17, 32.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 47.72 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.4232
INFO:root:NDCG@3: 0.5810
INFO:root:NDCG@5: 0.6272
INFO:root:NDCG@10: 0.6631
INFO:root:NDCG@100: 0.6812
INFO:root:NDCG@1000: 0.6818
INFO:root:

INFO:root:MAP@1: 0.4232
INFO:root:MAP@3: 0.5415
INFO:root:MAP@5: 0.5673
INFO:root:MAP@10: 0.5824
INFO:root:MAP@100: 0.5870
INFO:root:MAP@1000: 0.5871
INFO:root:

INFO:root:Recall@1: 0.4232
INFO:root:Recall@3: 0.6956
INFO:root:Recall@5: 0.8073
INFO:root:Recall@10: 0.9168
INFO:root:Recall@100: 0.9922
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.4232
INFO:root:P@3: 0.2319
INFO:root:P@5: 0.1615
INFO:root:P@10: 0.0917
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [06:19<02:11, 26.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:root:MRR@1: 0.4296
INFO:root:MRR@3: 0.5436
INFO:root:MRR@5: 0.5697
INFO:root:MRR@10: 0.5850
INFO:root:MRR@100: 0.5895
INFO:root:MRR@1000: 0.5895
Clustering: 100%|██████████| 31/31 [17:34<00:00, 32.83s/it]Clustering: 100%|██████████| 31/31 [17:34<00:00, 34.01s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 1054.41 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4327049962854653, 'v_measure_std': 0.14337546078728367, 'evaluation_time': 1054.41}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 52.19 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.42319, 'ndcg_at_3': 0.58099, 'ndcg_at_5': 0.62721, 'ndcg_at_10': 0.66313, 'ndcg_at_100': 0.68124, 'ndcg_at_1000': 0.68183, 'map_at_1': 0.42319, 'map_at_3': 0.54149, 'map_at_5': 0.56727, 'map_at_10': 0.58238, 'map_at_100': 0.58704, 'map_at_1000': 0.58707, 'recall_at_1': 0.42319, 'recall_at_3': 0.69559, 'recall_at_5': 0.80725, 'recall_at_10': 0.91679, 'recall_at_100': 0.99218, 'recall_at_1000': 0.99644, 'precision_at_1': 0.42319, 'precision_at_3': 0.23186, 'precision_at_5': 0.16145, 'precision_at_10': 0.09168, 'precision_at_100': 0.00992, 'precision_at_1000': 0.001, 'mrr_at_1': 0.42959, 'mrr_at_3': 0.54362, 'mrr_at_5': 0.56972, 'mrr_at_10': 0.58497, 'mrr_at_100': 0.58949, 'mrr_at_1000': 0.58952, 'evaluation_time': 52.19}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [04:43<09:30, 28.53s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [03:15<12:37, 30.28s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [06:50<01:50, 27.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [03:37<11:02, 27.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [05:11<08:55, 28.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [04:08<11:00, 28.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [07:26<01:30, 30.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [05:45<09:01, 30.08s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [07:31<00:45, 22.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [07:53<00:22, 22.51s/it]Clustering:  29%|██▉       | 9/31 [04:37<10:32, 28.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [06:18<08:45, 30.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  96%|█████████▌| 24/25 [08:14<00:20, 20.60s/it]
ERROR:mteb.evaluation.MTEB:Error while evaluating RedditClustering: Unable to allocate 991. MiB for an array with shape (25360, 5120) and data type float64
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [05:13<10:53, 31.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [06:46<08:00, 30.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [07:16<07:29, 29.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [05:50<10:55, 32.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [07:38<06:25, 27.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [06:35<11:35, 36.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [08:09<06:13, 28.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Creating model gist$gte-large$llmrails$mixed-bread$voyage for task RedditClustering
Loading gist from cache for RedditClustering...
Loading gte-large from cache for RedditClustering...
Loading llmrails from cache for RedditClustering...
Loading mixed-bread from cache for RedditClustering...
Loading voyage from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:12<04:53, 12.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [08:36<05:37, 28.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [07:12<11:01, 36.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:25<05:01, 13.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [09:00<04:56, 26.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:50<06:43, 18.35s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [01:03<05:43, 16.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [09:23<04:15, 25.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [07:55<10:57, 38.68s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [09:28<02:56, 19.63s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [01:14<04:46, 14.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [01:30<04:44, 14.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [09:53<02:49, 21.19s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [01:40<03:59, 13.28s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [10:06<02:11, 18.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [08:35<10:22, 38.93s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [01:57<04:03, 14.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [10:25<01:52, 18.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [02:22<04:46, 17.90s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [10:42<01:30, 18.05s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [09:17<09:58, 39.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$gist$gte-large$llmrails$mixed-bread$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [10:59<01:12, 18.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [02:41<04:33, 18.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [11:16<00:52, 17.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:28<14:00, 28.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  44%|████▍     | 11/25 [03:02<04:24, 18.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [03:05<03:03, 14.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  55%|█████▍    | 17/31 [09:58<09:22, 40.17s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [03:14<02:30, 12.52s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [11:34<00:35, 17.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [11:45<00:15, 15.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:54<13:05, 27.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [03:32<02:37, 14.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [03:38<01:58, 11.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [12:02<00:00, 16.15s/it]Clustering: 100%|██████████| 31/31 [12:02<00:00, 23.31s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 722.64 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4311076036270658, 'v_measure_std': 0.14293046008668675, 'evaluation_time': 722.64}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [10:36<08:34, 39.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [01:19<12:06, 25.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [03:59<02:10, 14.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [04:15<01:58, 14.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:41<11:05, 24.67s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [04:20<01:24, 12.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [11:11<07:39, 38.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [04:31<01:10, 11.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [02:06<10:39, 24.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [05:02<01:27, 17.43s/it]Clustering:  65%|██████▍   | 20/31 [11:49<06:58, 38.09s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [02:30<10:13, 24.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [05:26<01:17, 19.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [02:54<09:40, 24.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Creating model angle$flag-embedding$gist$llmrails$mixed-bread for task RedditClustering
Loading angle from cache for RedditClustering...
Loading flag-embedding from cache for RedditClustering...
Loading gist from cache for RedditClustering...
Loading llmrails from cache for RedditClustering...
Loading mixed-bread from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [12:20<05:59, 35.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [12:24<03:56, 26.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:04<01:54,  4.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:12<02:31,  6.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [05:47<00:59, 19.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [03:17<09:11, 23.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [05:52<00:30, 15.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [06:04<00:14, 14.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:31<04:33, 12.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [12:55<03:42, 27.81s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:41<03:58, 11.37s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [03:42<08:51, 24.17s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:49<03:23, 10.17s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [06:24<00:00, 16.15s/it]Clustering: 100%|██████████| 25/25 [06:24<00:00, 15.39s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 384.84 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.6090011128780154, 'v_measure_std': 0.04224471758097719, 'evaluation_time': 384.84}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [13:14<02:55, 25.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [00:59<03:12, 10.12s/it]INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [01:05<02:34,  8.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [04:06<08:27, 24.16s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Converting the results to a CSV file...
Using model name gist$gte-large$llmrails$mixed-bread$voyage
Converting results/gist$gte-large$llmrails$mixed-bread$voyage to results/gist$gte-large$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$gist$gte-large$llmrails...
Skipping STS17 as it already exists
Creating model angle$cohere$flag-embedding$gist$gte-large$llmrails for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading cohere from cache for TwitterSemEval2015...
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
Loading gte-large from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [13:38<02:29, 24.91s/it]Clustering:  32%|███▏      | 8/25 [01:18<02:52, 10.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [13:47<01:39, 19.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [01:35<03:16, 12.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 27.71 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8764975859808071, 'accuracy_threshold': 0.822279144814358, 'f1': 0.7232406101781822, 'f1_threshold': 0.7970694106194862, 'precision': 0.7033158813263525, 'recall': 0.7443271767810027, 'ap': 0.7892564627603526}, 'manhattan': {'accuracy': 0.8762591643321214, 'accuracy_threshold': 36.55935399230739, 'f1': 0.7211513749678747, 'f1_threshold': 38.41516286315111, 'precision': 0.7029058116232465, 'recall': 0.7403693931398417, 'ap': 0.788667994184982}, 'euclidean': {'accuracy': 0.8764975859808071, 'accuracy_threshold': 0.5961893240967996, 'f1': 0.7232406101781822, 'f1_threshold': 0.6370723496577233, 'precision': 0.7033158813263525, 'recall': 0.7443271767810027, 'ap': 0.7892564627603526}, 'dot': {'accuracy': 0.8764975859808071, 'accuracy_threshold': 0.8222791448143587, 'f1': 0.7232406101781822, 'f1_threshold': 0.7970694106194871, 'precision': 0.7033158813263525, 'recall': 0.7443271767810027, 'ap': 0.7892564627603526}, 'max': {'accuracy': 0.8764975859808071, 'f1': 0.7232406101781822, 'ap': 0.7892564627603526}, 'evaluation_time': 27.71}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model angle$cohere$flag-embedding$gist$gte-large$llmrails for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading cohere from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
Loading gte-large from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [01:51<03:19, 13.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [04:54<10:28, 31.40s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 10.53 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6474989457336897, 'mrr': 0.7820164446203226, 'evaluation_time': 10.53}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [14:16<01:30, 22.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gist$gte-large$llmrails for task SciFact
Loading angle from cache for SciFact...
Loading cohere from cache for SciFact...
Loading flag-embedding from cache for SciFact...
Loading gist from cache for SciFact...
Loading gte-large from cache for SciFact...
Loading llmrails from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s] 69%|██████▊   | 3551/5183 [00:00<00:00, 35502.33it/s]100%|██████████| 5183/5183 [00:00<00:00, 39402.09it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [02:04<03:07, 13.40s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [02:07<02:12, 10.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [02:13<01:46,  8.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 15.69 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.6567
INFO:root:NDCG@3: 0.7082
INFO:root:NDCG@5: 0.7326
INFO:root:NDCG@10: 0.7589
INFO:root:NDCG@100: 0.7813
INFO:root:NDCG@1000: 0.7843
INFO:root:

INFO:root:MAP@1: 0.6276
INFO:root:MAP@3: 0.6866
INFO:root:MAP@5: 0.7032
INFO:root:MAP@10: 0.7169
INFO:root:MAP@100: 0.7224
INFO:root:MAP@1000: 0.7225
INFO:root:

INFO:root:Recall@1: 0.6276
INFO:root:Recall@3: 0.7434
INFO:root:Recall@5: 0.8033
INFO:root:Recall@10: 0.8782
INFO:root:Recall@100: 0.9783
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6567
INFO:root:P@3: 0.2722
INFO:root:P@5: 0.1800
INFO:root:P@10: 0.0997
INFO:root:P@100: 0.0111
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6567
INFO:root:MRR@3: 0.7033
INFO:root:MRR@5: 0.7175
INFO:root:MRR@10: 0.7265
INFO:root:MRR@100: 0.7308
INFO:root:MRR@1000: 0.7309
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 16.31 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.65667, 'ndcg_at_3': 0.70818, 'ndcg_at_5': 0.73262, 'ndcg_at_10': 0.75891, 'ndcg_at_100': 0.7813, 'ndcg_at_1000': 0.78425, 'map_at_1': 0.62761, 'map_at_3': 0.68663, 'map_at_5': 0.7032, 'map_at_10': 0.71691, 'map_at_100': 0.7224, 'map_at_1000': 0.72254, 'recall_at_1': 0.62761, 'recall_at_3': 0.74339, 'recall_at_5': 0.80328, 'recall_at_10': 0.87822, 'recall_at_100': 0.97833, 'recall_at_1000': 1.0, 'precision_at_1': 0.65667, 'precision_at_3': 0.27222, 'precision_at_5': 0.18, 'precision_at_10': 0.09967, 'precision_at_100': 0.01107, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.65667, 'mrr_at_3': 0.70333, 'mrr_at_5': 0.7175, 'mrr_at_10': 0.72647, 'mrr_at_100': 0.73078, 'mrr_at_1000': 0.7309, 'evaluation_time': 16.31}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [14:40<01:09, 23.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gist$gte-large$llmrails for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading cohere from cache for EmotionClassification...
Loading flag-embedding from cache for EmotionClassification...
Loading gist from cache for EmotionClassification...
Loading gte-large from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
Clustering:  56%|█████▌    | 14/25 [02:41<02:40, 14.60s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [02:55<02:24, 14.46s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [15:29<01:01, 30.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 46.33 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5663, 'f1': 0.5032847887045396, 'accuracy_stderr': 0.021874871428193603, 'f1_stderr': 0.013172260610968838, 'main_score': 0.5663, 'evaluation_time': 46.33}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model angle$cohere$flag-embedding$gist$gte-large$llmrails for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading cohere from cache for AmazonCounterfactualClassification...
Loading flag-embedding from cache for AmazonCounterfactualClassification...
Loading gist from cache for AmazonCounterfactualClassification...
Loading gte-large from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Clustering:  39%|███▊      | 12/31 [06:13<14:33, 45.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 1.95 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7576119402985075, 'f1': 0.6966877926755665, 'ap': 0.3865247366919446, 'accuracy_stderr': 0.035541196575850066, 'f1_stderr': 0.03436388186065483, 'ap_stderr': 0.0387022570236444, 'main_score': 0.7576119402985075}, 'evaluation_time': 1.95}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [03:18<02:33, 17.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gist$gte-large$llmrails for task Banking77Classification
Loading angle from cache for Banking77Classification...
Loading cohere from cache for Banking77Classification...
Loading flag-embedding from cache for Banking77Classification...
Loading gist from cache for Banking77Classification...
Loading gte-large from cache for Banking77Classification...
Loading llmrails from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [03:30<02:04, 15.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
Clustering:  97%|█████████▋| 30/31 [15:52<00:28, 28.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [03:39<01:33, 13.41s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
Clustering:  76%|███████▌  | 19/25 [04:07<01:47, 17.95s/it]INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [16:36<00:00, 33.04s/it]Clustering: 100%|██████████| 31/31 [16:36<00:00, 32.13s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 996.16 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43249220528051485, 'v_measure_std': 0.14277550820695772, 'evaluation_time': 996.16}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [07:35<17:06, 57.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [04:38<01:48, 21.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 93.72 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8542532467532468, 'f1': 0.84902551381779, 'accuracy_stderr': 0.004654195581991862, 'f1_stderr': 0.005688782109582577, 'main_score': 0.8542532467532468, 'evaluation_time': 93.72}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [05:05<01:34, 23.54s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gist$gte-large$llmrails for task ArguAna
Loading angle from cache for ArguAna...
Loading cohere from cache for ArguAna...
Loading flag-embedding from cache for ArguAna...
Loading gist from cache for ArguAna...
Loading gte-large from cache for ArguAna...
Loading llmrails from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s]  8%|▊         | 717/8674 [00:00<00:01, 4800.12it/s] 51%|█████▏    | 4454/8674 [00:00<00:00, 20720.07it/s] 98%|█████████▊| 8470/8674 [00:00<00:00, 28711.09it/s]100%|██████████| 8674/8674 [00:00<00:00, 24395.36it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
Clustering:  84%|████████▍ | 21/25 [05:14<00:59, 15.00s/it]
ERROR:mteb.evaluation.MTEB:Error while evaluating RedditClustering: Unable to allocate 490. MiB for an array with shape (25083, 5120) and data type float32
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [08:26<15:35, 55.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 48.85 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.3940
INFO:root:NDCG@3: 0.5602
INFO:root:NDCG@5: 0.6100
INFO:root:NDCG@10: 0.6455
INFO:root:NDCG@100: 0.6660
INFO:root:NDCG@1000: 0.6664
INFO:root:

INFO:root:MAP@1: 0.3940
INFO:root:MAP@3: 0.5193
INFO:root:MAP@5: 0.5470
INFO:root:MAP@10: 0.5618
INFO:root:MAP@100: 0.5671
INFO:root:MAP@1000: 0.5671
INFO:root:

INFO:root:Recall@1: 0.3940
INFO:root:Recall@3: 0.6785
INFO:root:Recall@5: 0.7994
INFO:root:Recall@10: 0.9083
INFO:root:Recall@100: 0.9936
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.3940
INFO:root:P@3: 0.2262
INFO:root:P@5: 0.1599
INFO:root:P@10: 0.0908
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.4004
INFO:root:MRR@3: 0.5223
INFO:root:MRR@5: 0.5492
INFO:root:MRR@10: 0.5643
INFO:root:MRR@100: 0.5696
INFO:root:MRR@1000: 0.5696
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 51.97 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.39403, 'ndcg_at_3': 0.56021, 'ndcg_at_5': 0.61, 'ndcg_at_10': 0.64548, 'ndcg_at_100': 0.66603, 'ndcg_at_1000': 0.66642, 'map_at_1': 0.39403, 'map_at_3': 0.51932, 'map_at_5': 0.54695, 'map_at_10': 0.56176, 'map_at_100': 0.56707, 'map_at_1000': 0.56708, 'recall_at_1': 0.39403, 'recall_at_3': 0.67852, 'recall_at_5': 0.79943, 'recall_at_10': 0.90825, 'recall_at_100': 0.9936, 'recall_at_1000': 0.99644, 'precision_at_1': 0.39403, 'precision_at_3': 0.22617, 'precision_at_5': 0.15989, 'precision_at_10': 0.09083, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.40043, 'mrr_at_3': 0.52229, 'mrr_at_5': 0.54921, 'mrr_at_10': 0.56425, 'mrr_at_100': 0.56955, 'mrr_at_1000': 0.56957, 'evaluation_time': 51.97}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [09:04<13:21, 50.07s/it]INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [09:44<11:44, 46.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [10:27<10:41, 45.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Creating model cohere$flag-embedding$gist$llmrails$voyage for task RedditClustering
Loading cohere from cache for RedditClustering...
Loading flag-embedding from cache for RedditClustering...
Loading gist from cache for RedditClustering...
Loading llmrails from cache for RedditClustering...
Loading voyage from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [11:01<09:07, 42.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:05<02:16,  5.69s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:14<02:52,  7.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [11:35<07:55, 39.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:40<05:48, 15.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:50<04:46, 13.66s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [01:01<04:13, 12.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [12:06<06:47, 37.08s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [01:21<04:46, 15.05s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [01:29<03:52, 12.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [12:37<05:53, 35.34s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [12:41<03:53, 25.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [01:46<04:03, 14.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [02:07<04:18, 16.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [13:10<03:34, 26.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gist$gte-large$llmrails for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [13:29<02:51, 24.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
Clustering:  40%|████      | 10/25 [02:33<04:48, 19.22s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:23<11:46, 23.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [02:54<04:38, 19.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [02:57<03:12, 14.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [13:55<02:28, 24.82s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [03:05<02:31, 12.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [14:03<01:38, 19.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:46<11:07, 23.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [03:21<02:31, 13.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [03:26<01:51, 11.12s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [14:26<01:23, 20.94s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [01:08<10:36, 22.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [03:46<02:03, 13.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [14:49<01:04, 21.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:29<09:57, 22.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [03:57<01:42, 12.81s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [04:01<01:10, 10.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [04:12<01:03, 10.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [15:13<00:44, 22.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [01:51<09:32, 22.00s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [15:31<00:20, 20.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [04:36<01:13, 14.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [02:13<09:09, 21.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [15:56<00:00, 22.33s/it]Clustering: 100%|██████████| 31/31 [15:56<00:00, 30.87s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 956.86 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43398080788369897, 'v_measure_std': 0.14202770402101647, 'evaluation_time': 956.86}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [05:00<01:09, 17.37s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [02:34<08:41, 21.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [05:21<00:55, 18.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [02:55<08:14, 21.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [05:27<00:29, 14.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [05:39<00:13, 13.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [03:17<07:58, 21.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [03:43<08:02, 22.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [06:10<00:00, 19.05s/it]Clustering: 100%|██████████| 25/25 [06:10<00:00, 14.82s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 370.56 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.6116265326446435, 'v_measure_std': 0.03940557615009509, 'evaluation_time': 370.56}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [04:24<09:30, 28.52s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Converting the results to a CSV file...
Using model name cohere$flag-embedding$gist$llmrails$voyage
Converting results/cohere$flag-embedding$gist$llmrails$voyage to results/cohere$flag-embedding$gist$llmrails$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$flag-embedding$gist$mixed-bread$voyage...
Skipping STS17 as it already exists
Creating model cohere$flag-embedding$gist$mixed-bread$voyage for task TwitterSemEval2015
Loading cohere from cache for TwitterSemEval2015...
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
Loading voyage from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Creating model angle$gist$gte-large$llmrails$mixed-bread$voyage for task RedditClustering
Loading angle from cache for RedditClustering...
Loading gist from cache for RedditClustering...
Loading gte-large from cache for RedditClustering...
Loading llmrails from cache for RedditClustering...
Loading mixed-bread from cache for RedditClustering...
Loading voyage from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:06<02:39,  6.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [05:01<09:46, 30.86s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 24.50 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8775704833998927, 'accuracy_threshold': 0.8120227244743333, 'f1': 0.7190927218344966, 'f1_threshold': 0.7832570291214829, 'precision': 0.6813887576759565, 'recall': 0.7612137203166227, 'ap': 0.788946211335626}, 'manhattan': {'accuracy': 0.8769744292781785, 'accuracy_threshold': 33.80093622615729, 'f1': 0.7182070007554774, 'f1_threshold': 35.87909689345615, 'precision': 0.6868978805394991, 'recall': 0.7525065963060686, 'ap': 0.7890855053231294}, 'euclidean': {'accuracy': 0.8775704833998927, 'accuracy_threshold': 0.6131513256854406, 'f1': 0.7190927218344966, 'f1_threshold': 0.6583964927534934, 'precision': 0.6813887576759565, 'recall': 0.7612137203166227, 'ap': 0.788946211335626}, 'dot': {'accuracy': 0.8775704833998927, 'accuracy_threshold': 0.812022724474334, 'f1': 0.7190927218344966, 'f1_threshold': 0.783257029121483, 'precision': 0.6813887576759565, 'recall': 0.7612137203166227, 'ap': 0.788946211335626}, 'max': {'accuracy': 0.8775704833998927, 'f1': 0.7190927218344966, 'ap': 0.7890855053231294}, 'evaluation_time': 24.5}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:17<03:30,  9.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model cohere$flag-embedding$gist$mixed-bread$voyage for task AskUbuntuDupQuestions
Loading cohere from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 9.97 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6446423457246758, 'mrr': 0.7769115771885855, 'evaluation_time': 9.97}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist$mixed-bread$voyage for task SciFact
Loading cohere from cache for SciFact...
Loading flag-embedding from cache for SciFact...
Loading gist from cache for SciFact...
Loading mixed-bread from cache for SciFact...
Loading voyage from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s] 62%|██████▏   | 3230/5183 [00:00<00:00, 32291.18it/s]100%|██████████| 5183/5183 [00:00<00:00, 36723.83it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:45<06:29, 17.70s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 12.92 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.6367
INFO:root:NDCG@3: 0.6976
INFO:root:NDCG@5: 0.7335
INFO:root:NDCG@10: 0.7534
INFO:root:NDCG@100: 0.7736
INFO:root:NDCG@1000: 0.7770
INFO:root:

INFO:root:MAP@1: 0.6103
INFO:root:MAP@3: 0.6748
INFO:root:MAP@5: 0.6977
INFO:root:MAP@10: 0.7078
INFO:root:MAP@100: 0.7128
INFO:root:MAP@1000: 0.7130
INFO:root:

INFO:root:Recall@1: 0.6103
INFO:root:Recall@3: 0.7378
INFO:root:Recall@5: 0.8274
INFO:root:Recall@10: 0.8849
INFO:root:Recall@100: 0.9750
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6367
INFO:root:P@3: 0.2711
INFO:root:P@5: 0.1853
INFO:root:P@10: 0.1003
INFO:root:P@100: 0.0110
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6367
INFO:root:MRR@3: 0.6894
INFO:root:MRR@5: 0.7088
INFO:root:MRR@10: 0.7155
INFO:root:MRR@100: 0.7193
INFO:root:MRR@1000: 0.7194
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 13.40 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.63667, 'ndcg_at_3': 0.69759, 'ndcg_at_5': 0.73348, 'ndcg_at_10': 0.75339, 'ndcg_at_100': 0.77357, 'ndcg_at_1000': 0.77702, 'map_at_1': 0.61028, 'map_at_3': 0.67481, 'map_at_5': 0.69766, 'map_at_10': 0.70784, 'map_at_100': 0.71283, 'map_at_1000': 0.713, 'recall_at_1': 0.61028, 'recall_at_3': 0.73783, 'recall_at_5': 0.82744, 'recall_at_10': 0.88489, 'recall_at_100': 0.975, 'recall_at_1000': 1.0, 'precision_at_1': 0.63667, 'precision_at_3': 0.27111, 'precision_at_5': 0.18533, 'precision_at_10': 0.10033, 'precision_at_100': 0.01103, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.63667, 'mrr_at_3': 0.68944, 'mrr_at_5': 0.70878, 'mrr_at_10': 0.7155, 'mrr_at_100': 0.71926, 'mrr_at_1000': 0.71941, 'evaluation_time': 13.4}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [05:41<10:07, 33.75s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist$mixed-bread$voyage for task EmotionClassification
Loading cohere from cache for EmotionClassification...
Loading flag-embedding from cache for EmotionClassification...
Loading gist from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
Loading voyage from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [01:03<06:15, 17.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [01:32<07:19, 21.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 50.06 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5676, 'f1': 0.5063951055687801, 'accuracy_stderr': 0.019417517864031966, 'f1_stderr': 0.010421648000394136, 'main_score': 0.5676, 'evaluation_time': 50.06}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model cohere$flag-embedding$gist$mixed-bread$voyage for task AmazonCounterfactualClassification
Loading cohere from cache for AmazonCounterfactualClassification...
Loading flag-embedding from cache for AmazonCounterfactualClassification...
Loading gist from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
Loading voyage from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 1.61 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7728358208955224, 'f1': 0.7131312856817836, 'ap': 0.4077625873849078, 'accuracy_stderr': 0.03886218660579293, 'f1_stderr': 0.03770426745483527, 'ap_stderr': 0.04459818790715534, 'main_score': 0.7728358208955224}, 'evaluation_time': 1.61}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist$mixed-bread$voyage for task Banking77Classification
Loading cohere from cache for Banking77Classification...
Loading flag-embedding from cache for Banking77Classification...
Loading gist from cache for Banking77Classification...
Loading mixed-bread from cache for Banking77Classification...
Loading voyage from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
Clustering:  24%|██▍       | 6/25 [01:54<06:58, 22.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Clustering:  45%|████▌     | 14/31 [06:49<12:28, 44.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [02:08<05:45, 19.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [02:51<07:35, 26.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 69.17 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8532142857142857, 'f1': 0.8480999870648029, 'accuracy_stderr': 0.005167236097943229, 'f1_stderr': 0.006111892641235904, 'main_score': 0.8532142857142857, 'evaluation_time': 69.17}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist$mixed-bread$voyage for task ArguAna
Loading cohere from cache for ArguAna...
Loading flag-embedding from cache for ArguAna...
Loading gist from cache for ArguAna...
Loading mixed-bread from cache for ArguAna...
Loading voyage from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s] 16%|█▋        | 1426/8674 [00:00<00:00, 13526.40it/s] 74%|███████▍  | 6442/8674 [00:00<00:00, 34602.17it/s]100%|██████████| 8674/8674 [00:00<00:00, 34776.86it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [08:02<14:02, 52.69s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [03:19<07:16, 27.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 28.70 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.3713
INFO:root:NDCG@3: 0.5426
INFO:root:NDCG@5: 0.5889
INFO:root:NDCG@10: 0.6305
INFO:root:NDCG@100: 0.6519
INFO:root:NDCG@1000: 0.6523
INFO:root:

INFO:root:MAP@1: 0.3713
INFO:root:MAP@3: 0.5006
INFO:root:MAP@5: 0.5263
INFO:root:MAP@10: 0.5437
INFO:root:MAP@100: 0.5491
INFO:root:MAP@1000: 0.5491
INFO:root:

INFO:root:Recall@1: 0.3713
INFO:root:Recall@3: 0.6643
INFO:root:Recall@5: 0.7767
INFO:root:Recall@10: 0.9040
INFO:root:Recall@100: 0.9936
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.3713
INFO:root:P@3: 0.2214
INFO:root:P@5: 0.1553
INFO:root:P@10: 0.0904
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.3777
INFO:root:MRR@3: 0.5038
INFO:root:MRR@5: 0.5284
INFO:root:MRR@10: 0.5462
INFO:root:MRR@100: 0.5516
INFO:root:MRR@1000: 0.5516
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 31.23 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.37127, 'ndcg_at_3': 0.54264, 'ndcg_at_5': 0.58895, 'ndcg_at_10': 0.6305, 'ndcg_at_100': 0.65192, 'ndcg_at_1000': 0.65231, 'map_at_1': 0.37127, 'map_at_3': 0.50059, 'map_at_5': 0.5263, 'map_at_10': 0.54367, 'map_at_100': 0.54909, 'map_at_1000': 0.54911, 'recall_at_1': 0.37127, 'recall_at_3': 0.6643, 'recall_at_5': 0.77667, 'recall_at_10': 0.90398, 'recall_at_100': 0.9936, 'recall_at_1000': 0.99644, 'precision_at_1': 0.37127, 'precision_at_3': 0.22143, 'precision_at_5': 0.15533, 'precision_at_10': 0.0904, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.37767, 'mrr_at_3': 0.50379, 'mrr_at_5': 0.52837, 'mrr_at_10': 0.54622, 'mrr_at_100': 0.55163, 'mrr_at_1000': 0.55165, 'evaluation_time': 31.23}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [03:42<06:29, 25.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [08:41<12:10, 48.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [04:03<05:41, 24.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [04:11<04:11, 19.37s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [09:13<10:09, 43.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [04:33<04:03, 20.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [04:55<03:48, 20.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [09:57<09:30, 43.88s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [05:11<03:11, 19.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [05:37<03:11, 21.28s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [10:36<08:28, 42.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [05:53<02:38, 19.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [06:07<02:05, 17.91s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [11:10<07:17, 39.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [06:24<01:46, 17.81s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [11:38<06:04, 36.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [11:45<04:06, 27.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [06:55<01:48, 21.68s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [12:13<03:41, 27.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [07:28<01:39, 24.94s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [12:31<02:54, 24.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist$mixed-bread$voyage for task ArxivClusteringS2S
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [07:53<01:14, 24.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [07:59<00:38, 19.22s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [12:54<02:25, 24.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [13:02<01:36, 19.22s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:22<11:03, 22.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [08:14<00:18, 18.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:42<10:04, 20.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [13:27<01:23, 20.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [08:40<00:00, 20.38s/it]Clustering: 100%|██████████| 25/25 [08:40<00:00, 20.81s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 520.20 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.6097783105069302, 'v_measure_std': 0.04618917566005861, 'evaluation_time': 520.2}
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [01:03<09:47, 20.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [13:47<01:01, 20.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Converting the results to a CSV file...
Using model name angle$gist$gte-large$llmrails$mixed-bread$voyage
Converting results/angle$gist$gte-large$llmrails$mixed-bread$voyage to results/angle$gist$gte-large$llmrails$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread...
Skipping STS17 as it already exists
Creating model cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread for task TwitterSemEval2015
Loading cohere from cache for TwitterSemEval2015...
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
Loading gte-large from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:23<09:20, 20.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [14:08<00:41, 20.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 27.10 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8773916671633785, 'accuracy_threshold': 0.8276067793806957, 'f1': 0.7166687260595577, 'f1_threshold': 0.8004822495878288, 'precision': 0.6739484080873809, 'recall': 0.7651715039577837, 'ap': 0.7876893246826254}, 'manhattan': {'accuracy': 0.8767956130416642, 'accuracy_threshold': 35.66604118751189, 'f1': 0.7174666006927264, 'f1_threshold': 38.38088003290124, 'precision': 0.6753609687936656, 'recall': 0.7651715039577837, 'ap': 0.788629501157364}, 'euclidean': {'accuracy': 0.8773916671633785, 'accuracy_threshold': 0.5871851725778565, 'f1': 0.7166687260595577, 'f1_threshold': 0.6316925682828622, 'precision': 0.6739484080873809, 'recall': 0.7651715039577837, 'ap': 0.7876893246826254}, 'dot': {'accuracy': 0.8773916671633785, 'accuracy_threshold': 0.8276067793806969, 'f1': 0.7166687260595577, 'f1_threshold': 0.800482249587829, 'precision': 0.6739484080873809, 'recall': 0.7651715039577837, 'ap': 0.7876893246826254}, 'max': {'accuracy': 0.8773916671633785, 'f1': 0.7174666006927264, 'ap': 0.788629501157364}, 'evaluation_time': 27.1}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread for task AskUbuntuDupQuestions
Loading cohere from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
Loading gte-large from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [14:25<00:19, 19.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [01:43<08:50, 20.41s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 6.36 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6431962299840569, 'mrr': 0.776042078881414, 'evaluation_time': 6.36}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread for task SciFact
Loading cohere from cache for SciFact...
Loading flag-embedding from cache for SciFact...
Loading gist from cache for SciFact...
Loading gte-large from cache for SciFact...
Loading llmrails from cache for SciFact...
Loading mixed-bread from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s] 64%|██████▍   | 3330/5183 [00:00<00:00, 33291.06it/s]100%|██████████| 5183/5183 [00:00<00:00, 37521.54it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [14:47<00:00, 20.33s/it]Clustering: 100%|██████████| 31/31 [14:47<00:00, 28.62s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 887.23 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4356651537558994, 'v_measure_std': 0.1424616026391175, 'evaluation_time': 887.23}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [02:04<08:31, 20.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 14.65 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.6533
INFO:root:NDCG@3: 0.7016
INFO:root:NDCG@5: 0.7378
INFO:root:NDCG@10: 0.7595
INFO:root:NDCG@100: 0.7776
INFO:root:NDCG@1000: 0.7816
INFO:root:

INFO:root:MAP@1: 0.6216
INFO:root:MAP@3: 0.6794
INFO:root:MAP@5: 0.7027
INFO:root:MAP@10: 0.7140
INFO:root:MAP@100: 0.7183
INFO:root:MAP@1000: 0.7185
INFO:root:

INFO:root:Recall@1: 0.6216
INFO:root:Recall@3: 0.7366
INFO:root:Recall@5: 0.8274
INFO:root:Recall@10: 0.8899
INFO:root:Recall@100: 0.9717
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6533
INFO:root:P@3: 0.2700
INFO:root:P@5: 0.1853
INFO:root:P@10: 0.1010
INFO:root:P@100: 0.0110
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6533
INFO:root:MRR@3: 0.6978
INFO:root:MRR@5: 0.7176
INFO:root:MRR@10: 0.7244
INFO:root:MRR@100: 0.7278
INFO:root:MRR@1000: 0.7280
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 15.07 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.65333, 'ndcg_at_3': 0.70165, 'ndcg_at_5': 0.73783, 'ndcg_at_10': 0.7595, 'ndcg_at_100': 0.77764, 'ndcg_at_1000': 0.78159, 'map_at_1': 0.62161, 'map_at_3': 0.67935, 'map_at_5': 0.70272, 'map_at_10': 0.71398, 'map_at_100': 0.71828, 'map_at_1000': 0.71848, 'recall_at_1': 0.62161, 'recall_at_3': 0.73656, 'recall_at_5': 0.82744, 'recall_at_10': 0.88989, 'recall_at_100': 0.97167, 'recall_at_1000': 1.0, 'precision_at_1': 0.65333, 'precision_at_3': 0.27, 'precision_at_5': 0.18533, 'precision_at_10': 0.101, 'precision_at_100': 0.011, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.65333, 'mrr_at_3': 0.69778, 'mrr_at_5': 0.71761, 'mrr_at_10': 0.72438, 'mrr_at_100': 0.72781, 'mrr_at_1000': 0.728, 'evaluation_time': 15.07}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [02:22<07:57, 19.90s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [02:40<07:23, 19.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread for task EmotionClassification
Loading cohere from cache for EmotionClassification...
Loading flag-embedding from cache for EmotionClassification...
Loading gist from cache for EmotionClassification...
Loading gte-large from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [03:14<08:44, 23.85s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 45.12 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5610999999999999, 'f1': 0.5000618431346344, 'accuracy_stderr': 0.02186984224908813, 'f1_stderr': 0.012238745623042346, 'main_score': 0.5610999999999999, 'evaluation_time': 45.12}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [03:43<08:52, 25.35s/it]INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread for task AmazonCounterfactualClassification
Loading cohere from cache for AmazonCounterfactualClassification...
Loading flag-embedding from cache for AmazonCounterfactualClassification...
Loading gist from cache for AmazonCounterfactualClassification...
Loading gte-large from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 1.95 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7688059701492537, 'f1': 0.7090324391045917, 'ap': 0.4023366576262826, 'accuracy_stderr': 0.035941649699398594, 'f1_stderr': 0.03485474179522346, 'ap_stderr': 0.040725784175250995, 'main_score': 0.7688059701492537}, 'evaluation_time': 1.95}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread for task Banking77Classification
Loading cohere from cache for Banking77Classification...
Loading flag-embedding from cache for Banking77Classification...
Loading gist from cache for Banking77Classification...
Loading gte-large from cache for Banking77Classification...
Loading llmrails from cache for Banking77Classification...
Loading mixed-bread from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [04:30<10:42, 32.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Creating model angle$cohere$flag-embedding$gist$gte-large$llmrails for task RedditClustering
Loading angle from cache for RedditClustering...
Loading cohere from cache for RedditClustering...
Loading flag-embedding from cache for RedditClustering...
Loading gist from cache for RedditClustering...
Loading gte-large from cache for RedditClustering...
Loading llmrails from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:12<05:04, 12.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 68.25 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.846948051948052, 'f1': 0.8411172660140854, 'accuracy_stderr': 0.004883531344665768, 'f1_stderr': 0.005869111166654018, 'main_score': 0.846948051948052, 'evaluation_time': 68.25}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:35<07:06, 18.54s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread for task ArguAna
Loading cohere from cache for ArguAna...
Loading flag-embedding from cache for ArguAna...
Loading gist from cache for ArguAna...
Loading gte-large from cache for ArguAna...
Loading llmrails from cache for ArguAna...
Loading mixed-bread from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s]  8%|▊         | 717/8674 [00:00<00:01, 6052.33it/s] 69%|██████▊   | 5957/8674 [00:00<00:00, 31382.61it/s]100%|██████████| 8674/8674 [00:00<00:00, 32339.45it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [05:26<12:26, 39.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
Clustering:  39%|███▊      | 12/31 [05:38<08:55, 28.21s/it]
ERROR:mteb.evaluation.MTEB:Error while evaluating ArxivClusteringS2S: Unable to allocate 977. MiB for an array with shape (25000, 5120) and data type float64
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [01:01<08:03, 21.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 29.02 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.3677
INFO:root:NDCG@3: 0.5366
INFO:root:NDCG@5: 0.5853
INFO:root:NDCG@10: 0.6241
INFO:root:NDCG@100: 0.6476
INFO:root:NDCG@1000: 0.6480
INFO:root:

INFO:root:MAP@1: 0.3677
INFO:root:MAP@3: 0.4948
INFO:root:MAP@5: 0.5217
INFO:root:MAP@10: 0.5379
INFO:root:MAP@100: 0.5439
INFO:root:MAP@1000: 0.5439
INFO:root:

INFO:root:Recall@1: 0.3677
INFO:root:Recall@3: 0.6579
INFO:root:Recall@5: 0.7760
INFO:root:Recall@10: 0.8954
INFO:root:Recall@100: 0.9936
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.3677
INFO:root:P@3: 0.2193
INFO:root:P@5: 0.1552
INFO:root:P@10: 0.0895
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:root:MRR@1: 0.3748
INFO:root:MRR@3: 0.4972
INFO:root:MRR@5: 0.5242
INFO:root:MRR@10: 0.5407
INFO:root:MRR@100: 0.5466
INFO:root:MRR@1000: 0.5466
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 31.38 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.36771, 'ndcg_at_3': 0.53664, 'ndcg_at_5': 0.58525, 'ndcg_at_10': 0.62414, 'ndcg_at_100': 0.64762, 'ndcg_at_1000': 0.648, 'map_at_1': 0.36771, 'map_at_3': 0.49478, 'map_at_5': 0.52174, 'map_at_10': 0.53793, 'map_at_100': 0.54388, 'map_at_1000': 0.5439, 'recall_at_1': 0.36771, 'recall_at_3': 0.65789, 'recall_at_5': 0.77596, 'recall_at_10': 0.89545, 'recall_at_100': 0.9936, 'recall_at_1000': 0.99644, 'precision_at_1': 0.36771, 'precision_at_3': 0.2193, 'precision_at_5': 0.15519, 'precision_at_10': 0.08954, 'precision_at_100': 0.00994, 'precision_at_1000': 0.001, 'mrr_at_1': 0.37482, 'mrr_at_3': 0.49716, 'mrr_at_5': 0.52418, 'mrr_at_10': 0.54069, 'mrr_at_100': 0.54657, 'mrr_at_1000': 0.54659, 'evaluation_time': 31.38}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [01:12<06:12, 17.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [01:21<04:49, 14.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [01:35<04:31, 14.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [01:44<03:47, 12.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [02:02<04:04, 14.40s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [02:22<04:16, 16.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [02:40<04:09, 16.67s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [03:00<04:09, 17.84s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [03:04<02:56, 13.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [03:18<02:43, 13.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [03:36<02:46, 15.10s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [03:44<02:09, 12.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [04:05<02:18, 15.35s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [04:18<01:55, 14.40s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [04:22<01:20, 11.54s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [04:36<01:13, 12.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread for task ArxivClusteringS2S
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [05:02<01:22, 16.40s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:21<10:36, 21.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [05:27<01:16, 19.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:40<09:38, 19.94s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [05:51<01:00, 20.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [05:56<00:31, 15.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [01:00<09:27, 20.28s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [06:09<00:14, 14.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:19<08:45, 19.48s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [06:31<00:00, 17.00s/it]Clustering: 100%|██████████| 25/25 [06:31<00:00, 15.65s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 391.28 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.6144731386526784, 'v_measure_std': 0.04421903476763989, 'evaluation_time': 391.28}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [01:37<08:11, 18.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gist$gte-large$llmrails
Converting results/angle$cohere$flag-embedding$gist$gte-large$llmrails to results/angle$cohere$flag-embedding$gist$gte-large$llmrails_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$gist$gte-large$mixed-bread...
Skipping STS17 as it already exists
Creating model angle$cohere$flag-embedding$gist$gte-large$mixed-bread for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading cohere from cache for TwitterSemEval2015...
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
Loading gte-large from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [01:55<07:46, 18.67s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 23.04 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8759015318590928, 'accuracy_threshold': 0.8159224966238503, 'f1': 0.7196473551637278, 'f1_threshold': 0.7959628509883931, 'precision': 0.688433734939759, 'recall': 0.7538258575197889, 'ap': 0.7876499224196596}, 'manhattan': {'accuracy': 0.87578232103475, 'accuracy_threshold': 35.60562031160717, 'f1': 0.7181655137074046, 'f1_threshold': 38.2572963811803, 'precision': 0.6979581673306773, 'recall': 0.7395778364116095, 'ap': 0.7870074464336018}, 'euclidean': {'accuracy': 0.8759015318590928, 'accuracy_threshold': 0.6067577823807097, 'f1': 0.7196473551637278, 'f1_threshold': 0.6388069324268932, 'precision': 0.688433734939759, 'recall': 0.7538258575197889, 'ap': 0.7876499224196596}, 'dot': {'accuracy': 0.8759015318590928, 'accuracy_threshold': 0.8159224966238505, 'f1': 0.7196473551637278, 'f1_threshold': 0.7959628509883938, 'precision': 0.688433734939759, 'recall': 0.7538258575197889, 'ap': 0.7876499224196596}, 'max': {'accuracy': 0.8759015318590928, 'f1': 0.7196473551637278, 'ap': 0.7876499224196596}, 'evaluation_time': 23.04}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [02:12<07:16, 18.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model angle$cohere$flag-embedding$gist$gte-large$mixed-bread for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading cohere from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
Loading gte-large from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 5.01 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6467748951907687, 'mrr': 0.7799773556698764, 'evaluation_time': 5.01}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gist$gte-large$mixed-bread for task SciFact
Loading angle from cache for SciFact...
Loading cohere from cache for SciFact...
Loading flag-embedding from cache for SciFact...
Loading gist from cache for SciFact...
Loading gte-large from cache for SciFact...
Loading mixed-bread from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s] 91%|█████████ | 4699/5183 [00:00<00:00, 46977.84it/s]100%|██████████| 5183/5183 [00:00<00:00, 47343.26it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [02:29<06:51, 17.91s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 13.22 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.6500
INFO:root:NDCG@3: 0.7015
INFO:root:NDCG@5: 0.7257
INFO:root:NDCG@10: 0.7533
INFO:root:NDCG@100: 0.7750
INFO:root:NDCG@1000: 0.7795
INFO:root:

INFO:root:MAP@1: 0.6209
INFO:root:MAP@3: 0.6800
INFO:root:MAP@5: 0.6962
INFO:root:MAP@10: 0.7106
INFO:root:MAP@100: 0.7163
INFO:root:MAP@1000: 0.7165
INFO:root:

INFO:root:Recall@1: 0.6209
INFO:root:Recall@3: 0.7367
INFO:root:Recall@5: 0.7966
INFO:root:Recall@10: 0.8749
INFO:root:Recall@100: 0.9683
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6500
INFO:root:P@3: 0.2700
INFO:root:P@5: 0.1787
INFO:root:P@10: 0.0993
INFO:root:P@100: 0.0110
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6500
INFO:root:MRR@3: 0.6967
INFO:root:MRR@5: 0.7105
INFO:root:MRR@10: 0.7201
INFO:root:MRR@100: 0.7246
INFO:root:MRR@1000: 0.7249
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 13.67 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.65, 'ndcg_at_3': 0.70151, 'ndcg_at_5': 0.72566, 'ndcg_at_10': 0.75328, 'ndcg_at_100': 0.77504, 'ndcg_at_1000': 0.77949, 'map_at_1': 0.62094, 'map_at_3': 0.67996, 'map_at_5': 0.6962, 'map_at_10': 0.71062, 'map_at_100': 0.71626, 'map_at_1000': 0.7165, 'recall_at_1': 0.62094, 'recall_at_3': 0.73672, 'recall_at_5': 0.79661, 'recall_at_10': 0.87489, 'recall_at_100': 0.96833, 'recall_at_1000': 1.0, 'precision_at_1': 0.65, 'precision_at_3': 0.27, 'precision_at_5': 0.17867, 'precision_at_10': 0.09933, 'precision_at_100': 0.01097, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.65, 'mrr_at_3': 0.69667, 'mrr_at_5': 0.7105, 'mrr_at_10': 0.72014, 'mrr_at_100': 0.72463, 'mrr_at_1000': 0.72486, 'evaluation_time': 13.67}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gist$gte-large$mixed-bread for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading cohere from cache for EmotionClassification...
Loading flag-embedding from cache for EmotionClassification...
Loading gist from cache for EmotionClassification...
Loading gte-large from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
Clustering:  29%|██▉       | 9/31 [02:46<06:28, 17.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 34.48 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5631, 'f1': 0.5001682186102495, 'accuracy_stderr': 0.021905250512148915, 'f1_stderr': 0.0127502071334455, 'main_score': 0.5631, 'evaluation_time': 34.48}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [03:22<08:04, 23.09s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model angle$cohere$flag-embedding$gist$gte-large$mixed-bread for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading cohere from cache for AmazonCounterfactualClassification...
Loading flag-embedding from cache for AmazonCounterfactualClassification...
Loading gist from cache for AmazonCounterfactualClassification...
Loading gte-large from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 1.97 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7540298507462687, 'f1': 0.6934307483989637, 'ap': 0.3832166799229108, 'accuracy_stderr': 0.03772194290607908, 'f1_stderr': 0.03647005010328848, 'ap_stderr': 0.040302227227705475, 'main_score': 0.7540298507462687}, 'evaluation_time': 1.97}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gist$gte-large$mixed-bread for task Banking77Classification
Loading angle from cache for Banking77Classification...
Loading cohere from cache for Banking77Classification...
Loading flag-embedding from cache for Banking77Classification...
Loading gist from cache for Banking77Classification...
Loading gte-large from cache for Banking77Classification...
Loading mixed-bread from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [04:31<12:27, 37.39s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 61.56 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8541233766233767, 'f1': 0.848953943579702, 'accuracy_stderr': 0.004155463659529536, 'f1_stderr': 0.005051186443878313, 'main_score': 0.8541233766233767, 'evaluation_time': 61.56}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gist$gte-large$mixed-bread for task ArguAna
Loading angle from cache for ArguAna...
Loading cohere from cache for ArguAna...
Loading flag-embedding from cache for ArguAna...
Loading gist from cache for ArguAna...
Loading gte-large from cache for ArguAna...
Loading mixed-bread from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s] 15%|█▌        | 1329/8674 [00:00<00:00, 11744.52it/s] 74%|███████▍  | 6424/8674 [00:00<00:00, 33617.80it/s]100%|██████████| 8674/8674 [00:00<00:00, 34063.22it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [05:06<11:34, 36.56s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 31.16 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.3947
INFO:root:NDCG@3: 0.5600
INFO:root:NDCG@5: 0.6096
INFO:root:NDCG@10: 0.6453
INFO:root:NDCG@100: 0.6659
INFO:root:NDCG@1000: 0.6664
INFO:root:

INFO:root:MAP@1: 0.3947
INFO:root:MAP@3: 0.5191
INFO:root:MAP@5: 0.5466
INFO:root:MAP@10: 0.5616
INFO:root:MAP@100: 0.5670
INFO:root:MAP@1000: 0.5670
INFO:root:

INFO:root:Recall@1: 0.3947
INFO:root:Recall@3: 0.6785
INFO:root:Recall@5: 0.7987
INFO:root:Recall@10: 0.9083
INFO:root:Recall@100: 0.9929
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.3947
INFO:root:P@3: 0.2262
INFO:root:P@5: 0.1597
INFO:root:P@10: 0.0908
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.4018
INFO:root:MRR@3: 0.5219
INFO:root:MRR@5: 0.5491
INFO:root:MRR@10: 0.5641
INFO:root:MRR@100: 0.5695
INFO:root:MRR@1000: 0.5696
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 33.47 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.39474, 'ndcg_at_3': 0.56, 'ndcg_at_5': 0.60959, 'ndcg_at_10': 0.64533, 'ndcg_at_100': 0.66588, 'ndcg_at_1000': 0.66637, 'map_at_1': 0.39474, 'map_at_3': 0.51908, 'map_at_5': 0.54665, 'map_at_10': 0.56158, 'map_at_100': 0.56696, 'map_at_1000': 0.56698, 'recall_at_1': 0.39474, 'recall_at_3': 0.67852, 'recall_at_5': 0.79872, 'recall_at_10': 0.90825, 'recall_at_100': 0.99289, 'recall_at_1000': 0.99644, 'precision_at_1': 0.39474, 'precision_at_3': 0.22617, 'precision_at_5': 0.15974, 'precision_at_10': 0.09083, 'precision_at_100': 0.00993, 'precision_at_1000': 0.001, 'mrr_at_1': 0.40185, 'mrr_at_3': 0.52193, 'mrr_at_5': 0.5491, 'mrr_at_10': 0.5641, 'mrr_at_100': 0.56954, 'mrr_at_1000': 0.56957, 'evaluation_time': 33.47}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [05:41<10:50, 36.13s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [06:14<09:55, 35.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [06:51<09:32, 35.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [07:32<09:18, 37.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [08:05<08:22, 35.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gist$gte-large$mixed-bread for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:21<10:38, 21.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [08:38<07:34, 34.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:42<10:10, 21.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [09:12<06:56, 34.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [01:01<09:31, 20.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:22<09:10, 20.40s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [09:44<06:14, 34.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [01:41<08:38, 19.94s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [10:12<05:22, 32.28s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [10:15<03:31, 23.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [02:02<08:30, 20.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [02:22<08:05, 20.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [10:42<03:15, 24.39s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [02:41<07:39, 19.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [11:00<02:37, 22.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [03:01<07:14, 19.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [11:20<02:10, 21.82s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [11:27<01:26, 17.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [03:19<06:45, 19.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [11:48<01:13, 18.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [12:08<00:56, 18.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [03:55<08:10, 24.52s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [12:27<00:37, 18.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [12:43<00:18, 18.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [04:31<08:51, 27.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [13:02<00:00, 18.21s/it]Clustering: 100%|██████████| 31/31 [13:02<00:00, 25.23s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 782.28 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4360353389567877, 'v_measure_std': 0.1425226718073287, 'evaluation_time': 782.28}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [05:06<09:02, 30.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [05:48<09:32, 33.66s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [06:23<09:04, 34.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Creating model cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread for task RedditClustering
Loading cohere from cache for RedditClustering...
Loading flag-embedding from cache for RedditClustering...
Loading gist from cache for RedditClustering...
Loading gte-large from cache for RedditClustering...
Loading llmrails from cache for RedditClustering...
Loading mixed-bread from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:06<02:31,  6.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [07:02<08:54, 35.66s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:14<02:56,  7.67s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:39<05:41, 15.53s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [07:36<08:08, 34.91s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:50<04:43, 13.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:58<03:52, 11.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [01:13<04:00, 12.67s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [08:13<07:43, 35.69s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [01:20<03:14, 10.82s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [01:39<03:51, 13.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [08:48<07:06, 35.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [02:01<04:18, 16.17s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [02:20<04:14, 17.00s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [09:20<06:18, 34.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [02:37<04:00, 17.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [02:41<02:49, 13.00s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [02:49<02:18, 11.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [09:50<05:31, 33.16s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [09:53<03:36, 24.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [03:05<02:20, 12.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [03:10<01:43, 10.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [10:22<03:24, 25.52s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [03:31<02:04, 13.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [03:41<01:41, 12.67s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [03:46<01:11, 10.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [10:41<02:45, 23.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [03:57<01:03, 10.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [11:03<02:18, 23.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [11:13<01:35, 19.14s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [04:22<01:14, 14.81s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [11:37<01:22, 20.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [04:44<01:07, 16.87s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [11:58<01:01, 20.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Clustering:  88%|████████▊ | 22/25 [05:03<00:53, 17.72s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [05:07<00:27, 13.57s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [05:20<00:13, 13.30s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [12:19<00:41, 20.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [05:39<00:00, 15.02s/it]Clustering: 100%|██████████| 25/25 [05:39<00:00, 13.58s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 339.51 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.6150790826246769, 'v_measure_std': 0.0430180330994943, 'evaluation_time': 339.51}
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [12:36<00:19, 19.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
Converting the results to a CSV file...
Using model name cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread
Converting results/cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread to results/cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [12:55<00:00, 19.57s/it]Clustering: 100%|██████████| 31/31 [12:55<00:00, 25.03s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 775.88 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.43377366317948884, 'v_measure_std': 0.14249087759118514, 'evaluation_time': 775.88}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Creating model angle$cohere$flag-embedding$gist$gte-large$mixed-bread for task RedditClustering
Loading angle from cache for RedditClustering...
Loading cohere from cache for RedditClustering...
Loading flag-embedding from cache for RedditClustering...
Loading gist from cache for RedditClustering...
Loading gte-large from cache for RedditClustering...
Loading mixed-bread from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:05<02:17,  5.73s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:14<02:58,  7.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:39<05:38, 15.41s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:51<04:58, 14.23s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [01:01<04:08, 12.42s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [01:16<04:12, 13.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [01:22<03:21, 11.18s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [01:41<03:48, 13.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [02:02<04:12, 15.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [02:21<04:14, 17.00s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [02:40<04:07, 17.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [02:44<02:54, 13.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [02:52<02:19, 11.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [03:08<02:24, 13.09s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [03:13<01:46, 10.65s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [03:35<02:05, 13.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [03:46<01:44, 13.06s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [03:50<01:13, 10.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [04:02<01:05, 10.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [04:27<01:15, 15.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [04:50<01:10, 17.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [05:11<00:55, 18.62s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [05:16<00:28, 14.34s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [05:28<00:13, 13.69s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [05:48<00:00, 15.66s/it]Clustering: 100%|██████████| 25/25 [05:48<00:00, 13.95s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 348.78 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.612266700486058, 'v_measure_std': 0.044309039002543155, 'evaluation_time': 348.78}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gist$gte-large$mixed-bread
Converting results/angle$cohere$flag-embedding$gist$gte-large$mixed-bread to results/angle$cohere$flag-embedding$gist$gte-large$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$gist$gte-large$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model angle$cohere$flag-embedding$gist$gte-large$voyage for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading cohere from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
Loading gte-large from cache for AskUbuntuDupQuestions...
Loading voyage from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 5.41 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6460136989266589, 'mrr': 0.7838400826627973, 'evaluation_time': 5.41}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Creating model angle$cohere$flag-embedding$gist$gte-large$voyage for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading gte-large from cache for ArxivClusteringS2S...
Loading voyage from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:21<10:59, 21.98s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:42<10:11, 21.08s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [01:02<09:39, 20.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:23<09:24, 20.92s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [01:44<09:04, 20.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [02:05<08:38, 20.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [02:26<08:23, 20.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [02:48<08:06, 21.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [03:10<07:51, 21.43s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [03:32<07:34, 21.66s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [04:08<08:40, 26.01s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [04:44<09:11, 29.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [05:18<09:08, 30.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [05:52<08:59, 31.74s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [06:27<08:43, 32.69s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [07:02<08:19, 33.29s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [07:35<07:47, 33.39s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [08:09<07:16, 33.54s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [08:44<06:47, 33.96s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [09:21<06:22, 34.76s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [09:52<05:35, 33.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [09:55<03:40, 24.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [10:24<03:25, 25.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [10:44<02:48, 24.04s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [11:08<02:23, 23.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [11:16<01:36, 19.33s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [11:41<01:24, 21.13s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [12:03<01:04, 21.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [12:27<00:43, 21.99s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [12:46<00:21, 21.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [13:08<00:00, 21.33s/it]Clustering: 100%|██████████| 31/31 [13:08<00:00, 25.43s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 788.28 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4358663206894312, 'v_measure_std': 0.14233626998799045, 'evaluation_time': 788.28}
INFO:main:Running task: TwitterSemEval2015
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gist$gte-large$voyage
Converting results/angle$cohere$flag-embedding$gist$gte-large$voyage to results/angle$cohere$flag-embedding$gist$gte-large$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$gist$llmrails$mixed-bread...
Skipping STS17 as it already exists
Creating model angle$cohere$flag-embedding$gist$llmrails$mixed-bread for task TwitterSemEval2015
Loading angle from cache for TwitterSemEval2015...
Loading cohere from cache for TwitterSemEval2015...
Loading flag-embedding from cache for TwitterSemEval2015...
Loading gist from cache for TwitterSemEval2015...
Loading llmrails from cache for TwitterSemEval2015...
Loading mixed-bread from cache for TwitterSemEval2015...
─────────────────────────────── Selected tasks  ────────────────────────────────
PairClassification
    - TwitterSemEval2015, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating TwitterSemEval2015 **********************
INFO:mteb.evaluation.MTEB:Loading dataset for TwitterSemEval2015
INFO:mteb.abstasks.AbsTaskPairClassification:
Task: TwitterSemEval2015, split: test. Running...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Encoding 17600 sentences...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing similarity distances...
INFO:mteb.evaluation.evaluators.PairClassificationEvaluator:Computing metrics...
INFO:mteb.evaluation.MTEB:Evaluation for TwitterSemEval2015 on test took 22.27 seconds
INFO:mteb.evaluation.MTEB:Scores: {'cos_sim': {'accuracy': 0.8767956130416642, 'accuracy_threshold': 0.8004281650156326, 'f1': 0.7234205488194002, 'f1_threshold': 0.7811369045253336, 'precision': 0.7006180469715698, 'recall': 0.7477572559366754, 'ap': 0.7907675062389954}, 'manhattan': {'accuracy': 0.8770340346903499, 'accuracy_threshold': 38.618510645297874, 'f1': 0.722608919824697, 'f1_threshold': 40.526711862885875, 'precision': 0.7064012096774194, 'recall': 0.7395778364116095, 'ap': 0.791456295664215}, 'euclidean': {'accuracy': 0.8767956130416642, 'accuracy_threshold': 0.6317781808774448, 'f1': 0.7234205488194002, 'f1_threshold': 0.661608789935499, 'precision': 0.7006180469715698, 'recall': 0.7477572559366754, 'ap': 0.7907675062389954}, 'dot': {'accuracy': 0.8767956130416642, 'accuracy_threshold': 0.8004281650156331, 'f1': 0.7234205488194002, 'f1_threshold': 0.7811369045253342, 'precision': 0.7006180469715698, 'recall': 0.7477572559366754, 'ap': 0.7907675062389954}, 'max': {'accuracy': 0.8770340346903499, 'f1': 0.7234205488194002, 'ap': 0.791456295664215}, 'evaluation_time': 22.27}
INFO:main:Running task: AskUbuntuDupQuestions
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Creating model angle$cohere$flag-embedding$gist$llmrails$mixed-bread for task AskUbuntuDupQuestions
Loading angle from cache for AskUbuntuDupQuestions...
Loading cohere from cache for AskUbuntuDupQuestions...
Loading flag-embedding from cache for AskUbuntuDupQuestions...
Loading gist from cache for AskUbuntuDupQuestions...
Loading llmrails from cache for AskUbuntuDupQuestions...
Loading mixed-bread from cache for AskUbuntuDupQuestions...
─────────────────────────────── Selected tasks  ────────────────────────────────
Reranking
    - AskUbuntuDupQuestions, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating AskUbuntuDupQuestions **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AskUbuntuDupQuestions
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding queries...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Encoding candidates...
INFO:mteb.evaluation.evaluators.RerankingEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AskUbuntuDupQuestions on test took 4.57 seconds
INFO:mteb.evaluation.MTEB:Scores: {'map': 0.6482135311303513, 'mrr': 0.7808314646264786, 'evaluation_time': 4.57}
INFO:main:Running task: SciFact
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gist$llmrails$mixed-bread for task SciFact
Loading angle from cache for SciFact...
Loading cohere from cache for SciFact...
Loading flag-embedding from cache for SciFact...
Loading gist from cache for SciFact...
Loading llmrails from cache for SciFact...
Loading mixed-bread from cache for SciFact...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - SciFact, beir, s2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating SciFact **********************
INFO:mteb.evaluation.MTEB:Loading dataset for SciFact
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/5183 [00:00<?, ?it/s] 92%|█████████▏| 4773/5183 [00:00<00:00, 47718.67it/s]100%|██████████| 5183/5183 [00:00<00:00, 47693.92it/s]
INFO:beir.datasets.data_loader:Loaded 5183 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': 'Alterations of the architecture of cerebral white matter in the developing human brain can affect cortical development and result in functional disabilities. A line scan diffusion-weighted magnetic resonance imaging (MRI) sequence with diffusion tensor analysis was applied to measure the apparent diffusion coefficient, to calculate relative anisotropy, and to delineate three-dimensional fiber architecture in cerebral white matter in preterm (n = 17) and full-term infants (n = 7). To assess effects of prematurity on cerebral white matter development, early gestation preterm infants (n = 10) were studied a second time at term. In the central white matter the mean apparent diffusion coefficient at 28 wk was high, 1.8 microm2/ms, and decreased toward term to 1.2 microm2/ms. In the posterior limb of the internal capsule, the mean apparent diffusion coefficients at both times were similar (1.2 versus 1.1 microm2/ms). Relative anisotropy was higher the closer birth was to term with greater absolute values in the internal capsule than in the central white matter. Preterm infants at term showed higher mean diffusion coefficients in the central white matter (1.4 +/- 0.24 versus 1.15 +/- 0.09 microm2/ms, p = 0.016) and lower relative anisotropy in both areas compared with full-term infants (white matter, 10.9 +/- 0.6 versus 22.9 +/- 3.0%, p = 0.001; internal capsule, 24.0 +/- 4.44 versus 33.1 +/- 0.6% p = 0.006). Nonmyelinated fibers in the corpus callosum were visible by diffusion tensor MRI as early as 28 wk; full-term and preterm infants at term showed marked differences in white matter fiber organization. The data indicate that quantitative assessment of water diffusion by diffusion tensor MRI provides insight into microstructural development in cerebral white matter in living infants.', 'title': 'Microstructural development of human newborn cerebral white matter assessed in vivo by diffusion tensor magnetic resonance imaging.'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 300 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: 0-dimensional biomaterials show inductive properties.
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 12.49 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.6533
INFO:root:NDCG@3: 0.7072
INFO:root:NDCG@5: 0.7297
INFO:root:NDCG@10: 0.7558
INFO:root:NDCG@100: 0.7787
INFO:root:NDCG@1000: 0.7826
INFO:root:

INFO:root:MAP@1: 0.6259
INFO:root:MAP@3: 0.6860
INFO:root:MAP@5: 0.7009
INFO:root:MAP@10: 0.7149
INFO:root:MAP@100: 0.7207
INFO:root:MAP@1000: 0.7208
INFO:root:

INFO:root:Recall@1: 0.6259
INFO:root:Recall@3: 0.7407
INFO:root:Recall@5: 0.7983
INFO:root:Recall@10: 0.8716
INFO:root:Recall@100: 0.9717
INFO:root:Recall@1000: 1.0000
INFO:root:

INFO:root:P@1: 0.6533
INFO:root:P@3: 0.2722
INFO:root:P@5: 0.1787
INFO:root:P@10: 0.0990
INFO:root:P@100: 0.0110
INFO:root:P@1000: 0.0011
INFO:root:

INFO:root:MRR@1: 0.6533
INFO:root:MRR@3: 0.7017
INFO:root:MRR@5: 0.7153
INFO:root:MRR@10: 0.7240
INFO:root:MRR@100: 0.7286
INFO:root:MRR@1000: 0.7288
INFO:mteb.evaluation.MTEB:Evaluation for SciFact on test took 12.93 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.65333, 'ndcg_at_3': 0.70724, 'ndcg_at_5': 0.72968, 'ndcg_at_10': 0.75581, 'ndcg_at_100': 0.77868, 'ndcg_at_1000': 0.7826, 'map_at_1': 0.62594, 'map_at_3': 0.68596, 'map_at_5': 0.70092, 'map_at_10': 0.71491, 'map_at_100': 0.72065, 'map_at_1000': 0.72084, 'recall_at_1': 0.62594, 'recall_at_3': 0.74072, 'recall_at_5': 0.79828, 'recall_at_10': 0.87156, 'recall_at_100': 0.97167, 'recall_at_1000': 1.0, 'precision_at_1': 0.65333, 'precision_at_3': 0.27222, 'precision_at_5': 0.17867, 'precision_at_10': 0.099, 'precision_at_100': 0.011, 'precision_at_1000': 0.00113, 'mrr_at_1': 0.65333, 'mrr_at_3': 0.70167, 'mrr_at_5': 0.71533, 'mrr_at_10': 0.72403, 'mrr_at_100': 0.72859, 'mrr_at_1000': 0.72878, 'evaluation_time': 12.93}
INFO:main:Running task: EmotionClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gist$llmrails$mixed-bread for task EmotionClassification
Loading angle from cache for EmotionClassification...
Loading cohere from cache for EmotionClassification...
Loading flag-embedding from cache for EmotionClassification...
Loading gist from cache for EmotionClassification...
Loading llmrails from cache for EmotionClassification...
Loading mixed-bread from cache for EmotionClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - EmotionClassification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating EmotionClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for EmotionClassification
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: EmotionClassification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 96 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 2000 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for EmotionClassification on test took 28.63 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.5645, 'f1': 0.5013582086758896, 'accuracy_stderr': 0.02252332124709853, 'f1_stderr': 0.01299644903033776, 'main_score': 0.5645, 'evaluation_time': 28.63}
INFO:main:Running task: AmazonCounterfactualClassification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS14 as it already exists
Creating model angle$cohere$flag-embedding$gist$llmrails$mixed-bread for task AmazonCounterfactualClassification
Loading angle from cache for AmazonCounterfactualClassification...
Loading cohere from cache for AmazonCounterfactualClassification...
Loading flag-embedding from cache for AmazonCounterfactualClassification...
Loading gist from cache for AmazonCounterfactualClassification...
Loading llmrails from cache for AmazonCounterfactualClassification...
Loading mixed-bread from cache for AmazonCounterfactualClassification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - AmazonCounterfactualClassification, s2s, multilingual 1 / 4 langs


INFO:mteb.evaluation.MTEB:

********************** Evaluating AmazonCounterfactualClassification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for AmazonCounterfactualClassification
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/datasets/load.py:1461: FutureWarning: The repository for mteb/amazon_counterfactual contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/mteb/amazon_counterfactual
You can avoid this message in future by passing the argument `trust_remote_code=True`.
Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.
  warnings.warn(
Repo card metadata block was not found. Setting CardData to empty.
WARNING:huggingface_hub.repocard:Repo card metadata block was not found. Setting CardData to empty.
INFO:mteb.abstasks.AbsTaskClassification:
Task: AmazonCounterfactualClassification, split: test, language: en. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 64 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 670 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for AmazonCounterfactualClassification on test took 1.60 seconds
INFO:mteb.evaluation.MTEB:Scores: {'en': {'accuracy': 0.7555223880597015, 'f1': 0.6949918803054462, 'ap': 0.38496056497434017, 'accuracy_stderr': 0.03573247794305611, 'f1_stderr': 0.034648132908331, 'ap_stderr': 0.038847649914891605, 'main_score': 0.7555223880597015}, 'evaluation_time': 1.6}
INFO:main:Running task: Banking77Classification
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gist$llmrails$mixed-bread for task Banking77Classification
Loading angle from cache for Banking77Classification...
Loading cohere from cache for Banking77Classification...
Loading flag-embedding from cache for Banking77Classification...
Loading gist from cache for Banking77Classification...
Loading llmrails from cache for Banking77Classification...
Loading mixed-bread from cache for Banking77Classification...
─────────────────────────────── Selected tasks  ────────────────────────────────
Classification
    - Banking77Classification, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating Banking77Classification **********************
INFO:mteb.evaluation.MTEB:Loading dataset for Banking77Classification
INFO:mteb.abstasks.AbsTaskClassification:
Task: Banking77Classification, split: test. Running...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 1/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 2/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 3/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 4/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 5/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 6/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 7/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 8/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 9/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.abstasks.AbsTaskClassification:========== Experiment 10/10 ==========
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 616 training sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Encoding 3080 test sentences...
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Fitting logistic regression classifier...
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:1288: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  and effective_n_jobs(self.n_jobs) == 1
/cs/student/projects3/COMP0087/grp4/damien_code/.venv_short/lib/python3.10/site-packages/joblib/parallel.py:1332: UserWarning: Loky-backed parallel loops cannot be called in a multiprocessing, setting n_jobs=1
  n_jobs = self._backend.configure(n_jobs=self.n_jobs, parallel=self,
INFO:mteb.evaluation.evaluators.ClassificationEvaluator:Evaluating...
INFO:mteb.evaluation.MTEB:Evaluation for Banking77Classification on test took 49.03 seconds
INFO:mteb.evaluation.MTEB:Scores: {'accuracy': 0.8557142857142856, 'f1': 0.8506596754039789, 'accuracy_stderr': 0.004447459435368262, 'f1_stderr': 0.0054468459217987, 'main_score': 0.8557142857142856, 'evaluation_time': 49.03}
INFO:main:Running task: ArguAna
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gist$llmrails$mixed-bread for task ArguAna
Loading angle from cache for ArguAna...
Loading cohere from cache for ArguAna...
Loading flag-embedding from cache for ArguAna...
Loading gist from cache for ArguAna...
Loading llmrails from cache for ArguAna...
Loading mixed-bread from cache for ArguAna...
─────────────────────────────── Selected tasks  ────────────────────────────────
Retrieval
    - ArguAna, beir, p2p


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArguAna **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArguAna
INFO:mteb.abstasks.BeIRTask:Using GenericDataLoader for BeIR
INFO:beir.datasets.data_loader:Loading Corpus...
  0%|          | 0/8674 [00:00<?, ?it/s] 56%|█████▌    | 4840/8674 [00:00<00:00, 48381.82it/s]100%|██████████| 8674/8674 [00:00<00:00, 49189.57it/s]
INFO:beir.datasets.data_loader:Loaded 8674 TEST Documents.
INFO:beir.datasets.data_loader:Doc Example: {'text': "You don’t have to be vegetarian to be green. Many special environments have been created by livestock farming – for example chalk down land in England and mountain pastures in many countries. Ending livestock farming would see these areas go back to woodland with a loss of many unique plants and animals. Growing crops can also be very bad for the planet, with fertilisers and pesticides polluting rivers, lakes and seas. Most tropical forests are now cut down for timber, or to allow oil palm trees to be grown in plantations, not to create space for meat production.  British farmer and former editor Simon Farrell also states: “Many vegans and vegetarians rely on one source from the U.N. calculation that livestock generates 18% of global carbon emissions, but this figure contains basic mistakes. It attributes all deforestation from ranching to cattle, rather than logging or development. It also muddles up one-off emissions from deforestation with on-going pollution.”  He also refutes the statement of meat production inefficiency: “Scientists have calculated that globally the ratio between the amounts of useful plant food used to produce meat is about 5 to 1. If you feed animals only food that humans can eat — which is, indeed, largely the case in the Western world — that may be true. But animals also eat food we can't eat, such as grass. So the real conversion figure is 1.4 to 1.” [1] At the same time eating a vegetarian diet may be no more environmentally friendly than a meat based diet if it is not sustainably sourced or uses perishable fruit and vegetables that are flown in from around the world. Eating locally sourced food can has as big an impact as being vegetarian. [2]  [1] Tara Kelly, Simon Fairlie: How Eating Meat Can Save the World, 12 October 2010  [2] Lucy Siegle, ‘It is time to become a vegetarian?’ The Observer, 18th May 2008", 'title': 'animals environment general health health general weight philosophy ethics'}
INFO:beir.datasets.data_loader:Loading Queries...
INFO:beir.datasets.data_loader:Loaded 1406 TEST Queries.
INFO:beir.datasets.data_loader:Query Example: Being vegetarian helps the environment  Becoming a vegetarian is an environmentally friendly thing to do. Modern farming is one of the main sources of pollution in our rivers. Beef farming is one of the main causes of deforestation, and as long as people continue to buy fast food in their billions, there will be a financial incentive to continue cutting down trees to make room for cattle. Because of our desire to eat fish, our rivers and seas are being emptied of fish and many species are facing extinction. Energy resources are used up much more greedily by meat farming than my farming cereals, pulses etc. Eating meat and fish not only causes cruelty to animals, it causes serious harm to the environment and to biodiversity. For example consider Meat production related pollution and deforestation  At Toronto’s 1992 Royal Agricultural Winter Fair, Agriculture Canada displayed two contrasting statistics: “it takes four football fields of land (about 1.6 hectares) to feed each Canadian” and “one apple tree produces enough fruit to make 320 pies.” Think about it — a couple of apple trees and a few rows of wheat on a mere fraction of a hectare could produce enough food for one person! [1]  The 2006 U.N. Food and Agriculture Organization (FAO) report concluded that worldwide livestock farming generates 18% of the planet's greenhouse gas emissions — by comparison, all the world's cars, trains, planes and boats account for a combined 13% of greenhouse gas emissions. [2]  As a result of the above point producing meat damages the environment. The demand for meat drives deforestation. Daniel Cesar Avelino of Brazil's Federal Public Prosecution Office says “We know that the single biggest driver of deforestation in the Amazon is cattle.” This clearing of tropical rainforests such as the Amazon for agriculture is estimated to produce 17% of the world's greenhouse gas emissions. [3] Not only this but the production of meat takes a lot more energy than it ultimately gives us chicken meat production consumes energy in a 4:1 ratio to protein output; beef cattle production requires an energy input to protein output ratio of 54:1.  The same is true with water use due to the same phenomenon of meat being inefficient to produce in terms of the amount of grain needed to produce the same weight of meat, production requires a lot of water. Water is another scarce resource that we will soon not have enough of in various areas of the globe. Grain-fed beef production takes 100,000 liters of water for every kilogram of food. Raising broiler chickens takes 3,500 liters of water to make a kilogram of meat. In comparison, soybean production uses 2,000 liters for kilogram of food produced; rice, 1,912; wheat, 900; and potatoes, 500 liters. [4] This is while there are areas of the globe that have severe water shortages. With farming using up to 70 times more water than is used for domestic purposes: cooking and washing. A third of the population of the world is already suffering from a shortage of water. [5] Groundwater levels are falling all over the world and rivers are beginning to dry up. Already some of the biggest rivers such as China’s Yellow river do not reach the sea. [6]  With a rising population becoming vegetarian is the only responsible way to eat.  [1] Stephen Leckie, ‘How Meat-centred Eating Patterns Affect Food Security and the Environment’, International development research center  [2] Bryan Walsh, Meat: Making Global Warming Worse, Time magazine, 10 September 2008 .  [3] David Adam, Supermarket suppliers ‘helping to destroy Amazon rainforest’, The Guardian, 21st June 2009.  [4] Roger Segelken, U.S. could feed 800 million people with grain that livestock eat, Cornell Science News, 7th August 1997.  [5] Fiona Harvey, Water scarcity affects one in three, FT.com, 21st August 2003  [6] Rupert Wingfield-Hayes, Yellow river ‘drying up’, BBC News, 29th July 2004
INFO:beir.retrieval.search.dense.exact_search:Encoding Queries...
INFO:beir.retrieval.search.dense.exact_search:Sorting Corpus by document length (Longest first)...
INFO:beir.retrieval.search.dense.exact_search:Encoding Corpus in batches... Warning: This might take a while!
INFO:beir.retrieval.search.dense.exact_search:Scoring Function: Cosine Similarity (cos_sim)
INFO:beir.retrieval.search.dense.exact_search:Encoding Batch 1/1...
INFO:mteb.abstasks.AbsTaskRetrieval:Time taken to retrieve: 27.94 seconds
INFO:root:For evaluation, we ignore identical query and document ids (default), please explicitly set ``ignore_identical_ids=False`` to ignore this.
INFO:root:

INFO:root:NDCG@1: 0.4004
INFO:root:NDCG@3: 0.5647
INFO:root:NDCG@5: 0.6144
INFO:root:NDCG@10: 0.6504
INFO:root:NDCG@100: 0.6701
INFO:root:NDCG@1000: 0.6706
INFO:root:

INFO:root:MAP@1: 0.4004
INFO:root:MAP@3: 0.5245
INFO:root:MAP@5: 0.5523
INFO:root:MAP@10: 0.5674
INFO:root:MAP@100: 0.5725
INFO:root:MAP@1000: 0.5725
INFO:root:

INFO:root:Recall@1: 0.4004
INFO:root:Recall@3: 0.6806
INFO:root:Recall@5: 0.8008
INFO:root:Recall@10: 0.9111
INFO:root:Recall@100: 0.9929
INFO:root:Recall@1000: 0.9964
INFO:root:

INFO:root:P@1: 0.4004
INFO:root:P@3: 0.2269
INFO:root:P@5: 0.1602
INFO:root:P@10: 0.0911
INFO:root:P@100: 0.0099
INFO:root:P@1000: 0.0010
INFO:root:

INFO:root:MRR@1: 0.4068
INFO:root:MRR@3: 0.5276
INFO:root:MRR@5: 0.5546
INFO:root:MRR@10: 0.5699
INFO:root:MRR@100: 0.5749
INFO:root:MRR@1000: 0.5749
INFO:mteb.evaluation.MTEB:Evaluation for ArguAna on test took 30.21 seconds
INFO:mteb.evaluation.MTEB:Scores: {'ndcg_at_1': 0.40043, 'ndcg_at_3': 0.56466, 'ndcg_at_5': 0.61443, 'ndcg_at_10': 0.65044, 'ndcg_at_100': 0.67012, 'ndcg_at_1000': 0.67061, 'map_at_1': 0.40043, 'map_at_3': 0.52454, 'map_at_5': 0.55231, 'map_at_10': 0.56739, 'map_at_100': 0.57245, 'map_at_1000': 0.57247, 'recall_at_1': 0.40043, 'recall_at_3': 0.68065, 'recall_at_5': 0.80085, 'recall_at_10': 0.9111, 'recall_at_100': 0.99289, 'recall_at_1000': 0.99644, 'precision_at_1': 0.40043, 'precision_at_3': 0.22688, 'precision_at_5': 0.16017, 'precision_at_10': 0.09111, 'precision_at_100': 0.00993, 'precision_at_1000': 0.001, 'mrr_at_1': 0.40683, 'mrr_at_3': 0.52762, 'mrr_at_5': 0.55461, 'mrr_at_10': 0.56987, 'mrr_at_100': 0.57486, 'mrr_at_1000': 0.57489, 'evaluation_time': 30.21}
INFO:main:Running task: ArxivClusteringS2S
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Creating model angle$cohere$flag-embedding$gist$llmrails$mixed-bread for task ArxivClusteringS2S
Loading angle from cache for ArxivClusteringS2S...
Loading cohere from cache for ArxivClusteringS2S...
Loading flag-embedding from cache for ArxivClusteringS2S...
Loading gist from cache for ArxivClusteringS2S...
Loading llmrails from cache for ArxivClusteringS2S...
Loading mixed-bread from cache for ArxivClusteringS2S...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - ArxivClusteringS2S, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating ArxivClusteringS2S **********************
INFO:mteb.evaluation.MTEB:Loading dataset for ArxivClusteringS2S
Clustering:   0%|          | 0/31 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   3%|▎         | 1/31 [00:19<09:58, 19.97s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   6%|▋         | 2/31 [00:38<09:18, 19.25s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  10%|▉         | 3/31 [00:56<08:37, 18.49s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  13%|█▎        | 4/31 [01:15<08:22, 18.61s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 5/31 [01:32<07:48, 18.02s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  19%|█▉        | 6/31 [01:51<07:41, 18.46s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  23%|██▎       | 7/31 [02:09<07:22, 18.43s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  26%|██▌       | 8/31 [02:29<07:10, 18.71s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  29%|██▉       | 9/31 [02:47<06:49, 18.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 10/31 [03:05<06:28, 18.51s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  35%|███▌      | 11/31 [03:39<07:43, 23.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  39%|███▊      | 12/31 [04:12<08:18, 26.22s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  42%|████▏     | 13/31 [04:44<08:20, 27.83s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  45%|████▌     | 14/31 [05:17<08:19, 29.36s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 15/31 [05:52<08:16, 31.05s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 16/31 [06:24<07:50, 31.37s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  55%|█████▍    | 17/31 [06:57<07:29, 32.08s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  58%|█████▊    | 18/31 [07:31<07:01, 32.45s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  61%|██████▏   | 19/31 [08:02<06:26, 32.21s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  65%|██████▍   | 20/31 [08:31<05:44, 31.27s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 21/31 [08:59<05:02, 30.20s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 3750 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  71%|███████   | 22/31 [09:02<03:18, 22.07s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  74%|███████▍  | 23/31 [09:29<03:07, 23.50s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22438 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  77%|███████▋  | 24/31 [09:49<02:36, 22.32s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22608 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  81%|████████  | 25/31 [10:11<02:14, 22.38s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8927 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 26/31 [10:19<01:30, 18.03s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  87%|████████▋ | 27/31 [10:42<01:17, 19.46s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  90%|█████████ | 28/31 [11:01<00:58, 19.44s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  94%|█████████▎| 29/31 [11:22<00:39, 19.95s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  97%|█████████▋| 30/31 [11:38<00:18, 18.77s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25000 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 31/31 [12:00<00:00, 19.74s/it]Clustering: 100%|██████████| 31/31 [12:00<00:00, 23.26s/it]
INFO:mteb.evaluation.MTEB:Evaluation for ArxivClusteringS2S on test took 720.92 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.4349805990828181, 'v_measure_std': 0.14298784790365787, 'evaluation_time': 720.92}
INFO:main:Running task: RedditClustering
INFO:mteb.evaluation.MTEB:

## Evaluating 1 tasks:
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Creating model angle$cohere$flag-embedding$gist$llmrails$mixed-bread for task RedditClustering
Loading angle from cache for RedditClustering...
Loading cohere from cache for RedditClustering...
Loading flag-embedding from cache for RedditClustering...
Loading gist from cache for RedditClustering...
Loading llmrails from cache for RedditClustering...
Loading mixed-bread from cache for RedditClustering...
─────────────────────────────── Selected tasks  ────────────────────────────────
Clustering
    - RedditClustering, s2s


INFO:mteb.evaluation.MTEB:

********************** Evaluating RedditClustering **********************
INFO:mteb.evaluation.MTEB:Loading dataset for RedditClustering
Clustering:   0%|          | 0/25 [00:00<?, ?it/s]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 7194 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   4%|▍         | 1/25 [00:05<02:16,  5.68s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11557 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:   8%|▊         | 2/25 [00:14<02:54,  7.59s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 27578 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  12%|█▏        | 3/25 [00:37<05:21, 14.60s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14301 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  16%|█▌        | 4/25 [00:48<04:38, 13.26s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 11759 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  20%|██        | 5/25 [00:57<03:53, 11.66s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 18033 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  24%|██▍       | 6/25 [01:11<03:54, 12.33s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 8558 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  28%|██▊       | 7/25 [01:18<03:10, 10.58s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 21819 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  32%|███▏      | 8/25 [01:36<03:39, 12.94s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25026 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  36%|███▌      | 9/25 [01:58<04:14, 15.89s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22071 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  40%|████      | 10/25 [02:18<04:15, 17.05s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 22978 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  44%|████▍     | 11/25 [02:36<04:04, 17.47s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 4342 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  48%|████▊     | 12/25 [02:40<02:52, 13.31s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 9230 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  52%|█████▏    | 13/25 [02:47<02:18, 11.55s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 20782 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  56%|█████▌    | 14/25 [03:04<02:24, 13.15s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 6912 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  60%|██████    | 15/25 [03:09<01:46, 10.69s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 24761 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  64%|██████▍   | 16/25 [03:29<02:01, 13.54s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 14469 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  68%|██████▊   | 17/25 [03:40<01:41, 12.64s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5896 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  72%|███████▏  | 18/25 [03:44<01:10, 10.11s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16338 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  76%|███████▌  | 19/25 [03:57<01:04, 10.80s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 28568 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  80%|████████  | 20/25 [04:19<01:11, 14.25s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25991 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  84%|████████▍ | 21/25 [04:41<01:06, 16.69s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25083 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  88%|████████▊ | 22/25 [05:02<00:53, 17.79s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 5713 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  92%|█████████▏| 23/25 [05:06<00:27, 13.78s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 16145 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering:  96%|█████████▌| 24/25 [05:18<00:13, 13.24s/it]INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Encoding 25360 sentences...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Fitting Mini-Batch K-Means model...
INFO:mteb.evaluation.evaluators.ClusteringEvaluator:Evaluating...
Clustering: 100%|██████████| 25/25 [05:39<00:00, 15.45s/it]Clustering: 100%|██████████| 25/25 [05:39<00:00, 13.56s/it]
INFO:mteb.evaluation.MTEB:Evaluation for RedditClustering on test took 339.10 seconds
INFO:mteb.evaluation.MTEB:Scores: {'v_measure': 0.6090755224427974, 'v_measure_std': 0.03895687003035741, 'evaluation_time': 339.1}
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gist$llmrails$mixed-bread
Converting results/angle$cohere$flag-embedding$gist$llmrails$mixed-bread to results/angle$cohere$flag-embedding$gist$llmrails$mixed-bread_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$gist$llmrails$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gist$llmrails$voyage
Converting results/angle$cohere$flag-embedding$gist$llmrails$voyage to results/angle$cohere$flag-embedding$gist$llmrails$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
Evaluating the model angle$cohere$flag-embedding$gist$mixed-bread$voyage...
Skipping STS17 as it already exists
Skipping TwitterSemEval2015 as it already exists
Skipping SICK-R as it already exists
Skipping STS13 as it already exists
Skipping STS16 as it already exists
Skipping STS22 as it already exists
Skipping STS15 as it already exists
Skipping AskUbuntuDupQuestions as it already exists
Skipping SciFact as it already exists
Skipping EmotionClassification as it already exists
Skipping STS14 as it already exists
Skipping AmazonCounterfactualClassification as it already exists
Skipping Banking77Classification as it already exists
Skipping ArguAna as it already exists
Skipping ArxivClusteringS2S as it already exists
Skipping STS12 as it already exists
Skipping STSBenchmark as it already exists
Skipping RedditClustering as it already exists
Converting the results to a CSV file...
Using model name angle$cohere$flag-embedding$gist$mixed-bread$voyage
Converting results/angle$cohere$flag-embedding$gist$mixed-bread$voyage to results/angle$cohere$flag-embedding$gist$mixed-bread$voyage_results.csv
BUCC - test set not found
Tatoeba - test set not found
de & accuracy not found for task AmazonCounterfactualClassification.
en-ext & accuracy not found for task AmazonCounterfactualClassification.
ja & accuracy not found for task AmazonCounterfactualClassification.
AmazonPolarityClassification - test set not found
AmazonReviewsClassification - test set not found
ImdbClassification - test set not found
MassiveIntentClassification - test set not found
MassiveScenarioClassification - test set not found
MTOPDomainClassification - test set not found
MTOPIntentClassification - test set not found
ToxicConversationsClassification - test set not found
TweetSentimentExtractionClassification - test set not found
ArxivClusteringP2P - test set not found
BiorxivClusteringP2P - test set not found
BiorxivClusteringS2S - test set not found
MedrxivClusteringP2P - test set not found
MedrxivClusteringS2S - test set not found
RedditClusteringP2P - test set not found
StackExchangeClustering - test set not found
StackExchangeClusteringP2P - test set not found
TwentyNewsgroupsClustering - test set not found
SprintDuplicateQuestions - test set not found
TwitterURLCorpus - test set not found
MindSmallReranking - test set not found
SciDocsRR - test set not found
StackOverflowDupQuestions - test set not found
ClimateFEVER - test set not found
CQADupstackRetrieval - test set not found
DBPedia - test set not found
FEVER - test set not found
FiQA2018 - test set not found
HotpotQA - test set not found
MSMARCO - test set not found
NFCorpus - test set not found
NQ - test set not found
QuoraRetrieval - test set not found
SCIDOCS - test set not found
Touche2020 - test set not found
TRECCOVID - test set not found
BIOSSES - test set not found
ko-ko & cosine_spearman not found for task STS17.
ar-ar & cosine_spearman not found for task STS17.
en-ar & cosine_spearman not found for task STS17.
en-de & cosine_spearman not found for task STS17.
en-tr & cosine_spearman not found for task STS17.
es-en & cosine_spearman not found for task STS17.
es-es & cosine_spearman not found for task STS17.
fr-en & cosine_spearman not found for task STS17.
it-en & cosine_spearman not found for task STS17.
nl-en & cosine_spearman not found for task STS17.
de & cosine_spearman not found for task STS22.
es & cosine_spearman not found for task STS22.
pl & cosine_spearman not found for task STS22.
tr & cosine_spearman not found for task STS22.
ar & cosine_spearman not found for task STS22.
ru & cosine_spearman not found for task STS22.
zh & cosine_spearman not found for task STS22.
fr & cosine_spearman not found for task STS22.
de-en & cosine_spearman not found for task STS22.
es-en & cosine_spearman not found for task STS22.
it & cosine_spearman not found for task STS22.
pl-en & cosine_spearman not found for task STS22.
zh-en & cosine_spearman not found for task STS22.
es-it & cosine_spearman not found for task STS22.
de-fr & cosine_spearman not found for task STS22.
de-pl & cosine_spearman not found for task STS22.
fr-pl & cosine_spearman not found for task STS22.
SummEval - test set not found
Not found: 'BUCC','Tatoeba','AmazonPolarityClassification','AmazonReviewsClassification','ImdbClassification','MassiveIntentClassification','MassiveScenarioClassification','MTOPDomainClassification','MTOPIntentClassification','ToxicConversationsClassification','TweetSentimentExtractionClassification','ArxivClusteringP2P','BiorxivClusteringP2P','BiorxivClusteringS2S','MedrxivClusteringP2P','MedrxivClusteringS2S','RedditClusteringP2P','StackExchangeClustering','StackExchangeClusteringP2P','TwentyNewsgroupsClustering','SprintDuplicateQuestions','TwitterURLCorpus','MindSmallReranking','SciDocsRR','StackOverflowDupQuestions','ClimateFEVER','CQADupstackRetrieval','DBPedia','FEVER','FiQA2018','HotpotQA','MSMARCO','NFCorpus','NQ','QuoraRetrieval','SCIDOCS','Touche2020','TRECCOVID','BIOSSES','SummEval' 40
--DONE--
