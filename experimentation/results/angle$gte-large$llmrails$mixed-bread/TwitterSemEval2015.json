{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8753054777373785,
      "accuracy_threshold": 0.8368260264396667,
      "ap": 0.7872007359002496,
      "f1": 0.7191686490547139,
      "f1_threshold": 0.8171992301940918,
      "precision": 0.6842983083154635,
      "recall": 0.7577836411609499
    },
    "dot": {
      "accuracy": 0.8753054777373785,
      "accuracy_threshold": 0.8368260860443115,
      "ap": 0.7872008383719437,
      "f1": 0.7191686490547139,
      "f1_threshold": 0.8171992897987366,
      "precision": 0.6842983083154635,
      "recall": 0.7577836411609499
    },
    "euclidean": {
      "accuracy": 0.8753054777373785,
      "accuracy_threshold": 0.5712687969207764,
      "ap": 0.7872007125142678,
      "f1": 0.7191686490547139,
      "f1_threshold": 0.6046499013900757,
      "precision": 0.6842983083154635,
      "recall": 0.7577836411609499
    },
    "evaluation_time": 6.56,
    "manhattan": {
      "accuracy": 0.8753054777373785,
      "accuracy_threshold": 28.445663452148438,
      "ap": 0.7851718216995598,
      "f1": 0.7172361040285568,
      "f1_threshold": 30.09752655029297,
      "precision": 0.6938825851011347,
      "recall": 0.7422163588390501
    },
    "max": {
      "accuracy": 0.8753054777373785,
      "ap": 0.7872008383719437,
      "f1": 0.7191686490547139
    }
  }
}