{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.864993741431722,
      "accuracy_threshold": 0.8580523729324341,
      "ap": 0.7579447615315531,
      "f1": 0.6952778832763641,
      "f1_threshold": 0.8332144021987915,
      "precision": 0.6682891214407398,
      "recall": 0.7245382585751979
    },
    "dot": {
      "accuracy": 0.8231507420873815,
      "accuracy_threshold": 0.2537190616130829,
      "ap": 0.6050379345447877,
      "f1": 0.5741402687045483,
      "f1_threshold": 0.23242154717445374,
      "precision": 0.5387462410363174,
      "recall": 0.6145118733509235
    },
    "euclidean": {
      "accuracy": 0.8646361089586935,
      "accuracy_threshold": 0.2869989573955536,
      "ap": 0.7586861975266957,
      "f1": 0.693637178338241,
      "f1_threshold": 0.3020173907279968,
      "precision": 0.6737130067147475,
      "recall": 0.7147757255936675
    },
    "evaluation_time": 2.7,
    "manhattan": {
      "accuracy": 0.8640996602491506,
      "accuracy_threshold": 7.114213943481445,
      "ap": 0.7581956286799533,
      "f1": 0.6936117936117936,
      "f1_threshold": 7.858151435852051,
      "precision": 0.6489655172413793,
      "recall": 0.7448548812664908
    },
    "max": {
      "accuracy": 0.864993741431722,
      "ap": 0.7586861975266957,
      "f1": 0.6952778832763641
    }
  }
}