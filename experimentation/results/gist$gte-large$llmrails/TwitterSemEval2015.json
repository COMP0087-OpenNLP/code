{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8735173153722358,
      "accuracy_threshold": 0.8330517411231995,
      "ap": 0.7839608211633597,
      "f1": 0.7182075587837007,
      "f1_threshold": 0.8096883893013,
      "precision": 0.6732056312024002,
      "recall": 0.7696569920844327
    },
    "dot": {
      "accuracy": 0.8735173153722358,
      "accuracy_threshold": 0.8330519199371338,
      "ap": 0.7839600080763751,
      "f1": 0.7182075587837007,
      "f1_threshold": 0.8096884489059448,
      "precision": 0.6732056312024002,
      "recall": 0.7696569920844327
    },
    "euclidean": {
      "accuracy": 0.8735173153722358,
      "accuracy_threshold": 0.5778377652168274,
      "ap": 0.7839608114391255,
      "f1": 0.7182075587837007,
      "f1_threshold": 0.6169466972351074,
      "precision": 0.6732056312024002,
      "recall": 0.7696569920844327
    },
    "evaluation_time": 4.43,
    "manhattan": {
      "accuracy": 0.8730404720748643,
      "accuracy_threshold": 24.120939254760742,
      "ap": 0.7822806808994383,
      "f1": 0.7167586552935274,
      "f1_threshold": 25.715190887451172,
      "precision": 0.6831659493065518,
      "recall": 0.7538258575197889
    },
    "max": {
      "accuracy": 0.8735173153722358,
      "ap": 0.7839608211633597,
      "f1": 0.7182075587837007
    }
  }
}