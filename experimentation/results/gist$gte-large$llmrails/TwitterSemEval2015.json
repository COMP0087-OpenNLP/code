{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8735173153722358,
      "accuracy_threshold": 0.8330518007278442,
      "ap": 0.7839608842257698,
      "f1": 0.7182075587837007,
      "f1_threshold": 0.8096883893013,
      "precision": 0.6732056312024002,
      "recall": 0.7696569920844327
    },
    "dot": {
      "accuracy": 0.8735173153722358,
      "accuracy_threshold": 0.8330518007278442,
      "ap": 0.783960071249684,
      "f1": 0.7182075587837007,
      "f1_threshold": 0.8096885085105896,
      "precision": 0.6732056312024002,
      "recall": 0.7696569920844327
    },
    "euclidean": {
      "accuracy": 0.8735173153722358,
      "accuracy_threshold": 0.5778377056121826,
      "ap": 0.7839607722873442,
      "f1": 0.7182075587837007,
      "f1_threshold": 0.6169466972351074,
      "precision": 0.6732056312024002,
      "recall": 0.7696569920844327
    },
    "evaluation_time": 1.47,
    "manhattan": {
      "accuracy": 0.8730404720748643,
      "accuracy_threshold": 24.120939254760742,
      "ap": 0.7822807546799274,
      "f1": 0.7167586552935274,
      "f1_threshold": 25.71518898010254,
      "precision": 0.6831659493065518,
      "recall": 0.7538258575197889
    },
    "max": {
      "accuracy": 0.8735173153722358,
      "ap": 0.7839608842257698,
      "f1": 0.7182075587837007
    }
  }
}