{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8747690290278357,
      "accuracy_threshold": 0.8135254383087158,
      "ap": 0.7836291945064717,
      "f1": 0.7149538617115409,
      "f1_threshold": 0.7886128425598145,
      "precision": 0.6862412035913613,
      "recall": 0.7461741424802111
    },
    "dot": {
      "accuracy": 0.8747690290278357,
      "accuracy_threshold": 0.8135254979133606,
      "ap": 0.7836292580228242,
      "f1": 0.7149538617115409,
      "f1_threshold": 0.7886127233505249,
      "precision": 0.6862412035913613,
      "recall": 0.7461741424802111
    },
    "euclidean": {
      "accuracy": 0.8747690290278357,
      "accuracy_threshold": 0.610695481300354,
      "ap": 0.7836291685405077,
      "f1": 0.7149538617115409,
      "f1_threshold": 0.650210976600647,
      "precision": 0.6862412035913613,
      "recall": 0.7461741424802111
    },
    "evaluation_time": 1.26,
    "manhattan": {
      "accuracy": 0.8754842939738928,
      "accuracy_threshold": 26.385536193847656,
      "ap": 0.7834106380697007,
      "f1": 0.7159916926272066,
      "f1_threshold": 27.963581085205078,
      "precision": 0.7046499744506899,
      "recall": 0.7277044854881266
    },
    "max": {
      "accuracy": 0.8754842939738928,
      "ap": 0.7836292580228242,
      "f1": 0.7159916926272066
    }
  }
}