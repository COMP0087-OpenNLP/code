{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8755438993860643,
      "accuracy_threshold": 0.8020865365265197,
      "ap": 0.7853791061246655,
      "f1": 0.7170492648955378,
      "f1_threshold": 0.7772606736578787,
      "precision": 0.7013118062563067,
      "recall": 0.7335092348284961
    },
    "dot": {
      "accuracy": 0.8755438993860643,
      "accuracy_threshold": 0.8020865365265197,
      "ap": 0.7853791061246655,
      "f1": 0.7170492648955378,
      "f1_threshold": 0.7772606736578785,
      "precision": 0.7013118062563067,
      "recall": 0.7335092348284961
    },
    "euclidean": {
      "accuracy": 0.8755438993860643,
      "accuracy_threshold": 0.6291477782727092,
      "ap": 0.7853791061246655,
      "f1": 0.7170492648955378,
      "f1_threshold": 0.6674418685818124,
      "precision": 0.7013118062563067,
      "recall": 0.7335092348284961
    },
    "evaluation_time": 6.83,
    "manhattan": {
      "accuracy": 0.87578232103475,
      "accuracy_threshold": 27.94381469918529,
      "ap": 0.7845257778540077,
      "f1": 0.7169204109419484,
      "f1_threshold": 29.562773079588002,
      "precision": 0.6752156679878759,
      "recall": 0.7641160949868074
    },
    "max": {
      "accuracy": 0.87578232103475,
      "ap": 0.7853791061246655,
      "f1": 0.7170492648955378
    }
  }
}