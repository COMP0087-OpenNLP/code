{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8720271800679502,
      "accuracy_threshold": 0.8044394918389555,
      "ap": 0.7742097090554949,
      "f1": 0.7070973940194548,
      "f1_threshold": 0.7651490545790582,
      "precision": 0.6488869296892219,
      "recall": 0.7767810026385225
    },
    "dot": {
      "accuracy": 0.8720271800679502,
      "accuracy_threshold": 0.8044394918389556,
      "ap": 0.7742097090554949,
      "f1": 0.7070973940194548,
      "f1_threshold": 0.7651490545790582,
      "precision": 0.6488869296892219,
      "recall": 0.7767810026385225
    },
    "euclidean": {
      "accuracy": 0.8720271800679502,
      "accuracy_threshold": 0.6253966871484289,
      "ap": 0.7742097090554949,
      "f1": 0.7070973940194548,
      "f1_threshold": 0.6853480070110829,
      "precision": 0.6488869296892219,
      "recall": 0.7767810026385225
    },
    "evaluation_time": 10.38,
    "manhattan": {
      "accuracy": 0.87411336949395,
      "accuracy_threshold": 28.850270781515157,
      "ap": 0.7792310793368438,
      "f1": 0.7137121304294928,
      "f1_threshold": 31.35280227533652,
      "precision": 0.6622262361706932,
      "recall": 0.7738786279683377
    },
    "max": {
      "accuracy": 0.87411336949395,
      "ap": 0.7792310793368438,
      "f1": 0.7137121304294928
    }
  }
}