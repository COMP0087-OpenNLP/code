{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8696429635810932,
      "accuracy_threshold": 0.8220316774190242,
      "ap": 0.7679954639090876,
      "f1": 0.7047209214023542,
      "f1_threshold": 0.7923615110043665,
      "precision": 0.6772074920943809,
      "recall": 0.7345646437994723
    },
    "dot": {
      "accuracy": 0.8696429635810932,
      "accuracy_threshold": 0.8220316774190242,
      "ap": 0.7679954639090876,
      "f1": 0.7047209214023542,
      "f1_threshold": 0.7923615110043668,
      "precision": 0.6772074920943809,
      "recall": 0.7345646437994723
    },
    "euclidean": {
      "accuracy": 0.8696429635810932,
      "accuracy_threshold": 0.5966042582859633,
      "ap": 0.7679954639090876,
      "f1": 0.7047209214023542,
      "f1_threshold": 0.6444198770914793,
      "precision": 0.6772074920943809,
      "recall": 0.7345646437994723
    },
    "evaluation_time": 1.81,
    "manhattan": {
      "accuracy": 0.871013888061036,
      "accuracy_threshold": 25.058323206923085,
      "ap": 0.7707967495481414,
      "f1": 0.7090841307319498,
      "f1_threshold": 26.6644998730908,
      "precision": 0.6701902748414377,
      "recall": 0.7527704485488127
    },
    "max": {
      "accuracy": 0.871013888061036,
      "ap": 0.7707967495481414,
      "f1": 0.7090841307319498
    }
  }
}