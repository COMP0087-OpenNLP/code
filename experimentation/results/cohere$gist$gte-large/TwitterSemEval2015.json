{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8696429635810932,
      "accuracy_threshold": 0.8220316751562222,
      "ap": 0.7679954639090876,
      "f1": 0.7047209214023542,
      "f1_threshold": 0.7923615125193182,
      "precision": 0.6772074920943809,
      "recall": 0.7345646437994723
    },
    "dot": {
      "accuracy": 0.8696429635810932,
      "accuracy_threshold": 0.8220316751562223,
      "ap": 0.7679954639090876,
      "f1": 0.7047209214023542,
      "f1_threshold": 0.7923615125193191,
      "precision": 0.6772074920943809,
      "recall": 0.7345646437994723
    },
    "euclidean": {
      "accuracy": 0.8696429635810932,
      "accuracy_threshold": 0.5966042620792671,
      "ap": 0.7679954639090876,
      "f1": 0.7047209214023542,
      "f1_threshold": 0.6444198747406041,
      "precision": 0.6772074920943809,
      "recall": 0.7345646437994723
    },
    "evaluation_time": 7.8,
    "manhattan": {
      "accuracy": 0.871013888061036,
      "accuracy_threshold": 25.058323265281185,
      "ap": 0.7707967495481414,
      "f1": 0.7090841307319498,
      "f1_threshold": 26.664499801395547,
      "precision": 0.6701902748414377,
      "recall": 0.7527704485488127
    },
    "max": {
      "accuracy": 0.871013888061036,
      "ap": 0.7707967495481414,
      "f1": 0.7090841307319498
    }
  }
}