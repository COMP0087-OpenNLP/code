{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8744710019669786,
      "accuracy_threshold": 0.8396351933479309,
      "ap": 0.7851002001418967,
      "f1": 0.7183116390749399,
      "f1_threshold": 0.8210681676864624,
      "precision": 0.6893039049235993,
      "recall": 0.749868073878628
    },
    "dot": {
      "accuracy": 0.8744710019669786,
      "accuracy_threshold": 0.8396353721618652,
      "ap": 0.7851002824605959,
      "f1": 0.7183116390749399,
      "f1_threshold": 0.8210684061050415,
      "precision": 0.6893039049235993,
      "recall": 0.749868073878628
    },
    "euclidean": {
      "accuracy": 0.8744710019669786,
      "accuracy_threshold": 0.5663299560546875,
      "ap": 0.7851002932839615,
      "f1": 0.7183116390749399,
      "f1_threshold": 0.5982170104980469,
      "precision": 0.6893039049235993,
      "recall": 0.749868073878628
    },
    "evaluation_time": 6.52,
    "manhattan": {
      "accuracy": 0.8738749478452643,
      "accuracy_threshold": 23.898651123046875,
      "ap": 0.783216275349811,
      "f1": 0.7166773162939297,
      "f1_threshold": 25.073434829711914,
      "precision": 0.6949194547707559,
      "recall": 0.7398416886543535
    },
    "max": {
      "accuracy": 0.8744710019669786,
      "ap": 0.7851002932839615,
      "f1": 0.7183116390749399
    }
  }
}