{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8756631102104071,
      "accuracy_threshold": 0.8338960362264398,
      "ap": 0.7904525911246808,
      "f1": 0.7208360548661005,
      "f1_threshold": 0.8142443922785393,
      "precision": 0.7138421733505822,
      "recall": 0.7279683377308707
    },
    "dot": {
      "accuracy": 0.8756631102104071,
      "accuracy_threshold": 0.8338960362264398,
      "ap": 0.7904525911246808,
      "f1": 0.7208360548661005,
      "f1_threshold": 0.8142443922785393,
      "precision": 0.7138421733505822,
      "recall": 0.7279683377308707
    },
    "euclidean": {
      "accuracy": 0.8756631102104071,
      "accuracy_threshold": 0.5763748150534005,
      "ap": 0.7904525911246808,
      "f1": 0.7208360548661005,
      "f1_threshold": 0.6095171981834249,
      "precision": 0.7138421733505822,
      "recall": 0.7279683377308707
    },
    "evaluation_time": 3.63,
    "manhattan": {
      "accuracy": 0.8743517911426357,
      "accuracy_threshold": 29.544897922789023,
      "ap": 0.7877196851070446,
      "f1": 0.7193028095733611,
      "f1_threshold": 30.67870795470919,
      "precision": 0.7093381221139046,
      "recall": 0.7295514511873351
    },
    "max": {
      "accuracy": 0.8756631102104071,
      "ap": 0.7904525911246808,
      "f1": 0.7208360548661005
    }
  }
}