{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8753054777373785,
      "accuracy_threshold": 0.838118314743042,
      "ap": 0.7852664318563757,
      "f1": 0.717742946708464,
      "f1_threshold": 0.8182690143585205,
      "precision": 0.6838709677419355,
      "recall": 0.7551451187335092
    },
    "dot": {
      "accuracy": 0.8753054777373785,
      "accuracy_threshold": 0.838118314743042,
      "ap": 0.7852664999875005,
      "f1": 0.717742946708464,
      "f1_threshold": 0.8182689547538757,
      "precision": 0.6838709677419355,
      "recall": 0.7551451187335092
    },
    "euclidean": {
      "accuracy": 0.8753054777373785,
      "accuracy_threshold": 0.5690021514892578,
      "ap": 0.7852665921748871,
      "f1": 0.717742946708464,
      "f1_threshold": 0.6028780937194824,
      "precision": 0.6838709677419355,
      "recall": 0.7551451187335092
    },
    "evaluation_time": 5.83,
    "manhattan": {
      "accuracy": 0.8743517911426357,
      "accuracy_threshold": 28.515972137451172,
      "ap": 0.7831333427973592,
      "f1": 0.716281432562865,
      "f1_threshold": 30.097274780273438,
      "precision": 0.6904995102840352,
      "recall": 0.7440633245382586
    },
    "max": {
      "accuracy": 0.8753054777373785,
      "ap": 0.7852665921748871,
      "f1": 0.717742946708464
    }
  }
}