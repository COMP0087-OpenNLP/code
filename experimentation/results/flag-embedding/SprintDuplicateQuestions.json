{
  "dataset_revision": "d66bd1f72af766a5cc4b0ca5e00c162f89e8cc46",
  "mteb_dataset_name": "SprintDuplicateQuestions",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.9986237623762376,
      "accuracy_threshold": 0.8042981624603271,
      "ap": 0.9672599333415555,
      "f1": 0.9301858362631844,
      "f1_threshold": 0.8042981624603271,
      "precision": 0.934409687184662,
      "recall": 0.926
    },
    "dot": {
      "accuracy": 0.9986237623762376,
      "accuracy_threshold": 0.8042981624603271,
      "ap": 0.9672599333415555,
      "f1": 0.9301858362631844,
      "f1_threshold": 0.8042981624603271,
      "precision": 0.934409687184662,
      "recall": 0.926
    },
    "euclidean": {
      "accuracy": 0.9986237623762376,
      "accuracy_threshold": 0.6256226301193237,
      "ap": 0.9672599333415555,
      "f1": 0.9301858362631844,
      "f1_threshold": 0.6256226301193237,
      "precision": 0.934409687184662,
      "recall": 0.926
    },
    "evaluation_time": 2.23,
    "manhattan": {
      "accuracy": 0.9986633663366337,
      "accuracy_threshold": 16.09142303466797,
      "ap": 0.9674942736590371,
      "f1": 0.9324662331165583,
      "f1_threshold": 16.09142303466797,
      "precision": 0.9329329329329329,
      "recall": 0.932
    },
    "max": {
      "accuracy": 0.9986633663366337,
      "ap": 0.9674942736590371,
      "f1": 0.9324662331165583
    }
  }
}