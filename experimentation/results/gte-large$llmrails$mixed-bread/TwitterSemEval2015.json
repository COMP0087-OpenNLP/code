{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8742325803182929,
      "accuracy_threshold": 0.8669039011001587,
      "ap": 0.7850180883989817,
      "f1": 0.7169529499626587,
      "f1_threshold": 0.8485004901885986,
      "precision": 0.6786050895381716,
      "recall": 0.7598944591029023
    },
    "dot": {
      "accuracy": 0.8742325803182929,
      "accuracy_threshold": 0.8669038414955139,
      "ap": 0.7850178860569008,
      "f1": 0.7169529499626587,
      "f1_threshold": 0.8485004901885986,
      "precision": 0.6786050895381716,
      "recall": 0.7598944591029023
    },
    "euclidean": {
      "accuracy": 0.8742325803182929,
      "accuracy_threshold": 0.5159382820129395,
      "ap": 0.7850179613215911,
      "f1": 0.7169529499626587,
      "f1_threshold": 0.5504535436630249,
      "precision": 0.6786050895381716,
      "recall": 0.7598944591029023
    },
    "evaluation_time": 10.6,
    "manhattan": {
      "accuracy": 0.8738153424330929,
      "accuracy_threshold": 23.07763671875,
      "ap": 0.7833547351903658,
      "f1": 0.7155778894472361,
      "f1_threshold": 24.154251098632812,
      "precision": 0.6829736211031175,
      "recall": 0.7514511873350923
    },
    "max": {
      "accuracy": 0.8742325803182929,
      "ap": 0.7850180883989817,
      "f1": 0.7169529499626587
    }
  }
}