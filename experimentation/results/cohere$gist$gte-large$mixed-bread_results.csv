model,task,dataset,language,metric,value
cohere$gist$gte-large$mixed-bread,BitextMining,BUCC,,f1,
cohere$gist$gte-large$mixed-bread,BitextMining,Tatoeba,,f1,
cohere$gist$gte-large$mixed-bread,Classification,AmazonCounterfactualClassification,,accuracy,
cohere$gist$gte-large$mixed-bread,Classification,AmazonPolarityClassification,,accuracy,
cohere$gist$gte-large$mixed-bread,Classification,AmazonReviewsClassification,,accuracy,
cohere$gist$gte-large$mixed-bread,Classification,Banking77Classification,,accuracy,
cohere$gist$gte-large$mixed-bread,Classification,EmotionClassification,,accuracy,
cohere$gist$gte-large$mixed-bread,Classification,ImdbClassification,,accuracy,
cohere$gist$gte-large$mixed-bread,Classification,MassiveIntentClassification,,accuracy,
cohere$gist$gte-large$mixed-bread,Classification,MassiveScenarioClassification,,accuracy,
cohere$gist$gte-large$mixed-bread,Classification,MTOPDomainClassification,,accuracy,
cohere$gist$gte-large$mixed-bread,Classification,MTOPIntentClassification,,accuracy,
cohere$gist$gte-large$mixed-bread,Classification,ToxicConversationsClassification,,accuracy,
cohere$gist$gte-large$mixed-bread,Classification,TweetSentimentExtractionClassification,,accuracy,
cohere$gist$gte-large$mixed-bread,Clustering,ArxivClusteringP2P,,v_measure,
cohere$gist$gte-large$mixed-bread,Clustering,ArxivClusteringS2S,,v_measure,
cohere$gist$gte-large$mixed-bread,Clustering,BiorxivClusteringP2P,,v_measure,
cohere$gist$gte-large$mixed-bread,Clustering,BiorxivClusteringS2S,,v_measure,
cohere$gist$gte-large$mixed-bread,Clustering,MedrxivClusteringP2P,,v_measure,
cohere$gist$gte-large$mixed-bread,Clustering,MedrxivClusteringS2S,,v_measure,
cohere$gist$gte-large$mixed-bread,Clustering,RedditClustering,,v_measure,
cohere$gist$gte-large$mixed-bread,Clustering,RedditClusteringP2P,,v_measure,
cohere$gist$gte-large$mixed-bread,Clustering,StackExchangeClustering,,v_measure,
cohere$gist$gte-large$mixed-bread,Clustering,StackExchangeClusteringP2P,,v_measure,
cohere$gist$gte-large$mixed-bread,Clustering,TwentyNewsgroupsClustering,,v_measure,
cohere$gist$gte-large$mixed-bread,PairClassification,SprintDuplicateQuestions,,ap,
cohere$gist$gte-large$mixed-bread,PairClassification,TwitterSemEval2015,,ap,
cohere$gist$gte-large$mixed-bread,PairClassification,TwitterURLCorpus,,ap,
cohere$gist$gte-large$mixed-bread,Reranking,AskUbuntuDupQuestions,,map,
cohere$gist$gte-large$mixed-bread,Reranking,MindSmallReranking,,map,
cohere$gist$gte-large$mixed-bread,Reranking,SciDocsRR,,map,
cohere$gist$gte-large$mixed-bread,Reranking,StackOverflowDupQuestions,,map,
cohere$gist$gte-large$mixed-bread,Retrieval,ArguAna,,ndcg_at_10,
cohere$gist$gte-large$mixed-bread,Retrieval,ClimateFEVER,,ndcg_at_10,
cohere$gist$gte-large$mixed-bread,Retrieval,CQADupstackRetrieval,,ndcg_at_10,
cohere$gist$gte-large$mixed-bread,Retrieval,DBPedia,,ndcg_at_10,
cohere$gist$gte-large$mixed-bread,Retrieval,FEVER,,ndcg_at_10,
cohere$gist$gte-large$mixed-bread,Retrieval,FiQA2018,,ndcg_at_10,
cohere$gist$gte-large$mixed-bread,Retrieval,HotpotQA,,ndcg_at_10,
cohere$gist$gte-large$mixed-bread,Retrieval,MSMARCO,,ndcg_at_10,
cohere$gist$gte-large$mixed-bread,Retrieval,NFCorpus,,ndcg_at_10,
cohere$gist$gte-large$mixed-bread,Retrieval,NQ,,ndcg_at_10,
cohere$gist$gte-large$mixed-bread,Retrieval,QuoraRetrieval,,ndcg_at_10,
cohere$gist$gte-large$mixed-bread,Retrieval,SCIDOCS,,ndcg_at_10,
cohere$gist$gte-large$mixed-bread,Retrieval,SciFact,,ndcg_at_10,
cohere$gist$gte-large$mixed-bread,Retrieval,Touche2020,,ndcg_at_10,
cohere$gist$gte-large$mixed-bread,Retrieval,TRECCOVID,,ndcg_at_10,
cohere$gist$gte-large$mixed-bread,STS,BIOSSES,en,cosine_spearman,0.8783694118332759
cohere$gist$gte-large$mixed-bread,STS,SICK-R,en,cosine_spearman,0.8277198750386614
cohere$gist$gte-large$mixed-bread,STS,STS12,en,cosine_spearman,0.7787450475898372
cohere$gist$gte-large$mixed-bread,STS,STS13,en,cosine_spearman,0.8907340233937783
cohere$gist$gte-large$mixed-bread,STS,STS14,en,cosine_spearman,0.8421968693125237
cohere$gist$gte-large$mixed-bread,STS,STS15,en,cosine_spearman,0.9037756172302825
cohere$gist$gte-large$mixed-bread,STS,STS16,en,cosine_spearman,0.8722315912810569
cohere$gist$gte-large$mixed-bread,STS,STS17,ko-ko,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS17,ko-ko,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS17,ar-ar,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS17,ar-ar,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS17,en-ar,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS17,en-ar,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS17,en-de,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS17,en-de,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS17,en-en,cosine_spearman,0.9043970578667283
cohere$gist$gte-large$mixed-bread,STS,STS17,en-tr,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS17,en-tr,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS17,es-en,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS17,es-en,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS17,es-es,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS17,es-es,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS17,fr-en,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS17,fr-en,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS17,it-en,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS17,it-en,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS17,nl-en,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS17,nl-en,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,en,cosine_spearman,0.6924474788487341
cohere$gist$gte-large$mixed-bread,STS,STS22,de,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,de,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,es,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,es,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,pl,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,pl,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,tr,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,tr,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,ar,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,ar,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,ru,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,ru,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,zh,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,zh,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,fr,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,fr,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,de-en,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,de-en,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,es-en,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,es-en,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,it,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,it,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,pl-en,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,pl-en,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,zh-en,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,zh-en,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,es-it,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,es-it,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,de-fr,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,de-fr,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,de-pl,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,de-pl,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,fr-pl,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STS22,fr-pl,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,STSBenchmark,en,cosine_spearman,0.8937346108243719
cohere$gist$gte-large$mixed-bread,Summarization,SummEval,,cosine_spearman,
cohere$gist$gte-large$mixed-bread,STS,average,en,cosine_spearman,0.8484351583219251
