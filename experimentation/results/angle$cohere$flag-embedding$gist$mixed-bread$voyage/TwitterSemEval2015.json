{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.876914823866007,
      "accuracy_threshold": 0.8117664474644595,
      "ap": 0.7883833840134241,
      "f1": 0.7203521491455205,
      "f1_threshold": 0.7977198220256335,
      "precision": 0.7071682765632944,
      "recall": 0.7340369393139842
    },
    "dot": {
      "accuracy": 0.876914823866007,
      "accuracy_threshold": 0.811766447464459,
      "ap": 0.7883833840134241,
      "f1": 0.7203521491455205,
      "f1_threshold": 0.7977198220256332,
      "precision": 0.7071682765632944,
      "recall": 0.7340369393139842
    },
    "euclidean": {
      "accuracy": 0.876914823866007,
      "accuracy_threshold": 0.613569152569614,
      "ap": 0.7883833840134241,
      "f1": 0.7203521491455205,
      "f1_threshold": 0.6360505922839237,
      "precision": 0.7071682765632944,
      "recall": 0.7340369393139842
    },
    "evaluation_time": 4.59,
    "manhattan": {
      "accuracy": 0.8765571913929785,
      "accuracy_threshold": 37.378819053503044,
      "ap": 0.7885945370449786,
      "f1": 0.7188723570869223,
      "f1_threshold": 38.44219416888748,
      "precision": 0.7112603305785123,
      "recall": 0.7266490765171504
    },
    "max": {
      "accuracy": 0.876914823866007,
      "ap": 0.7885945370449786,
      "f1": 0.7203521491455205
    }
  }
}