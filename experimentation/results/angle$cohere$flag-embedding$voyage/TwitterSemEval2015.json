{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8772128509268642,
      "accuracy_threshold": 0.815928357537984,
      "ap": 0.7875660367761645,
      "f1": 0.7199700636148185,
      "f1_threshold": 0.7846286744338131,
      "precision": 0.6827537260468417,
      "recall": 0.7614775725593668
    },
    "dot": {
      "accuracy": 0.8772128509268642,
      "accuracy_threshold": 0.8159283575379839,
      "ap": 0.7875660367761645,
      "f1": 0.7199700636148185,
      "f1_threshold": 0.784628674433813,
      "precision": 0.6827537260468417,
      "recall": 0.7614775725593668
    },
    "euclidean": {
      "accuracy": 0.8772128509268642,
      "accuracy_threshold": 0.606748121926698,
      "ap": 0.7875660367761645,
      "f1": 0.7199700636148185,
      "f1_threshold": 0.656309874264563,
      "precision": 0.6827537260468417,
      "recall": 0.7614775725593668
    },
    "evaluation_time": 11.68,
    "manhattan": {
      "accuracy": 0.8771532455146928,
      "accuracy_threshold": 29.311015839173294,
      "ap": 0.7875250390261923,
      "f1": 0.7189655172413792,
      "f1_threshold": 31.267284092296613,
      "precision": 0.6741339491916859,
      "recall": 0.7701846965699208
    },
    "max": {
      "accuracy": 0.8772128509268642,
      "ap": 0.7875660367761645,
      "f1": 0.7199700636148185
    }
  }
}