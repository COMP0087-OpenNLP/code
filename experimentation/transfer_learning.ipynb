{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "Inspired by: https://github.com/openai/openai-cookbook/blob/main/examples/Customizing_embeddings.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "\n",
    "from typing import List, Tuple  # for type hints\n",
    "\n",
    "import numpy as np  # for manipulating arrays\n",
    "import pandas as pd  # for manipulating data in dataframes\n",
    "import plotly.express as px  # for plots\n",
    "import random  # for generating run IDs\n",
    "from sklearn.model_selection import train_test_split  # for splitting train & test data\n",
    "import torch  # for matrix optimization\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "import os\n",
    "import datasets\n",
    "from livelossplot import PlotLosses\n",
    "from sentence_transformers.util import pairwise_angle_sim\n",
    "\n",
    "from mteb import MTEB\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = 'cpu'\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and process input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_for_task(task_name: str):\n",
    "    # Note, we load all splits except the test set\n",
    "    mteb = MTEB(tasks=[task_name], task_langs=[\"en\"])\n",
    "    task = mteb.tasks[0]\n",
    "    task.load_data()\n",
    "    assert task.data_loaded, \"Data was not loaded\"\n",
    "    lis_dfs = []\n",
    "    for split in task.dataset:\n",
    "        if split == 'test':\n",
    "            continue\n",
    "        print(f\"Split: {split}\")\n",
    "        lis_dfs.append(task.dataset[split].to_pandas())\n",
    "    return pd.concat(lis_dfs)\n",
    "\n",
    "def process_dataset(train_df: datasets.Dataset) -> pd.DataFrame:\n",
    "    train_df = train_df[['sentence1', 'sentence2', 'score']]\n",
    "    def normalize(x, min_score, max_score): # Norm between 0 and 1\n",
    "        zero_one = (x - min_score) / (max_score - min_score)\n",
    "        scaled_down = zero_one \n",
    "        return scaled_down \n",
    "    train_df['score'] = normalize(train_df['score'], train_df['score'].min(), train_df['score'].max())\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TASKS = [ # Only ones with train or val data \n",
    "    \"STS12\",\n",
    "    \"STSBenchmark\",\n",
    "]\n",
    "\n",
    "dfs = {}\n",
    "for task_name in TASKS:\n",
    "    print(\"Loading task:\", task_name)\n",
    "    dataset_df = load_dataset_for_task(task_name)\n",
    "    df_task = process_dataset(dataset_df)\n",
    "    dfs[task_name] = df_task\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (Look at generating for dissimilar data cause all of them seem to be similar)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get Embeddings and Cosine Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_factory import model_factory\n",
    "model_name = 'angle$cohere$flag-embedding$gist$gte-large$llmrails$mixed-bread$voyage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(df: pd.DataFrame, model_name: str, task_name: str):\n",
    "    model = model_factory(model_name, task_name)\n",
    "    for column in ['sentence1', 'sentence2']:\n",
    "        df[f\"{column}_embedding\"] = model.encode(df[column].tolist())\n",
    "\n",
    "def get_cosine_similarity(a: np.array, b: np.array):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "def generate_cosine_similarity(df: pd.DataFrame):\n",
    "    df['cosine_similarity'] = df.apply(lambda x: get_cosine_similarity(x['sentence1_embedding'], x['sentence2_embedding']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for task_name, df in dfs.items():\n",
    "    generate_embedding(df, model_name, task_name)\n",
    "    generate_cosine_similarity(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all the dataframes\n",
    "df = pd.concat(dfs.values(), ignore_index=True)\n",
    "\n",
    "# Shuffle the data\n",
    "df = df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "# Split the data\n",
    "df_train, df_val = train_test_split(df, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Reset the index\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "\n",
    "df_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate The Baseline Performance\n",
    "\n",
    "We use spearman and Pearson to evaluate the performance. \n",
    "\n",
    "Pearson correlation is a measure of strength of linear relationship between two variables. It ranges from -1 to 1.\n",
    "\n",
    "While spearman correlation is a measure of monotonic relationship between two variables. It ranges from -1 to 1.\n",
    "\n",
    "We want both these values to be close to 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation(df: pd.DataFrame, column_name: str = 'cosine_similarity'):\n",
    "    return df[column_name].corr(df['score'], method='spearman'), df[column_name].corr(df['score'], method='pearson')\n",
    "\n",
    "spearmans, pearsons = get_correlation(df_train)\n",
    "print(f\"Train: Spearman: {spearmans}, Pearson: {pearsons}\")\n",
    "\n",
    "spearmans, pearsons = get_correlation(df_val)\n",
    "print(f\"Validation: Spearman: {spearmans}, Pearson: {pearsons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_correlation(df: pd.DataFrame, title: str):\n",
    "    sns.scatterplot(data=df, x='cosine_similarity', y='score')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Cosine Similarity')\n",
    "    plt.ylabel('Score')\n",
    "    plt.show()\n",
    "\n",
    "plot_correlation(df_train, 'Relation Between Score and Cosine Similarity (Train)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Preprocessing before training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensors(df):\n",
    "    df_x1 = np.stack(df['sentence1_embedding'].values)\n",
    "    df_x2 = np.stack(df['sentence2_embedding'].values)\n",
    "    df_y = df['score'].values\n",
    "\n",
    "    X1 = torch.from_numpy(df_x1).float()\n",
    "    X2 = torch.from_numpy(df_x2).float()\n",
    "    Y = torch.from_numpy(df_y).float()\n",
    "    return X1, X2, Y\n",
    "    \n",
    "X1_train, X2_train, Y_train = get_tensors(df_train)\n",
    "X1_val, X2_val, Y_val = get_tensors(df_val)\n",
    "\n",
    "# Move everything to the device\n",
    "X1_train = X1_train.to(device)\n",
    "X2_train = X2_train.to(device)\n",
    "Y_train = Y_train.to(device)\n",
    "\n",
    "X1_val = X1_val.to(device)\n",
    "X2_val = X2_val.to(device)\n",
    "Y_val = Y_val.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tl_models import LinearTransformationModel, ElementwiseProductModel, StackWiseProductModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CosineSimilarityModel(torch.nn.Module):\n",
    "    def __init__(self, transformation_model: torch.nn.Module):\n",
    "        super(CosineSimilarityModel, self).__init__()\n",
    "        self.transformation_model = transformation_model\n",
    "    \n",
    "    def forward(self, embeddings1: torch.Tensor, embeddings2: torch.Tensor):\n",
    "        embedding1_custom = self.transformation_model(embeddings1)\n",
    "        embedding2_custom = self.transformation_model(embeddings2)\n",
    "        return torch.nn.functional.cosine_similarity(embedding1_custom, embedding2_custom, dim=1)\n",
    "\n",
    "class AnglEModel(torch.nn.Module):\n",
    "    def __init__(self, transformation_model: torch.nn.Module, scale: float = 20.0):\n",
    "        super(AnglEModel, self).__init__()\n",
    "        self.transformation_model = transformation_model\n",
    "        self.scale = scale\n",
    "    \n",
    "    def forward(self, embeddings1: torch.Tensor, embeddings2: torch.Tensor):\n",
    "        scores = pairwise_angle_sim(self.transformation_model(embeddings1), self.transformation_model(embeddings2))\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(cosine_similarity: torch.Tensor, scores: torch.Tensor):\n",
    "    lossF = torch.nn.MSELoss()\n",
    "    return lossF(cosine_similarity, scores)\n",
    "\n",
    "def spearman_correlation(cosine_similarity: torch.Tensor, scores: torch.Tensor):\n",
    "    spearman_corr = torchmetrics.SpearmanCorrCoef().to(device)\n",
    "    return spearman_corr(cosine_similarity, scores)\n",
    "\n",
    "def pearson_correlation(cosine_similarity: torch.Tensor, scores: torch.Tensor):\n",
    "    pearson_corr = torchmetrics.PearsonCorrCoef().to(device)\n",
    "    return pearson_corr(cosine_similarity, scores)\n",
    "\n",
    "def angle_loss(scores: torch.Tensor, labels: torch.Tensor, scale: float = 20.0):\n",
    "    scores = scores * scale\n",
    "    scores = scores[:, None] - scores[None, :]\n",
    "\n",
    "    labels = labels[:, None] < labels[None, :]\n",
    "    labels = labels.float()\n",
    "\n",
    "    scores = scores - (1 - labels) * 1e12\n",
    "\n",
    "    scores = torch.cat((torch.zeros(1).to(device), scores.view(-1)), dim=0)\n",
    "    loss = torch.logsumexp(scores, dim=0)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, training_loader, optimizer, loss_function = None):\n",
    "    running_loss = 0.\n",
    "\n",
    "    for X1, X2, Y in training_loader:\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        cosine_sim = model(X1, X2)\n",
    "        loss = loss_function(cosine_sim, Y)\n",
    "        \n",
    "        # Compute the loss and its gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Record the loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    average_loss = running_loss / len(training_loader)\n",
    "    return average_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = 'test_results'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "# Hyperparameters\n",
    "max_epochs = 2000\n",
    "lr = 1e-5 # 1e-4 also works but bounces around \n",
    "batch_size = 300\n",
    "momentum = 0.9\n",
    "\n",
    "# Loss function\n",
    "# loss_function = mse_loss\n",
    "loss_function = angle_loss\n",
    "\n",
    "# Model\n",
    "transformation_model = LinearTransformationModel(1024 * 8, 1024 * 8, dropout_rate=0.5)  # NOTE: dropout of 0.5 seems to work better than 0.1\n",
    "# transformation_model = ElementwiseProductModel(1024 * 8)\n",
    "# transformation_model = StackWiseProductModel(8)\n",
    "\n",
    "# model = CosineSimilarityModel(transformation_model)\n",
    "# model = model.to(device)\n",
    "\n",
    "model = AnglEModel(transformation_model)\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizer\n",
    "# optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "# Data Loader\n",
    "train_dataset = torch.utils.data.TensorDataset(X1_train, X2_train, Y_train)\n",
    "training_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "\n",
    "# Keep track of losses\n",
    "plotlosses = PlotLosses()\n",
    "\n",
    "model.train()\n",
    "best_accuracy = -float('inf')\n",
    "for _ in range(max_epochs):\n",
    "    epoch_loss = train_one_epoch(model, training_loader, optimizer, loss_function)\n",
    "\n",
    "    # Additional metrics for performance tracking\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Generate the validation loss\n",
    "        val_predictions = model(X1_val, X2_val)\n",
    "        val_loss = loss_function(val_predictions, Y_val).item()\n",
    "\n",
    "        # Compute the correlations\n",
    "        train_spearman = spearman_correlation(model(X1_train, X2_train), Y_train).item()\n",
    "        val_spearman = spearman_correlation(val_predictions, Y_val).item()\n",
    "\n",
    "        # Save locally if it is the best\n",
    "        if val_spearman > best_accuracy:\n",
    "            best_accuracy = val_spearman\n",
    "            torch.save({'transformation_model': model.transformation_model}, f\"{out_dir}/best_model.pth\")\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    plotlosses.update({'loss': epoch_loss, 'val_loss': val_loss, 'acc': train_spearman, 'val_acc': val_spearman})\n",
    "    plotlosses.send()\n",
    "\n",
    "torch.save({'transformation_model': model.transformation_model}, f\"{out_dir}/final_model.pth\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(f\"test_results/best_model.pth\")\n",
    "transformation_model = state_dict[\"transformation_model\"].to(device)\n",
    "model = CosineSimilarityModel(transformation_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_predictions = model(X1_val, X2_val)\n",
    "    val_spearman = spearman_correlation(val_predictions, Y_val).item()\n",
    "    val_pearson = pearson_correlation(val_predictions, Y_val).item()\n",
    "\n",
    "print(f\"Validation Spearman: {val_spearman}, Validation Pearson: {val_pearson}\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
