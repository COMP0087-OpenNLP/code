{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "Inspired by: https://github.com/openai/openai-cookbook/blob/main/examples/Customizing_embeddings.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from typing import List, Tuple  # for type hints\n",
    "\n",
    "import numpy as np  # for manipulating arrays\n",
    "import pandas as pd  # for manipulating data in dataframes\n",
    "import plotly.express as px  # for plots\n",
    "import random  # for generating run IDs\n",
    "from sklearn.model_selection import train_test_split  # for splitting train & test data\n",
    "import torch  # for matrix optimization\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import torchmetrics\n",
    "import os\n",
    "import datasets\n",
    "from livelossplot import PlotLosses\n",
    "\n",
    "from mteb import MTEB\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setting device on GPU if available, else CPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print('Using device:', device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and process input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_for_task(task_name: str, split: str = 'train'):\n",
    "    mteb = MTEB(tasks=[task_name], task_langs=[\"en\"])\n",
    "    task = mteb.tasks[0]\n",
    "    task.load_data()\n",
    "    assert task.data_loaded, \"Data was not loaded\"\n",
    "    return task.dataset[split] # Have form train, validation, test (test is used for MTEB)\n",
    "\n",
    "def process_dataset(dataset: datasets.Dataset) -> pd.DataFrame:\n",
    "    train_df = dataset.to_pandas()\n",
    "    train_df = train_df[['sentence1', 'sentence2', 'score']]\n",
    "    def normalize(x, min_score, max_score): # Normalise between 0.5 and 1 (Seems to match our cosine similarity scores better)\n",
    "        zero_one = (x - min_score) / (max_score - min_score)\n",
    "        scaled_down = zero_one / 2\n",
    "        return scaled_down + 0.5\n",
    "    train_df['score'] = normalize(train_df['score'], train_df['score'].min(), train_df['score'].max())\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"STSBenchmark\"\n",
    "train_dataset = load_dataset_for_task(task_name, split='train')\n",
    "val_dataset = load_dataset_for_task(task_name, split='validation')\n",
    "\n",
    "df_train = process_dataset(train_dataset)\n",
    "df_val = process_dataset(val_dataset)\n",
    "\n",
    "df = pd.concat([df_train, df_val])\n",
    "\n",
    "# Shuffle the data\n",
    "df = df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "# Split the data\n",
    "df_train, df_val = train_test_split(df, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Reset the index\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (Look at generating for dismilliar data cause all of them seem to be simialr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get Embeddings and Cosine Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_factory import model_factory\n",
    "model_name = 'voyage$cohere'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(df: pd.DataFrame, model_name: str, task_name: str):\n",
    "    model = model_factory(model_name, task_name)\n",
    "    for column in ['sentence1', 'sentence2']:\n",
    "        df[f\"{column}_embedding\"] = model.encode(df[column].tolist())\n",
    "\n",
    "def get_cosine_similarity(a: np.array, b: np.array):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "def generate_cosine_similarity(df: pd.DataFrame):\n",
    "    df['cosine_similarity'] = df.apply(lambda x: get_cosine_similarity(x['sentence1_embedding'], x['sentence2_embedding']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_embedding(df_train, model_name, task_name)\n",
    "generate_embedding(df_val, model_name, task_name)\n",
    "\n",
    "generate_cosine_similarity(df_train)\n",
    "generate_cosine_similarity(df_val)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate The Baseline Performance\n",
    "\n",
    "We use spearman and Pearson to evaluate the performance. \n",
    "\n",
    "Pearson correlation is a measure of strength of linear relationship between two variables. It ranges from -1 to 1.\n",
    "\n",
    "While spearman correlation is a measure of monotonic relationship between two variables. It ranges from -1 to 1.\n",
    "\n",
    "We want both these values to be close to 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation(df: pd.DataFrame, column_name: str = 'cosine_similarity'):\n",
    "    return df[column_name].corr(df['score'], method='spearman'), df[column_name].corr(df['score'], method='pearson')\n",
    "\n",
    "spearmans, pearsons = get_correlation(df_train)\n",
    "print(f\"Train: Spearman: {spearmans}, Pearson: {pearsons}\")\n",
    "\n",
    "spearmans, pearsons = get_correlation(df_val)\n",
    "print(f\"Validation: Spearman: {spearmans}, Pearson: {pearsons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_correlation(df: pd.DataFrame, title: str):\n",
    "    sns.scatterplot(data=df, x='cosine_similarity', y='score')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Cosine Similarity')\n",
    "    plt.ylabel('Score')\n",
    "    plt.show()\n",
    "\n",
    "plot_correlation(df_train, 'Relation Between Score and Cosine Similarity (Train)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Preprocessing before training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tensors(df):\n",
    "    df_x1 = np.stack(df['sentence1_embedding'].values)\n",
    "    df_x2 = np.stack(df['sentence2_embedding'].values)\n",
    "    df_y = df['score'].values\n",
    "\n",
    "    X1 = torch.from_numpy(df_x1).float()\n",
    "    X2 = torch.from_numpy(df_x2).float()\n",
    "    Y = torch.from_numpy(df_y).float()\n",
    "    return X1, X2, Y\n",
    "    \n",
    "X1_train, X2_train, Y_train = get_tensors(df_train)\n",
    "X1_val, X2_val, Y_val = get_tensors(df_val)\n",
    "\n",
    "# Move everything to the device\n",
    "X1_train = X1_train.to(device)\n",
    "X2_train = X2_train.to(device)\n",
    "Y_train = Y_train.to(device)\n",
    "\n",
    "X1_val = X1_val.to(device)\n",
    "X2_val = X2_val.to(device)\n",
    "Y_val = Y_val.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining our Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearTransformationModel(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim: int, embedding_output_dim: int, dropout_rate: float = 0.1):\n",
    "        super(LinearTransformationModel, self).__init__()\n",
    "        self.linear = torch.nn.Linear(embedding_dim, embedding_output_dim)\n",
    "        self.dropout = torch.nn.Dropout(dropout_rate)\n",
    "    \n",
    "    def forward(self, x: torch.Tensor):\n",
    "        x = self.linear(x)\n",
    "        x = self.dropout(x)\n",
    "        return x\n",
    "\n",
    "class ElementwiseProductModel(torch.nn.Module):\n",
    "    def __init__(self, embedding_dim):\n",
    "        super(ElementwiseProductModel, self).__init__()\n",
    "        self.params = nn.Parameter(torch.ones(embedding_dim))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.params\n",
    "    \n",
    "class StackWiseProductModel(torch.nn.Module):\n",
    "    def __init__(self, stack_size):\n",
    "        super(StackWiseProductModel, self).__init__()\n",
    "        assert stack_size > 1, \"Stack size must be greater than 1\"\n",
    "        self.params = nn.Parameter(torch.ones(stack_size))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Make sure they some to one to prevent possible explosion\n",
    "        weights = F.softmax(self.params)\n",
    "        for i in range(self.stack_size):\n",
    "            x[:, i:(i+self.stack_size)] *= weights[i]\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class CosineSimilarityModel(torch.nn.Module):\n",
    "    def __init__(self, transformation_model: torch.nn.Module):\n",
    "        super(CosineSimilarityModel, self).__init__()\n",
    "        self.transformation_model = transformation_model\n",
    "    \n",
    "    def forward(self, embeddings1: torch.Tensor, embeddings2: torch.Tensor):\n",
    "        embedding1_custom = self.transformation_model(embeddings1)\n",
    "        embedding2_custom = self.transformation_model(embeddings2)\n",
    "        return torch.nn.functional.cosine_similarity(embedding1_custom, embedding2_custom, dim=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Possible Loss Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mse_loss(cosine_similarity: torch.Tensor, scores: torch.Tensor):\n",
    "    lossF = torch.nn.MSELoss()\n",
    "    return lossF(cosine_similarity, scores)\n",
    "\n",
    "def spearman_correlation(cosine_similarity: torch.Tensor, scores: torch.Tensor):\n",
    "    spearman_corr = torchmetrics.SpearmanCorrCoef()\n",
    "    return spearman_corr(cosine_similarity, scores)\n",
    "\n",
    "def pearson_correlation(cosine_similarity: torch.Tensor, scores: torch.Tensor):\n",
    "    pearson_corr = torchmetrics.PearsonCorrCoef()\n",
    "    return pearson_corr(cosine_similarity, scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(model, training_loader, optimizer, loss_function):\n",
    "    running_loss = 0.\n",
    "\n",
    "    for X1, X2, Y in training_loader:\n",
    "        # Zero your gradients for every batch!\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Make predictions for this batch\n",
    "        cosine_sim = model(X1, X2)\n",
    "\n",
    "        # Compute the loss and its gradients\n",
    "        loss = loss_function(cosine_sim, Y)\n",
    "        loss.backward()\n",
    "\n",
    "        # Adjust learning weights\n",
    "        optimizer.step()\n",
    "\n",
    "        # Record the loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    average_loss = running_loss / len(training_loader)\n",
    "    return average_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = 'test_results'\n",
    "if not os.path.exists(out_dir):\n",
    "    os.makedirs(out_dir)\n",
    "\n",
    "# Hyperparameters\n",
    "max_epochs = 30\n",
    "lr = 0.001\n",
    "batch_size = 200\n",
    "\n",
    "# Loss function\n",
    "loss_function = mse_loss\n",
    "\n",
    "# Model\n",
    "transformation_model = LinearTransformationModel(1024, 1024 // 2, dropout_rate=0.1)\n",
    "transformation_model = StackWiseProductModel(1024)\n",
    "# transformation_model = ElementwiseProductModel(1024)\n",
    "\n",
    "model = CosineSimilarityModel(transformation_model)\n",
    "\n",
    "# Move the model to the device\n",
    "model = model.to(device)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "# Data Loader\n",
    "train_dataset = torch.utils.data.TensorDataset(X1_train, X2_train, Y_train)\n",
    "training_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "\n",
    "# Keep track of losses\n",
    "plotlosses = PlotLosses()\n",
    "\n",
    "model.train()\n",
    "best_val_loss = float('inf')\n",
    "for _ in range(max_epochs):\n",
    "    epoch_loss = train_one_epoch(model, training_loader, optimizer, loss_function)\n",
    "\n",
    "    # Additional metrics for performance tracking\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        # Generate the validation loss\n",
    "        val_predictions = model(X1_val, X2_val)\n",
    "        val_loss = loss_function(val_predictions, Y_val).item()\n",
    "\n",
    "        # Save locally if it is the best\n",
    "        if val_loss < best_val_loss:\n",
    "            best_val_loss = val_loss\n",
    "            torch.save({'transformation_model': model.transformation_model}, f\"{out_dir}/best_model.pth\")\n",
    "\n",
    "        # Compute the correlations\n",
    "        train_spearman = spearman_correlation(model(X1_train, X2_train), Y_train).item()\n",
    "        val_spearman = spearman_correlation(val_predictions, Y_val).item()\n",
    "    model.train()\n",
    "\n",
    "    # NTH: Save the model if it has the best validation loss (check documentation for torch.save)\n",
    "    plotlosses.update({'loss': epoch_loss, 'val_loss': val_loss, 'acc': train_spearman, 'val_acc': val_spearman})\n",
    "    plotlosses.send()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load from memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(f\"test_results/best_model.pth\")\n",
    "transformation_model = state_dict[\"transformation_model\"].to(device)\n",
    "model = CosineSimilarityModel(transformation_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    val_predictions = model(X1_val, X2_val)\n",
    "    val_loss = loss_function(val_predictions, Y_val).item()\n",
    "    val_spearman = spearman_correlation(val_predictions, Y_val).item()\n",
    "    val_pearson = pearson_correlation(val_predictions, Y_val).item()\n",
    "\n",
    "print(f\"Validation Loss: {val_loss}, Validation Spearman: {val_spearman}, Validation Pearson: {val_pearson}\")    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
