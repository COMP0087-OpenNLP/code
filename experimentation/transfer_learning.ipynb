{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transfer Learning\n",
    "\n",
    "Inspired by: https://github.com/openai/openai-cookbook/blob/main/examples/Customizing_embeddings.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from typing import List, Tuple  # for type hints\n",
    "\n",
    "import numpy as np  # for manipulating arrays\n",
    "import pandas as pd  # for manipulating data in dataframes\n",
    "import pickle  # for saving the embeddings cache\n",
    "import plotly.express as px  # for plots\n",
    "import random  # for generating run IDs\n",
    "from sklearn.model_selection import train_test_split  # for splitting train & test data\n",
    "import torch  # for matrix optimization\n",
    "import os\n",
    "import datasets\n",
    "\n",
    "from mteb import MTEB\n",
    "\n",
    "seed = 42\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Load and process input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset_for_task(task_name: str, split: str = 'train'):\n",
    "    mteb = MTEB(tasks=[task_name], task_langs=[\"en\"])\n",
    "    task = mteb.tasks[0]\n",
    "    task.load_data()\n",
    "    assert task.data_loaded, \"Data was not loaded\"\n",
    "    return task.dataset[split] # Have form train, validation, test (test is used for MTEB)\n",
    "\n",
    "def process_dataset(dataset: datasets.Dataset) -> pd.DataFrame:\n",
    "    train_df = dataset.to_pandas()\n",
    "    train_df = train_df[['sentence1', 'sentence2', 'score']]\n",
    "    def normalize(x, min_score, max_score): # Normalise between 0 and 1 (Maybe better to do -1 and 1)\n",
    "        return (x - min_score) / (max_score - min_score)\n",
    "    train_df['score'] = normalize(train_df['score'], train_df['score'].min(), train_df['score'].max())\n",
    "    return train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "task_name = \"STSBenchmark\"\n",
    "train_dataset = load_dataset_for_task(task_name, split='train')\n",
    "val_dataset = load_dataset_for_task(task_name, split='validation')\n",
    "\n",
    "df_train = process_dataset(train_dataset)\n",
    "df_val = process_dataset(val_dataset)\n",
    "\n",
    "df = pd.concat([df_train, df_val])\n",
    "\n",
    "# Shuffle the data\n",
    "df = df.sample(frac=1, random_state=seed).reset_index(drop=True)\n",
    "\n",
    "# Split the data\n",
    "df_train, df_val = train_test_split(df, test_size=0.2, random_state=seed)\n",
    "\n",
    "# Reset the index\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Generate Synthetic Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO (Look at generating for dismilliar data cause all of them seem to be simialr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Get Embeddings and Cosine Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_factory import model_factory\n",
    "model_name = 'voyage'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(df: pd.DataFrame, model_name: str, task_name: str):\n",
    "    model = model_factory(model_name, task_name)\n",
    "    for column in ['sentence1', 'sentence2']:\n",
    "        df[f\"{column}_embedding\"] = model.encode(df[column].tolist())\n",
    "\n",
    "def get_cosine_similarity(a: np.array, b: np.array):\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "\n",
    "def generate_cosine_similarity(df: pd.DataFrame):\n",
    "    df['cosine_similarity'] = df.apply(lambda x: get_cosine_similarity(x['sentence1_embedding'], x['sentence2_embedding']), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_embedding(df_train, model_name, task_name)\n",
    "generate_embedding(df_val, model_name, task_name)\n",
    "\n",
    "generate_cosine_similarity(df_train)\n",
    "generate_cosine_similarity(df_val)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Evaluate The Baseline Performance\n",
    "\n",
    "We use spearman and Pearson to evaluate the performance. \n",
    "\n",
    "Pearson correlation is a measure of strength of linear relationship between two variables. It ranges from -1 to 1.\n",
    "\n",
    "While spearman correlation is a measure of monotonic relationship between two variables. It ranges from -1 to 1.\n",
    "\n",
    "We want both these values to be close to 1. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correlation(df: pd.DataFrame, column_name: str = 'cosine_similarity'):\n",
    "    return df[column_name].corr(df['score'], method='spearman'), df[column_name].corr(df['score'], method='pearson')\n",
    "\n",
    "spearmans, pearsons = get_correlation(df_train)\n",
    "print(f\"Train: Spearman: {spearmans}, Pearson: {pearsons}\")\n",
    "\n",
    "spearmans, pearsons = get_correlation(df_val)\n",
    "print(f\"Validation: Spearman: {spearmans}, Pearson: {pearsons}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_correlation(df: pd.DataFrame, title: str):\n",
    "    sns.scatterplot(data=df, x='cosine_similarity', y='score')\n",
    "    plt.title(title)\n",
    "    plt.xlabel('Cosine Similarity')\n",
    "    plt.ylabel('Score')\n",
    "    plt.show()\n",
    "\n",
    "plot_correlation(df_train, 'Relation Between Score and Cosine Similarity (Train)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_matrix(\n",
    "    new_length: int = 2048,\n",
    "    batch_size: int = 200,\n",
    "    max_epochs: int = 100,\n",
    "    lr: float = 100,\n",
    "    p: float = 0.1,\n",
    "    print_every: int = 10,\n",
    "):\n",
    "    def get_tensors(df):\n",
    "        df_x1 = np.stack(df['sentence1_embedding'].values)\n",
    "        df_x2 = np.stack(df['sentence2_embedding'].values)\n",
    "        df_y = df['score'].values\n",
    "\n",
    "\n",
    "        X1 = torch.from_numpy(df_x1).float()\n",
    "        X2 = torch.from_numpy(df_x2).float()\n",
    "        Y = torch.from_numpy(df_y).float()\n",
    "        return X1, X2, Y\n",
    "\n",
    "    X1_train, X2_train, Y_train = get_tensors(df_train)\n",
    "    X1_val, X2_val, Y_val = get_tensors(df_val)\n",
    "\n",
    "    train_dataset = torch.utils.data.TensorDataset(X1_train, X2_train, Y_train)\n",
    "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "    def model(X1, X2, matrix, p=p):\n",
    "        e1 = torch.nn.functional.dropout(X1, p=p)\n",
    "        e2 = torch.nn.functional.dropout(X2, p=p)\n",
    "        return torch.nn.functional.cosine_similarity(e1 @ matrix, e2 @ matrix)\n",
    "    \n",
    "    def mse_loss(predictions, targets):\n",
    "        real_preds = torch.clamp(2*(predictions - 0.5), 0, 1)\n",
    "        return torch.nn.functional.mse_loss(real_preds, targets)\n",
    "\n",
    "    def calc_custom(embedding, matrix):\n",
    "        embedding_tensor = torch.from_numpy(embedding).float()\n",
    "        modified_embedding = embedding_tensor @ matrix\n",
    "        return modified_embedding.detach().numpy()\n",
    "\n",
    "    epochs, types, losses, accuracies, matrices = [], [], [], [], []\n",
    "\n",
    "    matrix = torch.randn(len(df_train['sentence1_embedding'].values[0]), new_length, requires_grad=True)\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        epoch_loss = 0\n",
    "        for X1, X2, Y in train_loader:\n",
    "            predictions = model(X1, X2, matrix)\n",
    "            loss = mse_loss(predictions, Y)\n",
    "            loss.backward()\n",
    "            with torch.no_grad():\n",
    "                matrix -= lr * matrix.grad\n",
    "                matrix.grad.zero_()\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            test_preds = model(X1_val, X2_val, matrix)\n",
    "            test_loss = mse_loss(test_preds, Y_val)\n",
    "        \n",
    "        for df in [df_train, df_val]:\n",
    "            m = matrix.clone().detach().numpy()\n",
    "            df[\"custom_1\"] = df['sentence1_embedding'].apply(lambda x: calc_custom(x, matrix))\n",
    "            df[\"custom_2\"] = df['sentence2_embedding'].apply(lambda x: calc_custom(x, matrix))\n",
    "            df[\"custom_cosine_similarity\"] = df.apply(lambda x: get_cosine_similarity(x['custom_1'], x['custom_2']), axis=1)\n",
    "\n",
    "            spearmans, _ = get_correlation(df, 'custom_cosine_similarity')\n",
    "            type = \"train\" if df is df_train else \"val\"\n",
    "            l = loss.item() if df is df_train else test_loss.item()\n",
    "            accuracies.append(spearmans)\n",
    "            losses.append(l)\n",
    "            types.append(type)\n",
    "            epochs.append(epoch)\n",
    "            matrices.append(m)\n",
    "\n",
    "            if print_every and epoch % print_every == 0:\n",
    "                print(f\"Epoch {epoch+1}/{max_epochs} ({type}) - Loss: {l}, Spearman: {spearmans}\")\n",
    "\n",
    "            \n",
    "    data = pd.DataFrame({\n",
    "        \"epoch\": epochs,\n",
    "        \"type\": types,\n",
    "        \"loss\": losses,\n",
    "        \"accuracy\": accuracies,\n",
    "        \"matrix\": matrices,\n",
    "    })\n",
    "    result_dir = 'tlresults'\n",
    "    if not os.path.exists(result_dir):\n",
    "        os.makedirs(result_dir)\n",
    "    data.to_csv(f\"{result_dir}/{task_name}_{model_name}_matrix_optimization.csv\")\n",
    "    return data\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimize_matrix(print_every=1, max_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(f\"tlresults/{task_name}_{model_name}_matrix_optimization.csv\", index_col=0)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot loss, separate by train and val\n",
    "sns.lineplot(data=df, x='epoch', y='loss', hue='type')\n",
    "plt.title('Loss Over Time')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot spearmans, separate by train and val\n",
    "sns.lineplot(data=df, x='epoch', y='accuracy', hue='type')\n",
    "plt.title('Spearmans Over Time')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Spearmans')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "snlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
