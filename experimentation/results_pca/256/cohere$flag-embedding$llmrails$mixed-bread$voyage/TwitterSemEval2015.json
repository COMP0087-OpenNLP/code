{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8775704833998927,
      "accuracy_threshold": 0.7436525427619796,
      "ap": 0.7894429325623,
      "f1": 0.7212055974165769,
      "f1_threshold": 0.7274442025855707,
      "precision": 0.7358594179022515,
      "recall": 0.7071240105540897
    },
    "dot": {
      "accuracy": 0.8588543839780652,
      "accuracy_threshold": 0.31178690456007124,
      "ap": 0.7261688266617974,
      "f1": 0.6782742286519011,
      "f1_threshold": 0.2946590630015945,
      "precision": 0.6587913454364586,
      "recall": 0.6989445910290237
    },
    "euclidean": {
      "accuracy": 0.8763187697442928,
      "accuracy_threshold": 0.46075031537116706,
      "ap": 0.7867096343102185,
      "f1": 0.7198463508322663,
      "f1_threshold": 0.4883071412207176,
      "precision": 0.6992537313432836,
      "recall": 0.741688654353562
    },
    "evaluation_time": 1.55,
    "manhattan": {
      "accuracy": 0.8764975859808071,
      "accuracy_threshold": 5.5459870804546405,
      "ap": 0.7893621006472706,
      "f1": 0.7227470002552975,
      "f1_threshold": 5.964234242301913,
      "precision": 0.7000494559841741,
      "recall": 0.7469656992084432
    },
    "max": {
      "accuracy": 0.8775704833998927,
      "ap": 0.7894429325623,
      "f1": 0.7227470002552975
    }
  }
}