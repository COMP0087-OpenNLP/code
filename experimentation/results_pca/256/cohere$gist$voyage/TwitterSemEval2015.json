{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8726828396018358,
      "accuracy_threshold": 0.7653009887407539,
      "ap": 0.7708824839798017,
      "f1": 0.7112565445026178,
      "f1_threshold": 0.7374974274538018,
      "precision": 0.7057142857142857,
      "recall": 0.7168865435356201
    },
    "dot": {
      "accuracy": 0.8407939440901234,
      "accuracy_threshold": 0.30376443030882505,
      "ap": 0.6772549031515542,
      "f1": 0.6516509433962264,
      "f1_threshold": 0.27637418662324165,
      "precision": 0.5891257995735608,
      "recall": 0.729023746701847
    },
    "euclidean": {
      "accuracy": 0.8700602014662931,
      "accuracy_threshold": 0.4226236202923125,
      "ap": 0.7625160572787791,
      "f1": 0.7032910080331691,
      "f1_threshold": 0.4556700840523125,
      "precision": 0.6909368635437881,
      "recall": 0.7160949868073878
    },
    "evaluation_time": 2.35,
    "manhattan": {
      "accuracy": 0.8678548012159504,
      "accuracy_threshold": 5.2417346174627255,
      "ap": 0.7617433732953302,
      "f1": 0.7031530376826455,
      "f1_threshold": 5.627958789404938,
      "precision": 0.6836989032901296,
      "recall": 0.7237467018469657
    },
    "max": {
      "accuracy": 0.8726828396018358,
      "ap": 0.7708824839798017,
      "f1": 0.7112565445026178
    }
  }
}