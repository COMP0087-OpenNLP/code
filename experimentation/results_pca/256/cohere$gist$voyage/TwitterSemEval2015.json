{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.869762174405436,
      "accuracy_threshold": 0.7514183868248747,
      "ap": 0.769558477174962,
      "f1": 0.7052080737602792,
      "f1_threshold": 0.7045774005507901,
      "precision": 0.6680830972615676,
      "recall": 0.7467018469656992
    },
    "dot": {
      "accuracy": 0.8621326816474936,
      "accuracy_threshold": 0.47412490033236215,
      "ap": 0.7458727615042351,
      "f1": 0.6891560353287537,
      "f1_threshold": 0.4465084133910481,
      "precision": 0.6439706556625401,
      "recall": 0.7411609498680739
    },
    "euclidean": {
      "accuracy": 0.8705370447636646,
      "accuracy_threshold": 0.5618038346434788,
      "ap": 0.7724313523326484,
      "f1": 0.707820954254796,
      "f1_threshold": 0.6166519041448851,
      "precision": 0.6628281897742976,
      "recall": 0.7593667546174142
    },
    "evaluation_time": 3.33,
    "manhattan": {
      "accuracy": 0.8607617571675508,
      "accuracy_threshold": 12.939002129266857,
      "ap": 0.7469545222275931,
      "f1": 0.6911506643268989,
      "f1_threshold": 13.981913003634094,
      "precision": 0.6583094555873925,
      "recall": 0.7274406332453826
    },
    "max": {
      "accuracy": 0.8705370447636646,
      "ap": 0.7724313523326484,
      "f1": 0.707820954254796
    }
  }
}