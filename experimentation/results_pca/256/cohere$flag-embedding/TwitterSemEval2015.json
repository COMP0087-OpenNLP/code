{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8760207426834357,
      "accuracy_threshold": 0.7420929365721265,
      "ap": 0.7815682839722902,
      "f1": 0.7159120310478655,
      "f1_threshold": 0.7162819925145864,
      "precision": 0.7022842639593908,
      "recall": 0.7300791556728232
    },
    "dot": {
      "accuracy": 0.8533110806461227,
      "accuracy_threshold": 0.3362136536741057,
      "ap": 0.709872006832101,
      "f1": 0.6694612254962398,
      "f1_threshold": 0.3135210543419834,
      "precision": 0.6283267762092108,
      "recall": 0.716358839050132
    },
    "euclidean": {
      "accuracy": 0.8747690290278357,
      "accuracy_threshold": 0.4708416124488154,
      "ap": 0.7755368608309573,
      "f1": 0.7095865864584666,
      "f1_threshold": 0.5064410860927546,
      "precision": 0.6890380313199105,
      "recall": 0.7313984168865435
    },
    "evaluation_time": 0.57,
    "manhattan": {
      "accuracy": 0.8752458723252071,
      "accuracy_threshold": 5.871656391887148,
      "ap": 0.7770456572741495,
      "f1": 0.7125585985689613,
      "f1_threshold": 6.30621454912535,
      "precision": 0.6691380908248378,
      "recall": 0.7620052770448549
    },
    "max": {
      "accuracy": 0.8760207426834357,
      "ap": 0.7815682839722902,
      "f1": 0.7159120310478655
    }
  }
}