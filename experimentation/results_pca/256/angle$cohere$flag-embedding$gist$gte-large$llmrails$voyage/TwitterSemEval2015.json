{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8785241699946356,
      "accuracy_threshold": 0.7580605733675465,
      "ap": 0.7863556639731637,
      "f1": 0.7211600153984346,
      "f1_threshold": 0.721229573089904,
      "precision": 0.7019735198601049,
      "recall": 0.741424802110818
    },
    "dot": {
      "accuracy": 0.856589378315551,
      "accuracy_threshold": 0.31340542567819796,
      "ap": 0.7257389649848958,
      "f1": 0.6704424778761062,
      "f1_threshold": 0.28590434517140595,
      "precision": 0.6064034151547492,
      "recall": 0.7496042216358839
    },
    "euclidean": {
      "accuracy": 0.8764975859808071,
      "accuracy_threshold": 0.4484144928439583,
      "ap": 0.7860364745538413,
      "f1": 0.7217313356383659,
      "f1_threshold": 0.4788522643347083,
      "precision": 0.7011694451356059,
      "recall": 0.7435356200527704
    },
    "evaluation_time": 2.14,
    "manhattan": {
      "accuracy": 0.8764379805686356,
      "accuracy_threshold": 5.54928616543639,
      "ap": 0.7848565250304567,
      "f1": 0.7193115666919766,
      "f1_threshold": 5.883242652510576,
      "precision": 0.691147859922179,
      "recall": 0.749868073878628
    },
    "max": {
      "accuracy": 0.8785241699946356,
      "ap": 0.7863556639731637,
      "f1": 0.7217313356383659
    }
  }
}