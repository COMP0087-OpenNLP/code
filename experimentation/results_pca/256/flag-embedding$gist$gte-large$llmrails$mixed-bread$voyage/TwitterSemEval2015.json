{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.877749299636407,
      "accuracy_threshold": 0.7444273373405131,
      "ap": 0.7878523816385463,
      "f1": 0.7229007633587786,
      "f1_threshold": 0.7061812737711154,
      "precision": 0.698034398034398,
      "recall": 0.7496042216358839
    },
    "dot": {
      "accuracy": 0.8603445192823508,
      "accuracy_threshold": 0.32729436689603125,
      "ap": 0.7350789749917563,
      "f1": 0.6803030303030303,
      "f1_threshold": 0.30753756727490744,
      "precision": 0.6523002421307506,
      "recall": 0.7108179419525066
    },
    "euclidean": {
      "accuracy": 0.8761995589199499,
      "accuracy_threshold": 0.4791188958792934,
      "ap": 0.7882999243200118,
      "f1": 0.7213845548708535,
      "f1_threshold": 0.4988785821705821,
      "precision": 0.7169663799843627,
      "recall": 0.7258575197889182
    },
    "evaluation_time": 1.78,
    "manhattan": {
      "accuracy": 0.8752458723252071,
      "accuracy_threshold": 5.627224896784525,
      "ap": 0.7860113948112614,
      "f1": 0.7196834311973449,
      "f1_threshold": 6.18366068237872,
      "precision": 0.697082096933729,
      "recall": 0.7437994722955145
    },
    "max": {
      "accuracy": 0.877749299636407,
      "ap": 0.7882999243200118,
      "f1": 0.7229007633587786
    }
  }
}