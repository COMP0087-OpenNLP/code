{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8776896942242356,
      "accuracy_threshold": 0.7683700674567836,
      "ap": 0.7822424163346953,
      "f1": 0.7153322867608582,
      "f1_threshold": 0.7349421779701308,
      "precision": 0.7093928386092372,
      "recall": 0.7213720316622692
    },
    "dot": {
      "accuracy": 0.8527150265244084,
      "accuracy_threshold": 0.32065734593164297,
      "ap": 0.7117800958580063,
      "f1": 0.6676572560673601,
      "f1_threshold": 0.29653517564735077,
      "precision": 0.6290247316845544,
      "recall": 0.7113456464379947
    },
    "euclidean": {
      "accuracy": 0.8766764022173213,
      "accuracy_threshold": 0.44032840740852,
      "ap": 0.7802799429491543,
      "f1": 0.7158813711644627,
      "f1_threshold": 0.47184506535210596,
      "precision": 0.6971742935733933,
      "recall": 0.7356200527704485
    },
    "evaluation_time": 1.41,
    "manhattan": {
      "accuracy": 0.8754246885617214,
      "accuracy_threshold": 5.42472149613811,
      "ap": 0.7801053662121957,
      "f1": 0.7184368737474951,
      "f1_threshold": 5.8549809784451305,
      "precision": 0.6838340486409156,
      "recall": 0.7567282321899736
    },
    "max": {
      "accuracy": 0.8776896942242356,
      "ap": 0.7822424163346953,
      "f1": 0.7184368737474951
    }
  }
}