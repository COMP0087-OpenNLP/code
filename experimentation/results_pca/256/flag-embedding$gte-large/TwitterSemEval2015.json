{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8766167968051499,
      "accuracy_threshold": 0.7400242985520593,
      "ap": 0.7837636182401406,
      "f1": 0.7169761967041591,
      "f1_threshold": 0.711374440451531,
      "precision": 0.7108402489626556,
      "recall": 0.7232189973614775
    },
    "dot": {
      "accuracy": 0.857841091971151,
      "accuracy_threshold": 0.261146472233433,
      "ap": 0.729276533747277,
      "f1": 0.6746527335287371,
      "f1_threshold": 0.24866088013319856,
      "precision": 0.6524525511461671,
      "recall": 0.6984168865435356
    },
    "euclidean": {
      "accuracy": 0.8745902127913214,
      "accuracy_threshold": 0.4273889599237287,
      "ap": 0.7829238507313503,
      "f1": 0.7148162376744782,
      "f1_threshold": 0.4564397929519449,
      "precision": 0.6944513560587211,
      "recall": 0.7364116094986808
    },
    "evaluation_time": 0.62,
    "manhattan": {
      "accuracy": 0.8732192883113786,
      "accuracy_threshold": 5.174699605996464,
      "ap": 0.7787783183876658,
      "f1": 0.7160336477185827,
      "f1_threshold": 5.598914835714806,
      "precision": 0.6925542406311637,
      "recall": 0.7411609498680739
    },
    "max": {
      "accuracy": 0.8766167968051499,
      "ap": 0.7837636182401406,
      "f1": 0.7169761967041591
    }
  }
}