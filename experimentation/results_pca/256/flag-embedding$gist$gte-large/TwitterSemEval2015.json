{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8767956130416642,
      "accuracy_threshold": 0.7404747766241594,
      "ap": 0.7846852687512578,
      "f1": 0.7188696685593555,
      "f1_threshold": 0.7203760178580456,
      "precision": 0.7195347607718742,
      "recall": 0.7182058047493404
    },
    "dot": {
      "accuracy": 0.8612386004649222,
      "accuracy_threshold": 0.3456490391082198,
      "ap": 0.7358191599245008,
      "f1": 0.6793361206132016,
      "f1_threshold": 0.32062368065359714,
      "precision": 0.6534243236656105,
      "recall": 0.7073878627968337
    },
    "euclidean": {
      "accuracy": 0.8758419264469214,
      "accuracy_threshold": 0.47551064929539266,
      "ap": 0.785214007046213,
      "f1": 0.7190347837248108,
      "f1_threshold": 0.5106977681147553,
      "precision": 0.7000749812546864,
      "recall": 0.7390501319261213
    },
    "evaluation_time": 0.79,
    "manhattan": {
      "accuracy": 0.8751266615008643,
      "accuracy_threshold": 5.92986346510609,
      "ap": 0.7825000618845845,
      "f1": 0.7168697883258499,
      "f1_threshold": 6.255218929191031,
      "precision": 0.6976279650436954,
      "recall": 0.737203166226913
    },
    "max": {
      "accuracy": 0.8767956130416642,
      "ap": 0.785214007046213,
      "f1": 0.7190347837248108
    }
  }
}