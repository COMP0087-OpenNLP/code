{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8764379805686356,
      "accuracy_threshold": 0.741271600022837,
      "ap": 0.7824695347685311,
      "f1": 0.7180940115904701,
      "f1_threshold": 0.7155831677642872,
      "precision": 0.7013836477987422,
      "recall": 0.7356200527704485
    },
    "dot": {
      "accuracy": 0.8548608213625797,
      "accuracy_threshold": 0.34714646224125933,
      "ap": 0.7224684457648146,
      "f1": 0.6659793814432989,
      "f1_threshold": 0.32600599707810957,
      "precision": 0.6508816120906801,
      "recall": 0.6817941952506597
    },
    "euclidean": {
      "accuracy": 0.8755438993860643,
      "accuracy_threshold": 0.4723494799796114,
      "ap": 0.7841869180608902,
      "f1": 0.718290029438116,
      "f1_threshold": 0.5099376205181807,
      "precision": 0.6974894357444693,
      "recall": 0.7403693931398417
    },
    "evaluation_time": 0.97,
    "manhattan": {
      "accuracy": 0.8748882398521786,
      "accuracy_threshold": 5.892333141933733,
      "ap": 0.7808591178865701,
      "f1": 0.7173718522306022,
      "f1_threshold": 6.224798288513698,
      "precision": 0.6957599801636499,
      "recall": 0.7403693931398417
    },
    "max": {
      "accuracy": 0.8764379805686356,
      "ap": 0.7841869180608902,
      "f1": 0.718290029438116
    }
  }
}