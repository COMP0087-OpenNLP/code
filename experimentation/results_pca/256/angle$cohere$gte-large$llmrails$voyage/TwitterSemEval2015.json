{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8779877212850927,
      "accuracy_threshold": 0.755151743974261,
      "ap": 0.7828248659199682,
      "f1": 0.7171304569823845,
      "f1_threshold": 0.7236542425800678,
      "precision": 0.6946092977250248,
      "recall": 0.7411609498680739
    },
    "dot": {
      "accuracy": 0.8525958157000656,
      "accuracy_threshold": 0.26543067370357265,
      "ap": 0.7037009033101138,
      "f1": 0.6615942877209412,
      "f1_threshold": 0.2399463119523878,
      "precision": 0.5945718493583,
      "recall": 0.745646437994723
    },
    "euclidean": {
      "accuracy": 0.87536508314955,
      "accuracy_threshold": 0.3985071297834658,
      "ap": 0.7784159806299853,
      "f1": 0.7172995780590717,
      "f1_threshold": 0.4348404806690921,
      "precision": 0.6958571074175143,
      "recall": 0.7401055408970977
    },
    "evaluation_time": 1.64,
    "manhattan": {
      "accuracy": 0.8748286344400071,
      "accuracy_threshold": 5.005919846168703,
      "ap": 0.7788756032875837,
      "f1": 0.717407686510927,
      "f1_threshold": 5.370906487468347,
      "precision": 0.6845637583892618,
      "recall": 0.7535620052770449
    },
    "max": {
      "accuracy": 0.8779877212850927,
      "ap": 0.7828248659199682,
      "f1": 0.717407686510927
    }
  }
}