{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8742921857304643,
      "accuracy_threshold": 0.7619284833316242,
      "ap": 0.7731745290622836,
      "f1": 0.7106654018159643,
      "f1_threshold": 0.7444160424072527,
      "precision": 0.7305656171635553,
      "recall": 0.691820580474934
    },
    "dot": {
      "accuracy": 0.845085533766466,
      "accuracy_threshold": 0.3065808051188481,
      "ap": 0.6878525085601331,
      "f1": 0.6534466477809254,
      "f1_threshold": 0.2794971921861472,
      "precision": 0.5912003417343016,
      "recall": 0.7303430079155673
    },
    "euclidean": {
      "accuracy": 0.8722656017166359,
      "accuracy_threshold": 0.4331596239735068,
      "ap": 0.7659371050450634,
      "f1": 0.7040123061146007,
      "f1_threshold": 0.4666186769673269,
      "precision": 0.6846173024183495,
      "recall": 0.7245382585751979
    },
    "evaluation_time": 0.95,
    "manhattan": {
      "accuracy": 0.870179412290636,
      "accuracy_threshold": 5.2547411030011455,
      "ap": 0.7652244629144632,
      "f1": 0.7056906492855352,
      "f1_threshold": 5.787099304964952,
      "precision": 0.6721585482330468,
      "recall": 0.7427440633245382
    },
    "max": {
      "accuracy": 0.8742921857304643,
      "ap": 0.7731745290622836,
      "f1": 0.7106654018159643
    }
  }
}