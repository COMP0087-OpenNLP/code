{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8787625916433213,
      "accuracy_threshold": 0.7581317142291231,
      "ap": 0.787163238792705,
      "f1": 0.7182914046121593,
      "f1_threshold": 0.7278384995752403,
      "precision": 0.713430504945341,
      "recall": 0.7232189973614775
    },
    "dot": {
      "accuracy": 0.8572450378494367,
      "accuracy_threshold": 0.32311405295596607,
      "ap": 0.7208903411722062,
      "f1": 0.6704677682103792,
      "f1_threshold": 0.29184696219872563,
      "precision": 0.5997085761865112,
      "recall": 0.7601583113456465
    },
    "euclidean": {
      "accuracy": 0.8763783751564642,
      "accuracy_threshold": 0.45565252694124464,
      "ap": 0.7849576176727265,
      "f1": 0.7206931702344547,
      "f1_threshold": 0.48478233004086624,
      "precision": 0.696895022178413,
      "recall": 0.7461741424802111
    },
    "evaluation_time": 1.6,
    "manhattan": {
      "accuracy": 0.8767360076294928,
      "accuracy_threshold": 5.387856509305893,
      "ap": 0.7858737213079691,
      "f1": 0.7210715614535533,
      "f1_threshold": 6.00214734581843,
      "precision": 0.6803182775567517,
      "recall": 0.767018469656992
    },
    "max": {
      "accuracy": 0.8787625916433213,
      "ap": 0.787163238792705,
      "f1": 0.7210715614535533
    }
  }
}