{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8780473266972642,
      "accuracy_threshold": 0.7469523137766484,
      "ap": 0.7891296852266293,
      "f1": 0.7210278590510113,
      "f1_threshold": 0.7066602623974434,
      "precision": 0.6961434536968804,
      "recall": 0.7477572559366754
    },
    "dot": {
      "accuracy": 0.8587947785658938,
      "accuracy_threshold": 0.3565744732226433,
      "ap": 0.728571216007171,
      "f1": 0.6753086419753087,
      "f1_threshold": 0.326297625688726,
      "precision": 0.6345707656612529,
      "recall": 0.7216358839050132
    },
    "euclidean": {
      "accuracy": 0.8766167968051499,
      "accuracy_threshold": 0.49290314532070256,
      "ap": 0.787913356649087,
      "f1": 0.7205404703131089,
      "f1_threshold": 0.5171145212658184,
      "precision": 0.7097517276682876,
      "recall": 0.7316622691292876
    },
    "evaluation_time": 1.12,
    "manhattan": {
      "accuracy": 0.87578232103475,
      "accuracy_threshold": 5.919532378606762,
      "ap": 0.7885117109739318,
      "f1": 0.7245096765813741,
      "f1_threshold": 6.320646187159156,
      "precision": 0.7134817088769506,
      "recall": 0.7358839050131926
    },
    "max": {
      "accuracy": 0.8780473266972642,
      "ap": 0.7891296852266293,
      "f1": 0.7245096765813741
    }
  }
}