{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8787625916433213,
      "accuracy_threshold": 0.7647600780696379,
      "ap": 0.7836372091002454,
      "f1": 0.7183995922528033,
      "f1_threshold": 0.7247950668076918,
      "precision": 0.6946771808772795,
      "recall": 0.7437994722955145
    },
    "dot": {
      "accuracy": 0.8547416105382368,
      "accuracy_threshold": 0.3456526320913842,
      "ap": 0.7203196332473689,
      "f1": 0.6704326923076923,
      "f1_threshold": 0.3196015457875295,
      "precision": 0.615673289183223,
      "recall": 0.7358839050131926
    },
    "euclidean": {
      "accuracy": 0.8772128509268642,
      "accuracy_threshold": 0.4626799661698777,
      "ap": 0.7820385981586171,
      "f1": 0.7186491184504594,
      "f1_threshold": 0.5064647909647917,
      "precision": 0.6787054409005628,
      "recall": 0.7635883905013192
    },
    "evaluation_time": 1.38,
    "manhattan": {
      "accuracy": 0.8754246885617214,
      "accuracy_threshold": 5.640551559416427,
      "ap": 0.781265577398486,
      "f1": 0.7184664536741213,
      "f1_threshold": 6.086651975337851,
      "precision": 0.6966542750929368,
      "recall": 0.741688654353562
    },
    "max": {
      "accuracy": 0.8787625916433213,
      "ap": 0.7836372091002454,
      "f1": 0.7186491184504594
    }
  }
}