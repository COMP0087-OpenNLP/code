{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8770340346903499,
      "accuracy_threshold": 0.76465947335248,
      "ap": 0.7805097401251765,
      "f1": 0.7140902872777017,
      "f1_threshold": 0.7221713014159002,
      "precision": 0.6753705010585744,
      "recall": 0.7575197889182058
    },
    "dot": {
      "accuracy": 0.84901949096978,
      "accuracy_threshold": 0.2809073205900995,
      "ap": 0.7001141971696003,
      "f1": 0.6586141131595677,
      "f1_threshold": 0.2614444748368532,
      "precision": 0.6355828220858896,
      "recall": 0.683377308707124
    },
    "euclidean": {
      "accuracy": 0.8748882398521786,
      "accuracy_threshold": 0.404697865493612,
      "ap": 0.7762824913662365,
      "f1": 0.7139901732609257,
      "f1_threshold": 0.4357825589466755,
      "precision": 0.7000507099391481,
      "recall": 0.7284960422163589
    },
    "evaluation_time": 1.64,
    "manhattan": {
      "accuracy": 0.8735769207844072,
      "accuracy_threshold": 4.840259603428077,
      "ap": 0.7765941260615509,
      "f1": 0.7157490396927016,
      "f1_threshold": 5.370159448005799,
      "precision": 0.695273631840796,
      "recall": 0.737467018469657
    },
    "max": {
      "accuracy": 0.8770340346903499,
      "ap": 0.7805097401251765,
      "f1": 0.7157490396927016
    }
  }
}