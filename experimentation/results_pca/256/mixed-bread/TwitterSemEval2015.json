{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8747690290278357,
      "accuracy_threshold": 0.768208964152905,
      "ap": 0.7804686843547266,
      "f1": 0.716518145421671,
      "f1_threshold": 0.725766819787669,
      "precision": 0.7017455097394384,
      "recall": 0.7319261213720316
    },
    "dot": {
      "accuracy": 0.85068844251058,
      "accuracy_threshold": 0.43804976311680927,
      "ap": 0.7141426891520424,
      "f1": 0.6558372952984681,
      "f1_threshold": 0.41598213918138016,
      "precision": 0.6565309360126917,
      "recall": 0.6551451187335092
    },
    "euclidean": {
      "accuracy": 0.8756035047982357,
      "accuracy_threshold": 0.5154645336450636,
      "ap": 0.783689903452129,
      "f1": 0.7174415617775496,
      "f1_threshold": 0.5598498170727592,
      "precision": 0.698948948948949,
      "recall": 0.7369393139841689
    },
    "evaluation_time": 0.33,
    "manhattan": {
      "accuracy": 0.87578232103475,
      "accuracy_threshold": 6.356016416194087,
      "ap": 0.7805587619775236,
      "f1": 0.7142675321369479,
      "f1_threshold": 6.848004619089899,
      "precision": 0.6899434472584215,
      "recall": 0.7403693931398417
    },
    "max": {
      "accuracy": 0.87578232103475,
      "ap": 0.783689903452129,
      "f1": 0.7174415617775496
    }
  }
}