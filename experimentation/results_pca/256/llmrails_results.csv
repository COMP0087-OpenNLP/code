model,task,dataset,language,metric,value
llmrails,BitextMining,BUCC,,f1,
llmrails,BitextMining,Tatoeba,,f1,
llmrails,Classification,AmazonCounterfactualClassification,en,accuracy,0.7459701492537313
llmrails,Classification,AmazonCounterfactualClassification,de,accuracy,
llmrails,Classification,AmazonCounterfactualClassification,de,accuracy,
llmrails,Classification,AmazonCounterfactualClassification,en-ext,accuracy,
llmrails,Classification,AmazonCounterfactualClassification,en-ext,accuracy,
llmrails,Classification,AmazonCounterfactualClassification,ja,accuracy,
llmrails,Classification,AmazonCounterfactualClassification,ja,accuracy,
llmrails,Classification,AmazonPolarityClassification,,accuracy,
llmrails,Classification,AmazonReviewsClassification,,accuracy,
llmrails,Classification,Banking77Classification,en,accuracy,0.850909090909091
llmrails,Classification,EmotionClassification,en,accuracy,0.5514
llmrails,Classification,ImdbClassification,,accuracy,
llmrails,Classification,MassiveIntentClassification,,accuracy,
llmrails,Classification,MassiveScenarioClassification,,accuracy,
llmrails,Classification,MTOPDomainClassification,,accuracy,
llmrails,Classification,MTOPIntentClassification,,accuracy,
llmrails,Classification,ToxicConversationsClassification,,accuracy,
llmrails,Classification,TweetSentimentExtractionClassification,,accuracy,
llmrails,Clustering,ArxivClusteringP2P,,v_measure,
llmrails,Clustering,ArxivClusteringS2S,en,v_measure,0.4326919280027407
llmrails,Clustering,BiorxivClusteringP2P,,v_measure,
llmrails,Clustering,BiorxivClusteringS2S,,v_measure,
llmrails,Clustering,MedrxivClusteringP2P,,v_measure,
llmrails,Clustering,MedrxivClusteringS2S,,v_measure,
llmrails,Clustering,RedditClustering,en,v_measure,0.579948717082091
llmrails,Clustering,RedditClusteringP2P,,v_measure,
llmrails,Clustering,StackExchangeClustering,,v_measure,
llmrails,Clustering,StackExchangeClusteringP2P,,v_measure,
llmrails,Clustering,TwentyNewsgroupsClustering,,v_measure,
llmrails,PairClassification,SprintDuplicateQuestions,,ap,
llmrails,PairClassification,TwitterSemEval2015,en,ap,0.7901386665204044
llmrails,PairClassification,TwitterURLCorpus,,ap,
llmrails,Reranking,AskUbuntuDupQuestions,en,map,0.6480956698446022
llmrails,Reranking,MindSmallReranking,,map,
llmrails,Reranking,SciDocsRR,,map,
llmrails,Reranking,StackOverflowDupQuestions,,map,
llmrails,Retrieval,ArguAna,en,ndcg_at_10,0.64537
llmrails,Retrieval,ClimateFEVER,,ndcg_at_10,
llmrails,Retrieval,CQADupstackRetrieval,,ndcg_at_10,
llmrails,Retrieval,DBPedia,,ndcg_at_10,
llmrails,Retrieval,FEVER,,ndcg_at_10,
llmrails,Retrieval,FiQA2018,,ndcg_at_10,
llmrails,Retrieval,HotpotQA,,ndcg_at_10,
llmrails,Retrieval,MSMARCO,,ndcg_at_10,
llmrails,Retrieval,NFCorpus,,ndcg_at_10,
llmrails,Retrieval,NQ,,ndcg_at_10,
llmrails,Retrieval,QuoraRetrieval,,ndcg_at_10,
llmrails,Retrieval,SCIDOCS,,ndcg_at_10,
llmrails,Retrieval,SciFact,en,ndcg_at_10,0.7477
llmrails,Retrieval,Touche2020,,ndcg_at_10,
llmrails,Retrieval,TRECCOVID,,ndcg_at_10,
llmrails,STS,BIOSSES,,cosine_spearman,
llmrails,STS,SICK-R,en,cosine_spearman,0.8201643315520167
llmrails,STS,STS12,en,cosine_spearman,0.7583559998514044
llmrails,STS,STS13,en,cosine_spearman,0.8737041900240152
llmrails,STS,STS14,en,cosine_spearman,0.824293562704939
llmrails,STS,STS15,en,cosine_spearman,0.8834676452808952
llmrails,STS,STS16,en,cosine_spearman,0.854674138661803
llmrails,STS,STS17,ko-ko,cosine_spearman,
llmrails,STS,STS17,ko-ko,cosine_spearman,
llmrails,STS,STS17,ar-ar,cosine_spearman,
llmrails,STS,STS17,ar-ar,cosine_spearman,
llmrails,STS,STS17,en-ar,cosine_spearman,
llmrails,STS,STS17,en-ar,cosine_spearman,
llmrails,STS,STS17,en-de,cosine_spearman,
llmrails,STS,STS17,en-de,cosine_spearman,
llmrails,STS,STS17,en-en,cosine_spearman,0.8993568502890472
llmrails,STS,STS17,en-tr,cosine_spearman,
llmrails,STS,STS17,en-tr,cosine_spearman,
llmrails,STS,STS17,es-en,cosine_spearman,
llmrails,STS,STS17,es-en,cosine_spearman,
llmrails,STS,STS17,es-es,cosine_spearman,
llmrails,STS,STS17,es-es,cosine_spearman,
llmrails,STS,STS17,fr-en,cosine_spearman,
llmrails,STS,STS17,fr-en,cosine_spearman,
llmrails,STS,STS17,it-en,cosine_spearman,
llmrails,STS,STS17,it-en,cosine_spearman,
llmrails,STS,STS17,nl-en,cosine_spearman,
llmrails,STS,STS17,nl-en,cosine_spearman,
llmrails,STS,STS22,en,cosine_spearman,0.6824418262560802
llmrails,STS,STS22,de,cosine_spearman,
llmrails,STS,STS22,de,cosine_spearman,
llmrails,STS,STS22,es,cosine_spearman,
llmrails,STS,STS22,es,cosine_spearman,
llmrails,STS,STS22,pl,cosine_spearman,
llmrails,STS,STS22,pl,cosine_spearman,
llmrails,STS,STS22,tr,cosine_spearman,
llmrails,STS,STS22,tr,cosine_spearman,
llmrails,STS,STS22,ar,cosine_spearman,
llmrails,STS,STS22,ar,cosine_spearman,
llmrails,STS,STS22,ru,cosine_spearman,
llmrails,STS,STS22,ru,cosine_spearman,
llmrails,STS,STS22,zh,cosine_spearman,
llmrails,STS,STS22,zh,cosine_spearman,
llmrails,STS,STS22,fr,cosine_spearman,
llmrails,STS,STS22,fr,cosine_spearman,
llmrails,STS,STS22,de-en,cosine_spearman,
llmrails,STS,STS22,de-en,cosine_spearman,
llmrails,STS,STS22,es-en,cosine_spearman,
llmrails,STS,STS22,es-en,cosine_spearman,
llmrails,STS,STS22,it,cosine_spearman,
llmrails,STS,STS22,it,cosine_spearman,
llmrails,STS,STS22,pl-en,cosine_spearman,
llmrails,STS,STS22,pl-en,cosine_spearman,
llmrails,STS,STS22,zh-en,cosine_spearman,
llmrails,STS,STS22,zh-en,cosine_spearman,
llmrails,STS,STS22,es-it,cosine_spearman,
llmrails,STS,STS22,es-it,cosine_spearman,
llmrails,STS,STS22,de-fr,cosine_spearman,
llmrails,STS,STS22,de-fr,cosine_spearman,
llmrails,STS,STS22,de-pl,cosine_spearman,
llmrails,STS,STS22,de-pl,cosine_spearman,
llmrails,STS,STS22,fr-pl,cosine_spearman,
llmrails,STS,STS22,fr-pl,cosine_spearman,
llmrails,STS,STSBenchmark,en,cosine_spearman,0.8748509604514163
llmrails,Summarization,SummEval,,cosine_spearman,
