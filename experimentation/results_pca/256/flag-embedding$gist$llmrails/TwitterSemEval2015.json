{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8772724563390356,
      "accuracy_threshold": 0.7387038721009141,
      "ap": 0.7878292044934629,
      "f1": 0.7222575314605313,
      "f1_threshold": 0.6985325665738636,
      "precision": 0.6968359087564385,
      "recall": 0.7496042216358839
    },
    "dot": {
      "accuracy": 0.8625499195326936,
      "accuracy_threshold": 0.39971253621208785,
      "ap": 0.7404541342075143,
      "f1": 0.6835313657851029,
      "f1_threshold": 0.3735882881261003,
      "precision": 0.6626207579886054,
      "recall": 0.7058047493403694
    },
    "euclidean": {
      "accuracy": 0.8764975859808071,
      "accuracy_threshold": 0.5365822974580722,
      "ap": 0.7888285048703779,
      "f1": 0.72102550548434,
      "f1_threshold": 0.5559381858958271,
      "precision": 0.7222663489541965,
      "recall": 0.7197889182058047
    },
    "evaluation_time": 0.8,
    "manhattan": {
      "accuracy": 0.8757227156225785,
      "accuracy_threshold": 6.496389918927662,
      "ap": 0.7865563317569461,
      "f1": 0.7203972498090144,
      "f1_threshold": 6.925790913725552,
      "precision": 0.6961122047244095,
      "recall": 0.7464379947229551
    },
    "max": {
      "accuracy": 0.8772724563390356,
      "ap": 0.7888285048703779,
      "f1": 0.7222575314605313
    }
  }
}