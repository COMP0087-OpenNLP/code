{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8788221970554927,
      "accuracy_threshold": 0.7633292440886855,
      "ap": 0.7850381507628312,
      "f1": 0.7183673469387755,
      "f1_threshold": 0.7333388500915807,
      "precision": 0.7169513797634691,
      "recall": 0.7197889182058047
    },
    "dot": {
      "accuracy": 0.8567085891398939,
      "accuracy_threshold": 0.3901363666926663,
      "ap": 0.7239942102794168,
      "f1": 0.6718957403161578,
      "f1_threshold": 0.3509791542949515,
      "precision": 0.619079386257505,
      "recall": 0.7345646437994723
    },
    "euclidean": {
      "accuracy": 0.8776300888120642,
      "accuracy_threshold": 0.48278439637664655,
      "ap": 0.784408709402239,
      "f1": 0.7201520912547528,
      "f1_threshold": 0.5249947662464307,
      "precision": 0.6929268292682926,
      "recall": 0.7496042216358839
    },
    "evaluation_time": 1.37,
    "manhattan": {
      "accuracy": 0.8764975859808071,
      "accuracy_threshold": 6.054458916666945,
      "ap": 0.7840296016743005,
      "f1": 0.7224942025251224,
      "f1_threshold": 6.348031325847055,
      "precision": 0.7059415911379657,
      "recall": 0.7398416886543535
    },
    "max": {
      "accuracy": 0.8788221970554927,
      "ap": 0.7850381507628312,
      "f1": 0.7224942025251224
    }
  }
}