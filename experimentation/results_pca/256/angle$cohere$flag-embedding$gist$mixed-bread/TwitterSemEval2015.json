{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8788221970554927,
      "accuracy_threshold": 0.7600908676437994,
      "ap": 0.7863151461982629,
      "f1": 0.7194581922375619,
      "f1_threshold": 0.7262709646854562,
      "precision": 0.7103909465020576,
      "recall": 0.7287598944591029
    },
    "dot": {
      "accuracy": 0.857423854085951,
      "accuracy_threshold": 0.3740811258066899,
      "ap": 0.7250606022150161,
      "f1": 0.6726063197909242,
      "f1_threshold": 0.33699559110420874,
      "precision": 0.6117113223854796,
      "recall": 0.7469656992084432
    },
    "euclidean": {
      "accuracy": 0.8778089050485784,
      "accuracy_threshold": 0.47939090009115853,
      "ap": 0.7857147916199125,
      "f1": 0.7202433768538472,
      "f1_threshold": 0.5212528255333284,
      "precision": 0.6930958770431813,
      "recall": 0.7496042216358839
    },
    "evaluation_time": 1.39,
    "manhattan": {
      "accuracy": 0.877332061751207,
      "accuracy_threshold": 5.913648974180304,
      "ap": 0.785188276551658,
      "f1": 0.7229219143576827,
      "f1_threshold": 6.387599797235104,
      "precision": 0.691566265060241,
      "recall": 0.7572559366754618
    },
    "max": {
      "accuracy": 0.8788221970554927,
      "ap": 0.7863151461982629,
      "f1": 0.7229219143576827
    }
  }
}