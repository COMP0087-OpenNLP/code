{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.87411336949395,
      "accuracy_threshold": 0.7619024755055204,
      "ap": 0.7743685712199606,
      "f1": 0.7135678391959799,
      "f1_threshold": 0.7237754210908378,
      "precision": 0.697305464618484,
      "recall": 0.7306068601583113
    },
    "dot": {
      "accuracy": 0.8471717231924659,
      "accuracy_threshold": 0.2945816141246441,
      "ap": 0.6927624105635789,
      "f1": 0.6624295479074229,
      "f1_threshold": 0.2650278764468374,
      "precision": 0.6071664102000439,
      "recall": 0.7287598944591029
    },
    "euclidean": {
      "accuracy": 0.8707754664123503,
      "accuracy_threshold": 0.42306459379809264,
      "ap": 0.7655325897025902,
      "f1": 0.7049429657794677,
      "f1_threshold": 0.4616063581179546,
      "precision": 0.6782926829268293,
      "recall": 0.7337730870712401
    },
    "evaluation_time": 0.95,
    "manhattan": {
      "accuracy": 0.8702986231149789,
      "accuracy_threshold": 5.257486008778111,
      "ap": 0.7656734452817601,
      "f1": 0.7041999484668899,
      "f1_threshold": 5.604035892176407,
      "precision": 0.6880664652567976,
      "recall": 0.7211081794195251
    },
    "max": {
      "accuracy": 0.87411336949395,
      "ap": 0.7743685712199606,
      "f1": 0.7135678391959799
    }
  }
}