{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8787625916433213,
      "accuracy_threshold": 0.7509967236535605,
      "ap": 0.7877789813046774,
      "f1": 0.7195753495598135,
      "f1_threshold": 0.7224510771217942,
      "precision": 0.7064056939501779,
      "recall": 0.733245382585752
    },
    "dot": {
      "accuracy": 0.8567085891398939,
      "accuracy_threshold": 0.32370989856546917,
      "ap": 0.7198135620018316,
      "f1": 0.6706573040174975,
      "f1_threshold": 0.2920652744746768,
      "precision": 0.594853992240147,
      "recall": 0.7686015831134565
    },
    "euclidean": {
      "accuracy": 0.8769744292781785,
      "accuracy_threshold": 0.45796993360952454,
      "ap": 0.7860109038748577,
      "f1": 0.7219811079908093,
      "f1_threshold": 0.488619125304232,
      "precision": 0.6993076162215628,
      "recall": 0.7461741424802111
    },
    "evaluation_time": 1.59,
    "manhattan": {
      "accuracy": 0.876914823866007,
      "accuracy_threshold": 5.59505864649847,
      "ap": 0.7866407047120536,
      "f1": 0.7219822109275731,
      "f1_threshold": 5.9812918412687,
      "precision": 0.6963235294117647,
      "recall": 0.7496042216358839
    },
    "max": {
      "accuracy": 0.8787625916433213,
      "ap": 0.7877789813046774,
      "f1": 0.7219822109275731
    }
  }
}