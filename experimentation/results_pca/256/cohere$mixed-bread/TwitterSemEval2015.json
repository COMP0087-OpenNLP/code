{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.876914823866007,
      "accuracy_threshold": 0.7640787600233729,
      "ap": 0.7802059365162689,
      "f1": 0.7146488294314383,
      "f1_threshold": 0.7405095636021748,
      "precision": 0.7248303934871099,
      "recall": 0.7047493403693932
    },
    "dot": {
      "accuracy": 0.8496751505036657,
      "accuracy_threshold": 0.36785218668831215,
      "ap": 0.7024788756085895,
      "f1": 0.6603992571959145,
      "f1_threshold": 0.326329585609908,
      "precision": 0.5895151263986739,
      "recall": 0.7506596306068601
    },
    "euclidean": {
      "accuracy": 0.87494784526435,
      "accuracy_threshold": 0.47247731354257394,
      "ap": 0.7751870013584513,
      "f1": 0.7116564417177915,
      "f1_threshold": 0.5135048214403455,
      "precision": 0.6771503454848702,
      "recall": 0.749868073878628
    },
    "evaluation_time": 0.62,
    "manhattan": {
      "accuracy": 0.8739345532574357,
      "accuracy_threshold": 5.673505279162597,
      "ap": 0.7764147411942087,
      "f1": 0.7132499999999999,
      "f1_threshold": 6.254727695780166,
      "precision": 0.6776722090261282,
      "recall": 0.7527704485488127
    },
    "max": {
      "accuracy": 0.876914823866007,
      "ap": 0.7802059365162689,
      "f1": 0.7146488294314383
    }
  }
}