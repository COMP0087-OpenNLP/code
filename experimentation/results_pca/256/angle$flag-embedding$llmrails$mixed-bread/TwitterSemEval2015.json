{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8766764022173213,
      "accuracy_threshold": 0.7360663963172571,
      "ap": 0.786360855848269,
      "f1": 0.7203898050974512,
      "f1_threshold": 0.6961479656735554,
      "precision": 0.6841480778357855,
      "recall": 0.7606860158311346
    },
    "dot": {
      "accuracy": 0.8580795136198367,
      "accuracy_threshold": 0.40182082176218387,
      "ap": 0.7311592760538669,
      "f1": 0.6759503199096725,
      "f1_threshold": 0.3739287854530702,
      "precision": 0.6443434585027505,
      "recall": 0.7108179419525066
    },
    "euclidean": {
      "accuracy": 0.8759015318590928,
      "accuracy_threshold": 0.5376145804340433,
      "ap": 0.7873880881637135,
      "f1": 0.7180210202512176,
      "f1_threshold": 0.5639190005908309,
      "precision": 0.6981555333998006,
      "recall": 0.7390501319261213
    },
    "evaluation_time": 0.97,
    "manhattan": {
      "accuracy": 0.8767956130416642,
      "accuracy_threshold": 6.44665413460943,
      "ap": 0.7846016226490291,
      "f1": 0.7181038830055473,
      "f1_threshold": 6.9342160455008175,
      "precision": 0.6875905359729599,
      "recall": 0.7514511873350923
    },
    "max": {
      "accuracy": 0.8767956130416642,
      "ap": 0.7873880881637135,
      "f1": 0.7203898050974512
    }
  }
}