{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8778685104607499,
      "accuracy_threshold": 0.7440581376023103,
      "ap": 0.7884500848668062,
      "f1": 0.7196735501422036,
      "f1_threshold": 0.6946649735317013,
      "precision": 0.6772166627879916,
      "recall": 0.7678100263852242
    },
    "dot": {
      "accuracy": 0.8601060976336652,
      "accuracy_threshold": 0.24493006783793164,
      "ap": 0.7318256684524969,
      "f1": 0.677063993068449,
      "f1_threshold": 0.22959859064952964,
      "precision": 0.6376777803683842,
      "recall": 0.7216358839050132
    },
    "euclidean": {
      "accuracy": 0.8750670560886928,
      "accuracy_threshold": 0.4148314005073527,
      "ap": 0.786667315271368,
      "f1": 0.7173720783322804,
      "f1_threshold": 0.44435273101360073,
      "precision": 0.6882424242424242,
      "recall": 0.7490765171503958
    },
    "evaluation_time": 1.24,
    "manhattan": {
      "accuracy": 0.8752458723252071,
      "accuracy_threshold": 5.147915875034705,
      "ap": 0.7852295182237489,
      "f1": 0.7160871226595338,
      "f1_threshold": 5.416821888958189,
      "precision": 0.6921940408766314,
      "recall": 0.741688654353562
    },
    "max": {
      "accuracy": 0.8778685104607499,
      "ap": 0.7884500848668062,
      "f1": 0.7196735501422036
    }
  }
}