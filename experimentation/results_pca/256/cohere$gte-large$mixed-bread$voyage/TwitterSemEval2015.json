{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8763187697442928,
      "accuracy_threshold": 0.7707870158131261,
      "ap": 0.7795834228387055,
      "f1": 0.7152435167615434,
      "f1_threshold": 0.7327645743039525,
      "precision": 0.6869987849331713,
      "recall": 0.745910290237467
    },
    "dot": {
      "accuracy": 0.8460392203612088,
      "accuracy_threshold": 0.24111738077484146,
      "ap": 0.686428303054759,
      "f1": 0.6511852926947267,
      "f1_threshold": 0.21836764887297497,
      "precision": 0.6011612326931666,
      "recall": 0.7102902374670185
    },
    "euclidean": {
      "accuracy": 0.8733981045478929,
      "accuracy_threshold": 0.375468105989148,
      "ap": 0.7731639229084011,
      "f1": 0.7114745719396882,
      "f1_threshold": 0.39939988891856687,
      "precision": 0.6897918731417245,
      "recall": 0.7345646437994723
    },
    "evaluation_time": 1.17,
    "manhattan": {
      "accuracy": 0.8737557370209215,
      "accuracy_threshold": 4.535080153482202,
      "ap": 0.7751605958233125,
      "f1": 0.7133171293335039,
      "f1_threshold": 4.8743447737161585,
      "precision": 0.692326794139558,
      "recall": 0.7356200527704485
    },
    "max": {
      "accuracy": 0.8763187697442928,
      "ap": 0.7795834228387055,
      "f1": 0.7152435167615434
    }
  }
}