{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8778685104607499,
      "accuracy_threshold": 0.7523756518331809,
      "ap": 0.7854418832811737,
      "f1": 0.7180831149382254,
      "f1_threshold": 0.7098707056141504,
      "precision": 0.6812692398768648,
      "recall": 0.7591029023746702
    },
    "dot": {
      "accuracy": 0.8537879239434941,
      "accuracy_threshold": 0.2568326471129849,
      "ap": 0.7108804517320336,
      "f1": 0.6694946067143377,
      "f1_threshold": 0.23510334230115518,
      "precision": 0.6191436897556601,
      "recall": 0.7287598944591029
    },
    "euclidean": {
      "accuracy": 0.8748882398521786,
      "accuracy_threshold": 0.40835175884668035,
      "ap": 0.7799575075410062,
      "f1": 0.7151207115628971,
      "f1_threshold": 0.4355779097345022,
      "precision": 0.6897058823529412,
      "recall": 0.7424802110817942
    },
    "evaluation_time": 1.57,
    "manhattan": {
      "accuracy": 0.8747690290278357,
      "accuracy_threshold": 4.931860080285339,
      "ap": 0.7817328238455153,
      "f1": 0.7174725983236622,
      "f1_threshold": 5.287149187416733,
      "precision": 0.7016393442622951,
      "recall": 0.7340369393139842
    },
    "max": {
      "accuracy": 0.8778685104607499,
      "ap": 0.7854418832811737,
      "f1": 0.7180831149382254
    }
  }
}