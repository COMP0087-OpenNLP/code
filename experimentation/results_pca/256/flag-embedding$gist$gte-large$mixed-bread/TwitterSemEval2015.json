{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.876914823866007,
      "accuracy_threshold": 0.7516111777012449,
      "ap": 0.7818812234265696,
      "f1": 0.7163156559248922,
      "f1_threshold": 0.7176909361942201,
      "precision": 0.6898826979472141,
      "recall": 0.7448548812664908
    },
    "dot": {
      "accuracy": 0.8580199082076653,
      "accuracy_threshold": 0.36592206356724344,
      "ap": 0.7283839529715473,
      "f1": 0.6692800209068338,
      "f1_threshold": 0.33995708525642726,
      "precision": 0.6629562516179135,
      "recall": 0.6757255936675461
    },
    "euclidean": {
      "accuracy": 0.8761995589199499,
      "accuracy_threshold": 0.47356924302626846,
      "ap": 0.7837171572419646,
      "f1": 0.7188264058679706,
      "f1_threshold": 0.5100733946176725,
      "precision": 0.7015825169555389,
      "recall": 0.7369393139841689
    },
    "evaluation_time": 0.97,
    "manhattan": {
      "accuracy": 0.8739941586696072,
      "accuracy_threshold": 5.903573511905941,
      "ap": 0.7813483833574101,
      "f1": 0.7184143222506395,
      "f1_threshold": 6.267622982565467,
      "precision": 0.6970223325062035,
      "recall": 0.7411609498680739
    },
    "max": {
      "accuracy": 0.876914823866007,
      "ap": 0.7837171572419646,
      "f1": 0.7188264058679706
    }
  }
}