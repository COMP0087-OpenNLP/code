{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8770340346903499,
      "accuracy_threshold": 0.754039645996985,
      "ap": 0.7837304137136633,
      "f1": 0.7177334732423925,
      "f1_threshold": 0.7249519786463277,
      "precision": 0.7136150234741784,
      "recall": 0.7218997361477573
    },
    "dot": {
      "accuracy": 0.857006616200751,
      "accuracy_threshold": 0.3052132995437898,
      "ap": 0.7270852265051091,
      "f1": 0.671432154502132,
      "f1_threshold": 0.2854718544894217,
      "precision": 0.6398183556405354,
      "recall": 0.7063324538258575
    },
    "euclidean": {
      "accuracy": 0.8754842939738928,
      "accuracy_threshold": 0.43680629084870226,
      "ap": 0.7842247086688877,
      "f1": 0.7193654990085923,
      "f1_threshold": 0.4674993694411795,
      "precision": 0.720794701986755,
      "recall": 0.7179419525065963
    },
    "evaluation_time": 1.86,
    "manhattan": {
      "accuracy": 0.87453060737915,
      "accuracy_threshold": 5.460617058621984,
      "ap": 0.7814019252628737,
      "f1": 0.7187656798795785,
      "f1_threshold": 5.892242303474933,
      "precision": 0.6850789096126255,
      "recall": 0.7559366754617414
    },
    "max": {
      "accuracy": 0.8770340346903499,
      "ap": 0.7842247086688877,
      "f1": 0.7193654990085923
    }
  }
}