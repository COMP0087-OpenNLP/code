{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8785241699946356,
      "accuracy_threshold": 0.7486499570339187,
      "ap": 0.7860028769512388,
      "f1": 0.7200620074925721,
      "f1_threshold": 0.7225922697311153,
      "precision": 0.7053910402429765,
      "recall": 0.7353562005277045
    },
    "dot": {
      "accuracy": 0.854205161828694,
      "accuracy_threshold": 0.3027756693085838,
      "ap": 0.7147404664390428,
      "f1": 0.6661174532187831,
      "f1_threshold": 0.2752128835215994,
      "precision": 0.6012322073507542,
      "recall": 0.7467018469656992
    },
    "euclidean": {
      "accuracy": 0.8766764022173213,
      "accuracy_threshold": 0.44085430916096235,
      "ap": 0.7841499715049457,
      "f1": 0.7188975373229552,
      "f1_threshold": 0.4713868116575721,
      "precision": 0.6960711638250556,
      "recall": 0.7432717678100264
    },
    "evaluation_time": 1.1,
    "manhattan": {
      "accuracy": 0.8768552184538356,
      "accuracy_threshold": 5.278063939754702,
      "ap": 0.7847641006077714,
      "f1": 0.719938136357778,
      "f1_threshold": 5.721152171325041,
      "precision": 0.7037037037037037,
      "recall": 0.7369393139841689
    },
    "max": {
      "accuracy": 0.8785241699946356,
      "ap": 0.7860028769512388,
      "f1": 0.7200620074925721
    }
  }
}