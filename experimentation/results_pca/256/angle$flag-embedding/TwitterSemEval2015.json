{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8768552184538356,
      "accuracy_threshold": 0.7413742276052931,
      "ap": 0.7855027998457828,
      "f1": 0.720498474059003,
      "f1_threshold": 0.7016008683707615,
      "precision": 0.6953853706431026,
      "recall": 0.7474934036939314
    },
    "dot": {
      "accuracy": 0.8583775406806938,
      "accuracy_threshold": 0.39810040335046193,
      "ap": 0.7295650414292993,
      "f1": 0.6749348877588988,
      "f1_threshold": 0.3676807448264787,
      "precision": 0.636789141118652,
      "recall": 0.7179419525065963
    },
    "euclidean": {
      "accuracy": 0.87578232103475,
      "accuracy_threshold": 0.5231702895675268,
      "ap": 0.7860678698989421,
      "f1": 0.7185909980430528,
      "f1_threshold": 0.5551584255775273,
      "precision": 0.7107096774193549,
      "recall": 0.7266490765171504
    },
    "evaluation_time": 0.53,
    "manhattan": {
      "accuracy": 0.8765571913929785,
      "accuracy_threshold": 6.491853618860406,
      "ap": 0.78306457736256,
      "f1": 0.7173508619620488,
      "f1_threshold": 6.950075012895456,
      "precision": 0.6768078633278727,
      "recall": 0.7630606860158311
    },
    "max": {
      "accuracy": 0.8768552184538356,
      "ap": 0.7860678698989421,
      "f1": 0.720498474059003
    }
  }
}