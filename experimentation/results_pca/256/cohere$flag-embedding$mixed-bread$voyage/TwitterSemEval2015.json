{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8788221970554927,
      "accuracy_threshold": 0.7572569821677556,
      "ap": 0.78699851265681,
      "f1": 0.7181292431481016,
      "f1_threshold": 0.7212657171968248,
      "precision": 0.6858789625360231,
      "recall": 0.7535620052770449
    },
    "dot": {
      "accuracy": 0.8561125350181796,
      "accuracy_threshold": 0.2838650469255065,
      "ap": 0.7140763360589834,
      "f1": 0.6678260869565217,
      "f1_threshold": 0.2587045251351193,
      "precision": 0.5956566701137539,
      "recall": 0.7598944591029023
    },
    "euclidean": {
      "accuracy": 0.8756631102104071,
      "accuracy_threshold": 0.4186092079052608,
      "ap": 0.7828146139413729,
      "f1": 0.7187858691493433,
      "f1_threshold": 0.45174398708859576,
      "precision": 0.6956307084670452,
      "recall": 0.7435356200527704
    },
    "evaluation_time": 1.17,
    "manhattan": {
      "accuracy": 0.8764975859808071,
      "accuracy_threshold": 5.05374423158786,
      "ap": 0.7853632387511329,
      "f1": 0.7199299824956239,
      "f1_threshold": 5.56240212617308,
      "precision": 0.6841730038022814,
      "recall": 0.7596306068601583
    },
    "max": {
      "accuracy": 0.8788221970554927,
      "ap": 0.78699851265681,
      "f1": 0.7199299824956239
    }
  }
}