{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8757227156225785,
      "accuracy_threshold": 0.7450300016677314,
      "ap": 0.7826779392436822,
      "f1": 0.716209476309227,
      "f1_threshold": 0.7100664617532015,
      "precision": 0.6789598108747045,
      "recall": 0.7577836411609499
    },
    "dot": {
      "accuracy": 0.8532514752339513,
      "accuracy_threshold": 0.19525181499044286,
      "ap": 0.7107873934342468,
      "f1": 0.6643440653531956,
      "f1_threshold": 0.17903060511298466,
      "precision": 0.609836788707543,
      "recall": 0.7295514511873351
    },
    "euclidean": {
      "accuracy": 0.8738749478452643,
      "accuracy_threshold": 0.361472239779874,
      "ap": 0.779513107055486,
      "f1": 0.7124796595318563,
      "f1_threshold": 0.3845441511686526,
      "precision": 0.6777804239104549,
      "recall": 0.7509234828496042
    },
    "evaluation_time": 0.87,
    "manhattan": {
      "accuracy": 0.8743517911426357,
      "accuracy_threshold": 4.374447240968642,
      "ap": 0.7786136091822052,
      "f1": 0.7147286821705426,
      "f1_threshold": 4.644357464686079,
      "precision": 0.7002531645569621,
      "recall": 0.7298153034300792
    },
    "max": {
      "accuracy": 0.8757227156225785,
      "ap": 0.7826779392436822,
      "f1": 0.716209476309227
    }
  }
}