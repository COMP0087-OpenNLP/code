{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8769744292781785,
      "accuracy_threshold": 0.7515914195198606,
      "ap": 0.7848617048453153,
      "f1": 0.718769696205723,
      "f1_threshold": 0.7087879861448882,
      "precision": 0.6881486845281197,
      "recall": 0.7522427440633246
    },
    "dot": {
      "accuracy": 0.8566489837277225,
      "accuracy_threshold": 0.302621229692418,
      "ap": 0.7251579262926563,
      "f1": 0.66869918699187,
      "f1_threshold": 0.28352438158701665,
      "precision": 0.6447819696227339,
      "recall": 0.6944591029023747
    },
    "euclidean": {
      "accuracy": 0.8754246885617214,
      "accuracy_threshold": 0.44298054057707215,
      "ap": 0.7855960196622566,
      "f1": 0.7203694202154952,
      "f1_threshold": 0.47773657523763324,
      "precision": 0.7009485771342986,
      "recall": 0.7408970976253298
    },
    "evaluation_time": 1.45,
    "manhattan": {
      "accuracy": 0.8747690290278357,
      "accuracy_threshold": 5.466625707092632,
      "ap": 0.7820044924768759,
      "f1": 0.7157283514264076,
      "f1_threshold": 5.87781285000567,
      "precision": 0.686108422071636,
      "recall": 0.7480211081794196
    },
    "max": {
      "accuracy": 0.8769744292781785,
      "ap": 0.7855960196622566,
      "f1": 0.7203694202154952
    }
  }
}