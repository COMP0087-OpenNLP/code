{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8760803480956071,
      "accuracy_threshold": 0.7482870628008917,
      "ap": 0.7799288062000663,
      "f1": 0.7159201557935736,
      "f1_threshold": 0.7041950875271324,
      "precision": 0.6644826028016267,
      "recall": 0.7759894459102903
    },
    "dot": {
      "accuracy": 0.8499731775645228,
      "accuracy_threshold": 0.3571466176653261,
      "ap": 0.7032366985268187,
      "f1": 0.6669820245979187,
      "f1_threshold": 0.3236961804344368,
      "precision": 0.6043720531504501,
      "recall": 0.7440633245382586
    },
    "euclidean": {
      "accuracy": 0.8740537640817786,
      "accuracy_threshold": 0.4668210148764419,
      "ap": 0.7731132143841072,
      "f1": 0.7106558467473725,
      "f1_threshold": 0.4981168898895151,
      "precision": 0.716662194794741,
      "recall": 0.7047493403693932
    },
    "evaluation_time": 2.26,
    "manhattan": {
      "accuracy": 0.8729212612505215,
      "accuracy_threshold": 5.817517616209801,
      "ap": 0.7737673006754533,
      "f1": 0.7124951544127148,
      "f1_threshold": 6.2019947396219335,
      "precision": 0.69815143074196,
      "recall": 0.7274406332453826
    },
    "max": {
      "accuracy": 0.8760803480956071,
      "ap": 0.7799288062000663,
      "f1": 0.7159201557935736
    }
  }
}