{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8783453537581213,
      "accuracy_threshold": 0.761240752649673,
      "ap": 0.7846079226357225,
      "f1": 0.7167502752967086,
      "f1_threshold": 0.7183826103087314,
      "precision": 0.6682637462924937,
      "recall": 0.7728232189973615
    },
    "dot": {
      "accuracy": 0.8513441020444656,
      "accuracy_threshold": 0.30192772346687463,
      "ap": 0.7066145066204426,
      "f1": 0.6611753134988936,
      "f1_threshold": 0.2749404586381504,
      "precision": 0.6190147329650092,
      "recall": 0.7094986807387863
    },
    "euclidean": {
      "accuracy": 0.8760803480956071,
      "accuracy_threshold": 0.4152937058137447,
      "ap": 0.781216184487773,
      "f1": 0.7175807278318812,
      "f1_threshold": 0.4518996643851261,
      "precision": 0.6975585450921774,
      "recall": 0.7387862796833773
    },
    "evaluation_time": 1.18,
    "manhattan": {
      "accuracy": 0.8759611372712642,
      "accuracy_threshold": 5.001889679301742,
      "ap": 0.7820732060913682,
      "f1": 0.7185443283004258,
      "f1_threshold": 5.4878671175384905,
      "precision": 0.7032078807779742,
      "recall": 0.7345646437994723
    },
    "max": {
      "accuracy": 0.8783453537581213,
      "ap": 0.7846079226357225,
      "f1": 0.7185443283004258
    }
  }
}