{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8769744292781785,
      "accuracy_threshold": 0.7398015581425149,
      "ap": 0.7856528665593286,
      "f1": 0.7185213708124759,
      "f1_threshold": 0.7069907138637481,
      "precision": 0.6995751062234441,
      "recall": 0.7385224274406332
    },
    "dot": {
      "accuracy": 0.857841091971151,
      "accuracy_threshold": 0.3316412166201371,
      "ap": 0.7296122562867796,
      "f1": 0.6749840865690643,
      "f1_threshold": 0.3124281262796328,
      "precision": 0.6521525215252153,
      "recall": 0.6994722955145118
    },
    "euclidean": {
      "accuracy": 0.8757227156225785,
      "accuracy_threshold": 0.4772419143682309,
      "ap": 0.7860603538175962,
      "f1": 0.717266094969922,
      "f1_threshold": 0.5093940495491198,
      "precision": 0.6964951528709918,
      "recall": 0.7393139841688654
    },
    "evaluation_time": 0.74,
    "manhattan": {
      "accuracy": 0.8750670560886928,
      "accuracy_threshold": 5.877891275547833,
      "ap": 0.7827086834050594,
      "f1": 0.7172680412371134,
      "f1_threshold": 6.203805465234946,
      "precision": 0.701007556675063,
      "recall": 0.7343007915567282
    },
    "max": {
      "accuracy": 0.8769744292781785,
      "ap": 0.7860603538175962,
      "f1": 0.7185213708124759
    }
  }
}