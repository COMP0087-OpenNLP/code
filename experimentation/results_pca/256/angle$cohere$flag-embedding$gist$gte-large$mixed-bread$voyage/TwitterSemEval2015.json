{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8778089050485784,
      "accuracy_threshold": 0.7581901166755222,
      "ap": 0.7844036564568638,
      "f1": 0.7177470506152481,
      "f1_threshold": 0.7245580616210016,
      "precision": 0.6911800635230883,
      "recall": 0.7464379947229551
    },
    "dot": {
      "accuracy": 0.8556356917208082,
      "accuracy_threshold": 0.32002292033946445,
      "ap": 0.7218247636449633,
      "f1": 0.6670844823263976,
      "f1_threshold": 0.30021840213677803,
      "precision": 0.6353868194842407,
      "recall": 0.7021108179419525
    },
    "euclidean": {
      "accuracy": 0.876914823866007,
      "accuracy_threshold": 0.4442566768149844,
      "ap": 0.7843751156848916,
      "f1": 0.7215335463258785,
      "f1_threshold": 0.4768000157227025,
      "precision": 0.6996282527881041,
      "recall": 0.7448548812664908
    },
    "evaluation_time": 2.71,
    "manhattan": {
      "accuracy": 0.8767360076294928,
      "accuracy_threshold": 5.46982848256948,
      "ap": 0.7836359500426885,
      "f1": 0.7215189873417722,
      "f1_threshold": 5.8535706438347574,
      "precision": 0.6934306569343066,
      "recall": 0.7519788918205804
    },
    "max": {
      "accuracy": 0.8778089050485784,
      "ap": 0.7844036564568638,
      "f1": 0.7215335463258785
    }
  }
}