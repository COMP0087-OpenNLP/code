{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8761399535077785,
      "accuracy_threshold": 0.7455141560418517,
      "ap": 0.7825617707531414,
      "f1": 0.7166324435318275,
      "f1_threshold": 0.7117333812840436,
      "precision": 0.6976511744127936,
      "recall": 0.7366754617414248
    },
    "dot": {
      "accuracy": 0.8531918698217799,
      "accuracy_threshold": 0.3387988319081884,
      "ap": 0.7099065986420265,
      "f1": 0.6674388674388675,
      "f1_threshold": 0.32084737787078194,
      "precision": 0.6515075376884422,
      "recall": 0.6841688654353562
    },
    "euclidean": {
      "accuracy": 0.8742325803182929,
      "accuracy_threshold": 0.4748381962302717,
      "ap": 0.7760506497588016,
      "f1": 0.7106796116504854,
      "f1_threshold": 0.5068634417407775,
      "precision": 0.6975857687420585,
      "recall": 0.7242744063324539
    },
    "evaluation_time": 0.92,
    "manhattan": {
      "accuracy": 0.8747094236156643,
      "accuracy_threshold": 5.800045313408761,
      "ap": 0.7766145252965613,
      "f1": 0.7113376429636995,
      "f1_threshold": 6.337420981963553,
      "precision": 0.6725434884814292,
      "recall": 0.7548812664907651
    },
    "max": {
      "accuracy": 0.8761399535077785,
      "ap": 0.7825617707531414,
      "f1": 0.7166324435318275
    }
  }
}