{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8781069321094356,
      "accuracy_threshold": 0.7569004179881584,
      "ap": 0.7846797218743976,
      "f1": 0.7179941750031659,
      "f1_threshold": 0.7227577125033604,
      "precision": 0.6902848794740687,
      "recall": 0.7480211081794196
    },
    "dot": {
      "accuracy": 0.8555164808964654,
      "accuracy_threshold": 0.32026076173394236,
      "ap": 0.7223169411647112,
      "f1": 0.6678966789667896,
      "f1_threshold": 0.29897819416586435,
      "precision": 0.6255760368663594,
      "recall": 0.716358839050132
    },
    "euclidean": {
      "accuracy": 0.8766167968051499,
      "accuracy_threshold": 0.4471654626197771,
      "ap": 0.7850130663950267,
      "f1": 0.7215645908389088,
      "f1_threshold": 0.47758602150952,
      "precision": 0.7041687594173782,
      "recall": 0.7398416886543535
    },
    "evaluation_time": 2.2,
    "manhattan": {
      "accuracy": 0.8775108779877213,
      "accuracy_threshold": 5.449128542839166,
      "ap": 0.7842607067436078,
      "f1": 0.7205472510767672,
      "f1_threshold": 5.8799517420075755,
      "precision": 0.6929824561403509,
      "recall": 0.7503957783641161
    },
    "max": {
      "accuracy": 0.8781069321094356,
      "ap": 0.7850130663950267,
      "f1": 0.7215645908389088
    }
  }
}