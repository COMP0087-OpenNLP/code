{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8766167968051499,
      "accuracy_threshold": 0.7417535643572662,
      "ap": 0.7832755068158123,
      "f1": 0.7179162978884814,
      "f1_threshold": 0.7085418792813548,
      "precision": 0.6892449623695072,
      "recall": 0.7490765171503958
    },
    "dot": {
      "accuracy": 0.8553972700721225,
      "accuracy_threshold": 0.34785606364854543,
      "ap": 0.7223565450753853,
      "f1": 0.6664154734991209,
      "f1_threshold": 0.3250616287627094,
      "precision": 0.6359060402684564,
      "recall": 0.7
    },
    "euclidean": {
      "accuracy": 0.8760803480956071,
      "accuracy_threshold": 0.48825046622576873,
      "ap": 0.7852946173288045,
      "f1": 0.7192551403077719,
      "f1_threshold": 0.5116223568551396,
      "precision": 0.705300532589399,
      "recall": 0.7337730870712401
    },
    "evaluation_time": 0.95,
    "manhattan": {
      "accuracy": 0.8754246885617214,
      "accuracy_threshold": 5.896151903195915,
      "ap": 0.7819804785414562,
      "f1": 0.7158738366080662,
      "f1_threshold": 6.258354594721093,
      "precision": 0.7017232640648758,
      "recall": 0.7306068601583113
    },
    "max": {
      "accuracy": 0.8766167968051499,
      "ap": 0.7852946173288045,
      "f1": 0.7192551403077719
    }
  }
}