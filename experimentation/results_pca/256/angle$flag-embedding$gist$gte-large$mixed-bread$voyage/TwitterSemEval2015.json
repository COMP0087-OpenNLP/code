{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8763783751564642,
      "accuracy_threshold": 0.7648638345477856,
      "ap": 0.7811950246255833,
      "f1": 0.7159045460605252,
      "f1_threshold": 0.73663298740499,
      "precision": 0.7235246564268392,
      "recall": 0.7084432717678101
    },
    "dot": {
      "accuracy": 0.8557549025451511,
      "accuracy_threshold": 0.3158993847786149,
      "ap": 0.7229304141076855,
      "f1": 0.6650124069478908,
      "f1_threshold": 0.2914236507399901,
      "precision": 0.6276346604215457,
      "recall": 0.7071240105540897
    },
    "euclidean": {
      "accuracy": 0.87578232103475,
      "accuracy_threshold": 0.4402301994267877,
      "ap": 0.7823520693345731,
      "f1": 0.7188733877336141,
      "f1_threshold": 0.46653305889363583,
      "precision": 0.7171743697478992,
      "recall": 0.720580474934037
    },
    "evaluation_time": 1.86,
    "manhattan": {
      "accuracy": 0.8739941586696072,
      "accuracy_threshold": 5.492151683975103,
      "ap": 0.7797204533899846,
      "f1": 0.7161464733349717,
      "f1_threshold": 5.933773963807276,
      "precision": 0.6701931922723091,
      "recall": 0.7688654353562006
    },
    "max": {
      "accuracy": 0.8763783751564642,
      "ap": 0.7823520693345731,
      "f1": 0.7188733877336141
    }
  }
}