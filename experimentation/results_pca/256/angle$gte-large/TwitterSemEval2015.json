{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8748286344400071,
      "accuracy_threshold": 0.7505447887159686,
      "ap": 0.7752475012344038,
      "f1": 0.7141937974520655,
      "f1_threshold": 0.7247688297904142,
      "precision": 0.6970610399397137,
      "recall": 0.7321899736147758
    },
    "dot": {
      "accuracy": 0.8507480479227514,
      "accuracy_threshold": 0.29158246290976086,
      "ap": 0.7109627733303095,
      "f1": 0.656956303365143,
      "f1_threshold": 0.2709950700529281,
      "precision": 0.6267369429803545,
      "recall": 0.6902374670184697
    },
    "euclidean": {
      "accuracy": 0.8745902127913214,
      "accuracy_threshold": 0.4217129282610343,
      "ap": 0.77659563792272,
      "f1": 0.7148279021070542,
      "f1_threshold": 0.45184339094675885,
      "precision": 0.7091664502726565,
      "recall": 0.720580474934037
    },
    "evaluation_time": 0.53,
    "manhattan": {
      "accuracy": 0.87327889372355,
      "accuracy_threshold": 5.208610116432692,
      "ap": 0.7730451879477187,
      "f1": 0.7138687983758407,
      "f1_threshold": 5.632302801535227,
      "precision": 0.687606942067954,
      "recall": 0.7422163588390501
    },
    "max": {
      "accuracy": 0.8748286344400071,
      "ap": 0.77659563792272,
      "f1": 0.7148279021070542
    }
  }
}