{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.876914823866007,
      "accuracy_threshold": 0.7363033350459007,
      "ap": 0.7835307326106855,
      "f1": 0.7178763785586048,
      "f1_threshold": 0.7090036636593263,
      "precision": 0.6983532934131736,
      "recall": 0.7385224274406332
    },
    "dot": {
      "accuracy": 0.8545627943017226,
      "accuracy_threshold": 0.3382064857588049,
      "ap": 0.712682306393421,
      "f1": 0.670675537359263,
      "f1_threshold": 0.3198398227172003,
      "precision": 0.6510183805265772,
      "recall": 0.6915567282321899
    },
    "euclidean": {
      "accuracy": 0.8745902127913214,
      "accuracy_threshold": 0.4772411614988249,
      "ap": 0.776608829998567,
      "f1": 0.7128687690742624,
      "f1_threshold": 0.514113991252023,
      "precision": 0.6880216003927344,
      "recall": 0.7395778364116095
    },
    "evaluation_time": 0.94,
    "manhattan": {
      "accuracy": 0.8741729749061214,
      "accuracy_threshold": 5.915160779224923,
      "ap": 0.7785885062484944,
      "f1": 0.7153993610223641,
      "f1_threshold": 6.252989842820927,
      "precision": 0.6936802973977695,
      "recall": 0.7385224274406332
    },
    "max": {
      "accuracy": 0.876914823866007,
      "ap": 0.7835307326106855,
      "f1": 0.7178763785586048
    }
  }
}