{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8763783751564642,
      "accuracy_threshold": 0.7561736629955029,
      "ap": 0.7795404428293815,
      "f1": 0.7156935205715693,
      "f1_threshold": 0.708952942810045,
      "precision": 0.6712107208872459,
      "recall": 0.7664907651715039
    },
    "dot": {
      "accuracy": 0.8590332002145795,
      "accuracy_threshold": 0.37129609601884683,
      "ap": 0.7312851846686381,
      "f1": 0.6767088607594938,
      "f1_threshold": 0.3478005886998776,
      "precision": 0.6503649635036496,
      "recall": 0.7052770448548813
    },
    "euclidean": {
      "accuracy": 0.8767956130416642,
      "accuracy_threshold": 0.49364750192457807,
      "ap": 0.7809312018679829,
      "f1": 0.7159685863874345,
      "f1_threshold": 0.5131156207906704,
      "precision": 0.7103896103896103,
      "recall": 0.7216358839050132
    },
    "evaluation_time": 0.75,
    "manhattan": {
      "accuracy": 0.87411336949395,
      "accuracy_threshold": 6.006757104111635,
      "ap": 0.7773596393750528,
      "f1": 0.7158138935429823,
      "f1_threshold": 6.376639742656879,
      "precision": 0.6996724615772235,
      "recall": 0.7327176781002639
    },
    "max": {
      "accuracy": 0.8767956130416642,
      "ap": 0.7809312018679829,
      "f1": 0.7159685863874345
    }
  }
}