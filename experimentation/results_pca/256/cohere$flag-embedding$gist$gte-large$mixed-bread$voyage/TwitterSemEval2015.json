{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8776300888120642,
      "accuracy_threshold": 0.77127871331377,
      "ap": 0.7819335135236344,
      "f1": 0.7161641652277857,
      "f1_threshold": 0.7426613431071198,
      "precision": 0.7210484086654185,
      "recall": 0.7113456464379947
    },
    "dot": {
      "accuracy": 0.8499731775645228,
      "accuracy_threshold": 0.27378237416454376,
      "ap": 0.701046877714647,
      "f1": 0.6604091456077015,
      "f1_threshold": 0.24979166006286274,
      "precision": 0.6070796460176991,
      "recall": 0.7240105540897097
    },
    "euclidean": {
      "accuracy": 0.8751266615008643,
      "accuracy_threshold": 0.39499661831862315,
      "ap": 0.777871604257827,
      "f1": 0.7156416590820439,
      "f1_threshold": 0.42901520834342466,
      "precision": 0.7054601384260446,
      "recall": 0.7261213720316623
    },
    "evaluation_time": 2.02,
    "manhattan": {
      "accuracy": 0.8751266615008643,
      "accuracy_threshold": 4.883513508526255,
      "ap": 0.7793974670862892,
      "f1": 0.7169907881269192,
      "f1_threshold": 5.3039516210873785,
      "precision": 0.6959761549925484,
      "recall": 0.7393139841688654
    },
    "max": {
      "accuracy": 0.8776300888120642,
      "ap": 0.7819335135236344,
      "f1": 0.7169907881269192
    }
  }
}