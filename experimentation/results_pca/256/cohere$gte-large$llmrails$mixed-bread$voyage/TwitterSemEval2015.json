{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8780473266972642,
      "accuracy_threshold": 0.7557012681581705,
      "ap": 0.7844954825887462,
      "f1": 0.7171428571428572,
      "f1_threshold": 0.72604622389708,
      "precision": 0.7061381074168798,
      "recall": 0.7284960422163589
    },
    "dot": {
      "accuracy": 0.8531918698217799,
      "accuracy_threshold": 0.26327782613347284,
      "ap": 0.7060462791187265,
      "f1": 0.6647985989492119,
      "f1_threshold": 0.23779468837464657,
      "precision": 0.5962303664921466,
      "recall": 0.7511873350923483
    },
    "euclidean": {
      "accuracy": 0.87494784526435,
      "accuracy_threshold": 0.4059474489084446,
      "ap": 0.7805016352218725,
      "f1": 0.7171355498721227,
      "f1_threshold": 0.4363050250813445,
      "precision": 0.6957816377171215,
      "recall": 0.7398416886543535
    },
    "evaluation_time": 1.63,
    "manhattan": {
      "accuracy": 0.8756631102104071,
      "accuracy_threshold": 4.869745295912611,
      "ap": 0.7822119289096788,
      "f1": 0.7184805697863301,
      "f1_threshold": 5.392481029408552,
      "precision": 0.682411583194873,
      "recall": 0.758575197889182
    },
    "max": {
      "accuracy": 0.8780473266972642,
      "ap": 0.7844954825887462,
      "f1": 0.7184805697863301
    }
  }
}