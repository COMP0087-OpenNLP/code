{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8774512725755499,
      "accuracy_threshold": 0.7595294179814673,
      "ap": 0.7830514470141158,
      "f1": 0.7170905257609699,
      "f1_threshold": 0.7338063381420799,
      "precision": 0.7162411160831798,
      "recall": 0.7179419525065963
    },
    "dot": {
      "accuracy": 0.8514037074566371,
      "accuracy_threshold": 0.26636460229394204,
      "ap": 0.7051069487086978,
      "f1": 0.6660918832368519,
      "f1_threshold": 0.24626566791500945,
      "precision": 0.6246246246246246,
      "recall": 0.7134564643799473
    },
    "euclidean": {
      "accuracy": 0.8751266615008643,
      "accuracy_threshold": 0.40382332526193615,
      "ap": 0.7784063031322824,
      "f1": 0.7159383033419023,
      "f1_threshold": 0.4343863160283142,
      "precision": 0.6979949874686717,
      "recall": 0.7348284960422163
    },
    "evaluation_time": 1.84,
    "manhattan": {
      "accuracy": 0.8756631102104071,
      "accuracy_threshold": 4.900397369922942,
      "ap": 0.7796465811545271,
      "f1": 0.7159301893798737,
      "f1_threshold": 5.429986540396173,
      "precision": 0.6742830496619259,
      "recall": 0.7630606860158311
    },
    "max": {
      "accuracy": 0.8774512725755499,
      "ap": 0.7830514470141158,
      "f1": 0.7170905257609699
    }
  }
}