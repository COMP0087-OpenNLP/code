{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8787029862311498,
      "accuracy_threshold": 0.754420907964755,
      "ap": 0.7883195013273201,
      "f1": 0.7210795231232805,
      "f1_threshold": 0.721515880209407,
      "precision": 0.7161072079104867,
      "recall": 0.7261213720316623
    },
    "dot": {
      "accuracy": 0.8580795136198367,
      "accuracy_threshold": 0.35859151036942705,
      "ap": 0.7265277758332711,
      "f1": 0.6719489120151372,
      "f1_threshold": 0.3264588201215045,
      "precision": 0.6088726960994427,
      "recall": 0.7496042216358839
    },
    "euclidean": {
      "accuracy": 0.8776300888120642,
      "accuracy_threshold": 0.4798797337999048,
      "ap": 0.7872992290534592,
      "f1": 0.7212530243219153,
      "f1_threshold": 0.520160715129327,
      "precision": 0.6970219049963081,
      "recall": 0.7472295514511873
    },
    "evaluation_time": 1.38,
    "manhattan": {
      "accuracy": 0.8773916671633785,
      "accuracy_threshold": 5.98582318865496,
      "ap": 0.7874437282869213,
      "f1": 0.7230011367942403,
      "f1_threshold": 6.3811381800165465,
      "precision": 0.6934819481463533,
      "recall": 0.7551451187335092
    },
    "max": {
      "accuracy": 0.8787029862311498,
      "ap": 0.7883195013273201,
      "f1": 0.7230011367942403
    }
  }
}