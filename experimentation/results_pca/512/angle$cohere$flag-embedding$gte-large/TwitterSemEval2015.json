{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8783453537581213,
      "accuracy_threshold": 0.7468833908261403,
      "ap": 0.7880392854850019,
      "f1": 0.7203055378739657,
      "f1_threshold": 0.709168570765977,
      "precision": 0.6959409594095941,
      "recall": 0.7464379947229551
    },
    "dot": {
      "accuracy": 0.8585563569172081,
      "accuracy_threshold": 0.3761422282313896,
      "ap": 0.7356550356212863,
      "f1": 0.6780124223602485,
      "f1_threshold": 0.3475254470093867,
      "precision": 0.6406103286384977,
      "recall": 0.7200527704485488
    },
    "euclidean": {
      "accuracy": 0.8787029862311498,
      "accuracy_threshold": 0.5035544424780343,
      "ap": 0.7913395501547845,
      "f1": 0.7221793883320483,
      "f1_threshold": 0.5335534708102868,
      "precision": 0.7039078156312625,
      "recall": 0.741424802110818
    },
    "evaluation_time": 1.21,
    "manhattan": {
      "accuracy": 0.8754246885617214,
      "accuracy_threshold": 8.367914637790172,
      "ap": 0.7827810389216522,
      "f1": 0.7146032161066805,
      "f1_threshold": 8.845995388552886,
      "precision": 0.708214563358383,
      "recall": 0.7211081794195251
    },
    "max": {
      "accuracy": 0.8787029862311498,
      "ap": 0.7913395501547845,
      "f1": 0.7221793883320483
    }
  }
}