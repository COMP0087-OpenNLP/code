{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8730404720748643,
      "accuracy_threshold": 0.7577781564853207,
      "ap": 0.777077385246155,
      "f1": 0.7099895397489541,
      "f1_threshold": 0.729378760593871,
      "precision": 0.7037325038880249,
      "recall": 0.716358839050132
    },
    "dot": {
      "accuracy": 0.8528342373487513,
      "accuracy_threshold": 0.3658155121593699,
      "ap": 0.7161310932316677,
      "f1": 0.6574027286508337,
      "f1_threshold": 0.33572556454004804,
      "precision": 0.6306349975763451,
      "recall": 0.6865435356200528
    },
    "euclidean": {
      "accuracy": 0.8743517911426357,
      "accuracy_threshold": 0.48239940723667607,
      "ap": 0.7816490023821658,
      "f1": 0.7134268537074149,
      "f1_threshold": 0.5141032836103067,
      "precision": 0.6790653314258465,
      "recall": 0.7514511873350923
    },
    "evaluation_time": 0.63,
    "manhattan": {
      "accuracy": 0.866960720033379,
      "accuracy_threshold": 7.736867237354342,
      "ap": 0.7628360783295507,
      "f1": 0.698606952219763,
      "f1_threshold": 8.1911420054228,
      "precision": 0.6895399640195322,
      "recall": 0.7079155672823219
    },
    "max": {
      "accuracy": 0.8743517911426357,
      "ap": 0.7816490023821658,
      "f1": 0.7134268537074149
    }
  }
}