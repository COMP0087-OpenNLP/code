{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8787029862311498,
      "accuracy_threshold": 0.7468145425209083,
      "ap": 0.7903406815197384,
      "f1": 0.7209533267130089,
      "f1_threshold": 0.6978799660793777,
      "precision": 0.680731364275668,
      "recall": 0.7662269129287599
    },
    "dot": {
      "accuracy": 0.8587351731537224,
      "accuracy_threshold": 0.44900157667098684,
      "ap": 0.7366982726710812,
      "f1": 0.6788055353241078,
      "f1_threshold": 0.4142023935349306,
      "precision": 0.6285971223021583,
      "recall": 0.7377308707124011
    },
    "euclidean": {
      "accuracy": 0.8798354890624068,
      "accuracy_threshold": 0.5512846428080673,
      "ap": 0.7948936988330266,
      "f1": 0.7268756423432682,
      "f1_threshold": 0.5912487354783292,
      "precision": 0.7083124687030545,
      "recall": 0.7464379947229551
    },
    "evaluation_time": 1.2,
    "manhattan": {
      "accuracy": 0.8763187697442928,
      "accuracy_threshold": 9.257426403350205,
      "ap": 0.7848956678273253,
      "f1": 0.716917047681254,
      "f1_threshold": 9.723212662260808,
      "precision": 0.7099611901681759,
      "recall": 0.7240105540897097
    },
    "max": {
      "accuracy": 0.8798354890624068,
      "ap": 0.7948936988330266,
      "f1": 0.7268756423432682
    }
  }
}