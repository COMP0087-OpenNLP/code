{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8756631102104071,
      "accuracy_threshold": 0.7650881988940449,
      "ap": 0.7847048004184176,
      "f1": 0.7184210526315791,
      "f1_threshold": 0.7315679595506176,
      "precision": 0.7165354330708661,
      "recall": 0.7203166226912929
    },
    "dot": {
      "accuracy": 0.8584967515050367,
      "accuracy_threshold": 0.35625775856572195,
      "ap": 0.7289906355822523,
      "f1": 0.6751729072263296,
      "f1_threshold": 0.3211828585941008,
      "precision": 0.615970409051349,
      "recall": 0.7469656992084432
    },
    "euclidean": {
      "accuracy": 0.8768552184538356,
      "accuracy_threshold": 0.4698976740821146,
      "ap": 0.7867387825874783,
      "f1": 0.723169771713461,
      "f1_threshold": 0.4965799609427741,
      "precision": 0.7192066805845512,
      "recall": 0.7271767810026385
    },
    "evaluation_time": 1.76,
    "manhattan": {
      "accuracy": 0.8737557370209215,
      "accuracy_threshold": 7.843975763861954,
      "ap": 0.7783626433432703,
      "f1": 0.7135904155746912,
      "f1_threshold": 8.543318259155654,
      "precision": 0.6770068671560502,
      "recall": 0.754353562005277
    },
    "max": {
      "accuracy": 0.8768552184538356,
      "ap": 0.7867387825874783,
      "f1": 0.723169771713461
    }
  }
}