{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8786433808189784,
      "accuracy_threshold": 0.7390173028118836,
      "ap": 0.7911541684763748,
      "f1": 0.7215665931785761,
      "f1_threshold": 0.7127675545514539,
      "precision": 0.7095128793675083,
      "recall": 0.7340369393139842
    },
    "dot": {
      "accuracy": 0.8587947785658938,
      "accuracy_threshold": 0.40897718288882723,
      "ap": 0.7360052839293402,
      "f1": 0.6778515087016401,
      "f1_threshold": 0.3747722514021522,
      "precision": 0.6449845127472004,
      "recall": 0.7142480211081794
    },
    "euclidean": {
      "accuracy": 0.8795970674137211,
      "accuracy_threshold": 0.5264310641021355,
      "ap": 0.7949158973994583,
      "f1": 0.7261904761904762,
      "f1_threshold": 0.5545379418916346,
      "precision": 0.712544438801422,
      "recall": 0.7403693931398417
    },
    "evaluation_time": 1.75,
    "manhattan": {
      "accuracy": 0.8759611372712642,
      "accuracy_threshold": 8.84720536698719,
      "ap": 0.7862686921078872,
      "f1": 0.717116670795145,
      "f1_threshold": 9.43921305722992,
      "precision": 0.6757703081232493,
      "recall": 0.7638522427440633
    },
    "max": {
      "accuracy": 0.8795970674137211,
      "ap": 0.7949158973994583,
      "f1": 0.7261904761904762
    }
  }
}