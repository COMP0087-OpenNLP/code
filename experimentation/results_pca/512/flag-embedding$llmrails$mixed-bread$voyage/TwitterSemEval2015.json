{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8776896942242356,
      "accuracy_threshold": 0.7388690726935083,
      "ap": 0.7917708158521717,
      "f1": 0.7234596847726976,
      "f1_threshold": 0.7029810993165675,
      "precision": 0.7144327244661692,
      "recall": 0.7327176781002639
    },
    "dot": {
      "accuracy": 0.8590332002145795,
      "accuracy_threshold": 0.3752082738001075,
      "ap": 0.7345790854508598,
      "f1": 0.6791676748124849,
      "f1_threshold": 0.34601673812569733,
      "precision": 0.6271224307417337,
      "recall": 0.7406332453825858
    },
    "euclidean": {
      "accuracy": 0.8779877212850927,
      "accuracy_threshold": 0.5251571696719306,
      "ap": 0.7942789900210265,
      "f1": 0.7219524661385127,
      "f1_threshold": 0.5558765485973667,
      "precision": 0.6999504459861249,
      "recall": 0.7453825857519789
    },
    "evaluation_time": 1.23,
    "manhattan": {
      "accuracy": 0.8730404720748643,
      "accuracy_threshold": 8.443871847922455,
      "ap": 0.7816153819784574,
      "f1": 0.7107107107107107,
      "f1_threshold": 9.170514625890714,
      "precision": 0.6758686339838172,
      "recall": 0.7493403693931399
    },
    "max": {
      "accuracy": 0.8779877212850927,
      "ap": 0.7942789900210265,
      "f1": 0.7234596847726976
    }
  }
}