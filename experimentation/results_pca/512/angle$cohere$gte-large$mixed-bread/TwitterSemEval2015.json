{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8771532455146928,
      "accuracy_threshold": 0.7597456263698633,
      "ap": 0.784895989336716,
      "f1": 0.7194822006472492,
      "f1_threshold": 0.7229859370531924,
      "precision": 0.7062261753494282,
      "recall": 0.733245382585752
    },
    "dot": {
      "accuracy": 0.8567681945520653,
      "accuracy_threshold": 0.4028912273465265,
      "ap": 0.7291587805911363,
      "f1": 0.6686017163048965,
      "f1_threshold": 0.36498101420910123,
      "precision": 0.6407837445573294,
      "recall": 0.6989445910290237
    },
    "euclidean": {
      "accuracy": 0.8785241699946356,
      "accuracy_threshold": 0.5002885491977005,
      "ap": 0.789057059383691,
      "f1": 0.722287199480182,
      "f1_threshold": 0.5311897707693642,
      "precision": 0.711651728553137,
      "recall": 0.733245382585752
    },
    "evaluation_time": 1.2,
    "manhattan": {
      "accuracy": 0.8739941586696072,
      "accuracy_threshold": 8.457553254097231,
      "ap": 0.7788178775114265,
      "f1": 0.713793103448276,
      "f1_threshold": 8.75462774589313,
      "precision": 0.7176,
      "recall": 0.7100263852242744
    },
    "max": {
      "accuracy": 0.8785241699946356,
      "ap": 0.789057059383691,
      "f1": 0.722287199480182
    }
  }
}