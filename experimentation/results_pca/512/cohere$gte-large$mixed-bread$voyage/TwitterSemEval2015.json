{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.876914823866007,
      "accuracy_threshold": 0.7638214449907543,
      "ap": 0.7857572307963875,
      "f1": 0.7194778602508319,
      "f1_threshold": 0.7256661313258753,
      "precision": 0.6985586481113321,
      "recall": 0.741688654353562
    },
    "dot": {
      "accuracy": 0.8544435834773797,
      "accuracy_threshold": 0.3042823696962974,
      "ap": 0.717168297397076,
      "f1": 0.6642814549791295,
      "f1_threshold": 0.2753069690174872,
      "precision": 0.6060935799782372,
      "recall": 0.7348284960422163
    },
    "euclidean": {
      "accuracy": 0.8773916671633785,
      "accuracy_threshold": 0.4323526362194865,
      "ap": 0.7862431949872958,
      "f1": 0.721489526764934,
      "f1_threshold": 0.45953910250141883,
      "precision": 0.7074036511156186,
      "recall": 0.7361477572559367
    },
    "evaluation_time": 1.49,
    "manhattan": {
      "accuracy": 0.8737557370209215,
      "accuracy_threshold": 7.273968736433788,
      "ap": 0.7802711969468471,
      "f1": 0.71525,
      "f1_threshold": 7.862899335939794,
      "precision": 0.6795724465558195,
      "recall": 0.7548812664907651
    },
    "max": {
      "accuracy": 0.8773916671633785,
      "ap": 0.7862431949872958,
      "f1": 0.721489526764934
    }
  }
}