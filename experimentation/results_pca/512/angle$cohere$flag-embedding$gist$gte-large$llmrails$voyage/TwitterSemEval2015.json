{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8779877212850927,
      "accuracy_threshold": 0.7522379816143968,
      "ap": 0.7893197089729407,
      "f1": 0.722562883243649,
      "f1_threshold": 0.7066122937738193,
      "precision": 0.6872173292073316,
      "recall": 0.7617414248021108
    },
    "dot": {
      "accuracy": 0.8601060976336652,
      "accuracy_threshold": 0.3748971190010722,
      "ap": 0.740052741131646,
      "f1": 0.6814204837879568,
      "f1_threshold": 0.36042657654799715,
      "precision": 0.6649924660974385,
      "recall": 0.6986807387862797
    },
    "euclidean": {
      "accuracy": 0.8786433808189784,
      "accuracy_threshold": 0.5074993831394525,
      "ap": 0.7932005835465287,
      "f1": 0.7242367601246106,
      "f1_threshold": 0.5455117459136045,
      "precision": 0.6861865407319953,
      "recall": 0.766754617414248
    },
    "evaluation_time": 2.3,
    "manhattan": {
      "accuracy": 0.8739941586696072,
      "accuracy_threshold": 8.540194519834372,
      "ap": 0.7825405448424538,
      "f1": 0.7145888594164456,
      "f1_threshold": 8.706585408627461,
      "precision": 0.7184,
      "recall": 0.7108179419525066
    },
    "max": {
      "accuracy": 0.8786433808189784,
      "ap": 0.7932005835465287,
      "f1": 0.7242367601246106
    }
  }
}