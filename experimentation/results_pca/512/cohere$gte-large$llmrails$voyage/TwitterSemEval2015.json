{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.877332061751207,
      "accuracy_threshold": 0.7446492555971445,
      "ap": 0.7888633855127174,
      "f1": 0.7205016636805734,
      "f1_threshold": 0.7123497386738304,
      "precision": 0.6995526838966203,
      "recall": 0.7427440633245382
    },
    "dot": {
      "accuracy": 0.8555164808964654,
      "accuracy_threshold": 0.28641204942101306,
      "ap": 0.7238579460512133,
      "f1": 0.6738461538461539,
      "f1_threshold": 0.2629272358317867,
      "precision": 0.6109442060085837,
      "recall": 0.7511873350923483
    },
    "euclidean": {
      "accuracy": 0.8769744292781785,
      "accuracy_threshold": 0.43068547146010683,
      "ap": 0.7885885166742888,
      "f1": 0.7211675061345731,
      "f1_threshold": 0.46538255346543844,
      "precision": 0.7062990134075385,
      "recall": 0.7366754617414248
    },
    "evaluation_time": 1.34,
    "manhattan": {
      "accuracy": 0.8744113965548072,
      "accuracy_threshold": 7.417279986214341,
      "ap": 0.7826464339095477,
      "f1": 0.7166811576201714,
      "f1_threshold": 7.99967366518729,
      "precision": 0.6770711100680591,
      "recall": 0.7612137203166227
    },
    "max": {
      "accuracy": 0.877332061751207,
      "ap": 0.7888633855127174,
      "f1": 0.7211675061345731
    }
  }
}