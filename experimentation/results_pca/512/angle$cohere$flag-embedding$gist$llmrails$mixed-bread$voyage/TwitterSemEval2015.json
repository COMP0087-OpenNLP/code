{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8779877212850927,
      "accuracy_threshold": 0.7535086641355786,
      "ap": 0.7898636813349366,
      "f1": 0.7231384307846077,
      "f1_threshold": 0.7046901468044424,
      "precision": 0.6867584242999525,
      "recall": 0.7635883905013192
    },
    "dot": {
      "accuracy": 0.8595696489241224,
      "accuracy_threshold": 0.4151928256850371,
      "ap": 0.7392549185254105,
      "f1": 0.6818971939408989,
      "f1_threshold": 0.3894757995406963,
      "precision": 0.6439962476547842,
      "recall": 0.7245382585751979
    },
    "euclidean": {
      "accuracy": 0.878583775406807,
      "accuracy_threshold": 0.5281906060246604,
      "ap": 0.7939989456135591,
      "f1": 0.7257659467604219,
      "f1_threshold": 0.571724639428163,
      "precision": 0.6923814087206517,
      "recall": 0.762532981530343
    },
    "evaluation_time": 2.32,
    "manhattan": {
      "accuracy": 0.8750074506765214,
      "accuracy_threshold": 8.790239757707013,
      "ap": 0.7837188258290699,
      "f1": 0.7151193633952254,
      "f1_threshold": 9.121435391179075,
      "precision": 0.7189333333333333,
      "recall": 0.7113456464379947
    },
    "max": {
      "accuracy": 0.878583775406807,
      "ap": 0.7939989456135591,
      "f1": 0.7257659467604219
    }
  }
}