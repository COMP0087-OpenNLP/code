{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8738153424330929,
      "accuracy_threshold": 0.752015884171445,
      "ap": 0.7789681713993327,
      "f1": 0.7112165875593304,
      "f1_threshold": 0.7108700481967346,
      "precision": 0.6752846299810247,
      "recall": 0.7511873350923483
    },
    "dot": {
      "accuracy": 0.857423854085951,
      "accuracy_threshold": 0.39490906778014545,
      "ap": 0.7266965174702213,
      "f1": 0.6749755620723363,
      "f1_threshold": 0.3624137068876559,
      "precision": 0.6285844333181612,
      "recall": 0.7287598944591029
    },
    "euclidean": {
      "accuracy": 0.8730404720748643,
      "accuracy_threshold": 0.5023834605235253,
      "ap": 0.7787772181525106,
      "f1": 0.7137234987939571,
      "f1_threshold": 0.539091786567881,
      "precision": 0.6877905554196232,
      "recall": 0.741688654353562
    },
    "evaluation_time": 0.97,
    "manhattan": {
      "accuracy": 0.869762174405436,
      "accuracy_threshold": 8.464721165721032,
      "ap": 0.7692829079954119,
      "f1": 0.7094321108794309,
      "f1_threshold": 9.26680613025613,
      "precision": 0.6628466651386661,
      "recall": 0.7630606860158311
    },
    "max": {
      "accuracy": 0.8738153424330929,
      "ap": 0.7789681713993327,
      "f1": 0.7137234987939571
    }
  }
}