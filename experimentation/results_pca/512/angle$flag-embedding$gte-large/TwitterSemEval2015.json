{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8751862669130357,
      "accuracy_threshold": 0.7351916174770633,
      "ap": 0.7816427916067685,
      "f1": 0.7151655119322556,
      "f1_threshold": 0.7078057753819038,
      "precision": 0.6960539460539461,
      "recall": 0.7353562005277045
    },
    "dot": {
      "accuracy": 0.8548608213625797,
      "accuracy_threshold": 0.4193051158520866,
      "ap": 0.7231272932047953,
      "f1": 0.6682294879703887,
      "f1_threshold": 0.38281360687217825,
      "precision": 0.6275782155272306,
      "recall": 0.7145118733509235
    },
    "euclidean": {
      "accuracy": 0.87494784526435,
      "accuracy_threshold": 0.5331912452444747,
      "ap": 0.7858675350922352,
      "f1": 0.7192168985059249,
      "f1_threshold": 0.5672399648812985,
      "precision": 0.7025666834423755,
      "recall": 0.7366754617414248
    },
    "evaluation_time": 0.85,
    "manhattan": {
      "accuracy": 0.8686892769863503,
      "accuracy_threshold": 8.878438193737232,
      "ap": 0.7689290647841741,
      "f1": 0.7016476552598225,
      "f1_threshold": 9.283403277718934,
      "precision": 0.6751219512195122,
      "recall": 0.7303430079155673
    },
    "max": {
      "accuracy": 0.8751862669130357,
      "ap": 0.7858675350922352,
      "f1": 0.7192168985059249
    }
  }
}