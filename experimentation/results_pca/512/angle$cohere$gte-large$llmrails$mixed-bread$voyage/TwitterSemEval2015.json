{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.878583775406807,
      "accuracy_threshold": 0.7407547951326452,
      "ap": 0.7901875934812398,
      "f1": 0.7218726403221747,
      "f1_threshold": 0.7045174086148719,
      "precision": 0.6900866217516843,
      "recall": 0.7567282321899736
    },
    "dot": {
      "accuracy": 0.857841091971151,
      "accuracy_threshold": 0.3816134770452131,
      "ap": 0.7358379598258576,
      "f1": 0.6774788057500922,
      "f1_threshold": 0.34871917106103306,
      "precision": 0.6339388365141412,
      "recall": 0.7274406332453826
    },
    "euclidean": {
      "accuracy": 0.8787625916433213,
      "accuracy_threshold": 0.5140984779704169,
      "ap": 0.794252761056415,
      "f1": 0.7246487867177522,
      "f1_threshold": 0.5412591921770686,
      "precision": 0.7022277227722772,
      "recall": 0.7485488126649077
    },
    "evaluation_time": 2.0,
    "manhattan": {
      "accuracy": 0.8744113965548072,
      "accuracy_threshold": 8.220241819636106,
      "ap": 0.7833445696958918,
      "f1": 0.715,
      "f1_threshold": 8.763862991871214,
      "precision": 0.7131233595800525,
      "recall": 0.7168865435356201
    },
    "max": {
      "accuracy": 0.8787625916433213,
      "ap": 0.794252761056415,
      "f1": 0.7246487867177522
    }
  }
}