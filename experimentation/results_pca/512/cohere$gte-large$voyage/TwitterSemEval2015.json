{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8695833581689217,
      "accuracy_threshold": 0.7465262685847671,
      "ap": 0.7659695757867043,
      "f1": 0.7011453536426968,
      "f1_threshold": 0.6916722293683899,
      "precision": 0.6345372942936525,
      "recall": 0.783377308707124
    },
    "dot": {
      "accuracy": 0.8540263455921798,
      "accuracy_threshold": 0.3439732949442643,
      "ap": 0.7178550705962724,
      "f1": 0.6705667276051188,
      "f1_threshold": 0.3145817829476939,
      "precision": 0.6231030577576444,
      "recall": 0.7258575197889182
    },
    "euclidean": {
      "accuracy": 0.8685104607498361,
      "accuracy_threshold": 0.46502798730024164,
      "ap": 0.7649755153573953,
      "f1": 0.7062706270627063,
      "f1_threshold": 0.5160082176902764,
      "precision": 0.6579366886813938,
      "recall": 0.7622691292875989
    },
    "evaluation_time": 0.98,
    "manhattan": {
      "accuracy": 0.8642188710734935,
      "accuracy_threshold": 7.9953324755732,
      "ap": 0.7541996572965366,
      "f1": 0.6954761904761906,
      "f1_threshold": 8.874980611005968,
      "precision": 0.6336225596529285,
      "recall": 0.770712401055409
    },
    "max": {
      "accuracy": 0.8695833581689217,
      "ap": 0.7659695757867043,
      "f1": 0.7062706270627063
    }
  }
}