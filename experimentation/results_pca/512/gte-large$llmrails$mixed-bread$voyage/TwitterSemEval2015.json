{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8774512725755499,
      "accuracy_threshold": 0.7435950370555958,
      "ap": 0.7889968911812371,
      "f1": 0.7204147764095917,
      "f1_threshold": 0.7131792781213839,
      "precision": 0.7080254777070064,
      "recall": 0.733245382585752
    },
    "dot": {
      "accuracy": 0.8590332002145795,
      "accuracy_threshold": 0.3199058416779105,
      "ap": 0.7341113070578296,
      "f1": 0.675843253968254,
      "f1_threshold": 0.29448140002308903,
      "precision": 0.6375760411792232,
      "recall": 0.7189973614775725
    },
    "euclidean": {
      "accuracy": 0.8771532455146928,
      "accuracy_threshold": 0.4662941409485285,
      "ap": 0.7914819576905224,
      "f1": 0.7205806117159149,
      "f1_threshold": 0.49197070457906833,
      "precision": 0.7080998471726948,
      "recall": 0.7335092348284961
    },
    "evaluation_time": 1.43,
    "manhattan": {
      "accuracy": 0.8726828396018358,
      "accuracy_threshold": 7.761898948418928,
      "ap": 0.778366985317232,
      "f1": 0.7082792629120166,
      "f1_threshold": 8.102426883756355,
      "precision": 0.6968845760980592,
      "recall": 0.7200527704485488
    },
    "max": {
      "accuracy": 0.8774512725755499,
      "ap": 0.7914819576905224,
      "f1": 0.7205806117159149
    }
  }
}