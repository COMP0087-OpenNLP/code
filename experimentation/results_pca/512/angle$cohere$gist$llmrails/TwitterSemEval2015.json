{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8776300888120642,
      "accuracy_threshold": 0.7453183807611771,
      "ap": 0.7886756169141511,
      "f1": 0.7214150347441567,
      "f1_threshold": 0.7088452092010633,
      "precision": 0.6921212121212121,
      "recall": 0.7532981530343008
    },
    "dot": {
      "accuracy": 0.860940573404065,
      "accuracy_threshold": 0.46822782683685177,
      "ap": 0.7417418921849587,
      "f1": 0.6836220665929476,
      "f1_threshold": 0.4294807660540514,
      "precision": 0.639687284433203,
      "recall": 0.7340369393139842
    },
    "euclidean": {
      "accuracy": 0.8794778565893783,
      "accuracy_threshold": 0.5572253712018578,
      "ap": 0.7929324593792725,
      "f1": 0.7253422028911348,
      "f1_threshold": 0.5938322747098714,
      "precision": 0.703998013409486,
      "recall": 0.7480211081794196
    },
    "evaluation_time": 3.45,
    "manhattan": {
      "accuracy": 0.8750074506765214,
      "accuracy_threshold": 9.293739795928648,
      "ap": 0.7825581217721765,
      "f1": 0.7159697232907309,
      "f1_threshold": 10.005967320236634,
      "precision": 0.675802295619583,
      "recall": 0.7612137203166227
    },
    "max": {
      "accuracy": 0.8794778565893783,
      "ap": 0.7929324593792725,
      "f1": 0.7253422028911348
    }
  }
}