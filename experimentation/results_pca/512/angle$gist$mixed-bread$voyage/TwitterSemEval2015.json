{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8748882398521786,
      "accuracy_threshold": 0.7546326406633732,
      "ap": 0.7832637650879928,
      "f1": 0.71655776106522,
      "f1_threshold": 0.7110219303662034,
      "precision": 0.6725295070585513,
      "recall": 0.766754617414248
    },
    "dot": {
      "accuracy": 0.8591524110389224,
      "accuracy_threshold": 0.41824326399486045,
      "ap": 0.7361529909889276,
      "f1": 0.6766350279547523,
      "f1_threshold": 0.39769719408442916,
      "precision": 0.6670084593693925,
      "recall": 0.6865435356200528
    },
    "euclidean": {
      "accuracy": 0.8766167968051499,
      "accuracy_threshold": 0.524890533077115,
      "ap": 0.7870254745673687,
      "f1": 0.7204436601966221,
      "f1_threshold": 0.5568127415383157,
      "precision": 0.6896718146718147,
      "recall": 0.754089709762533
    },
    "evaluation_time": 1.2,
    "manhattan": {
      "accuracy": 0.8711927042975502,
      "accuracy_threshold": 8.539773713149,
      "ap": 0.7740798902046055,
      "f1": 0.707653383934219,
      "f1_threshold": 9.078484203346207,
      "precision": 0.6797083839611179,
      "recall": 0.7379947229551451
    },
    "max": {
      "accuracy": 0.8766167968051499,
      "ap": 0.7870254745673687,
      "f1": 0.7204436601966221
    }
  }
}