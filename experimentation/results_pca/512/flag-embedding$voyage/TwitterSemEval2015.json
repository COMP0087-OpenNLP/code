{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.876914823866007,
      "accuracy_threshold": 0.7278986551881317,
      "ap": 0.7913787325959244,
      "f1": 0.7182838121070151,
      "f1_threshold": 0.6825975841289851,
      "precision": 0.674149502429993,
      "recall": 0.7686015831134565
    },
    "dot": {
      "accuracy": 0.8636228169517792,
      "accuracy_threshold": 0.2897329031080493,
      "ap": 0.7437201822893509,
      "f1": 0.6884800592665761,
      "f1_threshold": 0.2656507978052592,
      "precision": 0.6470178695753075,
      "recall": 0.7356200527704485
    },
    "euclidean": {
      "accuracy": 0.8762591643321214,
      "accuracy_threshold": 0.4563096677874353,
      "ap": 0.7909155920572669,
      "f1": 0.7169859190663453,
      "f1_threshold": 0.4901963018197455,
      "precision": 0.6904471048130956,
      "recall": 0.745646437994723
    },
    "evaluation_time": 0.68,
    "manhattan": {
      "accuracy": 0.8734577099600643,
      "accuracy_threshold": 7.763990833130821,
      "ap": 0.7807809643160647,
      "f1": 0.7095273083517023,
      "f1_threshold": 8.305678074638568,
      "precision": 0.6620201096892139,
      "recall": 0.7643799472295515
    },
    "max": {
      "accuracy": 0.876914823866007,
      "ap": 0.7913787325959244,
      "f1": 0.7182838121070151
    }
  }
}