{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8762591643321214,
      "accuracy_threshold": 0.7605514834232217,
      "ap": 0.7863134415056691,
      "f1": 0.718937875751503,
      "f1_threshold": 0.7154628097534506,
      "precision": 0.6843109203624225,
      "recall": 0.7572559366754618
    },
    "dot": {
      "accuracy": 0.8580199082076653,
      "accuracy_threshold": 0.34678910393952317,
      "ap": 0.7282125954294822,
      "f1": 0.6710275927687915,
      "f1_threshold": 0.3135520147559957,
      "precision": 0.6108705067128627,
      "recall": 0.7443271767810027
    },
    "euclidean": {
      "accuracy": 0.8775108779877213,
      "accuracy_threshold": 0.4724864586145394,
      "ap": 0.7886476215176471,
      "f1": 0.7215604136667102,
      "f1_threshold": 0.49214840580174934,
      "precision": 0.7160301376981034,
      "recall": 0.7271767810026385
    },
    "evaluation_time": 1.99,
    "manhattan": {
      "accuracy": 0.8748286344400071,
      "accuracy_threshold": 7.877162845206087,
      "ap": 0.7812201257963544,
      "f1": 0.7143791704827949,
      "f1_threshold": 8.26222572185042,
      "precision": 0.7085388009343369,
      "recall": 0.7203166226912929
    },
    "max": {
      "accuracy": 0.8775108779877213,
      "ap": 0.7886476215176471,
      "f1": 0.7215604136667102
    }
  }
}