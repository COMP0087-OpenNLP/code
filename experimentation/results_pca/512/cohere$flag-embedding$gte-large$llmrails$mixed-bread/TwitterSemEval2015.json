{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.878166537521607,
      "accuracy_threshold": 0.7404586264458655,
      "ap": 0.7901364073875903,
      "f1": 0.7204656700621777,
      "f1_threshold": 0.7171171984940901,
      "precision": 0.7224728044574158,
      "recall": 0.7184696569920844
    },
    "dot": {
      "accuracy": 0.8585563569172081,
      "accuracy_threshold": 0.3750851175560592,
      "ap": 0.7360049517117947,
      "f1": 0.6786727519427657,
      "f1_threshold": 0.3424391043008964,
      "precision": 0.6372480889506602,
      "recall": 0.7258575197889182
    },
    "euclidean": {
      "accuracy": 0.8786433808189784,
      "accuracy_threshold": 0.5089732876324999,
      "ap": 0.7937107155235266,
      "f1": 0.7241468459152017,
      "f1_threshold": 0.5338542292635196,
      "precision": 0.7098327420172327,
      "recall": 0.7390501319261213
    },
    "evaluation_time": 1.55,
    "manhattan": {
      "accuracy": 0.8760207426834357,
      "accuracy_threshold": 8.416254649579574,
      "ap": 0.7862924959007971,
      "f1": 0.7166442460560108,
      "f1_threshold": 9.154928519177243,
      "precision": 0.667882379758377,
      "recall": 0.7730870712401056
    },
    "max": {
      "accuracy": 0.8786433808189784,
      "ap": 0.7937107155235266,
      "f1": 0.7241468459152017
    }
  }
}