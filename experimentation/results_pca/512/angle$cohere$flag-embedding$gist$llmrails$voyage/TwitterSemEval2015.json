{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8775108779877213,
      "accuracy_threshold": 0.7547400570760309,
      "ap": 0.7889759139918071,
      "f1": 0.7225065534889525,
      "f1_threshold": 0.7068201376450931,
      "precision": 0.6856195214404169,
      "recall": 0.7635883905013192
    },
    "dot": {
      "accuracy": 0.8614174167014365,
      "accuracy_threshold": 0.4209747844853067,
      "ap": 0.7426150329006725,
      "f1": 0.6835123183828175,
      "f1_threshold": 0.39867327848346634,
      "precision": 0.6557575757575758,
      "recall": 0.7137203166226913
    },
    "euclidean": {
      "accuracy": 0.8783453537581213,
      "accuracy_threshold": 0.5331426651666251,
      "ap": 0.7930994833658109,
      "f1": 0.7254754754754755,
      "f1_threshold": 0.5738256933670245,
      "precision": 0.6899095668729177,
      "recall": 0.7649076517150396
    },
    "evaluation_time": 2.03,
    "manhattan": {
      "accuracy": 0.8751862669130357,
      "accuracy_threshold": 8.865583016656808,
      "ap": 0.7832839877031346,
      "f1": 0.7154699655656166,
      "f1_threshold": 9.31877003700816,
      "precision": 0.6924216242902987,
      "recall": 0.7401055408970977
    },
    "max": {
      "accuracy": 0.8783453537581213,
      "ap": 0.7930994833658109,
      "f1": 0.7254754754754755
    }
  }
}