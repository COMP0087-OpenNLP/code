{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8776300888120642,
      "accuracy_threshold": 0.753892185149815,
      "ap": 0.7874797030436977,
      "f1": 0.7191068256787618,
      "f1_threshold": 0.7158615960256176,
      "precision": 0.6925708699902249,
      "recall": 0.7477572559366754
    },
    "dot": {
      "accuracy": 0.8577814865589796,
      "accuracy_threshold": 0.34822273727518804,
      "ap": 0.7329517483437357,
      "f1": 0.672289156626506,
      "f1_threshold": 0.31612845901649256,
      "precision": 0.6186252771618626,
      "recall": 0.7361477572559367
    },
    "euclidean": {
      "accuracy": 0.8778685104607499,
      "accuracy_threshold": 0.477817646942271,
      "ap": 0.7911835761949786,
      "f1": 0.7222592247235913,
      "f1_threshold": 0.49400873548235424,
      "precision": 0.7293516276567124,
      "recall": 0.7153034300791556
    },
    "evaluation_time": 2.01,
    "manhattan": {
      "accuracy": 0.8735769207844072,
      "accuracy_threshold": 7.721213922244372,
      "ap": 0.7803615416585901,
      "f1": 0.713222079589217,
      "f1_threshold": 8.313679527787727,
      "precision": 0.6945,
      "recall": 0.732981530343008
    },
    "max": {
      "accuracy": 0.8778685104607499,
      "ap": 0.7911835761949786,
      "f1": 0.7222592247235913
    }
  }
}