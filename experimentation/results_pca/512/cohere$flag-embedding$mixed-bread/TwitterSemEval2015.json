{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8760803480956071,
      "accuracy_threshold": 0.747289233492683,
      "ap": 0.7858001482126573,
      "f1": 0.7167322085500444,
      "f1_threshold": 0.7073063268392059,
      "precision": 0.690202785243098,
      "recall": 0.7453825857519789
    },
    "dot": {
      "accuracy": 0.8580199082076653,
      "accuracy_threshold": 0.4609770652964936,
      "ap": 0.734754904143009,
      "f1": 0.6791609780315254,
      "f1_threshold": 0.42224761371781216,
      "precision": 0.6411999062573236,
      "recall": 0.7218997361477573
    },
    "euclidean": {
      "accuracy": 0.8772724563390356,
      "accuracy_threshold": 0.5550665045035126,
      "ap": 0.7881566099254883,
      "f1": 0.7197477335435554,
      "f1_threshold": 0.5809064976803048,
      "precision": 0.7168280554828579,
      "recall": 0.7226912928759894
    },
    "evaluation_time": 0.91,
    "manhattan": {
      "accuracy": 0.8733981045478929,
      "accuracy_threshold": 9.179511326758927,
      "ap": 0.780446171869443,
      "f1": 0.7130612767046182,
      "f1_threshold": 9.96041651034615,
      "precision": 0.6920784703253042,
      "recall": 0.7353562005277045
    },
    "max": {
      "accuracy": 0.8772724563390356,
      "ap": 0.7881566099254883,
      "f1": 0.7197477335435554
    }
  }
}