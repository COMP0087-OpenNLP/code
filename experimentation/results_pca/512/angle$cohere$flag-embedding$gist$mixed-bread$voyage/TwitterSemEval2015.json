{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8767956130416642,
      "accuracy_threshold": 0.7564664606375088,
      "ap": 0.7872618195860519,
      "f1": 0.7211682476285571,
      "f1_threshold": 0.7121399004394934,
      "precision": 0.6842728564661298,
      "recall": 0.7622691292875989
    },
    "dot": {
      "accuracy": 0.8598676759849795,
      "accuracy_threshold": 0.4261953571904454,
      "ap": 0.7402886474980135,
      "f1": 0.6794412164668068,
      "f1_threshold": 0.4016635650647181,
      "precision": 0.639218422889044,
      "recall": 0.725065963060686
    },
    "euclidean": {
      "accuracy": 0.8785241699946356,
      "accuracy_threshold": 0.5317316910182104,
      "ap": 0.7915112740106057,
      "f1": 0.725141776937618,
      "f1_threshold": 0.5693600078200107,
      "precision": 0.6940892641737032,
      "recall": 0.7591029023746702
    },
    "evaluation_time": 2.03,
    "manhattan": {
      "accuracy": 0.8743517911426357,
      "accuracy_threshold": 8.727978490990413,
      "ap": 0.7812545584534107,
      "f1": 0.7143219908583037,
      "f1_threshold": 9.278157202570448,
      "precision": 0.6884483602545276,
      "recall": 0.7422163588390501
    },
    "max": {
      "accuracy": 0.8785241699946356,
      "ap": 0.7915112740106057,
      "f1": 0.725141776937618
    }
  }
}