{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8769744292781785,
      "accuracy_threshold": 0.7566796313096757,
      "ap": 0.7890001455984997,
      "f1": 0.7201011378002528,
      "f1_threshold": 0.7068048222527032,
      "precision": 0.6912621359223301,
      "recall": 0.7514511873350923
    },
    "dot": {
      "accuracy": 0.8608809679918936,
      "accuracy_threshold": 0.42384038057061085,
      "ap": 0.7404150347711361,
      "f1": 0.6819080573405832,
      "f1_threshold": 0.3877575420123821,
      "precision": 0.6413296141329614,
      "recall": 0.7279683377308707
    },
    "euclidean": {
      "accuracy": 0.8792394349406926,
      "accuracy_threshold": 0.5295244866531812,
      "ap": 0.7931341447846425,
      "f1": 0.7241602904940994,
      "f1_threshold": 0.5615487043236138,
      "precision": 0.7120632491711298,
      "recall": 0.7366754617414248
    },
    "evaluation_time": 1.53,
    "manhattan": {
      "accuracy": 0.8743517911426357,
      "accuracy_threshold": 8.787929468236818,
      "ap": 0.7839012377662375,
      "f1": 0.7159120310478655,
      "f1_threshold": 9.366855365945394,
      "precision": 0.7022842639593908,
      "recall": 0.7300791556728232
    },
    "max": {
      "accuracy": 0.8792394349406926,
      "ap": 0.7931341447846425,
      "f1": 0.7241602904940994
    }
  }
}