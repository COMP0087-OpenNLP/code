{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8774512725755499,
      "accuracy_threshold": 0.7557202728790663,
      "ap": 0.7868678261738875,
      "f1": 0.7214098237720287,
      "f1_threshold": 0.7122940173587122,
      "precision": 0.6853478983614344,
      "recall": 0.7614775725593668
    },
    "dot": {
      "accuracy": 0.8596888597484652,
      "accuracy_threshold": 0.35605582805644387,
      "ap": 0.7374275917133769,
      "f1": 0.6792219055879073,
      "f1_threshold": 0.32760380137422973,
      "precision": 0.6402709647278674,
      "recall": 0.7232189973614775
    },
    "euclidean": {
      "accuracy": 0.877749299636407,
      "accuracy_threshold": 0.475095832974354,
      "ap": 0.7903247051078512,
      "f1": 0.7233652208098547,
      "f1_threshold": 0.5029278338147594,
      "precision": 0.718562874251497,
      "recall": 0.7282321899736148
    },
    "evaluation_time": 2.03,
    "manhattan": {
      "accuracy": 0.8734577099600643,
      "accuracy_threshold": 7.824268814695027,
      "ap": 0.7799229667196866,
      "f1": 0.7128916281458656,
      "f1_threshold": 8.389085657151114,
      "precision": 0.6943471735867934,
      "recall": 0.7324538258575198
    },
    "max": {
      "accuracy": 0.877749299636407,
      "ap": 0.7903247051078512,
      "f1": 0.7233652208098547
    }
  }
}