{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8766764022173213,
      "accuracy_threshold": 0.7628046611776995,
      "ap": 0.7861947654294836,
      "f1": 0.7207527975584943,
      "f1_threshold": 0.7217877218154574,
      "precision": 0.6956308296514482,
      "recall": 0.7477572559366754
    },
    "dot": {
      "accuracy": 0.8590332002145795,
      "accuracy_threshold": 0.4261879795419613,
      "ap": 0.7347843694012955,
      "f1": 0.675176601809394,
      "f1_threshold": 0.39741402217074745,
      "precision": 0.6365973358261277,
      "recall": 0.7187335092348285
    },
    "euclidean": {
      "accuracy": 0.8782857483459499,
      "accuracy_threshold": 0.5154788683268219,
      "ap": 0.7898430799838316,
      "f1": 0.7240454603498915,
      "f1_threshold": 0.5565075845993375,
      "precision": 0.7015590200445434,
      "recall": 0.7480211081794196
    },
    "evaluation_time": 1.72,
    "manhattan": {
      "accuracy": 0.87411336949395,
      "accuracy_threshold": 8.863488613179271,
      "ap": 0.7807120225265112,
      "f1": 0.7160094539121781,
      "f1_threshold": 9.365963074322973,
      "precision": 0.677335843727936,
      "recall": 0.7593667546174142
    },
    "max": {
      "accuracy": 0.8782857483459499,
      "ap": 0.7898430799838316,
      "f1": 0.7240454603498915
    }
  }
}