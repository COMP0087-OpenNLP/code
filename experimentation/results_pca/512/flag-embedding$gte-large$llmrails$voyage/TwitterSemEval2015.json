{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8775108779877213,
      "accuracy_threshold": 0.7350922085293812,
      "ap": 0.7906700778346462,
      "f1": 0.7198659275493103,
      "f1_threshold": 0.6986322085508738,
      "precision": 0.7038064028232922,
      "recall": 0.7366754617414248
    },
    "dot": {
      "accuracy": 0.8605829409310365,
      "accuracy_threshold": 0.29805395366272125,
      "ap": 0.7372852565306066,
      "f1": 0.6833679579616279,
      "f1_threshold": 0.2776176213965506,
      "precision": 0.6364671067607558,
      "recall": 0.7377308707124011
    },
    "euclidean": {
      "accuracy": 0.876914823866007,
      "accuracy_threshold": 0.4692657407582159,
      "ap": 0.7925679722871265,
      "f1": 0.7206084029422765,
      "f1_threshold": 0.503676147683011,
      "precision": 0.6830536516190026,
      "recall": 0.762532981530343
    },
    "evaluation_time": 1.2,
    "manhattan": {
      "accuracy": 0.8728020504261786,
      "accuracy_threshold": 7.7590101646029845,
      "ap": 0.7794899415326788,
      "f1": 0.7074990184530819,
      "f1_threshold": 8.129164613653218,
      "precision": 0.7018956115294729,
      "recall": 0.7131926121372032
    },
    "max": {
      "accuracy": 0.8775108779877213,
      "ap": 0.7925679722871265,
      "f1": 0.7206084029422765
    }
  }
}