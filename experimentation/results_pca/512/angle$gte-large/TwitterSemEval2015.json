{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8728020504261786,
      "accuracy_threshold": 0.7473047789241194,
      "ap": 0.7739000232894048,
      "f1": 0.7093346825196052,
      "f1_threshold": 0.7153448606065231,
      "precision": 0.6812439261418853,
      "recall": 0.7398416886543535
    },
    "dot": {
      "accuracy": 0.8540859510043511,
      "accuracy_threshold": 0.3581613992830329,
      "ap": 0.7202537035585311,
      "f1": 0.6656174334140434,
      "f1_threshold": 0.32663109059285533,
      "precision": 0.6149888143176734,
      "recall": 0.7253298153034301
    },
    "euclidean": {
      "accuracy": 0.8725040233653216,
      "accuracy_threshold": 0.48586527736391044,
      "ap": 0.7783021198466663,
      "f1": 0.7126646667536195,
      "f1_threshold": 0.5075993309729763,
      "precision": 0.7046685581635285,
      "recall": 0.720844327176781
    },
    "evaluation_time": 0.73,
    "manhattan": {
      "accuracy": 0.8664242713238363,
      "accuracy_threshold": 7.645760670832868,
      "ap": 0.7595287411350671,
      "f1": 0.695060047047171,
      "f1_threshold": 8.491574582829891,
      "precision": 0.6547702355959879,
      "recall": 0.7406332453825858
    },
    "max": {
      "accuracy": 0.8728020504261786,
      "ap": 0.7783021198466663,
      "f1": 0.7126646667536195
    }
  }
}