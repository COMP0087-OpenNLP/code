{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8778089050485784,
      "accuracy_threshold": 0.7518087015471331,
      "ap": 0.7898233902219435,
      "f1": 0.7211386399578281,
      "f1_threshold": 0.7275643249887542,
      "precision": 0.7203791469194313,
      "recall": 0.7218997361477573
    },
    "dot": {
      "accuracy": 0.8606425463432079,
      "accuracy_threshold": 0.3682949306580624,
      "ap": 0.7355830948133425,
      "f1": 0.6799410029498525,
      "f1_threshold": 0.3399232703868724,
      "precision": 0.6364473078693051,
      "recall": 0.7298153034300792
    },
    "euclidean": {
      "accuracy": 0.878583775406807,
      "accuracy_threshold": 0.48115262322678654,
      "ap": 0.7916020595808209,
      "f1": 0.723804477414227,
      "f1_threshold": 0.5097195434112576,
      "precision": 0.7267890396382016,
      "recall": 0.720844327176781
    },
    "evaluation_time": 1.27,
    "manhattan": {
      "accuracy": 0.87536508314955,
      "accuracy_threshold": 8.231154716529488,
      "ap": 0.7852351049878167,
      "f1": 0.7194351542177628,
      "f1_threshold": 8.8510347957518,
      "precision": 0.6780294186318001,
      "recall": 0.7662269129287599
    },
    "max": {
      "accuracy": 0.878583775406807,
      "ap": 0.7916020595808209,
      "f1": 0.723804477414227
    }
  }
}