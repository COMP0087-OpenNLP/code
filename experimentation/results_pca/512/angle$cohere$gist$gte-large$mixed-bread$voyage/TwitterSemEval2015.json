{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8766167968051499,
      "accuracy_threshold": 0.7630261280223959,
      "ap": 0.7844225895848574,
      "f1": 0.7184563337927579,
      "f1_threshold": 0.7190160128738126,
      "precision": 0.6840849439274637,
      "recall": 0.7564643799472296
    },
    "dot": {
      "accuracy": 0.8585563569172081,
      "accuracy_threshold": 0.3676099732594629,
      "ap": 0.7333744803963429,
      "f1": 0.6725213185694284,
      "f1_threshold": 0.3378753982080394,
      "precision": 0.6496188836980575,
      "recall": 0.6970976253298153
    },
    "euclidean": {
      "accuracy": 0.877332061751207,
      "accuracy_threshold": 0.46979121300573623,
      "ap": 0.788298706844353,
      "f1": 0.7219339324136185,
      "f1_threshold": 0.510782318002646,
      "precision": 0.6937484796886403,
      "recall": 0.7525065963060686
    },
    "evaluation_time": 2.02,
    "manhattan": {
      "accuracy": 0.8722656017166359,
      "accuracy_threshold": 7.927162081413594,
      "ap": 0.7779812434326661,
      "f1": 0.7143037495265749,
      "f1_threshold": 8.407298275170687,
      "precision": 0.6848220769789397,
      "recall": 0.7464379947229551
    },
    "max": {
      "accuracy": 0.877332061751207,
      "ap": 0.788298706844353,
      "f1": 0.7219339324136185
    }
  }
}