{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8742325803182929,
      "accuracy_threshold": 0.7472243543274399,
      "ap": 0.780249949610634,
      "f1": 0.7119126720455624,
      "f1_threshold": 0.6879424802866703,
      "precision": 0.6468305304010349,
      "recall": 0.7915567282321899
    },
    "dot": {
      "accuracy": 0.8579006973833224,
      "accuracy_threshold": 0.376880558106271,
      "ap": 0.7296725036877952,
      "f1": 0.6790820617565781,
      "f1_threshold": 0.34747127627773744,
      "precision": 0.6234281932495036,
      "recall": 0.745646437994723
    },
    "euclidean": {
      "accuracy": 0.8729808666626929,
      "accuracy_threshold": 0.5113137894797142,
      "ap": 0.7796794289090092,
      "f1": 0.7130904878362723,
      "f1_threshold": 0.5353482167362802,
      "precision": 0.6961548127670268,
      "recall": 0.7308707124010554
    },
    "evaluation_time": 0.98,
    "manhattan": {
      "accuracy": 0.8708350718245217,
      "accuracy_threshold": 8.579789798701476,
      "ap": 0.7718560750674329,
      "f1": 0.7068075694273777,
      "f1_threshold": 9.265717001148118,
      "precision": 0.6614535418583257,
      "recall": 0.7588390501319261
    },
    "max": {
      "accuracy": 0.8742325803182929,
      "ap": 0.780249949610634,
      "f1": 0.7130904878362723
    }
  }
}