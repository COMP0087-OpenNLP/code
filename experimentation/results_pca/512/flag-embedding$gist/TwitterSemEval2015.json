{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8756631102104071,
      "accuracy_threshold": 0.7447365266718666,
      "ap": 0.784945903274749,
      "f1": 0.7193515704154003,
      "f1_threshold": 0.7053135058968465,
      "precision": 0.69167072576717,
      "recall": 0.7493403693931399
    },
    "dot": {
      "accuracy": 0.8623114978840078,
      "accuracy_threshold": 0.5028637950223239,
      "ap": 0.737886373977819,
      "f1": 0.6842563783447417,
      "f1_threshold": 0.4664975282844409,
      "precision": 0.647585394581861,
      "recall": 0.7253298153034301
    },
    "euclidean": {
      "accuracy": 0.8759015318590928,
      "accuracy_threshold": 0.5887702077236507,
      "ap": 0.7895033979635255,
      "f1": 0.7222722015165146,
      "f1_threshold": 0.6239937709193649,
      "precision": 0.704084189426209,
      "recall": 0.741424802110818
    },
    "evaluation_time": 0.61,
    "manhattan": {
      "accuracy": 0.8713119151218931,
      "accuracy_threshold": 9.631701803958329,
      "ap": 0.775410725595054,
      "f1": 0.706524375454766,
      "f1_threshold": 10.385150507039606,
      "precision": 0.6537253141831239,
      "recall": 0.7686015831134565
    },
    "max": {
      "accuracy": 0.8759015318590928,
      "ap": 0.7895033979635255,
      "f1": 0.7222722015165146
    }
  }
}