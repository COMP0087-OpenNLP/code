{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.870179412290636,
      "accuracy_threshold": 0.7455802835654299,
      "ap": 0.7658799058958976,
      "f1": 0.7038384786946824,
      "f1_threshold": 0.6857404990981372,
      "precision": 0.6339606682173821,
      "recall": 0.7910290237467018
    },
    "dot": {
      "accuracy": 0.8552184538356082,
      "accuracy_threshold": 0.3388685994114877,
      "ap": 0.7205117502559955,
      "f1": 0.6704558635889108,
      "f1_threshold": 0.3093895599375356,
      "precision": 0.5982198302628855,
      "recall": 0.762532981530343
    },
    "euclidean": {
      "accuracy": 0.8676163795672647,
      "accuracy_threshold": 0.47362643928053294,
      "ap": 0.7636355149729619,
      "f1": 0.7069204588428086,
      "f1_threshold": 0.5141639155794511,
      "precision": 0.6768042481293749,
      "recall": 0.7398416886543535
    },
    "evaluation_time": 1.3,
    "manhattan": {
      "accuracy": 0.8635632115396078,
      "accuracy_threshold": 8.193257338626795,
      "ap": 0.7533744904230933,
      "f1": 0.697127620894437,
      "f1_threshold": 8.962369466296739,
      "precision": 0.6446984980945977,
      "recall": 0.7588390501319261
    },
    "max": {
      "accuracy": 0.870179412290636,
      "ap": 0.7658799058958976,
      "f1": 0.7069204588428086
    }
  }
}