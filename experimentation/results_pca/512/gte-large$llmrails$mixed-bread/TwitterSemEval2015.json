{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8748882398521786,
      "accuracy_threshold": 0.7456881208346474,
      "ap": 0.7822424035076417,
      "f1": 0.7158394799349919,
      "f1_threshold": 0.7026614295017048,
      "precision": 0.6802090757899739,
      "recall": 0.7554089709762533
    },
    "dot": {
      "accuracy": 0.8547416105382368,
      "accuracy_threshold": 0.34840084684688666,
      "ap": 0.7237592458272181,
      "f1": 0.6694458067680236,
      "f1_threshold": 0.3168617473984558,
      "precision": 0.625286303252405,
      "recall": 0.7203166226912929
    },
    "euclidean": {
      "accuracy": 0.8742921857304643,
      "accuracy_threshold": 0.47793076181916055,
      "ap": 0.7862752394732337,
      "f1": 0.7200307377049181,
      "f1_threshold": 0.5142762141337988,
      "precision": 0.6996017919362867,
      "recall": 0.741688654353562
    },
    "evaluation_time": 0.84,
    "manhattan": {
      "accuracy": 0.8688084878106932,
      "accuracy_threshold": 7.8345094825984924,
      "ap": 0.76796815192814,
      "f1": 0.701501956329673,
      "f1_threshold": 8.438469352965168,
      "precision": 0.672392934914106,
      "recall": 0.733245382585752
    },
    "max": {
      "accuracy": 0.8748882398521786,
      "ap": 0.7862752394732337,
      "f1": 0.7200307377049181
    }
  }
}