{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8772128509268642,
      "accuracy_threshold": 0.7500212043313998,
      "ap": 0.7882473255453886,
      "f1": 0.7202893128819055,
      "f1_threshold": 0.7057892422198164,
      "precision": 0.682903759754079,
      "recall": 0.7620052770448549
    },
    "dot": {
      "accuracy": 0.8605829409310365,
      "accuracy_threshold": 0.46407687957036603,
      "ap": 0.7409136665535335,
      "f1": 0.6832313047653343,
      "f1_threshold": 0.4203240650797728,
      "precision": 0.6267341995155252,
      "recall": 0.7509234828496042
    },
    "euclidean": {
      "accuracy": 0.879299040352864,
      "accuracy_threshold": 0.5523163656718322,
      "ap": 0.7924292499570186,
      "f1": 0.723894939141576,
      "f1_threshold": 0.5889045744119001,
      "precision": 0.7036114570361146,
      "recall": 0.7453825857519789
    },
    "evaluation_time": 1.2,
    "manhattan": {
      "accuracy": 0.87453060737915,
      "accuracy_threshold": 9.165973928388071,
      "ap": 0.7825602788686914,
      "f1": 0.7167192429022081,
      "f1_threshold": 9.833789936030007,
      "precision": 0.686819830713422,
      "recall": 0.7493403693931399
    },
    "max": {
      "accuracy": 0.879299040352864,
      "ap": 0.7924292499570186,
      "f1": 0.723894939141576
    }
  }
}