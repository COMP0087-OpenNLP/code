{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8759015318590928,
      "accuracy_threshold": 0.7261839050754372,
      "ap": 0.7858956156687833,
      "f1": 0.7203214100570243,
      "f1_threshold": 0.6992748677195392,
      "precision": 0.7078451349974528,
      "recall": 0.733245382585752
    },
    "dot": {
      "accuracy": 0.8555760863086368,
      "accuracy_threshold": 0.48060665819477794,
      "ap": 0.7239633820577132,
      "f1": 0.6718537730023465,
      "f1_threshold": 0.4419067679684735,
      "precision": 0.6315300673322498,
      "recall": 0.7176781002638523
    },
    "euclidean": {
      "accuracy": 0.8759015318590928,
      "accuracy_threshold": 0.5924379925693115,
      "ap": 0.7896649414821507,
      "f1": 0.7206645898234684,
      "f1_threshold": 0.624722714240262,
      "precision": 0.7092488502810425,
      "recall": 0.7324538258575198
    },
    "evaluation_time": 0.85,
    "manhattan": {
      "accuracy": 0.8716099421827502,
      "accuracy_threshold": 9.682509755173701,
      "ap": 0.7731026177802498,
      "f1": 0.7038228858282919,
      "f1_threshold": 10.180695931317821,
      "precision": 0.6871073133953255,
      "recall": 0.7213720316622692
    },
    "max": {
      "accuracy": 0.8759015318590928,
      "ap": 0.7896649414821507,
      "f1": 0.7206645898234684
    }
  }
}