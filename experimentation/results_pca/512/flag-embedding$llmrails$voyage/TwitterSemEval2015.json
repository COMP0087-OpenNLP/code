{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8776896942242356,
      "accuracy_threshold": 0.7347454636442541,
      "ap": 0.7926759707024322,
      "f1": 0.7212647401840093,
      "f1_threshold": 0.6901623685889857,
      "precision": 0.7086834733893558,
      "recall": 0.7343007915567282
    },
    "dot": {
      "accuracy": 0.8620134708231507,
      "accuracy_threshold": 0.35898920953037017,
      "ap": 0.7371797509106952,
      "f1": 0.6852479598242309,
      "f1_threshold": 0.33759715088947095,
      "precision": 0.6536526946107785,
      "recall": 0.7200527704485488
    },
    "euclidean": {
      "accuracy": 0.8770936401025213,
      "accuracy_threshold": 0.51630835267339,
      "ap": 0.7939909301110757,
      "f1": 0.7213962508080155,
      "f1_threshold": 0.5553951576600036,
      "precision": 0.7072243346007605,
      "recall": 0.7361477572559367
    },
    "evaluation_time": 0.97,
    "manhattan": {
      "accuracy": 0.87327889372355,
      "accuracy_threshold": 8.556936995857665,
      "ap": 0.7813722866332782,
      "f1": 0.7079506691157176,
      "f1_threshold": 9.068136064341196,
      "precision": 0.704070981210856,
      "recall": 0.7118733509234828
    },
    "max": {
      "accuracy": 0.8776896942242356,
      "ap": 0.7939909301110757,
      "f1": 0.7213962508080155
    }
  }
}