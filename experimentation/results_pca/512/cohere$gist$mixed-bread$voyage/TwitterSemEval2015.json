{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8767956130416642,
      "accuracy_threshold": 0.7623704590237504,
      "ap": 0.7873311871600809,
      "f1": 0.7207207207207208,
      "f1_threshold": 0.7241474204974061,
      "precision": 0.6942067954045466,
      "recall": 0.7493403693931399
    },
    "dot": {
      "accuracy": 0.8587947785658938,
      "accuracy_threshold": 0.3872703772753915,
      "ap": 0.7295790257775994,
      "f1": 0.6703654565191172,
      "f1_threshold": 0.3525941084838182,
      "precision": 0.6174183514774495,
      "recall": 0.733245382585752
    },
    "euclidean": {
      "accuracy": 0.8780473266972642,
      "accuracy_threshold": 0.48842485221148285,
      "ap": 0.7897243246708705,
      "f1": 0.7236625774630074,
      "f1_threshold": 0.5242262679132188,
      "precision": 0.694923487976682,
      "recall": 0.7548812664907651
    },
    "evaluation_time": 1.57,
    "manhattan": {
      "accuracy": 0.8754842939738928,
      "accuracy_threshold": 8.182280687992257,
      "ap": 0.7826645280768194,
      "f1": 0.7173153692614771,
      "f1_threshold": 8.80183393072768,
      "precision": 0.6803123521060104,
      "recall": 0.758575197889182
    },
    "max": {
      "accuracy": 0.8780473266972642,
      "ap": 0.7897243246708705,
      "f1": 0.7236625774630074
    }
  }
}