{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8759611372712642,
      "accuracy_threshold": 0.747713360902776,
      "ap": 0.7859873358059457,
      "f1": 0.7178647866045575,
      "f1_threshold": 0.711523226096612,
      "precision": 0.6864916927522273,
      "recall": 0.7522427440633246
    },
    "dot": {
      "accuracy": 0.8604041246945222,
      "accuracy_threshold": 0.3929802141955633,
      "ap": 0.7363887343036161,
      "f1": 0.6792088760250844,
      "f1_threshold": 0.35629992096598817,
      "precision": 0.6254997778764994,
      "recall": 0.7430079155672823
    },
    "euclidean": {
      "accuracy": 0.8779877212850927,
      "accuracy_threshold": 0.5078570771213095,
      "ap": 0.789382248824732,
      "f1": 0.722120178430858,
      "f1_threshold": 0.5299540932371425,
      "precision": 0.7181628392484343,
      "recall": 0.7261213720316623
    },
    "evaluation_time": 1.19,
    "manhattan": {
      "accuracy": 0.8735769207844072,
      "accuracy_threshold": 8.34546539361629,
      "ap": 0.7804764692280686,
      "f1": 0.7156129032258064,
      "f1_threshold": 8.920897983476449,
      "precision": 0.7002525252525252,
      "recall": 0.7316622691292876
    },
    "max": {
      "accuracy": 0.8779877212850927,
      "ap": 0.789382248824732,
      "f1": 0.722120178430858
    }
  }
}