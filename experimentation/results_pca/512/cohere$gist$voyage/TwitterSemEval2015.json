{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8728020504261786,
      "accuracy_threshold": 0.7626001112779761,
      "ap": 0.7758248623965053,
      "f1": 0.7104874446085673,
      "f1_threshold": 0.7098813767802845,
      "precision": 0.6658975542224274,
      "recall": 0.7614775725593668
    },
    "dot": {
      "accuracy": 0.854622399713894,
      "accuracy_threshold": 0.39896654573128476,
      "ap": 0.7212364172563733,
      "f1": 0.6739632737443756,
      "f1_threshold": 0.37059402030722927,
      "precision": 0.6250845928265283,
      "recall": 0.7311345646437994
    },
    "euclidean": {
      "accuracy": 0.8720271800679502,
      "accuracy_threshold": 0.5019672295776881,
      "ap": 0.7750342699368235,
      "f1": 0.7127659574468085,
      "f1_threshold": 0.5415856924382847,
      "precision": 0.6853385289819776,
      "recall": 0.7424802110817942
    },
    "evaluation_time": 2.57,
    "manhattan": {
      "accuracy": 0.8692853311080646,
      "accuracy_threshold": 8.612749036013085,
      "ap": 0.7659902801637601,
      "f1": 0.7063306699446834,
      "f1_threshold": 9.312807688753761,
      "precision": 0.6612197928653625,
      "recall": 0.7580474934036939
    },
    "max": {
      "accuracy": 0.8728020504261786,
      "ap": 0.7758248623965053,
      "f1": 0.7127659574468085
    }
  }
}