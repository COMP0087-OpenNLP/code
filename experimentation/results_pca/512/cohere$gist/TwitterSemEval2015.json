{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8739941586696072,
      "accuracy_threshold": 0.7561064866591202,
      "ap": 0.778549788195919,
      "f1": 0.7134214100506235,
      "f1_threshold": 0.7104530395347918,
      "precision": 0.670457182640984,
      "recall": 0.7622691292875989
    },
    "dot": {
      "accuracy": 0.8570662216129225,
      "accuracy_threshold": 0.4940662089511517,
      "ap": 0.7278760546032377,
      "f1": 0.6769007615133568,
      "f1_threshold": 0.45221243258207533,
      "precision": 0.6245817532902075,
      "recall": 0.7387862796833773
    },
    "euclidean": {
      "accuracy": 0.8742325803182929,
      "accuracy_threshold": 0.569622281888909,
      "ap": 0.7798884546742153,
      "f1": 0.7159973666886109,
      "f1_threshold": 0.5874585262261328,
      "precision": 0.7145860709592641,
      "recall": 0.7174142480211082
    },
    "evaluation_time": 1.15,
    "manhattan": {
      "accuracy": 0.8707754664123503,
      "accuracy_threshold": 9.533247602302923,
      "ap": 0.770611116282445,
      "f1": 0.7101043522524816,
      "f1_threshold": 10.109801368181135,
      "precision": 0.6858407079646017,
      "recall": 0.7361477572559367
    },
    "max": {
      "accuracy": 0.8742325803182929,
      "ap": 0.7798884546742153,
      "f1": 0.7159973666886109
    }
  }
}