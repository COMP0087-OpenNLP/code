{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8759611372712642,
      "accuracy_threshold": 0.7439150985185068,
      "ap": 0.7832510757231148,
      "f1": 0.7164179104477612,
      "f1_threshold": 0.7060341495869986,
      "precision": 0.6776470588235294,
      "recall": 0.7598944591029023
    },
    "dot": {
      "accuracy": 0.8556356917208082,
      "accuracy_threshold": 0.4127198648165481,
      "ap": 0.7283993083414206,
      "f1": 0.66798810703667,
      "f1_threshold": 0.3759173688289781,
      "precision": 0.6296123306865951,
      "recall": 0.7113456464379947
    },
    "euclidean": {
      "accuracy": 0.8765571913929785,
      "accuracy_threshold": 0.5151909961282436,
      "ap": 0.7867099024897389,
      "f1": 0.7178631051752921,
      "f1_threshold": 0.5517111911028751,
      "precision": 0.6992744558418814,
      "recall": 0.737467018469657
    },
    "evaluation_time": 0.97,
    "manhattan": {
      "accuracy": 0.8700602014662931,
      "accuracy_threshold": 8.332861224970783,
      "ap": 0.7727689298456479,
      "f1": 0.7080649317186292,
      "f1_threshold": 9.016561011811014,
      "precision": 0.6918429003021148,
      "recall": 0.725065963060686
    },
    "max": {
      "accuracy": 0.8765571913929785,
      "ap": 0.7867099024897389,
      "f1": 0.7178631051752921
    }
  }
}