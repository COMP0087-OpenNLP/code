{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8760803480956071,
      "accuracy_threshold": 0.7303618586416525,
      "ap": 0.7869678347648252,
      "f1": 0.7196444909162201,
      "f1_threshold": 0.7034888186094591,
      "precision": 0.7130277130277131,
      "recall": 0.7263852242744063
    },
    "dot": {
      "accuracy": 0.8553376646599511,
      "accuracy_threshold": 0.48354821349657084,
      "ap": 0.7231897089891199,
      "f1": 0.6702649656526006,
      "f1_threshold": 0.44187386628423836,
      "precision": 0.6263182026593306,
      "recall": 0.720844327176781
    },
    "euclidean": {
      "accuracy": 0.8760803480956071,
      "accuracy_threshold": 0.5887059738055989,
      "ap": 0.7906949751858291,
      "f1": 0.721405335068315,
      "f1_threshold": 0.6219353629175947,
      "precision": 0.7116816431322208,
      "recall": 0.7313984168865435
    },
    "evaluation_time": 1.05,
    "manhattan": {
      "accuracy": 0.8710734934732074,
      "accuracy_threshold": 9.735686566498792,
      "ap": 0.7741891520150017,
      "f1": 0.7040723981900453,
      "f1_threshold": 10.125803927535303,
      "precision": 0.6902408111533587,
      "recall": 0.7184696569920844
    },
    "max": {
      "accuracy": 0.8760803480956071,
      "ap": 0.7906949751858291,
      "f1": 0.721405335068315
    }
  }
}