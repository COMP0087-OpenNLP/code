{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8772724563390356,
      "accuracy_threshold": 0.7301328529833606,
      "ap": 0.7876571983571395,
      "f1": 0.7168615984405459,
      "f1_threshold": 0.6854852713639099,
      "precision": 0.6659121774558624,
      "recall": 0.7762532981530343
    },
    "dot": {
      "accuracy": 0.8589735948024081,
      "accuracy_threshold": 0.4455878263808548,
      "ap": 0.737556160107827,
      "f1": 0.6838198911429986,
      "f1_threshold": 0.40968201243028585,
      "precision": 0.6436888681881695,
      "recall": 0.729287598944591
    },
    "euclidean": {
      "accuracy": 0.8772724563390356,
      "accuracy_threshold": 0.5571266608006596,
      "ap": 0.7895664822528664,
      "f1": 0.7195074020699594,
      "f1_threshold": 0.5879458049636674,
      "precision": 0.7145459276606818,
      "recall": 0.7245382585751979
    },
    "evaluation_time": 0.92,
    "manhattan": {
      "accuracy": 0.8738749478452643,
      "accuracy_threshold": 9.479246868260908,
      "ap": 0.7818004400215206,
      "f1": 0.7145641158893077,
      "f1_threshold": 9.979169273918846,
      "precision": 0.7038648579472742,
      "recall": 0.7255936675461742
    },
    "max": {
      "accuracy": 0.8772724563390356,
      "ap": 0.7895664822528664,
      "f1": 0.7195074020699594
    }
  }
}