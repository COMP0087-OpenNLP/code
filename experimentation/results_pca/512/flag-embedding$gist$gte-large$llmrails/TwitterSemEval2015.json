{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8764379805686356,
      "accuracy_threshold": 0.7322816775694311,
      "ap": 0.7859993205853343,
      "f1": 0.7197625525599801,
      "f1_threshold": 0.6935352420268676,
      "precision": 0.6773743016759777,
      "recall": 0.7678100263852242
    },
    "dot": {
      "accuracy": 0.8607021517553793,
      "accuracy_threshold": 0.41285688435889273,
      "ap": 0.7349667597591965,
      "f1": 0.6840652446675031,
      "f1_threshold": 0.3872832287334999,
      "precision": 0.6521531100478469,
      "recall": 0.7192612137203166
    },
    "euclidean": {
      "accuracy": 0.8766764022173213,
      "accuracy_threshold": 0.537541845143974,
      "ap": 0.7902714166430602,
      "f1": 0.7234911318106418,
      "f1_threshold": 0.5749905755538831,
      "precision": 0.7005189028910304,
      "recall": 0.7480211081794196
    },
    "evaluation_time": 1.06,
    "manhattan": {
      "accuracy": 0.8702986231149789,
      "accuracy_threshold": 8.745167863473682,
      "ap": 0.7739148443415971,
      "f1": 0.7077486272117144,
      "f1_threshold": 9.549683531655791,
      "precision": 0.6583427922814983,
      "recall": 0.7651715039577837
    },
    "max": {
      "accuracy": 0.8766764022173213,
      "ap": 0.7902714166430602,
      "f1": 0.7234911318106418
    }
  }
}