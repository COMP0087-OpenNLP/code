{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8757227156225785,
      "accuracy_threshold": 0.7352903582441693,
      "ap": 0.7829238292378584,
      "f1": 0.716494186789319,
      "f1_threshold": 0.7076725658061875,
      "precision": 0.6945751795888035,
      "recall": 0.7398416886543535
    },
    "dot": {
      "accuracy": 0.8545627943017226,
      "accuracy_threshold": 0.4213694764585848,
      "ap": 0.7215885458431309,
      "f1": 0.6664183736809435,
      "f1_threshold": 0.38564479119916345,
      "precision": 0.6293083235638921,
      "recall": 0.7081794195250659
    },
    "euclidean": {
      "accuracy": 0.8756035047982357,
      "accuracy_threshold": 0.5311861978648985,
      "ap": 0.7872779787118485,
      "f1": 0.7203528670447387,
      "f1_threshold": 0.5717547232840998,
      "precision": 0.6895054282267793,
      "recall": 0.754089709762533
    },
    "evaluation_time": 1.06,
    "manhattan": {
      "accuracy": 0.869344936520236,
      "accuracy_threshold": 8.439097788317419,
      "ap": 0.7702261844783187,
      "f1": 0.7023658102264055,
      "f1_threshold": 9.21552376435589,
      "precision": 0.6780451866404715,
      "recall": 0.7284960422163589
    },
    "max": {
      "accuracy": 0.8757227156225785,
      "ap": 0.7872779787118485,
      "f1": 0.7203528670447387
    }
  }
}