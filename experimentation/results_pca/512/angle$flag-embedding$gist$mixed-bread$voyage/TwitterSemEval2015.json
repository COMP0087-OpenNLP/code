{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8756631102104071,
      "accuracy_threshold": 0.740397207424291,
      "ap": 0.7853221332483056,
      "f1": 0.7189559047136341,
      "f1_threshold": 0.7089910225706683,
      "precision": 0.6916138469039493,
      "recall": 0.7485488126649077
    },
    "dot": {
      "accuracy": 0.8595696489241224,
      "accuracy_threshold": 0.4439494555273559,
      "ap": 0.7349795292249632,
      "f1": 0.6774572510116172,
      "f1_threshold": 0.42868526013040287,
      "precision": 0.6703694135882201,
      "recall": 0.6846965699208444
    },
    "euclidean": {
      "accuracy": 0.8768552184538356,
      "accuracy_threshold": 0.5467611127895369,
      "ap": 0.7895058566244445,
      "f1": 0.7209535759096612,
      "f1_threshold": 0.5918666386274855,
      "precision": 0.6873205741626794,
      "recall": 0.7580474934036939
    },
    "evaluation_time": 2.3,
    "manhattan": {
      "accuracy": 0.8718483638314359,
      "accuracy_threshold": 8.981382429666908,
      "ap": 0.77556688963259,
      "f1": 0.7070605908863294,
      "f1_threshold": 9.606624826031648,
      "precision": 0.6727012863268222,
      "recall": 0.7451187335092349
    },
    "max": {
      "accuracy": 0.8768552184538356,
      "ap": 0.7895058566244445,
      "f1": 0.7209535759096612
    }
  }
}