{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8760803480956071,
      "accuracy_threshold": 0.7427273096104006,
      "ap": 0.7856836859202527,
      "f1": 0.7185337093053062,
      "f1_threshold": 0.7107914824142301,
      "precision": 0.698654037886341,
      "recall": 0.7395778364116095
    },
    "dot": {
      "accuracy": 0.858258329856351,
      "accuracy_threshold": 0.40408041721911864,
      "ap": 0.7328902176699287,
      "f1": 0.6763110307414105,
      "f1_threshold": 0.38603273226087564,
      "precision": 0.6624493927125507,
      "recall": 0.6907651715039578
    },
    "euclidean": {
      "accuracy": 0.8768552184538356,
      "accuracy_threshold": 0.5239698869866372,
      "ap": 0.789757690886703,
      "f1": 0.7216338880484116,
      "f1_threshold": 0.564377857302113,
      "precision": 0.6909705456301304,
      "recall": 0.7551451187335092
    },
    "evaluation_time": 2.29,
    "manhattan": {
      "accuracy": 0.8713715205340645,
      "accuracy_threshold": 8.516682923192576,
      "ap": 0.7752887778104548,
      "f1": 0.7061321343824153,
      "f1_threshold": 9.222995457515172,
      "precision": 0.6703817880009485,
      "recall": 0.745910290237467
    },
    "max": {
      "accuracy": 0.8768552184538356,
      "ap": 0.789757690886703,
      "f1": 0.7216338880484116
    }
  }
}