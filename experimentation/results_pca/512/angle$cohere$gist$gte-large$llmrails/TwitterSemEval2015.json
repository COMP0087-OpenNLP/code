{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8770936401025213,
      "accuracy_threshold": 0.7509968078095928,
      "ap": 0.7859540580300368,
      "f1": 0.7201783723522853,
      "f1_threshold": 0.7076908756483511,
      "precision": 0.6787298622460892,
      "recall": 0.767018469656992
    },
    "dot": {
      "accuracy": 0.8601657030458366,
      "accuracy_threshold": 0.4388238416673984,
      "ap": 0.7377984075577838,
      "f1": 0.6783396596057304,
      "f1_threshold": 0.3995212307661521,
      "precision": 0.6328535526616403,
      "recall": 0.7308707124010554
    },
    "euclidean": {
      "accuracy": 0.8785241699946356,
      "accuracy_threshold": 0.5335597906224214,
      "ap": 0.7899601581625495,
      "f1": 0.7233329033922353,
      "f1_threshold": 0.5642487026191454,
      "precision": 0.7075447893010346,
      "recall": 0.7398416886543535
    },
    "evaluation_time": 1.56,
    "manhattan": {
      "accuracy": 0.87369613160875,
      "accuracy_threshold": 8.95570542068273,
      "ap": 0.7799175298655656,
      "f1": 0.7159748427672956,
      "f1_threshold": 9.51482264781038,
      "precision": 0.6841346153846154,
      "recall": 0.7509234828496042
    },
    "max": {
      "accuracy": 0.8785241699946356,
      "ap": 0.7899601581625495,
      "f1": 0.7233329033922353
    }
  }
}