{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8759015318590928,
      "accuracy_threshold": 0.7328117026736634,
      "ap": 0.7852007671802264,
      "f1": 0.7190369818813601,
      "f1_threshold": 0.6969744223386602,
      "precision": 0.6787722586691659,
      "recall": 0.7643799472295515
    },
    "dot": {
      "accuracy": 0.8602849138701794,
      "accuracy_threshold": 0.40716935803536936,
      "ap": 0.7333781262431378,
      "f1": 0.68172015730052,
      "f1_threshold": 0.38548877948801374,
      "precision": 0.6564866845834352,
      "recall": 0.7089709762532982
    },
    "euclidean": {
      "accuracy": 0.8761995589199499,
      "accuracy_threshold": 0.5338552486063844,
      "ap": 0.7894153510227422,
      "f1": 0.7223637289862456,
      "f1_threshold": 0.5704865915189512,
      "precision": 0.6981782373215165,
      "recall": 0.7482849604221636
    },
    "evaluation_time": 0.84,
    "manhattan": {
      "accuracy": 0.8706562555880074,
      "accuracy_threshold": 8.57173360788666,
      "ap": 0.7738232918461947,
      "f1": 0.7051187852069557,
      "f1_threshold": 9.427642265301683,
      "precision": 0.6579067641681902,
      "recall": 0.7596306068601583
    },
    "max": {
      "accuracy": 0.8761995589199499,
      "ap": 0.7894153510227422,
      "f1": 0.7223637289862456
    }
  }
}