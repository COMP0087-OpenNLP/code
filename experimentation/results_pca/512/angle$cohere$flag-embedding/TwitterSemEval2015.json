{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.878583775406807,
      "accuracy_threshold": 0.736567366211165,
      "ap": 0.7889282968071558,
      "f1": 0.7193695983731572,
      "f1_threshold": 0.7055573051783521,
      "precision": 0.6939676311917606,
      "recall": 0.7467018469656992
    },
    "dot": {
      "accuracy": 0.8583179352685224,
      "accuracy_threshold": 0.44257938334866953,
      "ap": 0.7371543259461925,
      "f1": 0.6807720861172977,
      "f1_threshold": 0.41311372973920535,
      "precision": 0.6409599254426841,
      "recall": 0.7258575197889182
    },
    "euclidean": {
      "accuracy": 0.8788818024676641,
      "accuracy_threshold": 0.5557628681513447,
      "ap": 0.7930677677496344,
      "f1": 0.7239969332992588,
      "f1_threshold": 0.5898745648235686,
      "precision": 0.7019326065411299,
      "recall": 0.7474934036939314
    },
    "evaluation_time": 0.97,
    "manhattan": {
      "accuracy": 0.8754842939738928,
      "accuracy_threshold": 9.313181217473105,
      "ap": 0.7836426342083025,
      "f1": 0.7174828857293312,
      "f1_threshold": 9.646325791001711,
      "precision": 0.7159747766684182,
      "recall": 0.7189973614775725
    },
    "max": {
      "accuracy": 0.8788818024676641,
      "ap": 0.7930677677496344,
      "f1": 0.7239969332992588
    }
  }
}