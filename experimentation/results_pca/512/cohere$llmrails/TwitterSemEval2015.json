{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8745902127913214,
      "accuracy_threshold": 0.7258488910258676,
      "ap": 0.7814574083733596,
      "f1": 0.7106957949236015,
      "f1_threshold": 0.6879002361858069,
      "precision": 0.681520949382417,
      "recall": 0.7424802110817942
    },
    "dot": {
      "accuracy": 0.8623114978840078,
      "accuracy_threshold": 0.5412578022237219,
      "ap": 0.7450416434297638,
      "f1": 0.6876834716017868,
      "f1_threshold": 0.5078933666780714,
      "precision": 0.6660074165636588,
      "recall": 0.7108179419525066
    },
    "euclidean": {
      "accuracy": 0.876914823866007,
      "accuracy_threshold": 0.6424146332600267,
      "ap": 0.787701971410957,
      "f1": 0.7148197596795728,
      "f1_threshold": 0.6591841020291533,
      "precision": 0.7235135135135136,
      "recall": 0.7063324538258575
    },
    "evaluation_time": 1.47,
    "manhattan": {
      "accuracy": 0.8650533468438935,
      "accuracy_threshold": 14.33613071717349,
      "ap": 0.7600868133686747,
      "f1": 0.6962828649138713,
      "f1_threshold": 15.293646132362845,
      "precision": 0.6837954718901043,
      "recall": 0.7092348284960422
    },
    "max": {
      "accuracy": 0.876914823866007,
      "ap": 0.787701971410957,
      "f1": 0.7148197596795728
    }
  }
}