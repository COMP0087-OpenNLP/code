{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8737557370209215,
      "accuracy_threshold": 0.7519176727595169,
      "ap": 0.776866412816347,
      "f1": 0.7092494779511116,
      "f1_threshold": 0.7053679929831993,
      "precision": 0.6635256262928062,
      "recall": 0.7617414248021108
    },
    "dot": {
      "accuracy": 0.8556952971329796,
      "accuracy_threshold": 0.4109569187057291,
      "ap": 0.7236384115501241,
      "f1": 0.6730486008836524,
      "f1_threshold": 0.37578612849722476,
      "precision": 0.6291877007801744,
      "recall": 0.7234828496042216
    },
    "euclidean": {
      "accuracy": 0.87327889372355,
      "accuracy_threshold": 0.5234800743337793,
      "ap": 0.7783651578431962,
      "f1": 0.7123320827786518,
      "f1_threshold": 0.5633601282958907,
      "precision": 0.6579476861167002,
      "recall": 0.7765171503957784
    },
    "evaluation_time": 0.92,
    "manhattan": {
      "accuracy": 0.8691661202837218,
      "accuracy_threshold": 8.75206019833625,
      "ap": 0.767849396050215,
      "f1": 0.7045542014111611,
      "f1_threshold": 9.241909809540054,
      "precision": 0.6856429463171037,
      "recall": 0.7245382585751979
    },
    "max": {
      "accuracy": 0.8737557370209215,
      "ap": 0.7783651578431962,
      "f1": 0.7123320827786518
    }
  }
}