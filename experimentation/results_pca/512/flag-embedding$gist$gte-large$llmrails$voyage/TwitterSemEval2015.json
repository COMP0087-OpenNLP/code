{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8753054777373785,
      "accuracy_threshold": 0.7454362713430547,
      "ap": 0.7860182023070899,
      "f1": 0.7190187152250885,
      "f1_threshold": 0.7067901035139518,
      "precision": 0.6903836813987373,
      "recall": 0.750131926121372
    },
    "dot": {
      "accuracy": 0.861357811289265,
      "accuracy_threshold": 0.365193723405952,
      "ap": 0.739391182317297,
      "f1": 0.6849042526734643,
      "f1_threshold": 0.343305795153943,
      "precision": 0.647695202257761,
      "recall": 0.7266490765171504
    },
    "euclidean": {
      "accuracy": 0.8760803480956071,
      "accuracy_threshold": 0.4989808394044356,
      "ap": 0.7898955649776571,
      "f1": 0.7229857521119656,
      "f1_threshold": 0.5367104517821645,
      "precision": 0.6923448442405216,
      "recall": 0.7564643799472296
    },
    "evaluation_time": 1.64,
    "manhattan": {
      "accuracy": 0.8718483638314359,
      "accuracy_threshold": 8.191990424434302,
      "ap": 0.7753651200713887,
      "f1": 0.7070980440398572,
      "f1_threshold": 8.842715578626656,
      "precision": 0.6623646001382807,
      "recall": 0.758311345646438
    },
    "max": {
      "accuracy": 0.8760803480956071,
      "ap": 0.7898955649776571,
      "f1": 0.7229857521119656
    }
  }
}