{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8761995589199499,
      "accuracy_threshold": 0.7276833125235642,
      "ap": 0.7861054959108963,
      "f1": 0.7187942805616386,
      "f1_threshold": 0.6962470417218073,
      "precision": 0.7022401208155047,
      "recall": 0.7361477572559367
    },
    "dot": {
      "accuracy": 0.8553376646599511,
      "accuracy_threshold": 0.4085305152415124,
      "ap": 0.7213037432989287,
      "f1": 0.6691046658259774,
      "f1_threshold": 0.38387567559807423,
      "precision": 0.6408212560386474,
      "recall": 0.7
    },
    "euclidean": {
      "accuracy": 0.8753054777373785,
      "accuracy_threshold": 0.555288440663172,
      "ap": 0.7897923662535372,
      "f1": 0.7215756490599821,
      "f1_threshold": 0.5841986600844393,
      "precision": 0.7001737403822288,
      "recall": 0.7443271767810027
    },
    "evaluation_time": 1.3,
    "manhattan": {
      "accuracy": 0.8670203254455504,
      "accuracy_threshold": 10.920420557216929,
      "ap": 0.7654683568019868,
      "f1": 0.6970839617898441,
      "f1_threshold": 11.66564533661641,
      "precision": 0.6656265002400384,
      "recall": 0.7316622691292876
    },
    "max": {
      "accuracy": 0.8761995589199499,
      "ap": 0.7897923662535372,
      "f1": 0.7215756490599821
    }
  }
}