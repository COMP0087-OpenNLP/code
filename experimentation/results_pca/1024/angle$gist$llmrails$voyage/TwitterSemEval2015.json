{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8761399535077785,
      "accuracy_threshold": 0.7399250266211655,
      "ap": 0.7852815433676481,
      "f1": 0.7188220230473752,
      "f1_threshold": 0.7044891827664292,
      "precision": 0.6982587064676616,
      "recall": 0.7406332453825858
    },
    "dot": {
      "accuracy": 0.8616558383501222,
      "accuracy_threshold": 0.4379005526637152,
      "ap": 0.7394990047257467,
      "f1": 0.6815529053539711,
      "f1_threshold": 0.4127886776953815,
      "precision": 0.6564027370478983,
      "recall": 0.7087071240105541
    },
    "euclidean": {
      "accuracy": 0.8760803480956071,
      "accuracy_threshold": 0.5567564887491332,
      "ap": 0.7890398960268697,
      "f1": 0.7225278239733913,
      "f1_threshold": 0.5900828861858951,
      "precision": 0.7012664514526943,
      "recall": 0.7451187335092349
    },
    "evaluation_time": 4.17,
    "manhattan": {
      "accuracy": 0.8660070334386363,
      "accuracy_threshold": 11.757054749453474,
      "ap": 0.7608734371543842,
      "f1": 0.6945403401099604,
      "f1_threshold": 12.538980251198577,
      "precision": 0.6737782188042669,
      "recall": 0.716622691292876
    },
    "max": {
      "accuracy": 0.8761399535077785,
      "ap": 0.7890398960268697,
      "f1": 0.7225278239733913
    }
  }
}