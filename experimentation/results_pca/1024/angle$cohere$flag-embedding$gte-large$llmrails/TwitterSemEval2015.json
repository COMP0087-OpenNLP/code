{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8771532455146928,
      "accuracy_threshold": 0.7277135945796698,
      "ap": 0.7867982604606651,
      "f1": 0.7171417515800337,
      "f1_threshold": 0.6998973471321805,
      "precision": 0.70148877113298,
      "recall": 0.7335092348284961
    },
    "dot": {
      "accuracy": 0.8618942599988079,
      "accuracy_threshold": 0.4676006950489484,
      "ap": 0.7419254399971831,
      "f1": 0.6847364476642518,
      "f1_threshold": 0.43625730623620246,
      "precision": 0.6501423149905123,
      "recall": 0.7232189973614775
    },
    "euclidean": {
      "accuracy": 0.8784049591702927,
      "accuracy_threshold": 0.5852003382091744,
      "ap": 0.7927470643773518,
      "f1": 0.7208527648234511,
      "f1_threshold": 0.6065161894775954,
      "precision": 0.7281292059219381,
      "recall": 0.7137203166226913
    },
    "evaluation_time": 1.91,
    "manhattan": {
      "accuracy": 0.867377957918579,
      "accuracy_threshold": 12.960733285892733,
      "ap": 0.7659379196770189,
      "f1": 0.700750711881957,
      "f1_threshold": 13.700381918727611,
      "precision": 0.6877540650406504,
      "recall": 0.7142480211081794
    },
    "max": {
      "accuracy": 0.8784049591702927,
      "ap": 0.7927470643773518,
      "f1": 0.7208527648234511
    }
  }
}