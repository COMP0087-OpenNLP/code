{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8744710019669786,
      "accuracy_threshold": 0.7467492076924904,
      "ap": 0.7805994643836863,
      "f1": 0.7137527978114897,
      "f1_threshold": 0.7038799089792782,
      "precision": 0.6749764816556915,
      "recall": 0.7572559366754618
    },
    "dot": {
      "accuracy": 0.8593908326876081,
      "accuracy_threshold": 0.4593293123118102,
      "ap": 0.7370636433895877,
      "f1": 0.6757363954068897,
      "f1_threshold": 0.42405009012276895,
      "precision": 0.6411653244907627,
      "recall": 0.7142480211081794
    },
    "euclidean": {
      "accuracy": 0.8772724563390356,
      "accuracy_threshold": 0.5502102758944827,
      "ap": 0.7869411976455558,
      "f1": 0.7173660426081343,
      "f1_threshold": 0.5866154281222582,
      "precision": 0.702402022756005,
      "recall": 0.732981530343008
    },
    "evaluation_time": 1.73,
    "manhattan": {
      "accuracy": 0.8645168981343506,
      "accuracy_threshold": 12.521892951511722,
      "ap": 0.7581938933067145,
      "f1": 0.6976291793313071,
      "f1_threshold": 13.489375802378895,
      "precision": 0.6468996617812852,
      "recall": 0.7569920844327177
    },
    "max": {
      "accuracy": 0.8772724563390356,
      "ap": 0.7869411976455558,
      "f1": 0.7173660426081343
    }
  }
}