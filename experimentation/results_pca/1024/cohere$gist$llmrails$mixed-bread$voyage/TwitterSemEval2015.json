{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8772128509268642,
      "accuracy_threshold": 0.736409197024281,
      "ap": 0.7877359178372506,
      "f1": 0.7205863768482245,
      "f1_threshold": 0.7040812003563187,
      "precision": 0.6914867814698036,
      "recall": 0.7522427440633246
    },
    "dot": {
      "accuracy": 0.8644572927221792,
      "accuracy_threshold": 0.479453696068151,
      "ap": 0.7499669145837615,
      "f1": 0.6907103825136611,
      "f1_threshold": 0.4414306040586361,
      "precision": 0.6398200224971878,
      "recall": 0.7503957783641161
    },
    "euclidean": {
      "accuracy": 0.8788221970554927,
      "accuracy_threshold": 0.5758480193120686,
      "ap": 0.7930866997987067,
      "f1": 0.723042739511175,
      "f1_threshold": 0.6054999851201552,
      "precision": 0.7163947163947164,
      "recall": 0.7298153034300792
    },
    "evaluation_time": 2.05,
    "manhattan": {
      "accuracy": 0.8679144066281218,
      "accuracy_threshold": 12.834161043697787,
      "ap": 0.768434311475462,
      "f1": 0.7036169659120478,
      "f1_threshold": 13.534750170836112,
      "precision": 0.6940451745379876,
      "recall": 0.7134564643799473
    },
    "max": {
      "accuracy": 0.8788221970554927,
      "ap": 0.7930866997987067,
      "f1": 0.723042739511175
    }
  }
}