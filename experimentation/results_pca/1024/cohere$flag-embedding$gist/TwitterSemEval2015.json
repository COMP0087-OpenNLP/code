{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.87327889372355,
      "accuracy_threshold": 0.7412982005143687,
      "ap": 0.7768433350664501,
      "f1": 0.7095261599210267,
      "f1_threshold": 0.6951076039366159,
      "precision": 0.6664348632359759,
      "recall": 0.758575197889182
    },
    "dot": {
      "accuracy": 0.861775049174465,
      "accuracy_threshold": 0.5554683892688694,
      "ap": 0.7472542264592109,
      "f1": 0.6883083290222453,
      "f1_threshold": 0.5293191855699004,
      "precision": 0.6750380517503806,
      "recall": 0.7021108179419525
    },
    "euclidean": {
      "accuracy": 0.8756631102104071,
      "accuracy_threshold": 0.6301749173600173,
      "ap": 0.7822728811182063,
      "f1": 0.7121977145894234,
      "f1_threshold": 0.6503887497658473,
      "precision": 0.7173447537473233,
      "recall": 0.7071240105540897
    },
    "evaluation_time": 1.37,
    "manhattan": {
      "accuracy": 0.8632651844787507,
      "accuracy_threshold": 13.991831582197287,
      "ap": 0.7544317929115197,
      "f1": 0.6944825009341138,
      "f1_threshold": 15.303900621289285,
      "precision": 0.6577022882755367,
      "recall": 0.7356200527704485
    },
    "max": {
      "accuracy": 0.8756631102104071,
      "ap": 0.7822728811182063,
      "f1": 0.7121977145894234
    }
  }
}