{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8751862669130357,
      "accuracy_threshold": 0.7428977110104784,
      "ap": 0.7851677996739146,
      "f1": 0.7180971558016612,
      "f1_threshold": 0.6985094001199263,
      "precision": 0.6864773820981713,
      "recall": 0.7527704485488127
    },
    "dot": {
      "accuracy": 0.8611193896405793,
      "accuracy_threshold": 0.3907229589921187,
      "ap": 0.7380468209512729,
      "f1": 0.6840269125342637,
      "f1_threshold": 0.36193993575500916,
      "precision": 0.6480169971671388,
      "recall": 0.7242744063324539
    },
    "euclidean": {
      "accuracy": 0.8755438993860643,
      "accuracy_threshold": 0.5235767209645864,
      "ap": 0.7890687341957021,
      "f1": 0.7208636836628511,
      "f1_threshold": 0.5511847667489713,
      "precision": 0.7108773730118009,
      "recall": 0.7311345646437994
    },
    "evaluation_time": 1.97,
    "manhattan": {
      "accuracy": 0.8675567741550932,
      "accuracy_threshold": 10.780817488682953,
      "ap": 0.7644521801968132,
      "f1": 0.6978461538461539,
      "f1_threshold": 11.620279596352788,
      "precision": 0.6539792387543253,
      "recall": 0.7480211081794196
    },
    "max": {
      "accuracy": 0.8755438993860643,
      "ap": 0.7890687341957021,
      "f1": 0.7208636836628511
    }
  }
}