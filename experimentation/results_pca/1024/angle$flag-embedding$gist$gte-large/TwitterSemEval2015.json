{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8738749478452643,
      "accuracy_threshold": 0.7490759969813359,
      "ap": 0.7812605195262018,
      "f1": 0.7152847152847152,
      "f1_threshold": 0.7003100238156907,
      "precision": 0.6789947842579421,
      "recall": 0.7556728232189973
    },
    "dot": {
      "accuracy": 0.8585563569172081,
      "accuracy_threshold": 0.43439691951231174,
      "ap": 0.7306477429091676,
      "f1": 0.6769074520756633,
      "f1_threshold": 0.4125306521657075,
      "precision": 0.6523122094445803,
      "recall": 0.7034300791556728
    },
    "euclidean": {
      "accuracy": 0.8751266615008643,
      "accuracy_threshold": 0.5559774699232738,
      "ap": 0.7858085765033334,
      "f1": 0.7192192192192193,
      "f1_threshold": 0.5915147881141287,
      "precision": 0.6839600190385531,
      "recall": 0.758311345646438
    },
    "evaluation_time": 1.56,
    "manhattan": {
      "accuracy": 0.8666626929725219,
      "accuracy_threshold": 11.00716531347636,
      "ap": 0.7633591857595721,
      "f1": 0.6958453096420173,
      "f1_threshold": 11.501511705200329,
      "precision": 0.6891821946169773,
      "recall": 0.7026385224274406
    },
    "max": {
      "accuracy": 0.8751266615008643,
      "ap": 0.7858085765033334,
      "f1": 0.7192192192192193
    }
  }
}