{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.87369613160875,
      "accuracy_threshold": 0.7399688196764008,
      "ap": 0.7819044082405094,
      "f1": 0.7163663293014071,
      "f1_threshold": 0.6946779290498204,
      "precision": 0.6730055658627088,
      "recall": 0.7656992084432718
    },
    "dot": {
      "accuracy": 0.8590332002145795,
      "accuracy_threshold": 0.4398486143832322,
      "ap": 0.7317534714146681,
      "f1": 0.6783173136936712,
      "f1_threshold": 0.4133309028617238,
      "precision": 0.6436863302534944,
      "recall": 0.7168865435356201
    },
    "euclidean": {
      "accuracy": 0.8752458723252071,
      "accuracy_threshold": 0.5625783382462708,
      "ap": 0.7864994048666731,
      "f1": 0.7195474544311753,
      "f1_threshold": 0.5956364276595865,
      "precision": 0.6871548619447779,
      "recall": 0.7551451187335092
    },
    "evaluation_time": 1.63,
    "manhattan": {
      "accuracy": 0.8664838767360076,
      "accuracy_threshold": 11.083587975584997,
      "ap": 0.7636277310614521,
      "f1": 0.6973180076628352,
      "f1_threshold": 11.738813085555723,
      "precision": 0.6757425742574258,
      "recall": 0.7203166226912929
    },
    "max": {
      "accuracy": 0.8752458723252071,
      "ap": 0.7864994048666731,
      "f1": 0.7195474544311753
    }
  }
}