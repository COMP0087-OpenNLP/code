{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8743517911426357,
      "accuracy_threshold": 0.7285322837038666,
      "ap": 0.7821884855262162,
      "f1": 0.715587044534413,
      "f1_threshold": 0.7002630809659656,
      "precision": 0.6874088478366553,
      "recall": 0.7461741424802111
    },
    "dot": {
      "accuracy": 0.8576622757346367,
      "accuracy_threshold": 0.509044967929515,
      "ap": 0.7280709899125797,
      "f1": 0.6732017823042648,
      "f1_threshold": 0.4857915584795673,
      "precision": 0.650430504305043,
      "recall": 0.6976253298153035
    },
    "euclidean": {
      "accuracy": 0.8751862669130357,
      "accuracy_threshold": 0.5888710614361592,
      "ap": 0.7868430080196813,
      "f1": 0.7185813415574402,
      "f1_threshold": 0.639299635970961,
      "precision": 0.7004008016032064,
      "recall": 0.7377308707124011
    },
    "evaluation_time": 1.3,
    "manhattan": {
      "accuracy": 0.8676759849794361,
      "accuracy_threshold": 11.972262195439285,
      "ap": 0.7647019418948622,
      "f1": 0.6943634596695821,
      "f1_threshold": 12.91799889322335,
      "precision": 0.6434038721296713,
      "recall": 0.754089709762533
    },
    "max": {
      "accuracy": 0.8751862669130357,
      "ap": 0.7868430080196813,
      "f1": 0.7185813415574402
    }
  }
}