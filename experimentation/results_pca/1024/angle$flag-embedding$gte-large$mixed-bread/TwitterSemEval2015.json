{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8755438993860643,
      "accuracy_threshold": 0.7324096216627751,
      "ap": 0.782422852030055,
      "f1": 0.7162957278076235,
      "f1_threshold": 0.7024901925828062,
      "precision": 0.6951340615690169,
      "recall": 0.7387862796833773
    },
    "dot": {
      "accuracy": 0.8545627943017226,
      "accuracy_threshold": 0.4343871209138788,
      "ap": 0.719848110313733,
      "f1": 0.6654862779815353,
      "f1_threshold": 0.4000669608299572,
      "precision": 0.6390575661889726,
      "recall": 0.6941952506596306
    },
    "euclidean": {
      "accuracy": 0.8754246885617214,
      "accuracy_threshold": 0.5508139046626224,
      "ap": 0.7868797535135423,
      "f1": 0.7186415468517601,
      "f1_threshold": 0.5922664907087665,
      "precision": 0.6776531089294062,
      "recall": 0.7649076517150396
    },
    "evaluation_time": 1.67,
    "manhattan": {
      "accuracy": 0.8666626929725219,
      "accuracy_threshold": 10.98207713507652,
      "ap": 0.7625845510293704,
      "f1": 0.6937114349481424,
      "f1_threshold": 11.454431824539466,
      "precision": 0.6903579827541155,
      "recall": 0.6970976253298153
    },
    "max": {
      "accuracy": 0.8755438993860643,
      "ap": 0.7868797535135423,
      "f1": 0.7186415468517601
    }
  }
}