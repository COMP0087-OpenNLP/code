{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8783453537581213,
      "accuracy_threshold": 0.7235628655800785,
      "ap": 0.7890333483846953,
      "f1": 0.7188244638602066,
      "f1_threshold": 0.701627595584162,
      "precision": 0.721307120085016,
      "recall": 0.716358839050132
    },
    "dot": {
      "accuracy": 0.8623711032961793,
      "accuracy_threshold": 0.5066536930060098,
      "ap": 0.7413143609056316,
      "f1": 0.6858670555353019,
      "f1_threshold": 0.4598496793895914,
      "precision": 0.635728767740482,
      "recall": 0.7445910290237467
    },
    "euclidean": {
      "accuracy": 0.8788818024676641,
      "accuracy_threshold": 0.6174809116668973,
      "ap": 0.795042453428335,
      "f1": 0.7238542890716804,
      "f1_threshold": 0.6411656265827315,
      "precision": 0.7164642026363401,
      "recall": 0.7313984168865435
    },
    "evaluation_time": 1.71,
    "manhattan": {
      "accuracy": 0.8686892769863503,
      "accuracy_threshold": 13.578575595540997,
      "ap": 0.7683913997397518,
      "f1": 0.7038755800827794,
      "f1_threshold": 14.462959425446837,
      "precision": 0.6708104231412861,
      "recall": 0.7403693931398417
    },
    "max": {
      "accuracy": 0.8788818024676641,
      "ap": 0.795042453428335,
      "f1": 0.7238542890716804
    }
  }
}