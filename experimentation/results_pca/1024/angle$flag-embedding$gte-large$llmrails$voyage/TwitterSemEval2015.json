{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8759611372712642,
      "accuracy_threshold": 0.723327381113188,
      "ap": 0.7856507456268095,
      "f1": 0.7187257187257187,
      "f1_threshold": 0.7004667398672588,
      "precision": 0.7057477110885045,
      "recall": 0.7321899736147758
    },
    "dot": {
      "accuracy": 0.8580795136198367,
      "accuracy_threshold": 0.3742876770446685,
      "ap": 0.7289185369486612,
      "f1": 0.6743266617247343,
      "f1_threshold": 0.34744061522963493,
      "precision": 0.6340613382899628,
      "recall": 0.7200527704485488
    },
    "euclidean": {
      "accuracy": 0.8754842939738928,
      "accuracy_threshold": 0.5180355674336408,
      "ap": 0.7891676150089623,
      "f1": 0.72165488347735,
      "f1_threshold": 0.5491579032557488,
      "precision": 0.7162162162162162,
      "recall": 0.7271767810026385
    },
    "evaluation_time": 2.05,
    "manhattan": {
      "accuracy": 0.8672587470942361,
      "accuracy_threshold": 10.751324790653285,
      "ap": 0.7633346140473426,
      "f1": 0.696528555431131,
      "f1_threshold": 11.568458237002904,
      "precision": 0.6590534494937603,
      "recall": 0.7385224274406332
    },
    "max": {
      "accuracy": 0.8759611372712642,
      "ap": 0.7891676150089623,
      "f1": 0.72165488347735
    }
  }
}