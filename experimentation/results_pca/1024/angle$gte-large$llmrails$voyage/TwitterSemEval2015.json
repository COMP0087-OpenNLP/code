{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8756631102104071,
      "accuracy_threshold": 0.731623843426128,
      "ap": 0.7843314200768767,
      "f1": 0.7180023532487907,
      "f1_threshold": 0.7056848742099482,
      "precision": 0.7115833117387924,
      "recall": 0.7245382585751979
    },
    "dot": {
      "accuracy": 0.8600464922214938,
      "accuracy_threshold": 0.34740477946473625,
      "ap": 0.7337746774705123,
      "f1": 0.6778656126482213,
      "f1_threshold": 0.32235641419898176,
      "precision": 0.6372503483511379,
      "recall": 0.7240105540897097
    },
    "euclidean": {
      "accuracy": 0.8760207426834357,
      "accuracy_threshold": 0.5074110453289773,
      "ap": 0.7873927398387796,
      "f1": 0.7188786008230453,
      "f1_threshold": 0.5305129602767218,
      "precision": 0.7012042147516307,
      "recall": 0.737467018469657
    },
    "evaluation_time": 1.72,
    "manhattan": {
      "accuracy": 0.8652321630804077,
      "accuracy_threshold": 10.829996850584617,
      "ap": 0.7561804404246432,
      "f1": 0.6883636833268759,
      "f1_threshold": 11.432174710290687,
      "precision": 0.6741715153048318,
      "recall": 0.7031662269129287
    },
    "max": {
      "accuracy": 0.8760207426834357,
      "ap": 0.7873927398387796,
      "f1": 0.7188786008230453
    }
  }
}