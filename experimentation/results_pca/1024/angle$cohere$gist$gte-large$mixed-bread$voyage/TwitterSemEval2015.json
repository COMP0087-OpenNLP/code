{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8750670560886928,
      "accuracy_threshold": 0.7507127730437642,
      "ap": 0.7825669628702656,
      "f1": 0.7182292961949763,
      "f1_threshold": 0.7094646840547875,
      "precision": 0.6792097836312324,
      "recall": 0.7620052770448549
    },
    "dot": {
      "accuracy": 0.8605233355188651,
      "accuracy_threshold": 0.4000795676400173,
      "ap": 0.7396219573451869,
      "f1": 0.6786193438224174,
      "f1_threshold": 0.368173337955179,
      "precision": 0.6309820821047857,
      "recall": 0.7340369393139842
    },
    "euclidean": {
      "accuracy": 0.8763187697442928,
      "accuracy_threshold": 0.5174918781837452,
      "ap": 0.7874558520795705,
      "f1": 0.719735503560529,
      "f1_threshold": 0.5459121005176082,
      "precision": 0.6946489936180658,
      "recall": 0.7467018469656992
    },
    "evaluation_time": 2.47,
    "manhattan": {
      "accuracy": 0.866960720033379,
      "accuracy_threshold": 11.394776771577227,
      "ap": 0.7642095264243876,
      "f1": 0.7024524524524525,
      "f1_threshold": 11.9269919562851,
      "precision": 0.668015230842456,
      "recall": 0.7406332453825858
    },
    "max": {
      "accuracy": 0.8763187697442928,
      "ap": 0.7874558520795705,
      "f1": 0.719735503560529
    }
  }
}