{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8734577099600643,
      "accuracy_threshold": 0.7428516388881238,
      "ap": 0.7797690258892763,
      "f1": 0.715485893416928,
      "f1_threshold": 0.7074119114149471,
      "precision": 0.6817204301075269,
      "recall": 0.7527704485488127
    },
    "dot": {
      "accuracy": 0.8615366275257793,
      "accuracy_threshold": 0.36439232630675883,
      "ap": 0.7441614309085968,
      "f1": 0.6856864179468422,
      "f1_threshold": 0.33024436854174677,
      "precision": 0.6373526745240253,
      "recall": 0.7419525065963061
    },
    "euclidean": {
      "accuracy": 0.8748882398521786,
      "accuracy_threshold": 0.4881671035090353,
      "ap": 0.7830788912499548,
      "f1": 0.7165277096615988,
      "f1_threshold": 0.5312278233813317,
      "precision": 0.6692624828218049,
      "recall": 0.770976253298153
    },
    "evaluation_time": 1.78,
    "manhattan": {
      "accuracy": 0.8654705847290934,
      "accuracy_threshold": 11.197621821834248,
      "ap": 0.7587305257791646,
      "f1": 0.6985837824288759,
      "f1_threshold": 12.04067525589307,
      "precision": 0.6653139174027214,
      "recall": 0.7353562005277045
    },
    "max": {
      "accuracy": 0.8748882398521786,
      "ap": 0.7830788912499548,
      "f1": 0.7165277096615988
    }
  }
}