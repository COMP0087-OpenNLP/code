{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8754842939738928,
      "accuracy_threshold": 0.7319078234721703,
      "ap": 0.7831037064071866,
      "f1": 0.7165125495376485,
      "f1_threshold": 0.7104968798386968,
      "precision": 0.7174603174603175,
      "recall": 0.7155672823218997
    },
    "dot": {
      "accuracy": 0.854622399713894,
      "accuracy_threshold": 0.4387214132511995,
      "ap": 0.7213305699577199,
      "f1": 0.6666666666666667,
      "f1_threshold": 0.4022611799398112,
      "precision": 0.6354939009806266,
      "recall": 0.7010554089709763
    },
    "euclidean": {
      "accuracy": 0.8754842939738928,
      "accuracy_threshold": 0.5590708201394614,
      "ap": 0.7875812214262246,
      "f1": 0.7198515769944343,
      "f1_threshold": 0.5982061220965376,
      "precision": 0.6775320139697323,
      "recall": 0.7678100263852242
    },
    "evaluation_time": 1.8,
    "manhattan": {
      "accuracy": 0.8666626929725219,
      "accuracy_threshold": 11.068836111295486,
      "ap": 0.763274185360634,
      "f1": 0.6940639269406392,
      "f1_threshold": 11.729010717461364,
      "precision": 0.668295065950171,
      "recall": 0.7218997361477573
    },
    "max": {
      "accuracy": 0.8754842939738928,
      "ap": 0.7875812214262246,
      "f1": 0.7198515769944343
    }
  }
}