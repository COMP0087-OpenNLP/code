{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8758419264469214,
      "accuracy_threshold": 0.7301035838302772,
      "ap": 0.7834840373871179,
      "f1": 0.7142129393785022,
      "f1_threshold": 0.7019771217283035,
      "precision": 0.690300344657804,
      "recall": 0.7398416886543535
    },
    "dot": {
      "accuracy": 0.861357811289265,
      "accuracy_threshold": 0.4400691321740554,
      "ap": 0.7415367015896023,
      "f1": 0.6833763361592332,
      "f1_threshold": 0.404502088339612,
      "precision": 0.6394573465164406,
      "recall": 0.7337730870712401
    },
    "euclidean": {
      "accuracy": 0.8781069321094356,
      "accuracy_threshold": 0.5572847953862299,
      "ap": 0.7893062226987742,
      "f1": 0.7192889360573096,
      "f1_threshold": 0.5786773719124098,
      "precision": 0.7233191035218783,
      "recall": 0.7153034300791556
    },
    "evaluation_time": 1.93,
    "manhattan": {
      "accuracy": 0.8668415092090361,
      "accuracy_threshold": 12.463924592567999,
      "ap": 0.7622222018698278,
      "f1": 0.6986640277090549,
      "f1_threshold": 13.39983916390575,
      "precision": 0.6576618537494178,
      "recall": 0.7451187335092349
    },
    "max": {
      "accuracy": 0.8781069321094356,
      "ap": 0.7893062226987742,
      "f1": 0.7192889360573096
    }
  }
}