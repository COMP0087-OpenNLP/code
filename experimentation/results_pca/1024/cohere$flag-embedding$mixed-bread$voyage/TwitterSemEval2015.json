{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8779281158729213,
      "accuracy_threshold": 0.7315807236073352,
      "ap": 0.7898205793008196,
      "f1": 0.7212282705240451,
      "f1_threshold": 0.7010409564635406,
      "precision": 0.6946956734294794,
      "recall": 0.749868073878628
    },
    "dot": {
      "accuracy": 0.8630863682422364,
      "accuracy_threshold": 0.4183078693346319,
      "ap": 0.7472046183583813,
      "f1": 0.686829268292683,
      "f1_threshold": 0.3841836016985133,
      "precision": 0.6385487528344671,
      "recall": 0.7430079155672823
    },
    "euclidean": {
      "accuracy": 0.8790606187041783,
      "accuracy_threshold": 0.5359899526321031,
      "ap": 0.7947280415391678,
      "f1": 0.7232704402515724,
      "f1_threshold": 0.5686067579874923,
      "precision": 0.7183758459135867,
      "recall": 0.7282321899736148
    },
    "evaluation_time": 1.79,
    "manhattan": {
      "accuracy": 0.871013888061036,
      "accuracy_threshold": 12.397094515572087,
      "ap": 0.772313252748864,
      "f1": 0.7083491221422255,
      "f1_threshold": 13.071339829242579,
      "precision": 0.6794281560455536,
      "recall": 0.7398416886543535
    },
    "max": {
      "accuracy": 0.8790606187041783,
      "ap": 0.7947280415391678,
      "f1": 0.7232704402515724
    }
  }
}