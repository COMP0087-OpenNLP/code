{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8750670560886928,
      "accuracy_threshold": 0.7415667758960466,
      "ap": 0.7823626208738272,
      "f1": 0.7149448859266855,
      "f1_threshold": 0.7070543538562503,
      "precision": 0.6951645064805583,
      "recall": 0.7358839050131926
    },
    "dot": {
      "accuracy": 0.8599868868093223,
      "accuracy_threshold": 0.45204948304656073,
      "ap": 0.7396852559078595,
      "f1": 0.6804733727810652,
      "f1_threshold": 0.4151534809708971,
      "precision": 0.6385932438685794,
      "recall": 0.7282321899736148
    },
    "euclidean": {
      "accuracy": 0.8776896942242356,
      "accuracy_threshold": 0.5595588188441512,
      "ap": 0.7885082113028713,
      "f1": 0.7181119066560594,
      "f1_threshold": 0.5812665842894682,
      "precision": 0.7217484008528785,
      "recall": 0.7145118733509235
    },
    "evaluation_time": 2.0,
    "manhattan": {
      "accuracy": 0.8664242713238363,
      "accuracy_threshold": 12.529544589079217,
      "ap": 0.7605687830773746,
      "f1": 0.6980223123732252,
      "f1_threshold": 13.297714839953645,
      "precision": 0.6717911176183504,
      "recall": 0.7263852242744063
    },
    "max": {
      "accuracy": 0.8776896942242356,
      "ap": 0.7885082113028713,
      "f1": 0.7181119066560594
    }
  }
}