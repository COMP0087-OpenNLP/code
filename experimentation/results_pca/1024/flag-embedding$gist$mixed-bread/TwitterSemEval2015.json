{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8755438993860643,
      "accuracy_threshold": 0.7321049902134499,
      "ap": 0.7866423347967622,
      "f1": 0.7204483252964943,
      "f1_threshold": 0.7041268592270788,
      "precision": 0.7118207571465361,
      "recall": 0.729287598944591
    },
    "dot": {
      "accuracy": 0.8584967515050367,
      "accuracy_threshold": 0.5020295429960897,
      "ap": 0.7285504919512303,
      "f1": 0.67672360054856,
      "f1_threshold": 0.467185932156207,
      "precision": 0.6414559205861499,
      "recall": 0.7160949868073878
    },
    "euclidean": {
      "accuracy": 0.8759015318590928,
      "accuracy_threshold": 0.5907073037486796,
      "ap": 0.7910131072393771,
      "f1": 0.7220543806646527,
      "f1_threshold": 0.6438911169225265,
      "precision": 0.6904188733750601,
      "recall": 0.7567282321899736
    },
    "evaluation_time": 1.28,
    "manhattan": {
      "accuracy": 0.8683316445133218,
      "accuracy_threshold": 12.154234030000051,
      "ap": 0.769779230125242,
      "f1": 0.7010671688637791,
      "f1_threshold": 12.724999055757928,
      "precision": 0.6687425149700599,
      "recall": 0.7366754617414248
    },
    "max": {
      "accuracy": 0.8759015318590928,
      "ap": 0.7910131072393771,
      "f1": 0.7220543806646527
    }
  }
}