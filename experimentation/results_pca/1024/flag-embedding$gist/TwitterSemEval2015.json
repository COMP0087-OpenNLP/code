{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8751862669130357,
      "accuracy_threshold": 0.7384331573204679,
      "ap": 0.7848770543695242,
      "f1": 0.7185372005044136,
      "f1_threshold": 0.6974325840487967,
      "precision": 0.6881642512077295,
      "recall": 0.7517150395778364
    },
    "dot": {
      "accuracy": 0.8620134708231507,
      "accuracy_threshold": 0.5163568610043082,
      "ap": 0.7366961164417548,
      "f1": 0.6847758982590444,
      "f1_threshold": 0.4781039030619064,
      "precision": 0.6435367834764446,
      "recall": 0.7316622691292876
    },
    "euclidean": {
      "accuracy": 0.8752458723252071,
      "accuracy_threshold": 0.5913440955236732,
      "ap": 0.7893742511863228,
      "f1": 0.7206861239119303,
      "f1_threshold": 0.6436353541092057,
      "precision": 0.6999005469915465,
      "recall": 0.7427440633245382
    },
    "evaluation_time": 0.91,
    "manhattan": {
      "accuracy": 0.867795195803779,
      "accuracy_threshold": 12.055617359282463,
      "ap": 0.7685884160779501,
      "f1": 0.6995210486513738,
      "f1_threshold": 12.866455029934762,
      "precision": 0.6696428571428571,
      "recall": 0.7321899736147758
    },
    "max": {
      "accuracy": 0.8752458723252071,
      "ap": 0.7893742511863228,
      "f1": 0.7206861239119303
    }
  }
}