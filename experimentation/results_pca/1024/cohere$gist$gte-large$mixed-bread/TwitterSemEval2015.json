{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8736365261965786,
      "accuracy_threshold": 0.7587846575890009,
      "ap": 0.7793077937907334,
      "f1": 0.7149598265527356,
      "f1_threshold": 0.7171009366102543,
      "precision": 0.6919279190323377,
      "recall": 0.7395778364116095
    },
    "dot": {
      "accuracy": 0.8605233355188651,
      "accuracy_threshold": 0.46999757393057273,
      "ap": 0.742786123625474,
      "f1": 0.6835379604109246,
      "f1_threshold": 0.4393249879544937,
      "precision": 0.6507633587786259,
      "recall": 0.7197889182058047
    },
    "euclidean": {
      "accuracy": 0.8757227156225785,
      "accuracy_threshold": 0.5590185276168296,
      "ap": 0.7849606332641004,
      "f1": 0.7187423237533775,
      "f1_threshold": 0.602615762272317,
      "precision": 0.6723345588235294,
      "recall": 0.7720316622691293
    },
    "evaluation_time": 1.71,
    "manhattan": {
      "accuracy": 0.8639804494248078,
      "accuracy_threshold": 12.376356827189326,
      "ap": 0.7561313735727957,
      "f1": 0.6960309777347532,
      "f1_threshold": 13.511025843452586,
      "precision": 0.6428252123379526,
      "recall": 0.7588390501319261
    },
    "max": {
      "accuracy": 0.8757227156225785,
      "ap": 0.7849606332641004,
      "f1": 0.7187423237533775
    }
  }
}