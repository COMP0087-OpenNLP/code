{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8760207426834357,
      "accuracy_threshold": 0.7273939803404275,
      "ap": 0.7877560260417129,
      "f1": 0.7180932854946183,
      "f1_threshold": 0.6811480528668021,
      "precision": 0.6980568011958147,
      "recall": 0.7393139841688654
    },
    "dot": {
      "accuracy": 0.8571854324372653,
      "accuracy_threshold": 0.39912123723233883,
      "ap": 0.7239566855000403,
      "f1": 0.6751930501930502,
      "f1_threshold": 0.3643815595397364,
      "precision": 0.622054246331703,
      "recall": 0.7382585751978892
    },
    "euclidean": {
      "accuracy": 0.87494784526435,
      "accuracy_threshold": 0.5514558024043299,
      "ap": 0.7906353038594656,
      "f1": 0.7199393096472373,
      "f1_threshold": 0.5959562767390766,
      "precision": 0.6911871813546977,
      "recall": 0.7511873350923483
    },
    "evaluation_time": 1.31,
    "manhattan": {
      "accuracy": 0.8663646659116648,
      "accuracy_threshold": 11.033743583391622,
      "ap": 0.7653907266039528,
      "f1": 0.6962423023752672,
      "f1_threshold": 11.886706393171025,
      "precision": 0.6647468202543797,
      "recall": 0.7308707124010554
    },
    "max": {
      "accuracy": 0.8760207426834357,
      "ap": 0.7906353038594656,
      "f1": 0.7199393096472373
    }
  }
}