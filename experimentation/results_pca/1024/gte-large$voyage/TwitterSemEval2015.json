{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8604637301066936,
      "accuracy_threshold": 0.7350233683814487,
      "ap": 0.7414136315172353,
      "f1": 0.684230525649145,
      "f1_threshold": 0.7074278615002232,
      "precision": 0.6579780755176614,
      "recall": 0.7126649076517151
    },
    "dot": {
      "accuracy": 0.8513441020444656,
      "accuracy_threshold": 0.22156918785915888,
      "ap": 0.710724970924934,
      "f1": 0.6627335299901672,
      "f1_threshold": 0.20684040629318287,
      "precision": 0.6203405430280718,
      "recall": 0.7113456464379947
    },
    "euclidean": {
      "accuracy": 0.8598080705728081,
      "accuracy_threshold": 0.3868138419445628,
      "ap": 0.7369139454795511,
      "f1": 0.6747250090656352,
      "f1_threshold": 0.4229012113331848,
      "precision": 0.6225741690832032,
      "recall": 0.7364116094986808
    },
    "evaluation_time": 1.07,
    "manhattan": {
      "accuracy": 0.8456219824760088,
      "accuracy_threshold": 8.97752038208397,
      "ap": 0.698434352168052,
      "f1": 0.6434461538461539,
      "f1_threshold": 9.74668072429519,
      "precision": 0.6029988465974625,
      "recall": 0.6897097625329816
    },
    "max": {
      "accuracy": 0.8604637301066936,
      "ap": 0.7414136315172353,
      "f1": 0.684230525649145
    }
  }
}