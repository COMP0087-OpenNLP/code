{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8790010132920069,
      "accuracy_threshold": 0.7267925192885134,
      "ap": 0.7916278378045316,
      "f1": 0.7209723299715541,
      "f1_threshold": 0.6970230420884238,
      "precision": 0.7068965517241379,
      "recall": 0.7356200527704485
    },
    "dot": {
      "accuracy": 0.8639208440126364,
      "accuracy_threshold": 0.4552707113124832,
      "ap": 0.7464039861882928,
      "f1": 0.6894730524546873,
      "f1_threshold": 0.4111292027172778,
      "precision": 0.6324598106144022,
      "recall": 0.7577836411609499
    },
    "euclidean": {
      "accuracy": 0.8791202241163497,
      "accuracy_threshold": 0.5711233677660128,
      "ap": 0.7970333006609199,
      "f1": 0.7252602450915798,
      "f1_threshold": 0.6037100567267346,
      "precision": 0.7244011581995262,
      "recall": 0.7261213720316623
    },
    "evaluation_time": 2.0,
    "manhattan": {
      "accuracy": 0.8704774393514931,
      "accuracy_threshold": 12.900787589757154,
      "ap": 0.7735558669856413,
      "f1": 0.7048358807316462,
      "f1_threshold": 13.786290912538565,
      "precision": 0.6710400763358778,
      "recall": 0.7422163588390501
    },
    "max": {
      "accuracy": 0.8791202241163497,
      "ap": 0.7970333006609199,
      "f1": 0.7252602450915798
    }
  }
}