{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8783453537581213,
      "accuracy_threshold": 0.7254646505682247,
      "ap": 0.7894448952538281,
      "f1": 0.7192799373858596,
      "f1_threshold": 0.702816913717143,
      "precision": 0.7113003095975232,
      "recall": 0.7274406332453826
    },
    "dot": {
      "accuracy": 0.8636824223639507,
      "accuracy_threshold": 0.46191824663946046,
      "ap": 0.7464805714281186,
      "f1": 0.688164337752299,
      "f1_threshold": 0.4146753150031353,
      "precision": 0.6286275365481125,
      "recall": 0.7601583113456465
    },
    "euclidean": {
      "accuracy": 0.8789414078798354,
      "accuracy_threshold": 0.5728158275203353,
      "ap": 0.7947513124956564,
      "f1": 0.7246681561308975,
      "f1_threshold": 0.602795987468588,
      "precision": 0.7219167321288296,
      "recall": 0.7274406332453826
    },
    "evaluation_time": 2.37,
    "manhattan": {
      "accuracy": 0.8688084878106932,
      "accuracy_threshold": 12.842727072008984,
      "ap": 0.7704328132611107,
      "f1": 0.7054564261701577,
      "f1_threshold": 13.556966422880333,
      "precision": 0.691683569979716,
      "recall": 0.7197889182058047
    },
    "max": {
      "accuracy": 0.8789414078798354,
      "ap": 0.7947513124956564,
      "f1": 0.7246681561308975
    }
  }
}