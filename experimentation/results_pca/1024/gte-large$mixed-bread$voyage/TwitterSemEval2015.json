{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8717291530070931,
      "accuracy_threshold": 0.7571642243881058,
      "ap": 0.7734370152981813,
      "f1": 0.7078944107076466,
      "f1_threshold": 0.7093190624321963,
      "precision": 0.6674456648749708,
      "recall": 0.7535620052770449
    },
    "dot": {
      "accuracy": 0.8552184538356082,
      "accuracy_threshold": 0.28692024376116354,
      "ap": 0.7243200764799872,
      "f1": 0.6663365110808468,
      "f1_threshold": 0.2680264086491123,
      "precision": 0.6277116864940517,
      "recall": 0.7100263852242744
    },
    "euclidean": {
      "accuracy": 0.8728020504261786,
      "accuracy_threshold": 0.4367399933842919,
      "ap": 0.7758825861511179,
      "f1": 0.7102368318881842,
      "f1_threshold": 0.45987021808725614,
      "precision": 0.6969773939547879,
      "recall": 0.7240105540897097
    },
    "evaluation_time": 1.43,
    "manhattan": {
      "accuracy": 0.860225308458008,
      "accuracy_threshold": 9.490819650442957,
      "ap": 0.7415270737944839,
      "f1": 0.6792916871618297,
      "f1_threshold": 10.324391483779802,
      "precision": 0.6361123906034085,
      "recall": 0.7287598944591029
    },
    "max": {
      "accuracy": 0.8728020504261786,
      "ap": 0.7758825861511179,
      "f1": 0.7102368318881842
    }
  }
}