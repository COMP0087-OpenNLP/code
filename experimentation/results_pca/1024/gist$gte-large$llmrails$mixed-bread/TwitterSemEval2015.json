{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8745902127913214,
      "accuracy_threshold": 0.7453014303473814,
      "ap": 0.7832005034082604,
      "f1": 0.7173144876325088,
      "f1_threshold": 0.7030217893284223,
      "precision": 0.687469762941461,
      "recall": 0.749868073878628
    },
    "dot": {
      "accuracy": 0.8580795136198367,
      "accuracy_threshold": 0.44373649048033603,
      "ap": 0.7301975330697729,
      "f1": 0.6758655293527345,
      "f1_threshold": 0.41544083722331393,
      "precision": 0.6441893830703013,
      "recall": 0.7108179419525066
    },
    "euclidean": {
      "accuracy": 0.8755438993860643,
      "accuracy_threshold": 0.5589449257192094,
      "ap": 0.7879438057618936,
      "f1": 0.7197179551750189,
      "f1_threshold": 0.5933744538736668,
      "precision": 0.6883429672447013,
      "recall": 0.754089709762533
    },
    "evaluation_time": 1.6,
    "manhattan": {
      "accuracy": 0.8667222983846933,
      "accuracy_threshold": 10.959785181071501,
      "ap": 0.7651252607760213,
      "f1": 0.6983391270760911,
      "f1_threshold": 11.639034478525215,
      "precision": 0.6819210460145838,
      "recall": 0.7155672823218997
    },
    "max": {
      "accuracy": 0.8755438993860643,
      "ap": 0.7879438057618936,
      "f1": 0.7197179551750189
    }
  }
}