{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8710734934732074,
      "accuracy_threshold": 0.7413281127247344,
      "ap": 0.7706667782541964,
      "f1": 0.7019230769230769,
      "f1_threshold": 0.6923967732090703,
      "precision": 0.6587228135122628,
      "recall": 0.7511873350923483
    },
    "dot": {
      "accuracy": 0.8594504380997795,
      "accuracy_threshold": 0.4720999184293472,
      "ap": 0.7399459038883976,
      "f1": 0.6811989100817439,
      "f1_threshold": 0.4388611146697029,
      "precision": 0.6419234360410832,
      "recall": 0.7255936675461742
    },
    "euclidean": {
      "accuracy": 0.8723848125409788,
      "accuracy_threshold": 0.5756146219366138,
      "ap": 0.7762233446698444,
      "f1": 0.7066446448989964,
      "f1_threshold": 0.6145369319519421,
      "precision": 0.6814506248468513,
      "recall": 0.7337730870712401
    },
    "evaluation_time": 1.62,
    "manhattan": {
      "accuracy": 0.8616558383501222,
      "accuracy_threshold": 12.913408561128108,
      "ap": 0.7486626582307795,
      "f1": 0.6867124142233313,
      "f1_threshold": 14.132564082739087,
      "precision": 0.6513609467455621,
      "recall": 0.7261213720316623
    },
    "max": {
      "accuracy": 0.8723848125409788,
      "ap": 0.7762233446698444,
      "f1": 0.7066446448989964
    }
  }
}