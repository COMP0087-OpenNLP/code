{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8775108779877213,
      "accuracy_threshold": 0.7381484839978667,
      "ap": 0.7878757832178073,
      "f1": 0.7203432609793036,
      "f1_threshold": 0.7018442363219067,
      "precision": 0.6903725205611998,
      "recall": 0.7530343007915568
    },
    "dot": {
      "accuracy": 0.8624903141205221,
      "accuracy_threshold": 0.42259095919306994,
      "ap": 0.7437215709743576,
      "f1": 0.6844770828057737,
      "f1_threshold": 0.3944234195966182,
      "precision": 0.6579844206426485,
      "recall": 0.7131926121372032
    },
    "euclidean": {
      "accuracy": 0.8782857483459499,
      "accuracy_threshold": 0.5467143391114291,
      "ap": 0.7927211588619234,
      "f1": 0.7236368484202107,
      "f1_threshold": 0.5638000617518288,
      "precision": 0.7313392616545406,
      "recall": 0.7160949868073878
    },
    "evaluation_time": 2.75,
    "manhattan": {
      "accuracy": 0.8688680932228646,
      "accuracy_threshold": 11.722624043658719,
      "ap": 0.7700159612807408,
      "f1": 0.7034044244270764,
      "f1_threshold": 12.219486053175581,
      "precision": 0.7063048683160414,
      "recall": 0.7005277044854882
    },
    "max": {
      "accuracy": 0.8782857483459499,
      "ap": 0.7927211588619234,
      "f1": 0.7236368484202107
    }
  }
}