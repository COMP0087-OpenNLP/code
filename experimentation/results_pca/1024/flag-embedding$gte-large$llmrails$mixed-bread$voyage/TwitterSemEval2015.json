{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8764975859808071,
      "accuracy_threshold": 0.7215119486627766,
      "ap": 0.7884218033669279,
      "f1": 0.720653018916818,
      "f1_threshold": 0.6957373521896595,
      "precision": 0.7079938900203666,
      "recall": 0.7337730870712401
    },
    "dot": {
      "accuracy": 0.8579603027954938,
      "accuracy_threshold": 0.36941219620687354,
      "ap": 0.72904839482684,
      "f1": 0.6753308128544424,
      "f1_threshold": 0.3358678330477082,
      "precision": 0.6114676936243046,
      "recall": 0.754089709762533
    },
    "euclidean": {
      "accuracy": 0.8764379805686356,
      "accuracy_threshold": 0.5255485564295339,
      "ap": 0.7916517963269782,
      "f1": 0.7240845796802476,
      "f1_threshold": 0.5555178004172325,
      "precision": 0.708018154311649,
      "recall": 0.7408970976253298
    },
    "evaluation_time": 2.08,
    "manhattan": {
      "accuracy": 0.8672587470942361,
      "accuracy_threshold": 10.752257952732391,
      "ap": 0.7659580755511367,
      "f1": 0.6986810090920732,
      "f1_threshold": 11.471741055143099,
      "precision": 0.6787758148793233,
      "recall": 0.7197889182058047
    },
    "max": {
      "accuracy": 0.8764975859808071,
      "ap": 0.7916517963269782,
      "f1": 0.7240845796802476
    }
  }
}