{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8744710019669786,
      "accuracy_threshold": 0.7470881793489048,
      "ap": 0.781528880491473,
      "f1": 0.7167425392008094,
      "f1_threshold": 0.7118076037116359,
      "precision": 0.6881981544439048,
      "recall": 0.7477572559366754
    },
    "dot": {
      "accuracy": 0.8611789950527508,
      "accuracy_threshold": 0.3625590506338124,
      "ap": 0.7425291362881492,
      "f1": 0.6835316217908578,
      "f1_threshold": 0.3355960965009365,
      "precision": 0.6505363528009536,
      "recall": 0.7200527704485488
    },
    "euclidean": {
      "accuracy": 0.87536508314955,
      "accuracy_threshold": 0.4840522802954914,
      "ap": 0.7852246877079752,
      "f1": 0.7195571955719557,
      "f1_threshold": 0.5291271216811586,
      "precision": 0.673963133640553,
      "recall": 0.7717678100263852
    },
    "evaluation_time": 1.81,
    "manhattan": {
      "accuracy": 0.8655897955534363,
      "accuracy_threshold": 11.1502139129667,
      "ap": 0.7612230175499932,
      "f1": 0.7008612932253502,
      "f1_threshold": 11.846863037994378,
      "precision": 0.6833792930559037,
      "recall": 0.7192612137203166
    },
    "max": {
      "accuracy": 0.87536508314955,
      "ap": 0.7852246877079752,
      "f1": 0.7195571955719557
    }
  }
}