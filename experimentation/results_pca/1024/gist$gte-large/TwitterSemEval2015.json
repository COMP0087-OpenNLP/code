{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8701198068784646,
      "accuracy_threshold": 0.7619774339318351,
      "ap": 0.7679598084459703,
      "f1": 0.7075757575757574,
      "f1_threshold": 0.7206875366848469,
      "precision": 0.678450363196126,
      "recall": 0.7393139841688654
    },
    "dot": {
      "accuracy": 0.8580199082076653,
      "accuracy_threshold": 0.39863414104998207,
      "ap": 0.7322704543869331,
      "f1": 0.678035645595589,
      "f1_threshold": 0.37816736052045624,
      "precision": 0.6595160888001995,
      "recall": 0.6976253298153035
    },
    "euclidean": {
      "accuracy": 0.8704178339393217,
      "accuracy_threshold": 0.5060601428897384,
      "ap": 0.7716295340481654,
      "f1": 0.7102181683717491,
      "f1_threshold": 0.5453741455452918,
      "precision": 0.6664353458246588,
      "recall": 0.7601583113456465
    },
    "evaluation_time": 0.99,
    "manhattan": {
      "accuracy": 0.8598080705728081,
      "accuracy_threshold": 9.845910660056536,
      "ap": 0.742535360823774,
      "f1": 0.6854506919336741,
      "f1_threshold": 10.80613436542877,
      "precision": 0.6497281966438194,
      "recall": 0.7253298153034301
    },
    "max": {
      "accuracy": 0.8704178339393217,
      "ap": 0.7716295340481654,
      "f1": 0.7102181683717491
    }
  }
}