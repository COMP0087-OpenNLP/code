{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8740537640817786,
      "accuracy_threshold": 0.7446918503303065,
      "ap": 0.7828362572755532,
      "f1": 0.7185705169112954,
      "f1_threshold": 0.7064607170184963,
      "precision": 0.695920889987639,
      "recall": 0.7427440633245382
    },
    "dot": {
      "accuracy": 0.8620730762353221,
      "accuracy_threshold": 0.3591345075044824,
      "ap": 0.7420002459909381,
      "f1": 0.6853267570900123,
      "f1_threshold": 0.33605380329734325,
      "precision": 0.643287037037037,
      "recall": 0.733245382585752
    },
    "euclidean": {
      "accuracy": 0.8746498182034929,
      "accuracy_threshold": 0.5044213680970361,
      "ap": 0.7863577958312303,
      "f1": 0.7193372898120672,
      "f1_threshold": 0.5410539412857673,
      "precision": 0.6768264308980921,
      "recall": 0.7675461741424802
    },
    "evaluation_time": 1.76,
    "manhattan": {
      "accuracy": 0.8651129522560649,
      "accuracy_threshold": 10.876705609059108,
      "ap": 0.7562590742376908,
      "f1": 0.6897449245184799,
      "f1_threshold": 11.381348421476432,
      "precision": 0.6805341551104263,
      "recall": 0.6992084432717678
    },
    "max": {
      "accuracy": 0.8746498182034929,
      "ap": 0.7863577958312303,
      "f1": 0.7193372898120672
    }
  }
}