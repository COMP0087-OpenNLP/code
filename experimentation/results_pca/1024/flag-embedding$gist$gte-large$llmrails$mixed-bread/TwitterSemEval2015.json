{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8748882398521786,
      "accuracy_threshold": 0.7387474791962227,
      "ap": 0.7843073564395618,
      "f1": 0.7180394138453763,
      "f1_threshold": 0.6994478384983052,
      "precision": 0.6888027144934561,
      "recall": 0.749868073878628
    },
    "dot": {
      "accuracy": 0.8590332002145795,
      "accuracy_threshold": 0.4328857284213968,
      "ap": 0.7315346009218304,
      "f1": 0.6786741713570981,
      "f1_threshold": 0.40438197788477487,
      "precision": 0.6451843043995243,
      "recall": 0.7158311345646438
    },
    "euclidean": {
      "accuracy": 0.8753054777373785,
      "accuracy_threshold": 0.5547855272769029,
      "ap": 0.7888274404589932,
      "f1": 0.7212089630015633,
      "f1_threshold": 0.5824175212537259,
      "precision": 0.712300566134843,
      "recall": 0.7303430079155673
    },
    "evaluation_time": 1.74,
    "manhattan": {
      "accuracy": 0.8670203254455504,
      "accuracy_threshold": 11.048776212799167,
      "ap": 0.7659463773428264,
      "f1": 0.6980159752641071,
      "f1_threshold": 11.619199974816238,
      "precision": 0.68202416918429,
      "recall": 0.7147757255936675
    },
    "max": {
      "accuracy": 0.8753054777373785,
      "ap": 0.7888274404589932,
      "f1": 0.7212089630015633
    }
  }
}