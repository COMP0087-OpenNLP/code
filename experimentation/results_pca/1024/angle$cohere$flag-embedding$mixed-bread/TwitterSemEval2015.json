{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8769744292781785,
      "accuracy_threshold": 0.740022067434488,
      "ap": 0.786765499689559,
      "f1": 0.7180830168914495,
      "f1_threshold": 0.7082530747822358,
      "precision": 0.7127631920977385,
      "recall": 0.7234828496042216
    },
    "dot": {
      "accuracy": 0.8604041246945222,
      "accuracy_threshold": 0.521571673197521,
      "ap": 0.7388628186884793,
      "f1": 0.6816077953714982,
      "f1_threshold": 0.47311330019451214,
      "precision": 0.6330316742081448,
      "recall": 0.7382585751978892
    },
    "euclidean": {
      "accuracy": 0.8783453537581213,
      "accuracy_threshold": 0.6042651796883494,
      "ap": 0.7929945282197397,
      "f1": 0.722107438016529,
      "f1_threshold": 0.6387046161487746,
      "precision": 0.7071320182094082,
      "recall": 0.7377308707124011
    },
    "evaluation_time": 1.74,
    "manhattan": {
      "accuracy": 0.8676759849794361,
      "accuracy_threshold": 13.537627974905227,
      "ap": 0.766069510620648,
      "f1": 0.7019038076152305,
      "f1_threshold": 14.323926847910467,
      "precision": 0.6680972818311874,
      "recall": 0.7393139841688654
    },
    "max": {
      "accuracy": 0.8783453537581213,
      "ap": 0.7929945282197397,
      "f1": 0.722107438016529
    }
  }
}