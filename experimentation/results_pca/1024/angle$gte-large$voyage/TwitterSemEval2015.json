{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8733981045478929,
      "accuracy_threshold": 0.7384190604212559,
      "ap": 0.7775837627134509,
      "f1": 0.7122536865457393,
      "f1_threshold": 0.7156180853009417,
      "precision": 0.7046217402530338,
      "recall": 0.7200527704485488
    },
    "dot": {
      "accuracy": 0.857423854085951,
      "accuracy_threshold": 0.36238887869028624,
      "ap": 0.7284427805591869,
      "f1": 0.6715255089218397,
      "f1_threshold": 0.3379069319194703,
      "precision": 0.6410748560460653,
      "recall": 0.7050131926121372
    },
    "euclidean": {
      "accuracy": 0.8744113965548072,
      "accuracy_threshold": 0.49849465426126555,
      "ap": 0.7811222404421687,
      "f1": 0.7152078492124968,
      "f1_threshold": 0.5252401549727489,
      "precision": 0.7002022244691608,
      "recall": 0.7308707124010554
    },
    "evaluation_time": 1.43,
    "manhattan": {
      "accuracy": 0.8632055790665792,
      "accuracy_threshold": 10.744818751484022,
      "ap": 0.7506081970033691,
      "f1": 0.6842754875339423,
      "f1_threshold": 11.5459343679595,
      "precision": 0.6428571428571429,
      "recall": 0.7313984168865435
    },
    "max": {
      "accuracy": 0.8744113965548072,
      "ap": 0.7811222404421687,
      "f1": 0.7152078492124968
    }
  }
}