{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.4.1",
  "test": {
    "cos_sim": {
      "accuracy": 0.8747690290278357,
      "accuracy_threshold": 0.7387666934725063,
      "ap": 0.7809475653221023,
      "f1": 0.7136411889596603,
      "f1_threshold": 0.7211421803405886,
      "precision": 0.7178323545114789,
      "recall": 0.7094986807387863
    },
    "dot": {
      "accuracy": 0.8522977886392085,
      "accuracy_threshold": 0.5400426505878585,
      "ap": 0.7117331322989413,
      "f1": 0.653002517080187,
      "f1_threshold": 0.48424721103543666,
      "precision": 0.5982868438392269,
      "recall": 0.7187335092348285
    },
    "euclidean": {
      "accuracy": 0.8758419264469214,
      "accuracy_threshold": 0.6034103527864234,
      "ap": 0.7855469113914375,
      "f1": 0.715021998742929,
      "f1_threshold": 0.6447800314450978,
      "precision": 0.6828331332533013,
      "recall": 0.7503957783641161
    },
    "evaluation_time": 0.71,
    "manhattan": {
      "accuracy": 0.8667819037968647,
      "accuracy_threshold": 11.78935439693523,
      "ap": 0.7597722271360831,
      "f1": 0.6902796271637817,
      "f1_threshold": 12.328829164353571,
      "precision": 0.6967741935483871,
      "recall": 0.6839050131926121
    },
    "max": {
      "accuracy": 0.8758419264469214,
      "ap": 0.7855469113914375,
      "f1": 0.715021998742929
    }
  }
}