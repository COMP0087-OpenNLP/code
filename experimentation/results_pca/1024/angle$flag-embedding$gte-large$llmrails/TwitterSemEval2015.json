{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.87578232103475,
      "accuracy_threshold": 0.7350180845573836,
      "ap": 0.7854541939458242,
      "f1": 0.7177145838768588,
      "f1_threshold": 0.6958964901627076,
      "precision": 0.7097523219814241,
      "recall": 0.7258575197889182
    },
    "dot": {
      "accuracy": 0.8563509566668653,
      "accuracy_threshold": 0.4115293783266716,
      "ap": 0.7239507334589865,
      "f1": 0.6727295692812933,
      "f1_threshold": 0.3860486611189671,
      "precision": 0.6452629028349891,
      "recall": 0.7026385224274406
    },
    "euclidean": {
      "accuracy": 0.8754842939738928,
      "accuracy_threshold": 0.5512175114455445,
      "ap": 0.789317246845058,
      "f1": 0.7223857673108922,
      "f1_threshold": 0.5914610011202206,
      "precision": 0.7014665672383793,
      "recall": 0.7445910290237467
    },
    "evaluation_time": 1.71,
    "manhattan": {
      "accuracy": 0.8671395362698933,
      "accuracy_threshold": 10.99669291143622,
      "ap": 0.7643929537946635,
      "f1": 0.6949259774769075,
      "f1_threshold": 11.813317946668327,
      "precision": 0.6676391928033066,
      "recall": 0.7245382585751979
    },
    "max": {
      "accuracy": 0.87578232103475,
      "ap": 0.789317246845058,
      "f1": 0.7223857673108922
    }
  }
}