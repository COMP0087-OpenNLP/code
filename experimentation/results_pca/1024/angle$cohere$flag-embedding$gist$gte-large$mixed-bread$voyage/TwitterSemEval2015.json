{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8765571913929785,
      "accuracy_threshold": 0.7434393910208049,
      "ap": 0.7860466250711092,
      "f1": 0.7189655172413792,
      "f1_threshold": 0.7004470881947558,
      "precision": 0.6741339491916859,
      "recall": 0.7701846965699208
    },
    "dot": {
      "accuracy": 0.8605829409310365,
      "accuracy_threshold": 0.4281040200826939,
      "ap": 0.7410055980831929,
      "f1": 0.6812523576009053,
      "f1_threshold": 0.4000410503259263,
      "precision": 0.65073264472736,
      "recall": 0.7147757255936675
    },
    "euclidean": {
      "accuracy": 0.8775108779877213,
      "accuracy_threshold": 0.5392765951481175,
      "ap": 0.7911572533120099,
      "f1": 0.7220615964802011,
      "f1_threshold": 0.5774975596366567,
      "precision": 0.6895558223289315,
      "recall": 0.7577836411609499
    },
    "evaluation_time": 2.74,
    "manhattan": {
      "accuracy": 0.8692853311080646,
      "accuracy_threshold": 11.544583036376583,
      "ap": 0.7690005546455976,
      "f1": 0.7035916326799105,
      "f1_threshold": 12.182606758711533,
      "precision": 0.7016531094200997,
      "recall": 0.7055408970976254
    },
    "max": {
      "accuracy": 0.8775108779877213,
      "ap": 0.7911572533120099,
      "f1": 0.7220615964802011
    }
  }
}