{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8784645645824641,
      "accuracy_threshold": 0.7325500166188081,
      "ap": 0.7901313969381359,
      "f1": 0.7211750942415183,
      "f1_threshold": 0.7057726893219505,
      "precision": 0.7107353317960543,
      "recall": 0.7319261213720316
    },
    "dot": {
      "accuracy": 0.8646361089586935,
      "accuracy_threshold": 0.4678806420538434,
      "ap": 0.7489441374228413,
      "f1": 0.6909987669543773,
      "f1_threshold": 0.4299308942164625,
      "precision": 0.6486111111111111,
      "recall": 0.7393139841688654
    },
    "euclidean": {
      "accuracy": 0.8794778565893783,
      "accuracy_threshold": 0.5695301241976205,
      "ap": 0.7955742524199682,
      "f1": 0.7247913078044256,
      "f1_threshold": 0.6010874955373324,
      "precision": 0.7279744476976311,
      "recall": 0.7216358839050132
    },
    "evaluation_time": 2.41,
    "manhattan": {
      "accuracy": 0.8689873040472075,
      "accuracy_threshold": 13.020109785202585,
      "ap": 0.7711442962694703,
      "f1": 0.7042067783199262,
      "f1_threshold": 13.439515500982855,
      "precision": 0.7039282889533351,
      "recall": 0.7044854881266491
    },
    "max": {
      "accuracy": 0.8794778565893783,
      "ap": 0.7955742524199682,
      "f1": 0.7247913078044256
    }
  }
}