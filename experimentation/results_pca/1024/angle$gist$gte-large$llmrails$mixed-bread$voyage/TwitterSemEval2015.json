{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8754842939738928,
      "accuracy_threshold": 0.7319322737132649,
      "ap": 0.7850061634715226,
      "f1": 0.7187861643307188,
      "f1_threshold": 0.7050444920512586,
      "precision": 0.7010283421118636,
      "recall": 0.737467018469657
    },
    "dot": {
      "accuracy": 0.858675567741551,
      "accuracy_threshold": 0.431731349885969,
      "ap": 0.7313820167629455,
      "f1": 0.6761628639858818,
      "f1_threshold": 0.40316951680156843,
      "precision": 0.6473569876900797,
      "recall": 0.7076517150395778
    },
    "euclidean": {
      "accuracy": 0.8758419264469214,
      "accuracy_threshold": 0.5463469091803778,
      "ap": 0.7892625644565784,
      "f1": 0.7222914072229141,
      "f1_threshold": 0.5931150555614195,
      "precision": 0.6839622641509434,
      "recall": 0.7651715039577837
    },
    "evaluation_time": 2.32,
    "manhattan": {
      "accuracy": 0.8676759849794361,
      "accuracy_threshold": 11.29506554807378,
      "ap": 0.7649907128738985,
      "f1": 0.6968045578399802,
      "f1_threshold": 12.126699544517376,
      "precision": 0.6566293183940243,
      "recall": 0.7422163588390501
    },
    "max": {
      "accuracy": 0.8758419264469214,
      "ap": 0.7892625644565784,
      "f1": 0.7222914072229141
    }
  }
}