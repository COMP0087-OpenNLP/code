{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.4.1",
  "test": {
    "cos_sim": {
      "accuracy": 0.8717887584192645,
      "accuracy_threshold": 0.742569054523799,
      "ap": 0.7728657570966099,
      "f1": 0.7093685300207039,
      "f1_threshold": 0.7148437142552748,
      "precision": 0.6960385982732351,
      "recall": 0.7232189973614775
    },
    "dot": {
      "accuracy": 0.8538475293556655,
      "accuracy_threshold": 0.37036941341378127,
      "ap": 0.7192174911780811,
      "f1": 0.6640596358303801,
      "f1_threshold": 0.3392203518908016,
      "precision": 0.6184839517414068,
      "recall": 0.7168865435356201
    },
    "euclidean": {
      "accuracy": 0.8723252071288073,
      "accuracy_threshold": 0.5091150067180426,
      "ap": 0.7773489484521479,
      "f1": 0.71097292395388,
      "f1_threshold": 0.5264103523157206,
      "precision": 0.6983965385594298,
      "recall": 0.7240105540897097
    },
    "evaluation_time": 0.94,
    "manhattan": {
      "accuracy": 0.8631459736544078,
      "accuracy_threshold": 10.10174435614109,
      "ap": 0.7491999222465211,
      "f1": 0.6854471955533098,
      "f1_threshold": 10.761693310399659,
      "precision": 0.657537566650509,
      "recall": 0.7158311345646438
    },
    "max": {
      "accuracy": 0.8723252071288073,
      "ap": 0.7773489484521479,
      "f1": 0.71097292395388
    }
  }
}