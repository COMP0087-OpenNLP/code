{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8760803480956071,
      "accuracy_threshold": 0.7423586544664955,
      "ap": 0.7845652408382535,
      "f1": 0.7194082246740221,
      "f1_threshold": 0.7057374863865904,
      "precision": 0.6853798375537506,
      "recall": 0.7569920844327177
    },
    "dot": {
      "accuracy": 0.8614770221136079,
      "accuracy_threshold": 0.390291334931859,
      "ap": 0.7423381629015845,
      "f1": 0.6839223494275759,
      "f1_threshold": 0.3641854080694995,
      "precision": 0.647197362223269,
      "recall": 0.725065963060686
    },
    "euclidean": {
      "accuracy": 0.876914823866007,
      "accuracy_threshold": 0.5159585690106733,
      "ap": 0.7893800556138094,
      "f1": 0.7212223229315033,
      "f1_threshold": 0.5435640462042874,
      "precision": 0.7081108568522756,
      "recall": 0.7348284960422163
    },
    "evaluation_time": 2.48,
    "manhattan": {
      "accuracy": 0.8676759849794361,
      "accuracy_threshold": 11.379179241892949,
      "ap": 0.7663707979582506,
      "f1": 0.7023702754644459,
      "f1_threshold": 11.876930493851377,
      "precision": 0.6826899128268992,
      "recall": 0.7232189973614775
    },
    "max": {
      "accuracy": 0.876914823866007,
      "ap": 0.7893800556138094,
      "f1": 0.7212223229315033
    }
  }
}