{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8752458723252071,
      "accuracy_threshold": 0.7232248004386082,
      "ap": 0.784185733888885,
      "f1": 0.7171161958328006,
      "f1_threshold": 0.6959625493482658,
      "precision": 0.6955120257872551,
      "recall": 0.7401055408970977
    },
    "dot": {
      "accuracy": 0.8553376646599511,
      "accuracy_threshold": 0.4173405158191306,
      "ap": 0.7222539730266442,
      "f1": 0.6687976395377427,
      "f1_threshold": 0.38827049543902353,
      "precision": 0.6261510128913443,
      "recall": 0.7176781002638523
    },
    "euclidean": {
      "accuracy": 0.8752458723252071,
      "accuracy_threshold": 0.55673140428787,
      "ap": 0.7883060779891954,
      "f1": 0.7206199974590269,
      "f1_threshold": 0.5891245941984341,
      "precision": 0.6949277137956383,
      "recall": 0.7482849604221636
    },
    "evaluation_time": 2.08,
    "manhattan": {
      "accuracy": 0.8667819037968647,
      "accuracy_threshold": 11.002973757359435,
      "ap": 0.7640603894039764,
      "f1": 0.6962261800971478,
      "f1_threshold": 11.77978139681902,
      "precision": 0.6593536211370606,
      "recall": 0.737467018469657
    },
    "max": {
      "accuracy": 0.8752458723252071,
      "ap": 0.7883060779891954,
      "f1": 0.7206199974590269
    }
  }
}