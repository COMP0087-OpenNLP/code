{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8770936401025213,
      "accuracy_threshold": 0.7400267736188545,
      "ap": 0.7872246546222826,
      "f1": 0.7186564249446686,
      "f1_threshold": 0.7046522131325132,
      "precision": 0.7093292212798766,
      "recall": 0.7282321899736148
    },
    "dot": {
      "accuracy": 0.8602849138701794,
      "accuracy_threshold": 0.5260661211841267,
      "ap": 0.7392190546571461,
      "f1": 0.6819221967963386,
      "f1_threshold": 0.4740565184099757,
      "precision": 0.6272989142477288,
      "recall": 0.7469656992084432
    },
    "euclidean": {
      "accuracy": 0.8785241699946356,
      "accuracy_threshold": 0.6083497438651808,
      "ap": 0.7934768584488165,
      "f1": 0.723106796116505,
      "f1_threshold": 0.6428267818441855,
      "precision": 0.7097839898348157,
      "recall": 0.7369393139841689
    },
    "evaluation_time": 1.78,
    "manhattan": {
      "accuracy": 0.8674971687429218,
      "accuracy_threshold": 13.641455378313108,
      "ap": 0.7661931681423693,
      "f1": 0.7011623547056618,
      "f1_threshold": 14.449013935571058,
      "precision": 0.6661125623367371,
      "recall": 0.7401055408970977
    },
    "max": {
      "accuracy": 0.8785241699946356,
      "ap": 0.7934768584488165,
      "f1": 0.723106796116505
    }
  }
}