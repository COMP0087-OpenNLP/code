{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8741729749061214,
      "accuracy_threshold": 0.7495681118404591,
      "ap": 0.7809478525009673,
      "f1": 0.7144706186901373,
      "f1_threshold": 0.7174229522669546,
      "precision": 0.7012195121951219,
      "recall": 0.7282321899736148
    },
    "dot": {
      "accuracy": 0.8594504380997795,
      "accuracy_threshold": 0.44913906768416456,
      "ap": 0.7341505817881135,
      "f1": 0.6755740044104295,
      "f1_threshold": 0.4302282513903436,
      "precision": 0.6644552181679,
      "recall": 0.6870712401055409
    },
    "euclidean": {
      "accuracy": 0.8751862669130357,
      "accuracy_threshold": 0.549548026938911,
      "ap": 0.7849931105819493,
      "f1": 0.7178502879078694,
      "f1_threshold": 0.5848095713954693,
      "precision": 0.6968944099378882,
      "recall": 0.7401055408970977
    },
    "evaluation_time": 1.79,
    "manhattan": {
      "accuracy": 0.8659474280264648,
      "accuracy_threshold": 11.700653350459225,
      "ap": 0.7569266959267098,
      "f1": 0.6890260262946071,
      "f1_threshold": 12.129155717784577,
      "precision": 0.7008733624454149,
      "recall": 0.6775725593667546
    },
    "max": {
      "accuracy": 0.8751862669130357,
      "ap": 0.7849931105819493,
      "f1": 0.7178502879078694
    }
  }
}