{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8729212612505215,
      "accuracy_threshold": 0.7479275301154799,
      "ap": 0.7747408448528532,
      "f1": 0.7090820786789704,
      "f1_threshold": 0.6964978462703502,
      "precision": 0.656770130454341,
      "recall": 0.7704485488126649
    },
    "dot": {
      "accuracy": 0.8605233355188651,
      "accuracy_threshold": 0.5709004191267512,
      "ap": 0.7443573127882495,
      "f1": 0.6839191451010685,
      "f1_threshold": 0.5453648352038662,
      "precision": 0.6678400804626603,
      "recall": 0.7007915567282322
    },
    "euclidean": {
      "accuracy": 0.8751862669130357,
      "accuracy_threshold": 0.625054303874576,
      "ap": 0.7804508751539729,
      "f1": 0.7121513944223107,
      "f1_threshold": 0.6724583263706907,
      "precision": 0.6742102781706742,
      "recall": 0.7546174142480211
    },
    "evaluation_time": 1.37,
    "manhattan": {
      "accuracy": 0.8627287357692078,
      "accuracy_threshold": 14.44449899167161,
      "ap": 0.7514204099131336,
      "f1": 0.691812791724486,
      "f1_threshold": 15.227417921974595,
      "precision": 0.662799129804206,
      "recall": 0.7234828496042216
    },
    "max": {
      "accuracy": 0.8751862669130357,
      "ap": 0.7804508751539729,
      "f1": 0.7121513944223107
    }
  }
}