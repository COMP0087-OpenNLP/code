{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8752458723252071,
      "accuracy_threshold": 0.7685522304716835,
      "ap": 0.784086351350866,
      "f1": 0.7179420553462388,
      "f1_threshold": 0.7239921776307635,
      "precision": 0.7071922190939339,
      "recall": 0.729023746701847
    },
    "dot": {
      "accuracy": 0.8602849138701794,
      "accuracy_threshold": 0.33801310255554307,
      "ap": 0.735120232039482,
      "f1": 0.6777624827931422,
      "f1_threshold": 0.3137942916705341,
      "precision": 0.6446084265651035,
      "recall": 0.7145118733509235
    },
    "euclidean": {
      "accuracy": 0.8761399535077785,
      "accuracy_threshold": 0.4622240839336267,
      "ap": 0.7868120529519493,
      "f1": 0.7199172805997157,
      "f1_threshold": 0.49350635741471127,
      "precision": 0.7055991892576641,
      "recall": 0.7348284960422163
    },
    "evaluation_time": 1.73,
    "manhattan": {
      "accuracy": 0.869762174405436,
      "accuracy_threshold": 9.506965100550996,
      "ap": 0.7716406054224321,
      "f1": 0.7071930249455073,
      "f1_threshold": 10.245698943651082,
      "precision": 0.6535362578334826,
      "recall": 0.7704485488126649
    },
    "max": {
      "accuracy": 0.8761399535077785,
      "ap": 0.7868120529519493,
      "f1": 0.7199172805997157
    }
  }
}