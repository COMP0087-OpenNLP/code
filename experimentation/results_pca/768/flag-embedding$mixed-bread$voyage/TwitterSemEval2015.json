{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8774512725755499,
      "accuracy_threshold": 0.7344147411367861,
      "ap": 0.7905287623462883,
      "f1": 0.7233003469991004,
      "f1_threshold": 0.6963370310714392,
      "precision": 0.7050864445001253,
      "recall": 0.7424802110817942
    },
    "dot": {
      "accuracy": 0.8595100435119509,
      "accuracy_threshold": 0.3911021165319677,
      "ap": 0.7320540198811738,
      "f1": 0.6767441860465117,
      "f1_threshold": 0.37220016013622736,
      "precision": 0.6630379746835443,
      "recall": 0.6910290237467018
    },
    "euclidean": {
      "accuracy": 0.8772724563390356,
      "accuracy_threshold": 0.5356737217077826,
      "ap": 0.7929704163487827,
      "f1": 0.7201143451143451,
      "f1_threshold": 0.5667684221481248,
      "precision": 0.7094214029697901,
      "recall": 0.7311345646437994
    },
    "evaluation_time": 1.15,
    "manhattan": {
      "accuracy": 0.8701198068784646,
      "accuracy_threshold": 10.180836580879474,
      "ap": 0.7733656856369365,
      "f1": 0.7057924888605983,
      "f1_threshold": 10.89515502632219,
      "precision": 0.6819188191881919,
      "recall": 0.7313984168865435
    },
    "max": {
      "accuracy": 0.8774512725755499,
      "ap": 0.7929704163487827,
      "f1": 0.7233003469991004
    }
  }
}