{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8760207426834357,
      "accuracy_threshold": 0.7380569938916663,
      "ap": 0.7868364983828026,
      "f1": 0.7191097467382963,
      "f1_threshold": 0.6944469137388163,
      "precision": 0.6978649453823237,
      "recall": 0.741688654353562
    },
    "dot": {
      "accuracy": 0.8559337187816654,
      "accuracy_threshold": 0.40885336370848485,
      "ap": 0.7228248973428157,
      "f1": 0.6714303622915883,
      "f1_threshold": 0.38391736571793966,
      "precision": 0.6395987580606639,
      "recall": 0.7065963060686016
    },
    "euclidean": {
      "accuracy": 0.8756631102104071,
      "accuracy_threshold": 0.5464367443638218,
      "ap": 0.7906885723605568,
      "f1": 0.7234096692111959,
      "f1_threshold": 0.5855676198454047,
      "precision": 0.6985257985257985,
      "recall": 0.750131926121372
    },
    "evaluation_time": 1.3,
    "manhattan": {
      "accuracy": 0.8692257256958932,
      "accuracy_threshold": 10.03189730828263,
      "ap": 0.7693881764480553,
      "f1": 0.7010386685020648,
      "f1_threshold": 10.831159278619284,
      "precision": 0.6667460128540824,
      "recall": 0.7390501319261213
    },
    "max": {
      "accuracy": 0.8760207426834357,
      "ap": 0.7906885723605568,
      "f1": 0.7234096692111959
    }
  }
}