{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8767956130416642,
      "accuracy_threshold": 0.7514350567761323,
      "ap": 0.7847583469997961,
      "f1": 0.7177672955974844,
      "f1_threshold": 0.7160925422813399,
      "precision": 0.7129099427381572,
      "recall": 0.7226912928759894
    },
    "dot": {
      "accuracy": 0.8584967515050367,
      "accuracy_threshold": 0.5130778347438884,
      "ap": 0.7365317905252904,
      "f1": 0.6737340982788725,
      "f1_threshold": 0.46966328464715557,
      "precision": 0.6388363292336803,
      "recall": 0.7126649076517151
    },
    "euclidean": {
      "accuracy": 0.8785241699946356,
      "accuracy_threshold": 0.5743677497139793,
      "ap": 0.7906673802933611,
      "f1": 0.723437911943053,
      "f1_threshold": 0.6143093125643294,
      "precision": 0.7228661749209695,
      "recall": 0.7240105540897097
    },
    "evaluation_time": 1.16,
    "manhattan": {
      "accuracy": 0.869762174405436,
      "accuracy_threshold": 11.891154763899976,
      "ap": 0.7717308480045171,
      "f1": 0.7060425953442299,
      "f1_threshold": 12.455820995833212,
      "precision": 0.66518898740084,
      "recall": 0.7522427440633246
    },
    "max": {
      "accuracy": 0.8785241699946356,
      "ap": 0.7906673802933611,
      "f1": 0.723437911943053
    }
  }
}