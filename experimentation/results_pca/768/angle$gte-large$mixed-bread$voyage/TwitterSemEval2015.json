{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.87411336949395,
      "accuracy_threshold": 0.7448179928638679,
      "ap": 0.780919833993564,
      "f1": 0.7138576779026218,
      "f1_threshold": 0.7089112006162553,
      "precision": 0.6774881516587677,
      "recall": 0.754353562005277
    },
    "dot": {
      "accuracy": 0.8569470107885796,
      "accuracy_threshold": 0.35266378533634934,
      "ap": 0.7282575267955116,
      "f1": 0.6694978765925556,
      "f1_threshold": 0.32674061187644776,
      "precision": 0.635673624288425,
      "recall": 0.7071240105540897
    },
    "euclidean": {
      "accuracy": 0.8758419264469214,
      "accuracy_threshold": 0.486856355172493,
      "ap": 0.7843281514255658,
      "f1": 0.7168804775816081,
      "f1_threshold": 0.5143805806067288,
      "precision": 0.6911584619152584,
      "recall": 0.7445910290237467
    },
    "evaluation_time": 1.76,
    "manhattan": {
      "accuracy": 0.8679740120402932,
      "accuracy_threshold": 9.194223407887215,
      "ap": 0.7620956988359585,
      "f1": 0.6939849624060149,
      "f1_threshold": 9.973921396275774,
      "precision": 0.6608591885441527,
      "recall": 0.7306068601583113
    },
    "max": {
      "accuracy": 0.8758419264469214,
      "ap": 0.7843281514255658,
      "f1": 0.7168804775816081
    }
  }
}