{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8791202241163497,
      "accuracy_threshold": 0.7313687120701566,
      "ap": 0.793802410512789,
      "f1": 0.7218436377152769,
      "f1_threshold": 0.6857172785541151,
      "precision": 0.680448493342677,
      "recall": 0.7686015831134565
    },
    "dot": {
      "accuracy": 0.8640996602491506,
      "accuracy_threshold": 0.380007040445815,
      "ap": 0.7481341498614492,
      "f1": 0.6900012238404112,
      "f1_threshold": 0.3503553238666194,
      "precision": 0.643460397169596,
      "recall": 0.7437994722955145
    },
    "euclidean": {
      "accuracy": 0.8793586457650354,
      "accuracy_threshold": 0.5280189030323443,
      "ap": 0.7972368480152796,
      "f1": 0.7245273442456541,
      "f1_threshold": 0.561935188833689,
      "precision": 0.6978733805915424,
      "recall": 0.7532981530343008
    },
    "evaluation_time": 1.48,
    "manhattan": {
      "accuracy": 0.8754842939738928,
      "accuracy_threshold": 10.63515811290877,
      "ap": 0.7833575612845639,
      "f1": 0.7140974967061924,
      "f1_threshold": 11.049660789440033,
      "precision": 0.7131578947368421,
      "recall": 0.7150395778364116
    },
    "max": {
      "accuracy": 0.8793586457650354,
      "ap": 0.7972368480152796,
      "f1": 0.7245273442456541
    }
  }
}