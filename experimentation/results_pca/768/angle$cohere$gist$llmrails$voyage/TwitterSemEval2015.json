{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8759611372712642,
      "accuracy_threshold": 0.7396283764129294,
      "ap": 0.7867035411071732,
      "f1": 0.7214690658121766,
      "f1_threshold": 0.7035740330443074,
      "precision": 0.6769195189639223,
      "recall": 0.7722955145118734
    },
    "dot": {
      "accuracy": 0.8635036061274364,
      "accuracy_threshold": 0.46843539052629185,
      "ap": 0.7472468996014723,
      "f1": 0.6863084922010398,
      "f1_threshold": 0.42899826039995204,
      "precision": 0.6464552238805971,
      "recall": 0.7313984168865435
    },
    "euclidean": {
      "accuracy": 0.8787625916433213,
      "accuracy_threshold": 0.5566532903552848,
      "ap": 0.7913071978662738,
      "f1": 0.7247089262613194,
      "f1_threshold": 0.5863385596791737,
      "precision": 0.7109137055837563,
      "recall": 0.7390501319261213
    },
    "evaluation_time": 6.93,
    "manhattan": {
      "accuracy": 0.8717291530070931,
      "accuracy_threshold": 11.097070953277786,
      "ap": 0.7742269158865525,
      "f1": 0.7094415731753435,
      "f1_threshold": 11.771478488204657,
      "precision": 0.6792179580014482,
      "recall": 0.7424802110817942
    },
    "max": {
      "accuracy": 0.8787625916433213,
      "ap": 0.7913071978662738,
      "f1": 0.7247089262613194
    }
  }
}