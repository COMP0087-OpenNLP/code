{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8747690290278357,
      "accuracy_threshold": 0.7293372127264922,
      "ap": 0.7831250336901026,
      "f1": 0.7177472167648984,
      "f1_threshold": 0.7074942599268048,
      "precision": 0.7126137841352406,
      "recall": 0.7229551451187335
    },
    "dot": {
      "accuracy": 0.8541455564165226,
      "accuracy_threshold": 0.5172866820092696,
      "ap": 0.7195873673284309,
      "f1": 0.6648065024869587,
      "f1_threshold": 0.4653119030112749,
      "precision": 0.6153155176285651,
      "recall": 0.7229551451187335
    },
    "euclidean": {
      "accuracy": 0.8758419264469214,
      "accuracy_threshold": 0.6135203385726039,
      "ap": 0.7874854845470579,
      "f1": 0.7188612099644127,
      "f1_threshold": 0.6434805890478595,
      "precision": 0.693477194703286,
      "recall": 0.7461741424802111
    },
    "evaluation_time": 1.05,
    "manhattan": {
      "accuracy": 0.8689873040472075,
      "accuracy_threshold": 11.006934859996681,
      "ap": 0.7655212992477445,
      "f1": 0.6972407710721936,
      "f1_threshold": 11.827153844182174,
      "precision": 0.6672293224017362,
      "recall": 0.7300791556728232
    },
    "max": {
      "accuracy": 0.8758419264469214,
      "ap": 0.7874854845470579,
      "f1": 0.7188612099644127
    }
  }
}