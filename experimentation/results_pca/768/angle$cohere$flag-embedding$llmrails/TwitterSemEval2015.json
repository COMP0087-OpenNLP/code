{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8795374620015497,
      "accuracy_threshold": 0.7296201006641133,
      "ap": 0.7908741967663075,
      "f1": 0.7206935544666414,
      "f1_threshold": 0.689394199620577,
      "precision": 0.6879347565363396,
      "recall": 0.7567282321899736
    },
    "dot": {
      "accuracy": 0.8619538654109793,
      "accuracy_threshold": 0.4791842919468319,
      "ap": 0.7431064411237812,
      "f1": 0.6848983543078413,
      "f1_threshold": 0.4352814268825683,
      "precision": 0.6325435851586947,
      "recall": 0.7467018469656992
    },
    "euclidean": {
      "accuracy": 0.8793586457650354,
      "accuracy_threshold": 0.5870428569773818,
      "ap": 0.796185464129132,
      "f1": 0.7267752442996743,
      "f1_threshold": 0.6217695047201617,
      "precision": 0.7178893178893179,
      "recall": 0.7358839050131926
    },
    "evaluation_time": 1.45,
    "manhattan": {
      "accuracy": 0.8727424450140072,
      "accuracy_threshold": 11.746806224574897,
      "ap": 0.7781457451821375,
      "f1": 0.7115730048755453,
      "f1_threshold": 12.35076784522876,
      "precision": 0.6925574425574426,
      "recall": 0.7316622691292876
    },
    "max": {
      "accuracy": 0.8795374620015497,
      "ap": 0.796185464129132,
      "f1": 0.7267752442996743
    }
  }
}