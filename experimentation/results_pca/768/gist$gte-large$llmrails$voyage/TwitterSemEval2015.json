{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.87494784526435,
      "accuracy_threshold": 0.7513670872961853,
      "ap": 0.7843092484744387,
      "f1": 0.718541797611565,
      "f1_threshold": 0.7043956101698696,
      "precision": 0.6861944777911164,
      "recall": 0.754089709762533
    },
    "dot": {
      "accuracy": 0.8627287357692078,
      "accuracy_threshold": 0.3530113810743599,
      "ap": 0.7431657395529034,
      "f1": 0.685948297926798,
      "f1_threshold": 0.32996159566864663,
      "precision": 0.6660039761431411,
      "recall": 0.7071240105540897
    },
    "euclidean": {
      "accuracy": 0.8756035047982357,
      "accuracy_threshold": 0.5012491035448337,
      "ap": 0.7876478387725498,
      "f1": 0.7200788857389375,
      "f1_threshold": 0.5295596041829597,
      "precision": 0.6756881795049734,
      "recall": 0.770712401055409
    },
    "evaluation_time": 1.57,
    "manhattan": {
      "accuracy": 0.8680336174524647,
      "accuracy_threshold": 9.38691991924512,
      "ap": 0.7653943231442458,
      "f1": 0.6991231514199713,
      "f1_threshold": 9.954039763850778,
      "precision": 0.6935860815372631,
      "recall": 0.7047493403693932
    },
    "max": {
      "accuracy": 0.8756035047982357,
      "ap": 0.7876478387725498,
      "f1": 0.7200788857389375
    }
  }
}