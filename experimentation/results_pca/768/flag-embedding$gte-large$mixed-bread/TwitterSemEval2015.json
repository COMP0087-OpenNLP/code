{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8761995589199499,
      "accuracy_threshold": 0.7299512598944666,
      "ap": 0.7862036100628572,
      "f1": 0.7188510803467459,
      "f1_threshold": 0.6996278643935265,
      "precision": 0.7052551408987052,
      "recall": 0.732981530343008
    },
    "dot": {
      "accuracy": 0.8552780592477797,
      "accuracy_threshold": 0.40505113144536914,
      "ap": 0.7213198940994945,
      "f1": 0.6694497153700191,
      "f1_threshold": 0.3819990090082045,
      "precision": 0.6430133657351155,
      "recall": 0.6981530343007916
    },
    "euclidean": {
      "accuracy": 0.87536508314955,
      "accuracy_threshold": 0.549855569889967,
      "ap": 0.7899491008713988,
      "f1": 0.7210519596578577,
      "f1_threshold": 0.5795122291786994,
      "precision": 0.6984912193915409,
      "recall": 0.7451187335092349
    },
    "evaluation_time": 1.04,
    "manhattan": {
      "accuracy": 0.8683316445133218,
      "accuracy_threshold": 9.978526445059883,
      "ap": 0.7686894435651388,
      "f1": 0.6995559940799211,
      "f1_threshold": 10.787817517472519,
      "precision": 0.6567855488652153,
      "recall": 0.7482849604221636
    },
    "max": {
      "accuracy": 0.8761995589199499,
      "ap": 0.7899491008713988,
      "f1": 0.7210519596578577
    }
  }
}