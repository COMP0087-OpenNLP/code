{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8725040233653216,
      "accuracy_threshold": 0.7579558630776368,
      "ap": 0.7753262632959721,
      "f1": 0.7112899292855401,
      "f1_threshold": 0.7021231176518108,
      "precision": 0.6611514052583862,
      "recall": 0.7696569920844327
    },
    "dot": {
      "accuracy": 0.8619538654109793,
      "accuracy_threshold": 0.5587752293671008,
      "ap": 0.7443750861785284,
      "f1": 0.6878549848942598,
      "f1_threshold": 0.5110758787641305,
      "precision": 0.6345596432552955,
      "recall": 0.7509234828496042
    },
    "euclidean": {
      "accuracy": 0.8743517911426357,
      "accuracy_threshold": 0.6137001791618257,
      "ap": 0.7791070771593891,
      "f1": 0.7130806999874102,
      "f1_threshold": 0.6470968544584992,
      "precision": 0.6819166867324825,
      "recall": 0.7472295514511873
    },
    "evaluation_time": 1.43,
    "manhattan": {
      "accuracy": 0.8655897955534363,
      "accuracy_threshold": 11.952917641094608,
      "ap": 0.7597901435407369,
      "f1": 0.7015283567007704,
      "f1_threshold": 13.100510245974547,
      "precision": 0.6728858735158711,
      "recall": 0.7327176781002639
    },
    "max": {
      "accuracy": 0.8743517911426357,
      "ap": 0.7791070771593891,
      "f1": 0.7130806999874102
    }
  }
}