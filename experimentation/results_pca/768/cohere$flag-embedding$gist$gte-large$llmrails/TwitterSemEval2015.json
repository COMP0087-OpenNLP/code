{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8769744292781785,
      "accuracy_threshold": 0.7407578606356606,
      "ap": 0.7877230635619559,
      "f1": 0.720898315658141,
      "f1_threshold": 0.699249453884584,
      "precision": 0.6837869822485207,
      "recall": 0.7622691292875989
    },
    "dot": {
      "accuracy": 0.8627883411813793,
      "accuracy_threshold": 0.45863374105746335,
      "ap": 0.7470983127210643,
      "f1": 0.6880517219942808,
      "f1_threshold": 0.4251218670082052,
      "precision": 0.6505995767693393,
      "recall": 0.7300791556728232
    },
    "euclidean": {
      "accuracy": 0.878583775406807,
      "accuracy_threshold": 0.5642125795428335,
      "ap": 0.7929230911878202,
      "f1": 0.7234097681046768,
      "f1_threshold": 0.5949953803186854,
      "precision": 0.7106133876304404,
      "recall": 0.7366754617414248
    },
    "evaluation_time": 1.73,
    "manhattan": {
      "accuracy": 0.8716695475949217,
      "accuracy_threshold": 11.329596935064771,
      "ap": 0.7748401466838963,
      "f1": 0.709848484848485,
      "f1_threshold": 11.911989444893763,
      "precision": 0.6806295399515738,
      "recall": 0.741688654353562
    },
    "max": {
      "accuracy": 0.878583775406807,
      "ap": 0.7929230911878202,
      "f1": 0.7234097681046768
    }
  }
}