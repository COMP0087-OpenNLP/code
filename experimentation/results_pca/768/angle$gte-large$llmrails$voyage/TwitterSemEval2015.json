{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8757227156225785,
      "accuracy_threshold": 0.7377529792345311,
      "ap": 0.7857102434677061,
      "f1": 0.7188144329896906,
      "f1_threshold": 0.7042240821704105,
      "precision": 0.7025188916876575,
      "recall": 0.7358839050131926
    },
    "dot": {
      "accuracy": 0.8602849138701794,
      "accuracy_threshold": 0.3337492581144657,
      "ap": 0.735333787957143,
      "f1": 0.6778457772337821,
      "f1_threshold": 0.30984369159646596,
      "precision": 0.6321917808219178,
      "recall": 0.7306068601583113
    },
    "euclidean": {
      "accuracy": 0.8763187697442928,
      "accuracy_threshold": 0.492292874246291,
      "ap": 0.7887241787547027,
      "f1": 0.7206300025819777,
      "f1_threshold": 0.5165081402352282,
      "precision": 0.7055106167846309,
      "recall": 0.7364116094986808
    },
    "evaluation_time": 1.44,
    "manhattan": {
      "accuracy": 0.8679144066281218,
      "accuracy_threshold": 9.455878063981558,
      "ap": 0.7655476914111506,
      "f1": 0.6990116801437557,
      "f1_threshold": 10.014103845877761,
      "precision": 0.680579855036241,
      "recall": 0.7184696569920844
    },
    "max": {
      "accuracy": 0.8763187697442928,
      "ap": 0.7887241787547027,
      "f1": 0.7206300025819777
    }
  }
}