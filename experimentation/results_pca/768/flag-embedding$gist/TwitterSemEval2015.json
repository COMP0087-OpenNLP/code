{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.87536508314955,
      "accuracy_threshold": 0.7418029072163759,
      "ap": 0.7850021457290584,
      "f1": 0.7193226336408441,
      "f1_threshold": 0.7004217425648356,
      "precision": 0.6902740722774678,
      "recall": 0.7509234828496042
    },
    "dot": {
      "accuracy": 0.862192287059665,
      "accuracy_threshold": 0.5131394001116778,
      "ap": 0.7370331028192149,
      "f1": 0.6846299810246679,
      "f1_threshold": 0.48022893235392294,
      "precision": 0.6575941676792224,
      "recall": 0.7139841688654354
    },
    "euclidean": {
      "accuracy": 0.8754246885617214,
      "accuracy_threshold": 0.6039414391991318,
      "ap": 0.7895139640536059,
      "f1": 0.7211427100759232,
      "f1_threshold": 0.6365852135480035,
      "precision": 0.7038432554634514,
      "recall": 0.7393139841688654
    },
    "evaluation_time": 0.8,
    "manhattan": {
      "accuracy": 0.8694641473445789,
      "accuracy_threshold": 11.123512242888307,
      "ap": 0.7715505137622057,
      "f1": 0.7015261446084562,
      "f1_threshold": 11.81196706297396,
      "precision": 0.6669838249286394,
      "recall": 0.7398416886543535
    },
    "max": {
      "accuracy": 0.8754246885617214,
      "ap": 0.7895139640536059,
      "f1": 0.7211427100759232
    }
  }
}