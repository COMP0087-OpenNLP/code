{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8748882398521786,
      "accuracy_threshold": 0.7460963155321708,
      "ap": 0.7830189965161723,
      "f1": 0.7178973717146433,
      "f1_threshold": 0.7091896988574735,
      "precision": 0.6828571428571428,
      "recall": 0.7567282321899736
    },
    "dot": {
      "accuracy": 0.8612386004649222,
      "accuracy_threshold": 0.4392345280627371,
      "ap": 0.7432606158867494,
      "f1": 0.6849793981770508,
      "f1_threshold": 0.4078657178188921,
      "precision": 0.6501540649442996,
      "recall": 0.7237467018469657
    },
    "euclidean": {
      "accuracy": 0.8771532455146928,
      "accuracy_threshold": 0.5408945157919103,
      "ap": 0.7881215801704458,
      "f1": 0.7213789554926678,
      "f1_threshold": 0.5703263597711057,
      "precision": 0.7038152610441767,
      "recall": 0.7398416886543535
    },
    "evaluation_time": 2.38,
    "manhattan": {
      "accuracy": 0.8695833581689217,
      "accuracy_threshold": 10.70336923622574,
      "ap": 0.7690998452211177,
      "f1": 0.7071078431372549,
      "f1_threshold": 11.5901835338144,
      "precision": 0.6601830663615561,
      "recall": 0.7612137203166227
    },
    "max": {
      "accuracy": 0.8771532455146928,
      "ap": 0.7881215801704458,
      "f1": 0.7213789554926678
    }
  }
}