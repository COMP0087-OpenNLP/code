{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8784049591702927,
      "accuracy_threshold": 0.7338186245843963,
      "ap": 0.7903481839236196,
      "f1": 0.7219257972453158,
      "f1_threshold": 0.6918162587908253,
      "precision": 0.6814242211290701,
      "recall": 0.7675461741424802
    },
    "dot": {
      "accuracy": 0.8630863682422364,
      "accuracy_threshold": 0.48681636179029847,
      "ap": 0.7481482072566432,
      "f1": 0.6894013738959764,
      "f1_threshold": 0.4507407652752571,
      "precision": 0.6441999082989455,
      "recall": 0.741424802110818
    },
    "euclidean": {
      "accuracy": 0.8793586457650354,
      "accuracy_threshold": 0.5877389781346369,
      "ap": 0.7957870180428877,
      "f1": 0.7248781772685368,
      "f1_threshold": 0.6175201349201249,
      "precision": 0.723639232185117,
      "recall": 0.7261213720316623
    },
    "evaluation_time": 1.44,
    "manhattan": {
      "accuracy": 0.8726828396018358,
      "accuracy_threshold": 11.745734924187918,
      "ap": 0.7785344607795734,
      "f1": 0.7131210191082803,
      "f1_threshold": 12.359345710146659,
      "precision": 0.6894088669950739,
      "recall": 0.7385224274406332
    },
    "max": {
      "accuracy": 0.8793586457650354,
      "ap": 0.7957870180428877,
      "f1": 0.7248781772685368
    }
  }
}