{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8763187697442928,
      "accuracy_threshold": 0.7434061448634537,
      "ap": 0.7866729661871323,
      "f1": 0.719970432425773,
      "f1_threshold": 0.6981024759522378,
      "precision": 0.6752946614282412,
      "recall": 0.770976253298153
    },
    "dot": {
      "accuracy": 0.861775049174465,
      "accuracy_threshold": 0.5030481278039163,
      "ap": 0.7452063818317894,
      "f1": 0.6848515605176351,
      "f1_threshold": 0.4693243545272936,
      "precision": 0.6595796676441837,
      "recall": 0.7121372031662269
    },
    "euclidean": {
      "accuracy": 0.8787625916433213,
      "accuracy_threshold": 0.5848002745884094,
      "ap": 0.7922284777657572,
      "f1": 0.7229935210895148,
      "f1_threshold": 0.6119257175791828,
      "precision": 0.7246223164590512,
      "recall": 0.7213720316622692
    },
    "evaluation_time": 1.41,
    "manhattan": {
      "accuracy": 0.870596650175836,
      "accuracy_threshold": 11.498560988938081,
      "ap": 0.7743113411952828,
      "f1": 0.7107565620174986,
      "f1_threshold": 12.20861244059131,
      "precision": 0.6936212958312405,
      "recall": 0.7287598944591029
    },
    "max": {
      "accuracy": 0.8787625916433213,
      "ap": 0.7922284777657572,
      "f1": 0.7229935210895148
    }
  }
}