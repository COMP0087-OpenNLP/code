{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8731596828992072,
      "accuracy_threshold": 0.7433821784241534,
      "ap": 0.7775685175878617,
      "f1": 0.7122861586314152,
      "f1_threshold": 0.7157169155899558,
      "precision": 0.6999490575649516,
      "recall": 0.725065963060686
    },
    "dot": {
      "accuracy": 0.8529534481730942,
      "accuracy_threshold": 0.4516633909855967,
      "ap": 0.7173442172291422,
      "f1": 0.6602153138986331,
      "f1_threshold": 0.40655942232785014,
      "precision": 0.6095599731963368,
      "recall": 0.7200527704485488
    },
    "euclidean": {
      "accuracy": 0.8745902127913214,
      "accuracy_threshold": 0.5487051057347383,
      "ap": 0.7823639536853473,
      "f1": 0.7141605108300989,
      "f1_threshold": 0.5867273789899747,
      "precision": 0.6795329997617345,
      "recall": 0.7525065963060686
    },
    "evaluation_time": 1.04,
    "manhattan": {
      "accuracy": 0.8669011146212076,
      "accuracy_threshold": 10.06877348896012,
      "ap": 0.7596807299265511,
      "f1": 0.6930891759688951,
      "f1_threshold": 10.755578891584753,
      "precision": 0.6605307195792494,
      "recall": 0.729023746701847
    },
    "max": {
      "accuracy": 0.8745902127913214,
      "ap": 0.7823639536853473,
      "f1": 0.7141605108300989
    }
  }
}