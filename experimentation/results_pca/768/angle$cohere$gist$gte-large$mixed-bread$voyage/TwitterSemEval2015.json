{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8756631102104071,
      "accuracy_threshold": 0.7483881536944879,
      "ap": 0.783450730911824,
      "f1": 0.7188171363578921,
      "f1_threshold": 0.716936294142305,
      "precision": 0.6897889886005336,
      "recall": 0.7503957783641161
    },
    "dot": {
      "accuracy": 0.8595100435119509,
      "accuracy_threshold": 0.3933128693034022,
      "ap": 0.7382912156458523,
      "f1": 0.6762305218896858,
      "f1_threshold": 0.35635489742100523,
      "precision": 0.6364059590316573,
      "recall": 0.7213720316622692
    },
    "euclidean": {
      "accuracy": 0.8768552184538356,
      "accuracy_threshold": 0.5039107028744652,
      "ap": 0.7880600097791509,
      "f1": 0.7218785506880444,
      "f1_threshold": 0.5336160721627254,
      "precision": 0.6920842411038489,
      "recall": 0.754353562005277
    },
    "evaluation_time": 2.25,
    "manhattan": {
      "accuracy": 0.8691065148715503,
      "accuracy_threshold": 9.520588671298537,
      "ap": 0.7709608410096422,
      "f1": 0.7071140262361251,
      "f1_threshold": 10.334784280093288,
      "precision": 0.6773803769937168,
      "recall": 0.7395778364116095
    },
    "max": {
      "accuracy": 0.8768552184538356,
      "ap": 0.7880600097791509,
      "f1": 0.7218785506880444
    }
  }
}