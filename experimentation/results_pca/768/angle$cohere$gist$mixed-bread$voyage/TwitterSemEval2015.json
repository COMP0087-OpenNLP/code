{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8753054777373785,
      "accuracy_threshold": 0.7578880998681965,
      "ap": 0.7847937277251269,
      "f1": 0.7206487835308797,
      "f1_threshold": 0.7112268883083518,
      "precision": 0.6835502958579882,
      "recall": 0.7620052770448549
    },
    "dot": {
      "accuracy": 0.861357811289265,
      "accuracy_threshold": 0.47625592735138594,
      "ap": 0.7440163793163325,
      "f1": 0.6822616962722041,
      "f1_threshold": 0.4364590478626756,
      "precision": 0.6486679352997146,
      "recall": 0.7195250659630607
    },
    "euclidean": {
      "accuracy": 0.8783453537581213,
      "accuracy_threshold": 0.5544712634415645,
      "ap": 0.7897444007032216,
      "f1": 0.7232646634299962,
      "f1_threshold": 0.580871162035387,
      "precision": 0.719394413991125,
      "recall": 0.7271767810026385
    },
    "evaluation_time": 2.56,
    "manhattan": {
      "accuracy": 0.8700005960541217,
      "accuracy_threshold": 11.171784006008352,
      "ap": 0.7722438282600564,
      "f1": 0.7085769980506823,
      "f1_threshold": 11.9011805980243,
      "precision": 0.6582163875056587,
      "recall": 0.7672823218997361
    },
    "max": {
      "accuracy": 0.8783453537581213,
      "ap": 0.7897444007032216,
      "f1": 0.7232646634299962
    }
  }
}