{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.870596650175836,
      "accuracy_threshold": 0.7509024345999734,
      "ap": 0.7697580425485084,
      "f1": 0.7054743621501115,
      "f1_threshold": 0.7052601366440161,
      "precision": 0.6647992530345471,
      "recall": 0.7514511873350923
    },
    "dot": {
      "accuracy": 0.8591524110389224,
      "accuracy_threshold": 0.46922034141021707,
      "ap": 0.7381665359939893,
      "f1": 0.6818515797207936,
      "f1_threshold": 0.43583224442465485,
      "precision": 0.6361974405850092,
      "recall": 0.7345646437994723
    },
    "euclidean": {
      "accuracy": 0.8713119151218931,
      "accuracy_threshold": 0.5619738375509764,
      "ap": 0.7732397761088006,
      "f1": 0.7085700172882193,
      "f1_threshold": 0.6034275045467887,
      "precision": 0.6659702878365831,
      "recall": 0.7569920844327177
    },
    "evaluation_time": 1.12,
    "manhattan": {
      "accuracy": 0.8638612386004649,
      "accuracy_threshold": 11.076844230495599,
      "ap": 0.7529415120082418,
      "f1": 0.6949045391326337,
      "f1_threshold": 12.082772175272474,
      "precision": 0.6671522214129643,
      "recall": 0.725065963060686
    },
    "max": {
      "accuracy": 0.8713119151218931,
      "ap": 0.7732397761088006,
      "f1": 0.7085700172882193
    }
  }
}