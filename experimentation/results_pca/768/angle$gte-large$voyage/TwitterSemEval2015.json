{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8737557370209215,
      "accuracy_threshold": 0.7378153355915544,
      "ap": 0.7792073225518479,
      "f1": 0.7137771918259723,
      "f1_threshold": 0.721740902893997,
      "precision": 0.7133069828722003,
      "recall": 0.7142480211081794
    },
    "dot": {
      "accuracy": 0.8572450378494367,
      "accuracy_threshold": 0.3513971684550238,
      "ap": 0.7300379345947589,
      "f1": 0.6724946154820727,
      "f1_threshold": 0.32720257552761245,
      "precision": 0.6468437728491347,
      "recall": 0.700263852242744
    },
    "euclidean": {
      "accuracy": 0.8748286344400071,
      "accuracy_threshold": 0.489359815421769,
      "ap": 0.7825960691068955,
      "f1": 0.7162431489785749,
      "f1_threshold": 0.5216199239031435,
      "precision": 0.6783860311467673,
      "recall": 0.758575197889182
    },
    "evaluation_time": 1.16,
    "manhattan": {
      "accuracy": 0.8664242713238363,
      "accuracy_threshold": 9.383040401535759,
      "ap": 0.7602722231683385,
      "f1": 0.6935793925413303,
      "f1_threshold": 9.943894183524979,
      "precision": 0.6743084973835036,
      "recall": 0.7139841688654354
    },
    "max": {
      "accuracy": 0.8748286344400071,
      "ap": 0.7825960691068955,
      "f1": 0.7162431489785749
    }
  }
}