{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8729808666626929,
      "accuracy_threshold": 0.7417029644797672,
      "ap": 0.7790514198519621,
      "f1": 0.7121938904317091,
      "f1_threshold": 0.7096548631064917,
      "precision": 0.6827202323330106,
      "recall": 0.7443271767810027
    },
    "dot": {
      "accuracy": 0.8556356917208082,
      "accuracy_threshold": 0.5382842810025071,
      "ap": 0.7245385051260398,
      "f1": 0.6678369905956113,
      "f1_threshold": 0.497597768368031,
      "precision": 0.6363201911589008,
      "recall": 0.7026385224274406
    },
    "euclidean": {
      "accuracy": 0.8754246885617214,
      "accuracy_threshold": 0.6049773664949559,
      "ap": 0.7840245563552832,
      "f1": 0.7153006851053033,
      "f1_threshold": 0.6387046270730112,
      "precision": 0.6889051808406648,
      "recall": 0.7437994722955145
    },
    "evaluation_time": 1.05,
    "manhattan": {
      "accuracy": 0.8680932228646361,
      "accuracy_threshold": 10.955181097375622,
      "ap": 0.7630510667139767,
      "f1": 0.6957842764906951,
      "f1_threshold": 11.681523679063652,
      "precision": 0.6687758578729618,
      "recall": 0.725065963060686
    },
    "max": {
      "accuracy": 0.8754246885617214,
      "ap": 0.7840245563552832,
      "f1": 0.7153006851053033
    }
  }
}