{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8775108779877213,
      "accuracy_threshold": 0.7403826489496641,
      "ap": 0.7890733411615164,
      "f1": 0.7213114754098361,
      "f1_threshold": 0.6997136587245651,
      "precision": 0.681370248709526,
      "recall": 0.7662269129287599
    },
    "dot": {
      "accuracy": 0.862609524944865,
      "accuracy_threshold": 0.44354331144964576,
      "ap": 0.7472695710323443,
      "f1": 0.6860537062244771,
      "f1_threshold": 0.411320845281119,
      "precision": 0.6460032626427407,
      "recall": 0.7313984168865435
    },
    "euclidean": {
      "accuracy": 0.8796566728258925,
      "accuracy_threshold": 0.5529077344359543,
      "ap": 0.7936105877806316,
      "f1": 0.7243664717348928,
      "f1_threshold": 0.5821534244959197,
      "precision": 0.7137003841229194,
      "recall": 0.7353562005277045
    },
    "evaluation_time": 1.91,
    "manhattan": {
      "accuracy": 0.8730404720748643,
      "accuracy_threshold": 11.005014501250335,
      "ap": 0.7770840033643648,
      "f1": 0.7111167448345798,
      "f1_threshold": 11.675941372057089,
      "precision": 0.6843132471334472,
      "recall": 0.7401055408970977
    },
    "max": {
      "accuracy": 0.8796566728258925,
      "ap": 0.7936105877806316,
      "f1": 0.7243664717348928
    }
  }
}