{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8761399535077785,
      "accuracy_threshold": 0.7343051919059463,
      "ap": 0.7863943246753087,
      "f1": 0.7213406119080868,
      "f1_threshold": 0.6980060294976091,
      "precision": 0.6951309028627355,
      "recall": 0.7496042216358839
    },
    "dot": {
      "accuracy": 0.8586159623293795,
      "accuracy_threshold": 0.4134856314162196,
      "ap": 0.7321683323282301,
      "f1": 0.6739823912211306,
      "f1_threshold": 0.3892765338464244,
      "precision": 0.6525821596244131,
      "recall": 0.6968337730870713
    },
    "euclidean": {
      "accuracy": 0.8766167968051499,
      "accuracy_threshold": 0.5436242881659701,
      "ap": 0.7897061680138302,
      "f1": 0.7213488843813388,
      "f1_threshold": 0.5809850515079242,
      "precision": 0.694241093216203,
      "recall": 0.7506596306068601
    },
    "evaluation_time": 2.93,
    "manhattan": {
      "accuracy": 0.8680932228646361,
      "accuracy_threshold": 10.297743611129816,
      "ap": 0.7684446583377335,
      "f1": 0.7006629270780214,
      "f1_threshold": 11.08116731356911,
      "precision": 0.6778490379871731,
      "recall": 0.725065963060686
    },
    "max": {
      "accuracy": 0.8766167968051499,
      "ap": 0.7897061680138302,
      "f1": 0.7213488843813388
    }
  }
}