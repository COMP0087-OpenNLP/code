{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8794182511772068,
      "accuracy_threshold": 0.7329691635135305,
      "ap": 0.7917422890527065,
      "f1": 0.7223850171996434,
      "f1_threshold": 0.6952738145599225,
      "precision": 0.6984478935698448,
      "recall": 0.7480211081794196
    },
    "dot": {
      "accuracy": 0.8610597842284079,
      "accuracy_threshold": 0.4810871128347287,
      "ap": 0.7417079519846602,
      "f1": 0.6844389336639802,
      "f1_threshold": 0.4419287840652435,
      "precision": 0.6456140350877193,
      "recall": 0.7282321899736148
    },
    "euclidean": {
      "accuracy": 0.8795374620015497,
      "accuracy_threshold": 0.5863631173444745,
      "ap": 0.7974352671125635,
      "f1": 0.7272254710851203,
      "f1_threshold": 0.620533505719552,
      "precision": 0.7165172855313701,
      "recall": 0.7382585751978892
    },
    "evaluation_time": 1.44,
    "manhattan": {
      "accuracy": 0.8730404720748643,
      "accuracy_threshold": 11.711551249191608,
      "ap": 0.780624245678814,
      "f1": 0.7125109800476848,
      "f1_threshold": 12.413223771057957,
      "precision": 0.6793491265853074,
      "recall": 0.7490765171503958
    },
    "max": {
      "accuracy": 0.8795374620015497,
      "ap": 0.7974352671125635,
      "f1": 0.7272254710851203
    }
  }
}