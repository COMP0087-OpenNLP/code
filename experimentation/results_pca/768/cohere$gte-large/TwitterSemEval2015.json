{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8664242713238363,
      "accuracy_threshold": 0.745707081714764,
      "ap": 0.7590526146109163,
      "f1": 0.6959688559588095,
      "f1_threshold": 0.7068613611826977,
      "precision": 0.6640306733764678,
      "recall": 0.7311345646437994
    },
    "dot": {
      "accuracy": 0.8567681945520653,
      "accuracy_threshold": 0.38468451800706915,
      "ap": 0.730527901204498,
      "f1": 0.6750750750750751,
      "f1_threshold": 0.3610257705189521,
      "precision": 0.619625137816979,
      "recall": 0.741424802110818
    },
    "euclidean": {
      "accuracy": 0.8664242713238363,
      "accuracy_threshold": 0.5032390964111563,
      "ap": 0.7613314530190113,
      "f1": 0.7007244566575068,
      "f1_threshold": 0.5532280279214119,
      "precision": 0.6653225806451613,
      "recall": 0.7401055408970977
    },
    "evaluation_time": 0.89,
    "manhattan": {
      "accuracy": 0.8594504380997795,
      "accuracy_threshold": 10.400291249018668,
      "ap": 0.7390339220262006,
      "f1": 0.6843076923076922,
      "f1_threshold": 11.24564344036277,
      "precision": 0.6412918108419838,
      "recall": 0.7335092348284961
    },
    "max": {
      "accuracy": 0.8664242713238363,
      "ap": 0.7613314530190113,
      "f1": 0.7007244566575068
    }
  }
}