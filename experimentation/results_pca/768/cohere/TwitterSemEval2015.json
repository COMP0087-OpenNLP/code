{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.861357811289265,
      "accuracy_threshold": 0.7484017269033667,
      "ap": 0.7433995892021577,
      "f1": 0.6825579905164679,
      "f1_threshold": 0.706637537456408,
      "precision": 0.6635933217044605,
      "recall": 0.7026385224274406
    },
    "dot": {
      "accuracy": 0.853072658997437,
      "accuracy_threshold": 0.6539502467195373,
      "ap": 0.7175925016591291,
      "f1": 0.6637467150544363,
      "f1_threshold": 0.6092291998239183,
      "precision": 0.6312782670792668,
      "recall": 0.6997361477572559
    },
    "euclidean": {
      "accuracy": 0.8624307087083507,
      "accuracy_threshold": 0.66510112711029,
      "ap": 0.7482781508659516,
      "f1": 0.6896636085626912,
      "f1_threshold": 0.730642007714917,
      "precision": 0.6428734321550741,
      "recall": 0.7437994722955145
    },
    "evaluation_time": 0.77,
    "manhattan": {
      "accuracy": 0.853907134767837,
      "accuracy_threshold": 12.946630134319431,
      "ap": 0.7216912067779414,
      "f1": 0.666421568627451,
      "f1_threshold": 14.378237122471912,
      "precision": 0.6221967963386728,
      "recall": 0.7174142480211082
    },
    "max": {
      "accuracy": 0.8624307087083507,
      "ap": 0.7482781508659516,
      "f1": 0.6896636085626912
    }
  }
}