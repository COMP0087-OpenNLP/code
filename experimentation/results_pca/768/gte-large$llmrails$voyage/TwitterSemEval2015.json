{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8739941586696072,
      "accuracy_threshold": 0.7395570407203693,
      "ap": 0.7815685961378657,
      "f1": 0.7154532880673959,
      "f1_threshold": 0.6989512646084927,
      "precision": 0.6834013932260389,
      "recall": 0.7506596306068601
    },
    "dot": {
      "accuracy": 0.8593908326876081,
      "accuracy_threshold": 0.2636698778201392,
      "ap": 0.7343139334335651,
      "f1": 0.678429003021148,
      "f1_threshold": 0.24105194229335375,
      "precision": 0.6258639910813824,
      "recall": 0.7406332453825858
    },
    "euclidean": {
      "accuracy": 0.8735769207844072,
      "accuracy_threshold": 0.42850169815482797,
      "ap": 0.783331071676896,
      "f1": 0.7166666666666667,
      "f1_threshold": 0.452815699022865,
      "precision": 0.7074550128534705,
      "recall": 0.7261213720316623
    },
    "evaluation_time": 1.15,
    "manhattan": {
      "accuracy": 0.8648745306073792,
      "accuracy_threshold": 8.58186207985338,
      "ap": 0.7593590607594607,
      "f1": 0.6925083861349236,
      "f1_threshold": 9.07959047793188,
      "precision": 0.654378962197699,
      "recall": 0.7353562005277045
    },
    "max": {
      "accuracy": 0.8739941586696072,
      "ap": 0.783331071676896,
      "f1": 0.7166666666666667
    }
  }
}