{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8772724563390356,
      "accuracy_threshold": 0.7406205089234218,
      "ap": 0.7872643081306755,
      "f1": 0.718232044198895,
      "f1_threshold": 0.7025657551230788,
      "precision": 0.6851940584571155,
      "recall": 0.7546174142480211
    },
    "dot": {
      "accuracy": 0.8594504380997795,
      "accuracy_threshold": 0.4229384985571203,
      "ap": 0.7402758824950162,
      "f1": 0.6792074241284174,
      "f1_threshold": 0.3869234087144728,
      "precision": 0.6472275334608031,
      "recall": 0.7145118733509235
    },
    "euclidean": {
      "accuracy": 0.8788818024676641,
      "accuracy_threshold": 0.5397839323771989,
      "ap": 0.7927454938423933,
      "f1": 0.7227422544495714,
      "f1_threshold": 0.5584224893434097,
      "precision": 0.722266139657444,
      "recall": 0.7232189973614775
    },
    "evaluation_time": 1.44,
    "manhattan": {
      "accuracy": 0.8716099421827502,
      "accuracy_threshold": 10.624186004803798,
      "ap": 0.7749942094075635,
      "f1": 0.7101321585903084,
      "f1_threshold": 11.345289650331036,
      "precision": 0.6789410348977136,
      "recall": 0.7443271767810027
    },
    "max": {
      "accuracy": 0.8788818024676641,
      "ap": 0.7927454938423933,
      "f1": 0.7227422544495714
    }
  }
}