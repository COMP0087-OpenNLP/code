{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8736365261965786,
      "accuracy_threshold": 0.7407474669526941,
      "ap": 0.7794076876087817,
      "f1": 0.7133640552995391,
      "f1_threshold": 0.7174072201798305,
      "precision": 0.7119579500657031,
      "recall": 0.7147757255936675
    },
    "dot": {
      "accuracy": 0.8528938427609227,
      "accuracy_threshold": 0.5361710027028247,
      "ap": 0.7148091247142805,
      "f1": 0.6572689384653102,
      "f1_threshold": 0.4824587520852694,
      "precision": 0.6137820512820513,
      "recall": 0.7073878627968337
    },
    "euclidean": {
      "accuracy": 0.8750074506765214,
      "accuracy_threshold": 0.5928438890547423,
      "ap": 0.7840521866848802,
      "f1": 0.7140653124196451,
      "f1_threshold": 0.6357082255377475,
      "precision": 0.6963390170511534,
      "recall": 0.7327176781002639
    },
    "evaluation_time": 0.79,
    "manhattan": {
      "accuracy": 0.8674971687429218,
      "accuracy_threshold": 10.87912286486143,
      "ap": 0.7612939193462822,
      "f1": 0.6939727802981206,
      "f1_threshold": 11.573830570878751,
      "precision": 0.6820382165605096,
      "recall": 0.7063324538258575
    },
    "max": {
      "accuracy": 0.8750074506765214,
      "ap": 0.7840521866848802,
      "f1": 0.7140653124196451
    }
  }
}