{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8766764022173213,
      "accuracy_threshold": 0.7403810736474056,
      "ap": 0.7870570473438052,
      "f1": 0.720440881763527,
      "f1_threshold": 0.7068358634695171,
      "precision": 0.6857415355269433,
      "recall": 0.7588390501319261
    },
    "dot": {
      "accuracy": 0.8596888597484652,
      "accuracy_threshold": 0.41963164728073343,
      "ap": 0.7402026224644265,
      "f1": 0.6786727519427657,
      "f1_threshold": 0.3841626635222694,
      "precision": 0.6372480889506602,
      "recall": 0.7258575197889182
    },
    "euclidean": {
      "accuracy": 0.8778685104607499,
      "accuracy_threshold": 0.5229323882390889,
      "ap": 0.7919600093560065,
      "f1": 0.7226612286515423,
      "f1_threshold": 0.5618366331705251,
      "precision": 0.6989644970414202,
      "recall": 0.7480211081794196
    },
    "evaluation_time": 2.54,
    "manhattan": {
      "accuracy": 0.8708350718245217,
      "accuracy_threshold": 10.168432745069751,
      "ap": 0.7752722872456224,
      "f1": 0.7101579555669707,
      "f1_threshold": 10.799634403332977,
      "precision": 0.691768826619965,
      "recall": 0.7295514511873351
    },
    "max": {
      "accuracy": 0.8778685104607499,
      "ap": 0.7919600093560065,
      "f1": 0.7226612286515423
    }
  }
}