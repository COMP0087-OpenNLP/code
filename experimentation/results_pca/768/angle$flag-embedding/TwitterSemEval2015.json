{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8754246885617214,
      "accuracy_threshold": 0.7240253920188131,
      "ap": 0.7849134946038336,
      "f1": 0.7187418086500654,
      "f1_threshold": 0.7001298177334399,
      "precision": 0.7140625,
      "recall": 0.7234828496042216
    },
    "dot": {
      "accuracy": 0.8549800321869225,
      "accuracy_threshold": 0.48670880974169173,
      "ap": 0.7206689038261727,
      "f1": 0.6698725655205578,
      "f1_threshold": 0.4428560419139862,
      "precision": 0.6152826855123675,
      "recall": 0.7350923482849604
    },
    "euclidean": {
      "accuracy": 0.8751266615008643,
      "accuracy_threshold": 0.6064865441892415,
      "ap": 0.7887241601696611,
      "f1": 0.7210519596578577,
      "f1_threshold": 0.6374106555442407,
      "precision": 0.6984912193915409,
      "recall": 0.7451187335092349
    },
    "evaluation_time": 0.81,
    "manhattan": {
      "accuracy": 0.868927698635036,
      "accuracy_threshold": 10.938698318389982,
      "ap": 0.7679000912699607,
      "f1": 0.6984794164915317,
      "f1_threshold": 11.858492886145825,
      "precision": 0.6571295650151198,
      "recall": 0.7453825857519789
    },
    "max": {
      "accuracy": 0.8754246885617214,
      "ap": 0.7887241601696611,
      "f1": 0.7210519596578577
    }
  }
}