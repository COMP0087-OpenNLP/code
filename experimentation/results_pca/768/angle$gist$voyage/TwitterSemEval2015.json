{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8742921857304643,
      "accuracy_threshold": 0.7420973764449228,
      "ap": 0.7808405277293112,
      "f1": 0.7146680259971964,
      "f1_threshold": 0.7148649526061579,
      "precision": 0.6911510968696081,
      "recall": 0.7398416886543535
    },
    "dot": {
      "accuracy": 0.8598080705728081,
      "accuracy_threshold": 0.4354790399226178,
      "ap": 0.7369129909776811,
      "f1": 0.6778532086588959,
      "f1_threshold": 0.41592826405086075,
      "precision": 0.6587005227781927,
      "recall": 0.6981530343007916
    },
    "euclidean": {
      "accuracy": 0.8751862669130357,
      "accuracy_threshold": 0.545724120445422,
      "ap": 0.784603647095901,
      "f1": 0.719240506329114,
      "f1_threshold": 0.5770775849265649,
      "precision": 0.6912408759124088,
      "recall": 0.7496042216358839
    },
    "evaluation_time": 2.49,
    "manhattan": {
      "accuracy": 0.866960720033379,
      "accuracy_threshold": 10.081147330582585,
      "ap": 0.7625530020023572,
      "f1": 0.6979675842552098,
      "f1_threshold": 10.950309725417595,
      "precision": 0.6809738955823293,
      "recall": 0.7158311345646438
    },
    "max": {
      "accuracy": 0.8751862669130357,
      "ap": 0.784603647095901,
      "f1": 0.719240506329114
    }
  }
}