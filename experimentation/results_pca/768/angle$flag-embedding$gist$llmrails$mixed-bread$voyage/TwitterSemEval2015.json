{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8761399535077785,
      "accuracy_threshold": 0.7310762848485601,
      "ap": 0.7873517975984984,
      "f1": 0.7216441207075961,
      "f1_threshold": 0.7054471448423026,
      "precision": 0.7116469984607491,
      "recall": 0.7319261213720316
    },
    "dot": {
      "accuracy": 0.8587947785658938,
      "accuracy_threshold": 0.4492063337457877,
      "ap": 0.7321206651995719,
      "f1": 0.6757852077001012,
      "f1_threshold": 0.4250416794343156,
      "precision": 0.6497808085728203,
      "recall": 0.7039577836411609
    },
    "euclidean": {
      "accuracy": 0.8769744292781785,
      "accuracy_threshold": 0.5634963257107694,
      "ap": 0.7913035642983314,
      "f1": 0.7225543823940975,
      "f1_threshold": 0.6069586564480143,
      "precision": 0.697617293048391,
      "recall": 0.7493403693931399
    },
    "evaluation_time": 2.46,
    "manhattan": {
      "accuracy": 0.8696429635810932,
      "accuracy_threshold": 10.509235070932618,
      "ap": 0.7717551702576795,
      "f1": 0.7021112255406797,
      "f1_threshold": 11.200229552213788,
      "precision": 0.6855203619909502,
      "recall": 0.7195250659630607
    },
    "max": {
      "accuracy": 0.8769744292781785,
      "ap": 0.7913035642983314,
      "f1": 0.7225543823940975
    }
  }
}