{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8751862669130357,
      "accuracy_threshold": 0.7467979407515556,
      "ap": 0.7802763522578322,
      "f1": 0.7126103252327409,
      "f1_threshold": 0.6914452711406598,
      "precision": 0.6576656996206204,
      "recall": 0.7775725593667546
    },
    "dot": {
      "accuracy": 0.8627287357692078,
      "accuracy_threshold": 0.5218510107904335,
      "ap": 0.7474643672009951,
      "f1": 0.6883960298982967,
      "f1_threshold": 0.4837537137515849,
      "precision": 0.6426447037291237,
      "recall": 0.7411609498680739
    },
    "euclidean": {
      "accuracy": 0.8766167968051499,
      "accuracy_threshold": 0.6046285192640148,
      "ap": 0.7845466120985026,
      "f1": 0.7157894736842105,
      "f1_threshold": 0.6143914349642746,
      "precision": 0.7426950354609929,
      "recall": 0.6907651715039578
    },
    "evaluation_time": 1.11,
    "manhattan": {
      "accuracy": 0.8681528282768075,
      "accuracy_threshold": 12.268453954987367,
      "ap": 0.7657240772750852,
      "f1": 0.7032939714108141,
      "f1_threshold": 13.042575301450357,
      "precision": 0.6648648648648648,
      "recall": 0.7464379947229551
    },
    "max": {
      "accuracy": 0.8766167968051499,
      "ap": 0.7845466120985026,
      "f1": 0.7157894736842105
    }
  }
}