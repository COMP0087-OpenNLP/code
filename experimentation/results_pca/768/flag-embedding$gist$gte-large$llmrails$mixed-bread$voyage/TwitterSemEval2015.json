{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8766764022173213,
      "accuracy_threshold": 0.7303707394691089,
      "ap": 0.789094695479402,
      "f1": 0.7222653219550038,
      "f1_threshold": 0.7007132247334275,
      "precision": 0.7081643002028397,
      "recall": 0.7369393139841689
    },
    "dot": {
      "accuracy": 0.8604041246945222,
      "accuracy_threshold": 0.40336665268543404,
      "ap": 0.7339636779124792,
      "f1": 0.6794175715695953,
      "f1_threshold": 0.37715813282151306,
      "precision": 0.6381548446917015,
      "recall": 0.7263852242744063
    },
    "euclidean": {
      "accuracy": 0.8767956130416642,
      "accuracy_threshold": 0.5358306468962623,
      "ap": 0.7927474638134487,
      "f1": 0.723899692937564,
      "f1_threshold": 0.5771611310283546,
      "precision": 0.702682563338301,
      "recall": 0.7464379947229551
    },
    "evaluation_time": 2.39,
    "manhattan": {
      "accuracy": 0.8698813852297789,
      "accuracy_threshold": 10.063262679643568,
      "ap": 0.7729163364588761,
      "f1": 0.7040204211869815,
      "f1_threshold": 10.754396294640799,
      "precision": 0.6818294190358467,
      "recall": 0.7277044854881266
    },
    "max": {
      "accuracy": 0.8767956130416642,
      "ap": 0.7927474638134487,
      "f1": 0.723899692937564
    }
  }
}