{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8604041246945222,
      "accuracy_threshold": 0.7561530358408608,
      "ap": 0.7401000597022201,
      "f1": 0.6850603941513033,
      "f1_threshold": 0.7212243692312025,
      "precision": 0.6611042944785276,
      "recall": 0.7108179419525066
    },
    "dot": {
      "accuracy": 0.8462776420098945,
      "accuracy_threshold": 0.220747964799284,
      "ap": 0.6958324442347533,
      "f1": 0.6501556016597511,
      "f1_threshold": 0.20981288227854972,
      "precision": 0.6392146863844977,
      "recall": 0.6614775725593668
    },
    "euclidean": {
      "accuracy": 0.8595100435119509,
      "accuracy_threshold": 0.3775934666330486,
      "ap": 0.7380089004429986,
      "f1": 0.6850442809030809,
      "f1_threshold": 0.4041320018559131,
      "precision": 0.6496333096758931,
      "recall": 0.7245382585751979
    },
    "evaluation_time": 0.58,
    "manhattan": {
      "accuracy": 0.8434761876378375,
      "accuracy_threshold": 6.903146159506453,
      "ap": 0.6907896832933735,
      "f1": 0.6459948320413437,
      "f1_threshold": 7.822164786724446,
      "precision": 0.5821337849280271,
      "recall": 0.7255936675461742
    },
    "max": {
      "accuracy": 0.8604041246945222,
      "ap": 0.7401000597022201,
      "f1": 0.6850603941513033
    }
  }
}