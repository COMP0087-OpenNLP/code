{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8781069321094356,
      "accuracy_threshold": 0.7413561974744198,
      "ap": 0.7897741783475747,
      "f1": 0.7206549118387908,
      "f1_threshold": 0.7010029016604953,
      "precision": 0.6893975903614458,
      "recall": 0.7548812664907651
    },
    "dot": {
      "accuracy": 0.8617154437622936,
      "accuracy_threshold": 0.4401663066281005,
      "ap": 0.7431653078668352,
      "f1": 0.6829452485840152,
      "f1_threshold": 0.40901322516098504,
      "precision": 0.6529482551143201,
      "recall": 0.7158311345646438
    },
    "euclidean": {
      "accuracy": 0.8795970674137211,
      "accuracy_threshold": 0.5542407763365946,
      "ap": 0.7947498958582203,
      "f1": 0.7261329502416091,
      "f1_threshold": 0.5807154684253666,
      "precision": 0.7189035427980347,
      "recall": 0.7335092348284961
    },
    "evaluation_time": 1.91,
    "manhattan": {
      "accuracy": 0.8733384991357215,
      "accuracy_threshold": 10.970492845057269,
      "ap": 0.7788005848053732,
      "f1": 0.713016608729239,
      "f1_threshold": 11.604196154751875,
      "precision": 0.6962534573799346,
      "recall": 0.7306068601583113
    },
    "max": {
      "accuracy": 0.8795970674137211,
      "ap": 0.7947498958582203,
      "f1": 0.7261329502416091
    }
  }
}