{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8786433808189784,
      "accuracy_threshold": 0.7412607844424127,
      "ap": 0.7915483038495786,
      "f1": 0.7218425715008859,
      "f1_threshold": 0.7009485199033872,
      "precision": 0.693579766536965,
      "recall": 0.7525065963060686
    },
    "dot": {
      "accuracy": 0.8625499195326936,
      "accuracy_threshold": 0.44235728335638647,
      "ap": 0.747141029440046,
      "f1": 0.6862547288776798,
      "f1_threshold": 0.4119270076756624,
      "precision": 0.6572463768115943,
      "recall": 0.7179419525065963
    },
    "euclidean": {
      "accuracy": 0.8798354890624068,
      "accuracy_threshold": 0.5532727066794354,
      "ap": 0.7964994017500886,
      "f1": 0.7254725472547254,
      "f1_threshold": 0.5894481019157003,
      "precision": 0.7075495359919739,
      "recall": 0.7443271767810027
    },
    "evaluation_time": 2.34,
    "manhattan": {
      "accuracy": 0.8729808666626929,
      "accuracy_threshold": 11.242907155736063,
      "ap": 0.7800061021913343,
      "f1": 0.7135665418871822,
      "f1_threshold": 11.65077293265255,
      "precision": 0.6985089714430124,
      "recall": 0.729287598944591
    },
    "max": {
      "accuracy": 0.8798354890624068,
      "ap": 0.7964994017500886,
      "f1": 0.7254725472547254
    }
  }
}