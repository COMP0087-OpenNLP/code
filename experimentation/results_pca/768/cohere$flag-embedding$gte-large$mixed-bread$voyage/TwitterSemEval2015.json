{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8772128509268642,
      "accuracy_threshold": 0.7422442658948009,
      "ap": 0.7878471413905589,
      "f1": 0.718558282208589,
      "f1_threshold": 0.7090407768610684,
      "precision": 0.6968269707486366,
      "recall": 0.741688654353562
    },
    "dot": {
      "accuracy": 0.8618346545866364,
      "accuracy_threshold": 0.36776914639163444,
      "ap": 0.7425285997146108,
      "f1": 0.6816922689498867,
      "f1_threshold": 0.3411800946907171,
      "precision": 0.6519749518304432,
      "recall": 0.7142480211081794
    },
    "euclidean": {
      "accuracy": 0.8780473266972642,
      "accuracy_threshold": 0.5005761378110027,
      "ap": 0.7918751925861086,
      "f1": 0.7222366036758997,
      "f1_threshold": 0.52700783990951,
      "precision": 0.7088414634146342,
      "recall": 0.7361477572559367
    },
    "evaluation_time": 1.9,
    "manhattan": {
      "accuracy": 0.8718483638314359,
      "accuracy_threshold": 10.258715428814513,
      "ap": 0.776401456518477,
      "f1": 0.7105697246542316,
      "f1_threshold": 10.636806338197978,
      "precision": 0.684429234905891,
      "recall": 0.7387862796833773
    },
    "max": {
      "accuracy": 0.8780473266972642,
      "ap": 0.7918751925861086,
      "f1": 0.7222366036758997
    }
  }
}