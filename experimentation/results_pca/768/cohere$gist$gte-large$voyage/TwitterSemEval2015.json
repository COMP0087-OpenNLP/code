{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8733981045478929,
      "accuracy_threshold": 0.7676856125598278,
      "ap": 0.7794579643375437,
      "f1": 0.7145143419918748,
      "f1_threshold": 0.7116283567205042,
      "precision": 0.6697438264481883,
      "recall": 0.7656992084432718
    },
    "dot": {
      "accuracy": 0.8602849138701794,
      "accuracy_threshold": 0.35448511585286846,
      "ap": 0.7361650478093036,
      "f1": 0.680840420210105,
      "f1_threshold": 0.3259200264913087,
      "precision": 0.64717070851165,
      "recall": 0.7182058047493404
    },
    "euclidean": {
      "accuracy": 0.8743517911426357,
      "accuracy_threshold": 0.4756133974359551,
      "ap": 0.7812660298879223,
      "f1": 0.717207875223728,
      "f1_threshold": 0.5022627500821943,
      "precision": 0.6956845238095238,
      "recall": 0.7401055408970977
    },
    "evaluation_time": 1.66,
    "manhattan": {
      "accuracy": 0.8675567741550932,
      "accuracy_threshold": 9.359010645690633,
      "ap": 0.7651684670045621,
      "f1": 0.7049799098989407,
      "f1_threshold": 10.365319942905396,
      "precision": 0.6545331223151707,
      "recall": 0.7638522427440633
    },
    "max": {
      "accuracy": 0.8743517911426357,
      "ap": 0.7812660298879223,
      "f1": 0.717207875223728
    }
  }
}