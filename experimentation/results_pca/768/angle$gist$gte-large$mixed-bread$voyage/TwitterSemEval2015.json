{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8732192883113786,
      "accuracy_threshold": 0.7603933582514506,
      "ap": 0.7784472798327259,
      "f1": 0.713771265366944,
      "f1_threshold": 0.7123617417957453,
      "precision": 0.6741731175228712,
      "recall": 0.758311345646438
    },
    "dot": {
      "accuracy": 0.8581391190320081,
      "accuracy_threshold": 0.4036518617107411,
      "ap": 0.7331303849989547,
      "f1": 0.6740189792254424,
      "f1_threshold": 0.38348006250109695,
      "precision": 0.655688622754491,
      "recall": 0.6934036939313984
    },
    "euclidean": {
      "accuracy": 0.8745902127913214,
      "accuracy_threshold": 0.5158458017371563,
      "ap": 0.782622628505398,
      "f1": 0.7168915542228885,
      "f1_threshold": 0.5513567323796875,
      "precision": 0.6808258186995728,
      "recall": 0.7569920844327177
    },
    "evaluation_time": 1.86,
    "manhattan": {
      "accuracy": 0.8668415092090361,
      "accuracy_threshold": 9.698549751341758,
      "ap": 0.7619796606150292,
      "f1": 0.6955321285140562,
      "f1_threshold": 10.252117242545273,
      "precision": 0.6632359980852083,
      "recall": 0.7311345646437994
    },
    "max": {
      "accuracy": 0.8745902127913214,
      "ap": 0.782622628505398,
      "f1": 0.7168915542228885
    }
  }
}