{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8742921857304643,
      "accuracy_threshold": 0.747016322065365,
      "ap": 0.778523423201462,
      "f1": 0.710718789407314,
      "f1_threshold": 0.7040457683115675,
      "precision": 0.6806763285024154,
      "recall": 0.7435356200527704
    },
    "dot": {
      "accuracy": 0.8598676759849795,
      "accuracy_threshold": 0.5314095235911538,
      "ap": 0.7421613830112703,
      "f1": 0.6827181618186263,
      "f1_threshold": 0.4849464165488947,
      "precision": 0.6359289617486339,
      "recall": 0.7369393139841689
    },
    "euclidean": {
      "accuracy": 0.8764975859808071,
      "accuracy_threshold": 0.6067135656695402,
      "ap": 0.7835156304128874,
      "f1": 0.7164858711664659,
      "f1_threshold": 0.6219829072229848,
      "precision": 0.7274952406853413,
      "recall": 0.7058047493403694
    },
    "evaluation_time": 1.37,
    "manhattan": {
      "accuracy": 0.8679144066281218,
      "accuracy_threshold": 12.191524151795397,
      "ap": 0.7646122275947527,
      "f1": 0.702844968041108,
      "f1_threshold": 13.041839040399697,
      "precision": 0.6693721651945572,
      "recall": 0.7398416886543535
    },
    "max": {
      "accuracy": 0.8764975859808071,
      "ap": 0.7835156304128874,
      "f1": 0.7164858711664659
    }
  }
}