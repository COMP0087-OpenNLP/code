{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8762591643321214,
      "accuracy_threshold": 0.7267785223216883,
      "ap": 0.7865294859693946,
      "f1": 0.7199369168090418,
      "f1_threshold": 0.701264004956591,
      "precision": 0.7172034564021995,
      "recall": 0.7226912928759894
    },
    "dot": {
      "accuracy": 0.8549204267747511,
      "accuracy_threshold": 0.4891833100119196,
      "ap": 0.721091290023976,
      "f1": 0.6692250557068581,
      "f1_threshold": 0.4534464912894232,
      "precision": 0.6303638059701493,
      "recall": 0.7131926121372032
    },
    "euclidean": {
      "accuracy": 0.8758419264469214,
      "accuracy_threshold": 0.6025635352709167,
      "ap": 0.7903884431041646,
      "f1": 0.7216761510605276,
      "f1_threshold": 0.6369657576093218,
      "precision": 0.7077625570776256,
      "recall": 0.7361477572559367
    },
    "evaluation_time": 1.29,
    "manhattan": {
      "accuracy": 0.8688084878106932,
      "accuracy_threshold": 11.04326215619427,
      "ap": 0.7692500727459889,
      "f1": 0.698773633111906,
      "f1_threshold": 11.754843981365944,
      "precision": 0.6773155027241209,
      "recall": 0.7216358839050132
    },
    "max": {
      "accuracy": 0.8762591643321214,
      "ap": 0.7903884431041646,
      "f1": 0.7216761510605276
    }
  }
}