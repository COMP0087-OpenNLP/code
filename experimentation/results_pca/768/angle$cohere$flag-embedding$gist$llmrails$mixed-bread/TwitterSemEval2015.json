{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8765571913929785,
      "accuracy_threshold": 0.7356937239809642,
      "ap": 0.7867647307330928,
      "f1": 0.7199001871490954,
      "f1_threshold": 0.7009802980808553,
      "precision": 0.6828402366863905,
      "recall": 0.7612137203166227
    },
    "dot": {
      "accuracy": 0.8601657030458366,
      "accuracy_threshold": 0.507173973483888,
      "ap": 0.7395901005233086,
      "f1": 0.6805607244758715,
      "f1_threshold": 0.46584898850960454,
      "precision": 0.642238351674081,
      "recall": 0.7237467018469657
    },
    "euclidean": {
      "accuracy": 0.8775108779877213,
      "accuracy_threshold": 0.5794095218211206,
      "ap": 0.7922477578871712,
      "f1": 0.7246339583868482,
      "f1_threshold": 0.6227891554932601,
      "precision": 0.705955955955956,
      "recall": 0.7443271767810027
    },
    "evaluation_time": 2.07,
    "manhattan": {
      "accuracy": 0.871013888061036,
      "accuracy_threshold": 11.28969637641615,
      "ap": 0.7745399645871219,
      "f1": 0.7086713995943206,
      "f1_threshold": 11.907212009793334,
      "precision": 0.6820400195217179,
      "recall": 0.737467018469657
    },
    "max": {
      "accuracy": 0.8775108779877213,
      "ap": 0.7922477578871712,
      "f1": 0.7246339583868482
    }
  }
}