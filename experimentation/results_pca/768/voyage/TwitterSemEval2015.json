{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.845085533766466,
      "accuracy_threshold": 0.7488250207865377,
      "ap": 0.6943415086412558,
      "f1": 0.6418637822417687,
      "f1_threshold": 0.6815948777520247,
      "precision": 0.5840363400389358,
      "recall": 0.712401055408971
    },
    "dot": {
      "accuracy": 0.839482625022352,
      "accuracy_threshold": 0.2554261377252978,
      "ap": 0.6730122091365762,
      "f1": 0.6300715990453462,
      "f1_threshold": 0.23388900610107874,
      "precision": 0.6012946535602973,
      "recall": 0.6617414248021108
    },
    "euclidean": {
      "accuracy": 0.8410323657388091,
      "accuracy_threshold": 0.40450220753489796,
      "ap": 0.6816547757633122,
      "f1": 0.6288672204165163,
      "f1_threshold": 0.4597128380472725,
      "precision": 0.5782599070179323,
      "recall": 0.6891820580474934
    },
    "evaluation_time": 0.76,
    "manhattan": {
      "accuracy": 0.8332836621565238,
      "accuracy_threshold": 7.904888874730823,
      "ap": 0.6538382723740234,
      "f1": 0.6020358700920989,
      "f1_threshold": 9.125583916757092,
      "precision": 0.5567010309278351,
      "recall": 0.6554089709762533
    },
    "max": {
      "accuracy": 0.845085533766466,
      "ap": 0.6943415086412558,
      "f1": 0.6418637822417687
    }
  }
}