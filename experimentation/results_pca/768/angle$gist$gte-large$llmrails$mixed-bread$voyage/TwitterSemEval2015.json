{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8754842939738928,
      "accuracy_threshold": 0.7388269862273673,
      "ap": 0.7854568920852965,
      "f1": 0.7191157347204161,
      "f1_threshold": 0.710834111721699,
      "precision": 0.708974358974359,
      "recall": 0.7295514511873351
    },
    "dot": {
      "accuracy": 0.8587351731537224,
      "accuracy_threshold": 0.42256849104428573,
      "ap": 0.7326212386759925,
      "f1": 0.6757431926055458,
      "f1_threshold": 0.3941846154062105,
      "precision": 0.6416034155597723,
      "recall": 0.7137203166226913
    },
    "euclidean": {
      "accuracy": 0.8766764022173213,
      "accuracy_threshold": 0.5374499950691407,
      "ap": 0.7895724861164054,
      "f1": 0.7219623214059933,
      "f1_threshold": 0.5803118241445864,
      "precision": 0.6931294003398883,
      "recall": 0.7532981530343008
    },
    "evaluation_time": 2.19,
    "manhattan": {
      "accuracy": 0.8691065148715503,
      "accuracy_threshold": 9.930968588669916,
      "ap": 0.7693637533522995,
      "f1": 0.7003556972893413,
      "f1_threshold": 10.936780220791238,
      "precision": 0.6543662617465047,
      "recall": 0.7532981530343008
    },
    "max": {
      "accuracy": 0.8766764022173213,
      "ap": 0.7895724861164054,
      "f1": 0.7219623214059933
    }
  }
}