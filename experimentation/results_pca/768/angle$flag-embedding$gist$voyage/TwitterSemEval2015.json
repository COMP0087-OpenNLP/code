{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8756631102104071,
      "accuracy_threshold": 0.7479688047249268,
      "ap": 0.7857936160794943,
      "f1": 0.7186536485097637,
      "f1_threshold": 0.7093612636429787,
      "precision": 0.700300450676014,
      "recall": 0.7379947229551451
    },
    "dot": {
      "accuracy": 0.8622518924718364,
      "accuracy_threshold": 0.4216501785083253,
      "ap": 0.7409145567407859,
      "f1": 0.6820547031354237,
      "f1_threshold": 0.4046649667950417,
      "precision": 0.6898785425101215,
      "recall": 0.6744063324538259
    },
    "euclidean": {
      "accuracy": 0.8763783751564642,
      "accuracy_threshold": 0.5370832177815601,
      "ap": 0.7893286066716448,
      "f1": 0.7216702301597284,
      "f1_threshold": 0.5771339044866455,
      "precision": 0.6894977168949772,
      "recall": 0.7569920844327177
    },
    "evaluation_time": 1.46,
    "manhattan": {
      "accuracy": 0.8688680932228646,
      "accuracy_threshold": 10.182900881778707,
      "ap": 0.768986323730228,
      "f1": 0.7015228426395939,
      "f1_threshold": 10.967498903131219,
      "precision": 0.6757946210268949,
      "recall": 0.729287598944591
    },
    "max": {
      "accuracy": 0.8763783751564642,
      "ap": 0.7893286066716448,
      "f1": 0.7216702301597284
    }
  }
}