{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.87494784526435,
      "accuracy_threshold": 0.7548954807900117,
      "ap": 0.783994359099302,
      "f1": 0.7190113593808513,
      "f1_threshold": 0.7093815994889372,
      "precision": 0.6823027718550106,
      "recall": 0.7598944591029023
    },
    "dot": {
      "accuracy": 0.8620134708231507,
      "accuracy_threshold": 0.4820465421097725,
      "ap": 0.7462012976582686,
      "f1": 0.6844814905614122,
      "f1_threshold": 0.44498467711172696,
      "precision": 0.6391941391941391,
      "recall": 0.7366754617414248
    },
    "euclidean": {
      "accuracy": 0.8782261429337784,
      "accuracy_threshold": 0.5658139472491872,
      "ap": 0.789166033082583,
      "f1": 0.7222581898226078,
      "f1_threshold": 0.5957996122369228,
      "precision": 0.7091278921942538,
      "recall": 0.7358839050131926
    },
    "evaluation_time": 1.98,
    "manhattan": {
      "accuracy": 0.8686296715741789,
      "accuracy_threshold": 12.02614061643903,
      "ap": 0.7677640582971088,
      "f1": 0.7054349159612318,
      "f1_threshold": 12.884755859413499,
      "precision": 0.6592524650309562,
      "recall": 0.758575197889182
    },
    "max": {
      "accuracy": 0.8782261429337784,
      "ap": 0.789166033082583,
      "f1": 0.7222581898226078
    }
  }
}