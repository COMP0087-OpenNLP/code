{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8766764022173213,
      "accuracy_threshold": 0.743936809795215,
      "ap": 0.78634920693441,
      "f1": 0.718422674060382,
      "f1_threshold": 0.7020645559246855,
      "precision": 0.6739884393063584,
      "recall": 0.7691292875989446
    },
    "dot": {
      "accuracy": 0.8601060976336652,
      "accuracy_threshold": 0.42329666917333686,
      "ap": 0.7404622391530019,
      "f1": 0.6796962529565542,
      "f1_threshold": 0.3917443406119545,
      "precision": 0.643412679707754,
      "recall": 0.7203166226912929
    },
    "euclidean": {
      "accuracy": 0.8778089050485784,
      "accuracy_threshold": 0.5333914969150245,
      "ap": 0.79137310559998,
      "f1": 0.7224422020692298,
      "f1_threshold": 0.5662892938331014,
      "precision": 0.7001733102253033,
      "recall": 0.7461741424802111
    },
    "evaluation_time": 2.64,
    "manhattan": {
      "accuracy": 0.8698813852297789,
      "accuracy_threshold": 10.807787872628303,
      "ap": 0.7720175148492099,
      "f1": 0.7051938551572787,
      "f1_threshold": 11.834421982062263,
      "precision": 0.6554850407978241,
      "recall": 0.7630606860158311
    },
    "max": {
      "accuracy": 0.8778089050485784,
      "ap": 0.79137310559998,
      "f1": 0.7224422020692298
    }
  }
}