{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8739941586696072,
      "accuracy_threshold": 0.7418234522894492,
      "ap": 0.7808507461867038,
      "f1": 0.712608473711077,
      "f1_threshold": 0.7082417634564675,
      "precision": 0.690064260998517,
      "recall": 0.7366754617414248
    },
    "dot": {
      "accuracy": 0.858675567741551,
      "accuracy_threshold": 0.36742867278951286,
      "ap": 0.7317428389580853,
      "f1": 0.6734295747171284,
      "f1_threshold": 0.343983571296952,
      "precision": 0.6640164144652475,
      "recall": 0.6831134564643799
    },
    "euclidean": {
      "accuracy": 0.8750670560886928,
      "accuracy_threshold": 0.5047970187028594,
      "ap": 0.7828726312658025,
      "f1": 0.7115612258319084,
      "f1_threshold": 0.5228794799113892,
      "precision": 0.7094151586677158,
      "recall": 0.7137203166226913
    },
    "evaluation_time": 0.86,
    "manhattan": {
      "accuracy": 0.8643380818978363,
      "accuracy_threshold": 10.57988797905791,
      "ap": 0.7536001650620592,
      "f1": 0.6861020356873586,
      "f1_threshold": 11.336676573993184,
      "precision": 0.6549904030710173,
      "recall": 0.7203166226912929
    },
    "max": {
      "accuracy": 0.8750670560886928,
      "ap": 0.7828726312658025,
      "f1": 0.712608473711077
    }
  }
}