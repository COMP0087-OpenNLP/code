{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8761399535077785,
      "accuracy_threshold": 0.7374610274324886,
      "ap": 0.7868623881637483,
      "f1": 0.720262925041082,
      "f1_threshold": 0.7058562162286646,
      "precision": 0.6913370541130793,
      "recall": 0.7517150395778364
    },
    "dot": {
      "accuracy": 0.8620134708231507,
      "accuracy_threshold": 0.5184978091467398,
      "ap": 0.7442056043535534,
      "f1": 0.6845904904157332,
      "f1_threshold": 0.4803975355043655,
      "precision": 0.6479736098020735,
      "recall": 0.7255936675461742
    },
    "euclidean": {
      "accuracy": 0.8787625916433213,
      "accuracy_threshold": 0.5964216086105343,
      "ap": 0.7930259107287052,
      "f1": 0.7235698534180827,
      "f1_threshold": 0.6275962198536704,
      "precision": 0.7116611380454197,
      "recall": 0.7358839050131926
    },
    "evaluation_time": 1.64,
    "manhattan": {
      "accuracy": 0.870179412290636,
      "accuracy_threshold": 12.594444909413799,
      "ap": 0.7712854070158564,
      "f1": 0.7062256809338522,
      "f1_threshold": 13.52972252349215,
      "precision": 0.6549391069012178,
      "recall": 0.7662269129287599
    },
    "max": {
      "accuracy": 0.8787625916433213,
      "ap": 0.7930259107287052,
      "f1": 0.7235698534180827
    }
  }
}