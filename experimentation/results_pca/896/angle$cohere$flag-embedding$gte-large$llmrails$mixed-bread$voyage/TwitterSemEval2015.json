{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.877749299636407,
      "accuracy_threshold": 0.7355241275982205,
      "ap": 0.7890315042369038,
      "f1": 0.7209876543209877,
      "f1_threshold": 0.6942279582545915,
      "precision": 0.6774941995359629,
      "recall": 0.7704485488126649
    },
    "dot": {
      "accuracy": 0.8601060976336652,
      "accuracy_threshold": 0.41144756432582497,
      "ap": 0.7387915674251082,
      "f1": 0.6810205351586808,
      "f1_threshold": 0.3793094390665231,
      "precision": 0.6445229681978799,
      "recall": 0.7218997361477573
    },
    "euclidean": {
      "accuracy": 0.878583775406807,
      "accuracy_threshold": 0.5351918846414094,
      "ap": 0.7938400862123293,
      "f1": 0.725,
      "f1_threshold": 0.5637021332032408,
      "precision": 0.715681233933162,
      "recall": 0.7345646437994723
    },
    "evaluation_time": 2.64,
    "manhattan": {
      "accuracy": 0.8707158610001788,
      "accuracy_threshold": 10.949028804400374,
      "ap": 0.773788524827686,
      "f1": 0.7066294132588266,
      "f1_threshold": 11.68437076435593,
      "precision": 0.6811949069539667,
      "recall": 0.7340369393139842
    },
    "max": {
      "accuracy": 0.878583775406807,
      "ap": 0.7938400862123293,
      "f1": 0.725
    }
  }
}