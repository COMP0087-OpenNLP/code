{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8780473266972642,
      "accuracy_threshold": 0.7341328313932434,
      "ap": 0.789195306558321,
      "f1": 0.7201778216843665,
      "f1_threshold": 0.6931108886901209,
      "precision": 0.6768802228412256,
      "recall": 0.7693931398416887
    },
    "dot": {
      "accuracy": 0.8605233355188651,
      "accuracy_threshold": 0.4148358965890915,
      "ap": 0.7387212299786845,
      "f1": 0.680538250685273,
      "f1_threshold": 0.3812168599585307,
      "precision": 0.6447119924457035,
      "recall": 0.720580474934037
    },
    "euclidean": {
      "accuracy": 0.878583775406807,
      "accuracy_threshold": 0.536229955902931,
      "ap": 0.7941659270118517,
      "f1": 0.7249483471074379,
      "f1_threshold": 0.5686065186036562,
      "precision": 0.7099140111279717,
      "recall": 0.7406332453825858
    },
    "evaluation_time": 2.32,
    "manhattan": {
      "accuracy": 0.8707754664123503,
      "accuracy_threshold": 10.920118762294575,
      "ap": 0.7743286724874459,
      "f1": 0.7076260450975425,
      "f1_threshold": 11.749347975582538,
      "precision": 0.6805555555555556,
      "recall": 0.7369393139841689
    },
    "max": {
      "accuracy": 0.878583775406807,
      "ap": 0.7941659270118517,
      "f1": 0.7249483471074379
    }
  }
}