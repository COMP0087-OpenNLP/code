{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8742921857304643,
      "accuracy_threshold": 0.7366376637275922,
      "ap": 0.782530880339643,
      "f1": 0.715929429813347,
      "f1_threshold": 0.7075078191547622,
      "precision": 0.6944444444444444,
      "recall": 0.7387862796833773
    },
    "dot": {
      "accuracy": 0.8576026703224653,
      "accuracy_threshold": 0.4731852360697756,
      "ap": 0.7287852733312078,
      "f1": 0.6738756451216515,
      "f1_threshold": 0.44196973345328816,
      "precision": 0.6306347746090156,
      "recall": 0.7234828496042216
    },
    "euclidean": {
      "accuracy": 0.87536508314955,
      "accuracy_threshold": 0.5672457139769521,
      "ap": 0.7872385118167967,
      "f1": 0.7187461127005846,
      "f1_threshold": 0.6183050561167751,
      "precision": 0.6799246881619204,
      "recall": 0.7622691292875989
    },
    "evaluation_time": 1.6,
    "manhattan": {
      "accuracy": 0.8682124336889789,
      "accuracy_threshold": 11.019808023922884,
      "ap": 0.7661555126861432,
      "f1": 0.6979288784681517,
      "f1_threshold": 11.544696828244708,
      "precision": 0.6892204785181374,
      "recall": 0.7068601583113456
    },
    "max": {
      "accuracy": 0.87536508314955,
      "ap": 0.7872385118167967,
      "f1": 0.7187461127005846
    }
  }
}