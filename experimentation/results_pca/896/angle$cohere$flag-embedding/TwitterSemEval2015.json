{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8771532455146928,
      "accuracy_threshold": 0.7377803823602547,
      "ap": 0.7864218068350259,
      "f1": 0.7183339923553447,
      "f1_threshold": 0.7096371615656105,
      "precision": 0.717671846194364,
      "recall": 0.7189973614775725
    },
    "dot": {
      "accuracy": 0.8601657030458366,
      "accuracy_threshold": 0.5049049142333968,
      "ap": 0.740002675984446,
      "f1": 0.6821609593274819,
      "f1_threshold": 0.4645223337842894,
      "precision": 0.6417771574784834,
      "recall": 0.7279683377308707
    },
    "euclidean": {
      "accuracy": 0.8785241699946356,
      "accuracy_threshold": 0.5967396281273851,
      "ap": 0.7923548972838448,
      "f1": 0.7225840062516279,
      "f1_threshold": 0.6289562099089584,
      "precision": 0.713477366255144,
      "recall": 0.7319261213720316
    },
    "evaluation_time": 1.18,
    "manhattan": {
      "accuracy": 0.8690469094593789,
      "accuracy_threshold": 12.503867439670564,
      "ap": 0.7697381749503526,
      "f1": 0.7044694812430359,
      "f1_threshold": 13.52292029796925,
      "precision": 0.6636342430604152,
      "recall": 0.7506596306068601
    },
    "max": {
      "accuracy": 0.8785241699946356,
      "ap": 0.7923548972838448,
      "f1": 0.7225840062516279
    }
  }
}