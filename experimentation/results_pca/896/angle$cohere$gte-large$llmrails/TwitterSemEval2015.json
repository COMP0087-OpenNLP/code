{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8767360076294928,
      "accuracy_threshold": 0.7374082680568221,
      "ap": 0.7851739866004658,
      "f1": 0.7162311372837689,
      "f1_threshold": 0.690446043220855,
      "precision": 0.6693418940609952,
      "recall": 0.7701846965699208
    },
    "dot": {
      "accuracy": 0.8615366275257793,
      "accuracy_threshold": 0.4356135960164726,
      "ap": 0.7424886640742491,
      "f1": 0.684676069806359,
      "f1_threshold": 0.39265255489001183,
      "precision": 0.6258741258741258,
      "recall": 0.7556728232189973
    },
    "euclidean": {
      "accuracy": 0.8787029862311498,
      "accuracy_threshold": 0.5522837682409774,
      "ap": 0.7907149761545081,
      "f1": 0.7205530444030842,
      "f1_threshold": 0.5746897398361397,
      "precision": 0.7261521972132905,
      "recall": 0.7150395778364116
    },
    "evaluation_time": 1.71,
    "manhattan": {
      "accuracy": 0.8685104607498361,
      "accuracy_threshold": 11.738664195130674,
      "ap": 0.767647185757061,
      "f1": 0.7046632124352331,
      "f1_threshold": 12.632350120577962,
      "precision": 0.6617238183503243,
      "recall": 0.7535620052770449
    },
    "max": {
      "accuracy": 0.8787029862311498,
      "ap": 0.7907149761545081,
      "f1": 0.7205530444030842
    }
  }
}