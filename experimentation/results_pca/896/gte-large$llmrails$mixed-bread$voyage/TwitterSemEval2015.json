{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8761399535077785,
      "accuracy_threshold": 0.7400108347981025,
      "ap": 0.7868862817228375,
      "f1": 0.7188775510204082,
      "f1_threshold": 0.7020701963103548,
      "precision": 0.6958024691358025,
      "recall": 0.7435356200527704
    },
    "dot": {
      "accuracy": 0.858675567741551,
      "accuracy_threshold": 0.3464589487458758,
      "ap": 0.7330651553681928,
      "f1": 0.6761144035042516,
      "f1_threshold": 0.3250346134979799,
      "precision": 0.6606243705941591,
      "recall": 0.6923482849604221
    },
    "euclidean": {
      "accuracy": 0.8761995589199499,
      "accuracy_threshold": 0.49484520123340603,
      "ap": 0.7899227038236663,
      "f1": 0.7220586352579694,
      "f1_threshold": 0.5238671367752853,
      "precision": 0.7013180800795822,
      "recall": 0.7440633245382586
    },
    "evaluation_time": 1.47,
    "manhattan": {
      "accuracy": 0.867795195803779,
      "accuracy_threshold": 10.130109437099318,
      "ap": 0.7631097046282643,
      "f1": 0.6936589012084216,
      "f1_threshold": 10.828348689422013,
      "precision": 0.6570686806702856,
      "recall": 0.7345646437994723
    },
    "max": {
      "accuracy": 0.8761995589199499,
      "ap": 0.7899227038236663,
      "f1": 0.7220586352579694
    }
  }
}