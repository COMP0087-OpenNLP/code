{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8734577099600643,
      "accuracy_threshold": 0.7583328513064203,
      "ap": 0.7789442171341214,
      "f1": 0.7146807440925089,
      "f1_threshold": 0.7127144616902135,
      "precision": 0.6824291886701872,
      "recall": 0.750131926121372
    },
    "dot": {
      "accuracy": 0.8608809679918936,
      "accuracy_threshold": 0.4545201664859049,
      "ap": 0.7436883138428396,
      "f1": 0.6835066864784547,
      "f1_threshold": 0.4249532103802851,
      "precision": 0.6439570695286981,
      "recall": 0.7282321899736148
    },
    "euclidean": {
      "accuracy": 0.8759015318590928,
      "accuracy_threshold": 0.5534641702106964,
      "ap": 0.7840800787472526,
      "f1": 0.7176644493717664,
      "f1_threshold": 0.5941682948323073,
      "precision": 0.6730591497227357,
      "recall": 0.7686015831134565
    },
    "evaluation_time": 1.65,
    "manhattan": {
      "accuracy": 0.8664242713238363,
      "accuracy_threshold": 11.54348697792943,
      "ap": 0.7596893342682168,
      "f1": 0.6999632757987514,
      "f1_threshold": 12.589286813490146,
      "precision": 0.6528887873943823,
      "recall": 0.754353562005277
    },
    "max": {
      "accuracy": 0.8759015318590928,
      "ap": 0.7840800787472526,
      "f1": 0.7176644493717664
    }
  }
}