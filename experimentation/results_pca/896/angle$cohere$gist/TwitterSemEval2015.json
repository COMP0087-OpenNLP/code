{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8746498182034929,
      "accuracy_threshold": 0.7523728733275137,
      "ap": 0.7820037540471252,
      "f1": 0.7173966839891116,
      "f1_threshold": 0.7048989933850727,
      "precision": 0.6754426840633737,
      "recall": 0.7649076517150396
    },
    "dot": {
      "accuracy": 0.8604041246945222,
      "accuracy_threshold": 0.5409396044372761,
      "ap": 0.7422418049974806,
      "f1": 0.682619958060935,
      "f1_threshold": 0.49452104795919105,
      "precision": 0.6409543664581886,
      "recall": 0.7300791556728232
    },
    "euclidean": {
      "accuracy": 0.8767360076294928,
      "accuracy_threshold": 0.5900218069001675,
      "ap": 0.7878676186886006,
      "f1": 0.7199584739164288,
      "f1_threshold": 0.6301579353017234,
      "precision": 0.7083758937691522,
      "recall": 0.7319261213720316
    },
    "evaluation_time": 2.57,
    "manhattan": {
      "accuracy": 0.8672587470942361,
      "accuracy_threshold": 12.572924332317992,
      "ap": 0.7647970716928658,
      "f1": 0.702076777847703,
      "f1_threshold": 13.43108333859055,
      "precision": 0.6712394705174488,
      "recall": 0.7358839050131926
    },
    "max": {
      "accuracy": 0.8767360076294928,
      "ap": 0.7878676186886006,
      "f1": 0.7199584739164288
    }
  }
}