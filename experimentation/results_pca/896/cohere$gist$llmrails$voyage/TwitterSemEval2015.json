{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8772128509268642,
      "accuracy_threshold": 0.7399325225100094,
      "ap": 0.7886073053438576,
      "f1": 0.7215696075981004,
      "f1_threshold": 0.7024766691130664,
      "precision": 0.6854226020892688,
      "recall": 0.7617414248021108
    },
    "dot": {
      "accuracy": 0.8646361089586935,
      "accuracy_threshold": 0.42767063476036177,
      "ap": 0.7519431694629242,
      "f1": 0.6905750597709828,
      "f1_threshold": 0.39521775578029034,
      "precision": 0.6600914120760164,
      "recall": 0.7240105540897097
    },
    "euclidean": {
      "accuracy": 0.8779877212850927,
      "accuracy_threshold": 0.5415322122121012,
      "ap": 0.7924588578656758,
      "f1": 0.7236129032258064,
      "f1_threshold": 0.5689884767744713,
      "precision": 0.7080808080808081,
      "recall": 0.7398416886543535
    },
    "evaluation_time": 4.39,
    "manhattan": {
      "accuracy": 0.8706562555880074,
      "accuracy_threshold": 11.519236437290903,
      "ap": 0.7740516161682485,
      "f1": 0.7090578769789774,
      "f1_threshold": 12.12837268367068,
      "precision": 0.6976506639427987,
      "recall": 0.720844327176781
    },
    "max": {
      "accuracy": 0.8779877212850927,
      "ap": 0.7924588578656758,
      "f1": 0.7236129032258064
    }
  }
}