{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8643976873100078,
      "accuracy_threshold": 0.750558734144956,
      "ap": 0.756022353694173,
      "f1": 0.6954793840039741,
      "f1_threshold": 0.6967325583381379,
      "precision": 0.656968559361802,
      "recall": 0.7387862796833773
    },
    "dot": {
      "accuracy": 0.8589139893902367,
      "accuracy_threshold": 0.4046531806199843,
      "ap": 0.7354015580669763,
      "f1": 0.6802807913209955,
      "f1_threshold": 0.3856423726508935,
      "precision": 0.6588380716934487,
      "recall": 0.7031662269129287
    },
    "euclidean": {
      "accuracy": 0.8646361089586935,
      "accuracy_threshold": 0.5357348443932691,
      "ap": 0.7576521286462103,
      "f1": 0.6998144712430426,
      "f1_threshold": 0.5769582772846881,
      "precision": 0.6586728754365542,
      "recall": 0.7464379947229551
    },
    "evaluation_time": 1.4,
    "manhattan": {
      "accuracy": 0.8557549025451511,
      "accuracy_threshold": 11.80903228213225,
      "ap": 0.7320926836841196,
      "f1": 0.6789815277084372,
      "f1_threshold": 12.595277059811934,
      "precision": 0.6442444339175746,
      "recall": 0.7176781002638523
    },
    "max": {
      "accuracy": 0.8646361089586935,
      "ap": 0.7576521286462103,
      "f1": 0.6998144712430426
    }
  }
}