{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8736365261965786,
      "accuracy_threshold": 0.7598521382594029,
      "ap": 0.7801335527310825,
      "f1": 0.7166198621393924,
      "f1_threshold": 0.7182201966785002,
      "precision": 0.6941147378832839,
      "recall": 0.7406332453825858
    },
    "dot": {
      "accuracy": 0.8603445192823508,
      "accuracy_threshold": 0.4550504277928159,
      "ap": 0.7412133411574828,
      "f1": 0.6816220880069025,
      "f1_threshold": 0.42579290789237084,
      "precision": 0.6396021281517464,
      "recall": 0.7295514511873351
    },
    "euclidean": {
      "accuracy": 0.8762591643321214,
      "accuracy_threshold": 0.5520314211819288,
      "ap": 0.7858592121528205,
      "f1": 0.7186113286348212,
      "f1_threshold": 0.5759039188878194,
      "precision": 0.7110020661157025,
      "recall": 0.7263852242744063
    },
    "evaluation_time": 1.47,
    "manhattan": {
      "accuracy": 0.8663050604994934,
      "accuracy_threshold": 11.460499838933309,
      "ap": 0.7613353196136378,
      "f1": 0.7011962017511406,
      "f1_threshold": 12.496914489618534,
      "precision": 0.6582542255151655,
      "recall": 0.750131926121372
    },
    "max": {
      "accuracy": 0.8762591643321214,
      "ap": 0.7858592121528205,
      "f1": 0.7186113286348212
    }
  }
}