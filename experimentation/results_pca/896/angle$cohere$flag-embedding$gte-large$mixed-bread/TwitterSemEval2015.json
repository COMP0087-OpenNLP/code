{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8770936401025213,
      "accuracy_threshold": 0.7431778065494675,
      "ap": 0.7865448111893516,
      "f1": 0.7172151898734177,
      "f1_threshold": 0.7008333276700415,
      "precision": 0.689294403892944,
      "recall": 0.7474934036939314
    },
    "dot": {
      "accuracy": 0.8611193896405793,
      "accuracy_threshold": 0.46426698718667336,
      "ap": 0.7413769637814187,
      "f1": 0.6812912875482987,
      "f1_threshold": 0.432621891807659,
      "precision": 0.6456413890857547,
      "recall": 0.7211081794195251
    },
    "euclidean": {
      "accuracy": 0.8789414078798354,
      "accuracy_threshold": 0.5723981211812823,
      "ap": 0.792440305293082,
      "f1": 0.7225325884543762,
      "f1_threshold": 0.5949491972692911,
      "precision": 0.7285407725321889,
      "recall": 0.716622691292876
    },
    "evaluation_time": 1.82,
    "manhattan": {
      "accuracy": 0.868927698635036,
      "accuracy_threshold": 12.22953238556168,
      "ap": 0.7692767862952586,
      "f1": 0.7067331670822943,
      "f1_threshold": 12.951822112925523,
      "precision": 0.6699763593380614,
      "recall": 0.7477572559366754
    },
    "max": {
      "accuracy": 0.8789414078798354,
      "ap": 0.792440305293082,
      "f1": 0.7225325884543762
    }
  }
}