{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8772724563390356,
      "accuracy_threshold": 0.7238388831423993,
      "ap": 0.790693022909549,
      "f1": 0.7241244629605521,
      "f1_threshold": 0.6971097000421644,
      "precision": 0.7147262914417888,
      "recall": 0.7337730870712401
    },
    "dot": {
      "accuracy": 0.8592716218632652,
      "accuracy_threshold": 0.40303858126923586,
      "ap": 0.7322011354724178,
      "f1": 0.6784061696658097,
      "f1_threshold": 0.38115296691333655,
      "precision": 0.6614035087719298,
      "recall": 0.6963060686015831
    },
    "euclidean": {
      "accuracy": 0.8772128509268642,
      "accuracy_threshold": 0.547993345949594,
      "ap": 0.7933647841283034,
      "f1": 0.7218259629101283,
      "f1_threshold": 0.579922723266304,
      "precision": 0.7097679163478704,
      "recall": 0.7343007915567282
    },
    "evaluation_time": 1.49,
    "manhattan": {
      "accuracy": 0.8677355903916075,
      "accuracy_threshold": 11.234150623583098,
      "ap": 0.7687952676671632,
      "f1": 0.7005505056970938,
      "f1_threshold": 11.759703915937035,
      "precision": 0.6804277542899776,
      "recall": 0.7218997361477573
    },
    "max": {
      "accuracy": 0.8772724563390356,
      "ap": 0.7933647841283034,
      "f1": 0.7241244629605521
    }
  }
}