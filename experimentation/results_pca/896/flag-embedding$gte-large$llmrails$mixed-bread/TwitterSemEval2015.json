{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8760207426834357,
      "accuracy_threshold": 0.725772038134496,
      "ap": 0.7867790047008776,
      "f1": 0.7196394075981971,
      "f1_threshold": 0.6949123806619648,
      "precision": 0.7028930817610063,
      "recall": 0.737203166226913
    },
    "dot": {
      "accuracy": 0.8558145079573225,
      "accuracy_threshold": 0.41114194551425,
      "ap": 0.7226793118016528,
      "f1": 0.671426781911562,
      "f1_threshold": 0.3853924103691336,
      "precision": 0.639160505604579,
      "recall": 0.7071240105540897
    },
    "euclidean": {
      "accuracy": 0.8755438993860643,
      "accuracy_threshold": 0.5459132851390671,
      "ap": 0.7906453265170723,
      "f1": 0.7228454869964305,
      "f1_threshold": 0.5881131282223686,
      "precision": 0.6993093241243217,
      "recall": 0.7480211081794196
    },
    "evaluation_time": 1.4,
    "manhattan": {
      "accuracy": 0.867795195803779,
      "accuracy_threshold": 10.568654283225563,
      "ap": 0.7677576428024788,
      "f1": 0.6985321791494166,
      "f1_threshold": 11.345994064924438,
      "precision": 0.6658694092322411,
      "recall": 0.7345646437994723
    },
    "max": {
      "accuracy": 0.8760207426834357,
      "ap": 0.7906453265170723,
      "f1": 0.7228454869964305
    }
  }
}