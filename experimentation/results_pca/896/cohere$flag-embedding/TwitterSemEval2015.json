{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.87453060737915,
      "accuracy_threshold": 0.7384314078625444,
      "ap": 0.7824444613811826,
      "f1": 0.7111777944486121,
      "f1_threshold": 0.6891069252010195,
      "precision": 0.6758555133079848,
      "recall": 0.7503957783641161
    },
    "dot": {
      "accuracy": 0.8632651844787507,
      "accuracy_threshold": 0.5185439091620713,
      "ap": 0.7474597186860713,
      "f1": 0.6875321998969602,
      "f1_threshold": 0.4883811509030265,
      "precision": 0.671615500754907,
      "recall": 0.704221635883905
    },
    "euclidean": {
      "accuracy": 0.8768552184538356,
      "accuracy_threshold": 0.6183784226650968,
      "ap": 0.787869760828654,
      "f1": 0.715356315574329,
      "f1_threshold": 0.6331377642914744,
      "precision": 0.7396449704142012,
      "recall": 0.6926121372031663
    },
    "evaluation_time": 0.86,
    "manhattan": {
      "accuracy": 0.866960720033379,
      "accuracy_threshold": 13.226386057811565,
      "ap": 0.7654980108345552,
      "f1": 0.7014470677837014,
      "f1_threshold": 14.144565899176254,
      "precision": 0.675880626223092,
      "recall": 0.729023746701847
    },
    "max": {
      "accuracy": 0.8768552184538356,
      "ap": 0.787869760828654,
      "f1": 0.715356315574329
    }
  }
}