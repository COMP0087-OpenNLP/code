{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8767360076294928,
      "accuracy_threshold": 0.7301767322568753,
      "ap": 0.788930871821082,
      "f1": 0.7217630853994491,
      "f1_threshold": 0.7040255428481523,
      "precision": 0.7177145838768588,
      "recall": 0.7258575197889182
    },
    "dot": {
      "accuracy": 0.8604637301066936,
      "accuracy_threshold": 0.4093246546822259,
      "ap": 0.7334345845070541,
      "f1": 0.6796044499381954,
      "f1_threshold": 0.38118106583931155,
      "precision": 0.6393023255813953,
      "recall": 0.7253298153034301
    },
    "euclidean": {
      "accuracy": 0.8770340346903499,
      "accuracy_threshold": 0.5411390193073067,
      "ap": 0.792672900899023,
      "f1": 0.7243355914538823,
      "f1_threshold": 0.5767036532327634,
      "precision": 0.7153885743695316,
      "recall": 0.7335092348284961
    },
    "evaluation_time": 2.17,
    "manhattan": {
      "accuracy": 0.8691065148715503,
      "accuracy_threshold": 10.573303735238827,
      "ap": 0.7707135576454984,
      "f1": 0.701973265436028,
      "f1_threshold": 11.409380652702257,
      "precision": 0.6782287822878229,
      "recall": 0.7274406332453826
    },
    "max": {
      "accuracy": 0.8770340346903499,
      "ap": 0.792672900899023,
      "f1": 0.7243355914538823
    }
  }
}