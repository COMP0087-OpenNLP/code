{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8757227156225785,
      "accuracy_threshold": 0.741789990270789,
      "ap": 0.7858499484968874,
      "f1": 0.7190579802892615,
      "f1_threshold": 0.7057920583874882,
      "precision": 0.6982351478995774,
      "recall": 0.7411609498680739
    },
    "dot": {
      "accuracy": 0.862609524944865,
      "accuracy_threshold": 0.4335937148447334,
      "ap": 0.7403214988233382,
      "f1": 0.6820428336079079,
      "f1_threshold": 0.4074264014158252,
      "precision": 0.6561814191660571,
      "recall": 0.7100263852242744
    },
    "euclidean": {
      "accuracy": 0.8764975859808071,
      "accuracy_threshold": 0.555852036545631,
      "ap": 0.7895382166545492,
      "f1": 0.7221793883320483,
      "f1_threshold": 0.5831933707687662,
      "precision": 0.7039078156312625,
      "recall": 0.741424802110818
    },
    "evaluation_time": 3.92,
    "manhattan": {
      "accuracy": 0.867377957918579,
      "accuracy_threshold": 10.987923027178637,
      "ap": 0.7649457751416664,
      "f1": 0.6984247006931317,
      "f1_threshold": 11.910863002878362,
      "precision": 0.6685162846803377,
      "recall": 0.7311345646437994
    },
    "max": {
      "accuracy": 0.8764975859808071,
      "ap": 0.7895382166545492,
      "f1": 0.7221793883320483
    }
  }
}