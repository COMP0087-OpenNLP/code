{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8753054777373785,
      "accuracy_threshold": 0.7315553463923274,
      "ap": 0.7848941972773524,
      "f1": 0.7185460130551644,
      "f1_threshold": 0.701760633548605,
      "precision": 0.6977380064628387,
      "recall": 0.7406332453825858
    },
    "dot": {
      "accuracy": 0.8581391190320081,
      "accuracy_threshold": 0.510841187350272,
      "ap": 0.7291417763180867,
      "f1": 0.6755081804660388,
      "f1_threshold": 0.4732188525457383,
      "precision": 0.6369798971482001,
      "recall": 0.7189973614775725
    },
    "euclidean": {
      "accuracy": 0.8759611372712642,
      "accuracy_threshold": 0.5928123530187721,
      "ap": 0.7894727952628089,
      "f1": 0.721407624633431,
      "f1_threshold": 0.6408512642415072,
      "precision": 0.6980014803849001,
      "recall": 0.7464379947229551
    },
    "evaluation_time": 1.66,
    "manhattan": {
      "accuracy": 0.8682720391011504,
      "accuracy_threshold": 11.703601594276737,
      "ap": 0.7686014468390967,
      "f1": 0.699318040917545,
      "f1_threshold": 12.389983926527828,
      "precision": 0.6596491228070176,
      "recall": 0.7440633245382586
    },
    "max": {
      "accuracy": 0.8759611372712642,
      "ap": 0.7894727952628089,
      "f1": 0.721407624633431
    }
  }
}