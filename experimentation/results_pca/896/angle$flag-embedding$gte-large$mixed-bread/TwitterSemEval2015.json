{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8755438993860643,
      "accuracy_threshold": 0.7336060602870917,
      "ap": 0.7825087328233794,
      "f1": 0.7163228927934809,
      "f1_threshold": 0.7017652742593156,
      "precision": 0.6921751968503937,
      "recall": 0.7422163588390501
    },
    "dot": {
      "accuracy": 0.8546820051260654,
      "accuracy_threshold": 0.4338042785706999,
      "ap": 0.7199708012869623,
      "f1": 0.6655795283492222,
      "f1_threshold": 0.39785803788978547,
      "precision": 0.6343854615016739,
      "recall": 0.7
    },
    "euclidean": {
      "accuracy": 0.8754246885617214,
      "accuracy_threshold": 0.5475289194134485,
      "ap": 0.7869282117619996,
      "f1": 0.7185781869326173,
      "f1_threshold": 0.5818063772825115,
      "precision": 0.6970974944182585,
      "recall": 0.741424802110818
    },
    "evaluation_time": 1.31,
    "manhattan": {
      "accuracy": 0.8671395362698933,
      "accuracy_threshold": 10.494470418358778,
      "ap": 0.7639922645513331,
      "f1": 0.6952890512853974,
      "f1_threshold": 11.040587730367786,
      "precision": 0.6878388845855926,
      "recall": 0.7029023746701847
    },
    "max": {
      "accuracy": 0.8755438993860643,
      "ap": 0.7869282117619996,
      "f1": 0.7185781869326173
    }
  }
}