{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8751266615008643,
      "accuracy_threshold": 0.7408205716657024,
      "ap": 0.784930501751552,
      "f1": 0.7191011235955055,
      "f1_threshold": 0.6988315920021599,
      "precision": 0.6894214475913822,
      "recall": 0.7514511873350923
    },
    "dot": {
      "accuracy": 0.8620134708231507,
      "accuracy_threshold": 0.5166027684854164,
      "ap": 0.7366635583151313,
      "f1": 0.6843568359868587,
      "f1_threshold": 0.4819866824675465,
      "precision": 0.6566440349175557,
      "recall": 0.7145118733509235
    },
    "euclidean": {
      "accuracy": 0.8753054777373785,
      "accuracy_threshold": 0.6044381130308539,
      "ap": 0.7894508691274511,
      "f1": 0.7211058492256496,
      "f1_threshold": 0.6410901969934117,
      "precision": 0.7002237136465325,
      "recall": 0.7432717678100264
    },
    "evaluation_time": 0.81,
    "manhattan": {
      "accuracy": 0.8688084878106932,
      "accuracy_threshold": 11.66958553112672,
      "ap": 0.770118251048388,
      "f1": 0.7005139776858468,
      "f1_threshold": 12.383875391772374,
      "precision": 0.6673035586338667,
      "recall": 0.737203166226913
    },
    "max": {
      "accuracy": 0.8753054777373785,
      "ap": 0.7894508691274511,
      "f1": 0.7211058492256496
    }
  }
}