{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8756035047982357,
      "accuracy_threshold": 0.7476347395835203,
      "ap": 0.7848872929110724,
      "f1": 0.7188646929287987,
      "f1_threshold": 0.6974528668024218,
      "precision": 0.6701642335766423,
      "recall": 0.775197889182058
    },
    "dot": {
      "accuracy": 0.861775049174465,
      "accuracy_threshold": 0.5215205649001919,
      "ap": 0.7443620051870583,
      "f1": 0.6855517070757051,
      "f1_threshold": 0.4873886971512046,
      "precision": 0.6453190498369819,
      "recall": 0.7311345646437994
    },
    "euclidean": {
      "accuracy": 0.877749299636407,
      "accuracy_threshold": 0.5969430724016406,
      "ap": 0.7907796035236916,
      "f1": 0.7222147560811718,
      "f1_threshold": 0.6202273451102482,
      "precision": 0.7359627499315257,
      "recall": 0.7089709762532982
    },
    "evaluation_time": 1.81,
    "manhattan": {
      "accuracy": 0.8683912499254932,
      "accuracy_threshold": 12.757426770255304,
      "ap": 0.768087097527448,
      "f1": 0.7050237197421239,
      "f1_threshold": 13.637173319424704,
      "precision": 0.6540284360189573,
      "recall": 0.7646437994722955
    },
    "max": {
      "accuracy": 0.877749299636407,
      "ap": 0.7907796035236916,
      "f1": 0.7222147560811718
    }
  }
}