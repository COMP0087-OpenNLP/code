{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.870179412290636,
      "accuracy_threshold": 0.7626875592010447,
      "ap": 0.7681135968946085,
      "f1": 0.7073572242623781,
      "f1_threshold": 0.7222176667695936,
      "precision": 0.6800584368151936,
      "recall": 0.7369393139841689
    },
    "dot": {
      "accuracy": 0.8581987244441796,
      "accuracy_threshold": 0.39831286636167534,
      "ap": 0.7323767326026711,
      "f1": 0.6778180002496569,
      "f1_threshold": 0.3724960577744488,
      "precision": 0.6432125088841507,
      "recall": 0.716358839050132
    },
    "euclidean": {
      "accuracy": 0.8702390177028074,
      "accuracy_threshold": 0.5052639528534639,
      "ap": 0.7718023976784211,
      "f1": 0.7100518646579402,
      "f1_threshold": 0.5427162684379152,
      "precision": 0.6673630454967502,
      "recall": 0.758575197889182
    },
    "evaluation_time": 0.96,
    "manhattan": {
      "accuracy": 0.8605233355188651,
      "accuracy_threshold": 9.414864669632182,
      "ap": 0.7448732758820582,
      "f1": 0.6873080230986608,
      "f1_threshold": 10.433091855806445,
      "precision": 0.6431363531846401,
      "recall": 0.7379947229551451
    },
    "max": {
      "accuracy": 0.8702390177028074,
      "ap": 0.7718023976784211,
      "f1": 0.7100518646579402
    }
  }
}