{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8759015318590928,
      "accuracy_threshold": 0.7356058775467177,
      "ap": 0.7854794613070875,
      "f1": 0.7166773162939297,
      "f1_threshold": 0.7062177380958273,
      "precision": 0.6949194547707559,
      "recall": 0.7398416886543535
    },
    "dot": {
      "accuracy": 0.862609524944865,
      "accuracy_threshold": 0.3350773672293119,
      "ap": 0.7452410408720824,
      "f1": 0.686529794692038,
      "f1_threshold": 0.30998473283069505,
      "precision": 0.6531681753215817,
      "recall": 0.7234828496042216
    },
    "euclidean": {
      "accuracy": 0.8763187697442928,
      "accuracy_threshold": 0.48211945587908367,
      "ap": 0.7880040546929876,
      "f1": 0.7193368734619869,
      "f1_threshold": 0.5061481025900751,
      "precision": 0.7064360213686085,
      "recall": 0.7327176781002639
    },
    "evaluation_time": 1.56,
    "manhattan": {
      "accuracy": 0.8695833581689217,
      "accuracy_threshold": 10.436943241191788,
      "ap": 0.7695939955808007,
      "f1": 0.7044587662764699,
      "f1_threshold": 10.845822217323134,
      "precision": 0.7023341201153948,
      "recall": 0.7065963060686016
    },
    "max": {
      "accuracy": 0.8763187697442928,
      "ap": 0.7880040546929876,
      "f1": 0.7193368734619869
    }
  }
}