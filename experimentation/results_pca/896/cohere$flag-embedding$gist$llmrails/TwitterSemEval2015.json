{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8776300888120642,
      "accuracy_threshold": 0.7343963985696149,
      "ap": 0.7894468051099384,
      "f1": 0.7211120764552563,
      "f1_threshold": 0.6906793776687141,
      "precision": 0.6808061870166393,
      "recall": 0.7664907651715039
    },
    "dot": {
      "accuracy": 0.8639208440126364,
      "accuracy_threshold": 0.501195029923862,
      "ap": 0.7481882479170633,
      "f1": 0.6893145404168173,
      "f1_threshold": 0.4601126160488125,
      "precision": 0.634227444025715,
      "recall": 0.7548812664907651
    },
    "euclidean": {
      "accuracy": 0.8792394349406926,
      "accuracy_threshold": 0.6006418712315503,
      "ap": 0.7951850718455257,
      "f1": 0.7258361864629971,
      "f1_threshold": 0.6292291275517217,
      "precision": 0.7245005257623555,
      "recall": 0.7271767810026385
    },
    "evaluation_time": 1.48,
    "manhattan": {
      "accuracy": 0.8705370447636646,
      "accuracy_threshold": 12.773995642533853,
      "ap": 0.773310209886352,
      "f1": 0.7076691351826284,
      "f1_threshold": 13.488236729884058,
      "precision": 0.674886282020589,
      "recall": 0.7437994722955145
    },
    "max": {
      "accuracy": 0.8792394349406926,
      "ap": 0.7951850718455257,
      "f1": 0.7258361864629971
    }
  }
}