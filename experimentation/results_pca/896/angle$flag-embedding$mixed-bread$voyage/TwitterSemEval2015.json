{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8763187697442928,
      "accuracy_threshold": 0.7349195612567848,
      "ap": 0.786568017453183,
      "f1": 0.7198581560283689,
      "f1_threshold": 0.6989526172907197,
      "precision": 0.6921578178275695,
      "recall": 0.749868073878628
    },
    "dot": {
      "accuracy": 0.8580795136198367,
      "accuracy_threshold": 0.4182361426328769,
      "ap": 0.7295377539355231,
      "f1": 0.6721971452970599,
      "f1_threshold": 0.3838154988592867,
      "precision": 0.6251418198320853,
      "recall": 0.7269129287598944
    },
    "euclidean": {
      "accuracy": 0.8766167968051499,
      "accuracy_threshold": 0.54846746459664,
      "ap": 0.7898322170822639,
      "f1": 0.719620171949185,
      "f1_threshold": 0.5776448776698776,
      "precision": 0.7004746440169872,
      "recall": 0.7398416886543535
    },
    "evaluation_time": 1.48,
    "manhattan": {
      "accuracy": 0.8673183525064075,
      "accuracy_threshold": 10.933581899681386,
      "ap": 0.7654982819311951,
      "f1": 0.6990415335463259,
      "f1_threshold": 11.679905807528726,
      "precision": 0.677819083023544,
      "recall": 0.7216358839050132
    },
    "max": {
      "accuracy": 0.8766167968051499,
      "ap": 0.7898322170822639,
      "f1": 0.7198581560283689
    }
  }
}