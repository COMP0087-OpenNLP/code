{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8759015318590928,
      "accuracy_threshold": 0.7473661519829542,
      "ap": 0.7835083353047517,
      "f1": 0.7157223448614177,
      "f1_threshold": 0.6965006995981857,
      "precision": 0.6686526122823098,
      "recall": 0.7699208443271768
    },
    "dot": {
      "accuracy": 0.8602849138701794,
      "accuracy_threshold": 0.4436222247192078,
      "ap": 0.7398301267830436,
      "f1": 0.6798041615667075,
      "f1_threshold": 0.4033889362710299,
      "precision": 0.6340182648401826,
      "recall": 0.7327176781002639
    },
    "euclidean": {
      "accuracy": 0.878166537521607,
      "accuracy_threshold": 0.5495722087029966,
      "ap": 0.789485957120363,
      "f1": 0.7197970898411427,
      "f1_threshold": 0.5705825008607213,
      "precision": 0.7284517697919481,
      "recall": 0.7113456464379947
    },
    "evaluation_time": 2.48,
    "manhattan": {
      "accuracy": 0.8686296715741789,
      "accuracy_threshold": 11.748154742015112,
      "ap": 0.7661730898167896,
      "f1": 0.7035553329994992,
      "f1_threshold": 12.489897793910849,
      "precision": 0.6693663649356837,
      "recall": 0.741424802110818
    },
    "max": {
      "accuracy": 0.878166537521607,
      "ap": 0.789485957120363,
      "f1": 0.7197970898411427
    }
  }
}