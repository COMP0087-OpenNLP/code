{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.876914823866007,
      "accuracy_threshold": 0.7304828797527094,
      "ap": 0.7883397872651395,
      "f1": 0.7231565329883571,
      "f1_threshold": 0.6950708117922545,
      "precision": 0.7093908629441624,
      "recall": 0.737467018469657
    },
    "dot": {
      "accuracy": 0.8580199082076653,
      "accuracy_threshold": 0.4427704024016772,
      "ap": 0.727600549826906,
      "f1": 0.6750992063492064,
      "f1_threshold": 0.4113258298529363,
      "precision": 0.6368741226017782,
      "recall": 0.7182058047493404
    },
    "euclidean": {
      "accuracy": 0.8764379805686356,
      "accuracy_threshold": 0.5715916842827293,
      "ap": 0.7916062180842565,
      "f1": 0.7221238938053096,
      "f1_threshold": 0.6143063137343159,
      "precision": 0.6932038834951456,
      "recall": 0.7535620052770449
    },
    "evaluation_time": 1.86,
    "manhattan": {
      "accuracy": 0.8682720391011504,
      "accuracy_threshold": 11.166039277181966,
      "ap": 0.7689212582638886,
      "f1": 0.6999744441604907,
      "f1_threshold": 11.929984474273043,
      "precision": 0.6786422200198216,
      "recall": 0.7226912928759894
    },
    "max": {
      "accuracy": 0.876914823866007,
      "ap": 0.7916062180842565,
      "f1": 0.7231565329883571
    }
  }
}