{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.871013888061036,
      "accuracy_threshold": 0.7453181030616849,
      "ap": 0.7724923020923851,
      "f1": 0.7036438253948515,
      "f1_threshold": 0.6956552617562435,
      "precision": 0.6654904728299224,
      "recall": 0.7464379947229551
    },
    "dot": {
      "accuracy": 0.8598080705728081,
      "accuracy_threshold": 0.461935725498368,
      "ap": 0.741958777668231,
      "f1": 0.6834376197165112,
      "f1_threshold": 0.4323288479912609,
      "precision": 0.6622123236822569,
      "recall": 0.7060686015831135
    },
    "euclidean": {
      "accuracy": 0.8725040233653216,
      "accuracy_threshold": 0.5696397686192132,
      "ap": 0.7773006490427118,
      "f1": 0.7076469800455337,
      "f1_threshold": 0.5889209662722041,
      "precision": 0.7185205330432418,
      "recall": 0.6970976253298153
    },
    "evaluation_time": 1.17,
    "manhattan": {
      "accuracy": 0.8637420277761221,
      "accuracy_threshold": 12.353222319755846,
      "ap": 0.7535446727325348,
      "f1": 0.6908146866114476,
      "f1_threshold": 13.229186640081473,
      "precision": 0.6499185857176087,
      "recall": 0.737203166226913
    },
    "max": {
      "accuracy": 0.8725040233653216,
      "ap": 0.7773006490427118,
      "f1": 0.7076469800455337
    }
  }
}