{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8719079692436074,
      "accuracy_threshold": 0.7613222991447774,
      "ap": 0.7755125861535562,
      "f1": 0.7109414758269721,
      "f1_threshold": 0.7205521108834269,
      "precision": 0.6864864864864865,
      "recall": 0.737203166226913
    },
    "dot": {
      "accuracy": 0.8580199082076653,
      "accuracy_threshold": 0.47318764267244795,
      "ap": 0.7317955621285378,
      "f1": 0.6761742771163155,
      "f1_threshold": 0.4515305590060116,
      "precision": 0.6706462496755775,
      "recall": 0.6817941952506597
    },
    "euclidean": {
      "accuracy": 0.8733981045478929,
      "accuracy_threshold": 0.5520497220394864,
      "ap": 0.7802843906440594,
      "f1": 0.7141406448337141,
      "f1_threshold": 0.5885378026880135,
      "precision": 0.6881115459882583,
      "recall": 0.7422163588390501
    },
    "evaluation_time": 1.07,
    "manhattan": {
      "accuracy": 0.8648149251952078,
      "accuracy_threshold": 10.409219325196428,
      "ap": 0.7580135727894981,
      "f1": 0.6942381562099872,
      "f1_threshold": 11.15188336795924,
      "precision": 0.6743781094527364,
      "recall": 0.7153034300791556
    },
    "max": {
      "accuracy": 0.8733981045478929,
      "ap": 0.7802843906440594,
      "f1": 0.7141406448337141
    }
  }
}