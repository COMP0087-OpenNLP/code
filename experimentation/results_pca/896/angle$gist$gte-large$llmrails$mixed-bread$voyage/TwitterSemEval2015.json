{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.87578232103475,
      "accuracy_threshold": 0.7315560744857958,
      "ap": 0.7852087150021965,
      "f1": 0.718705501618123,
      "f1_threshold": 0.7082168456255671,
      "precision": 0.7054637865311308,
      "recall": 0.7324538258575198
    },
    "dot": {
      "accuracy": 0.8588543839780652,
      "accuracy_threshold": 0.42674234261922717,
      "ap": 0.7318115251769074,
      "f1": 0.6764928193499623,
      "f1_threshold": 0.3997266571475937,
      "precision": 0.6472999035679846,
      "recall": 0.7084432717678101
    },
    "euclidean": {
      "accuracy": 0.8761995589199499,
      "accuracy_threshold": 0.543290274397735,
      "ap": 0.7893711094917192,
      "f1": 0.7223746570217012,
      "f1_threshold": 0.5888685808607835,
      "precision": 0.684957426679281,
      "recall": 0.7641160949868074
    },
    "evaluation_time": 2.2,
    "manhattan": {
      "accuracy": 0.8682720391011504,
      "accuracy_threshold": 10.833913733471169,
      "ap": 0.767015122125865,
      "f1": 0.6984737719635757,
      "f1_threshold": 11.37189767992676,
      "precision": 0.679560768654854,
      "recall": 0.7184696569920844
    },
    "max": {
      "accuracy": 0.8761995589199499,
      "ap": 0.7893711094917192,
      "f1": 0.7223746570217012
    }
  }
}