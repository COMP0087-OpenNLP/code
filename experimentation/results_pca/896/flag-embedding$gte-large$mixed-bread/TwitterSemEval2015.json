{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8763783751564642,
      "accuracy_threshold": 0.7289214903829515,
      "ap": 0.7861577869818321,
      "f1": 0.7187903851124321,
      "f1_threshold": 0.6978069656652873,
      "precision": 0.7044072948328267,
      "recall": 0.7337730870712401
    },
    "dot": {
      "accuracy": 0.8552184538356082,
      "accuracy_threshold": 0.40782122518070474,
      "ap": 0.7210858105588865,
      "f1": 0.6690945623508727,
      "f1_threshold": 0.3823192866026777,
      "precision": 0.6383896477354422,
      "recall": 0.7029023746701847
    },
    "euclidean": {
      "accuracy": 0.8751862669130357,
      "accuracy_threshold": 0.5525978994107099,
      "ap": 0.7899159415926612,
      "f1": 0.7214203601992591,
      "f1_threshold": 0.5823432176984324,
      "precision": 0.6991829660807131,
      "recall": 0.7451187335092349
    },
    "evaluation_time": 1.07,
    "manhattan": {
      "accuracy": 0.8677355903916075,
      "accuracy_threshold": 10.521994183464193,
      "ap": 0.7672068839412526,
      "f1": 0.6979530703944083,
      "f1_threshold": 11.260316296534716,
      "precision": 0.6622453813358598,
      "recall": 0.7377308707124011
    },
    "max": {
      "accuracy": 0.8763783751564642,
      "ap": 0.7899159415926612,
      "f1": 0.7214203601992591
    }
  }
}