{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8756631102104071,
      "accuracy_threshold": 0.7250056188933027,
      "ap": 0.7845197856253853,
      "f1": 0.7158989975891384,
      "f1_threshold": 0.686435834519095,
      "precision": 0.6895624541676851,
      "recall": 0.7443271767810027
    },
    "dot": {
      "accuracy": 0.8561721404303511,
      "accuracy_threshold": 0.3415179863751596,
      "ap": 0.7261115408302818,
      "f1": 0.6770612448546838,
      "f1_threshold": 0.3169443977400709,
      "precision": 0.6420629287911048,
      "recall": 0.7160949868073878
    },
    "euclidean": {
      "accuracy": 0.8746498182034929,
      "accuracy_threshold": 0.5042233506064491,
      "ap": 0.7882445774036093,
      "f1": 0.7205959226346054,
      "f1_threshold": 0.5332311616955759,
      "precision": 0.7138788192646297,
      "recall": 0.7274406332453826
    },
    "evaluation_time": 0.91,
    "manhattan": {
      "accuracy": 0.8650533468438935,
      "accuracy_threshold": 9.836065412782116,
      "ap": 0.76175626526159,
      "f1": 0.6946092977250247,
      "f1_threshold": 10.649440685826674,
      "precision": 0.6535597952536063,
      "recall": 0.7411609498680739
    },
    "max": {
      "accuracy": 0.8756631102104071,
      "ap": 0.7882445774036093,
      "f1": 0.7205959226346054
    }
  }
}