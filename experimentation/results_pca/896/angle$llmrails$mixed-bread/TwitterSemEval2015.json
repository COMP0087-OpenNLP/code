{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8748286344400071,
      "accuracy_threshold": 0.7276093255958934,
      "ap": 0.7831481010171941,
      "f1": 0.717579250720461,
      "f1_threshold": 0.70649934920336,
      "precision": 0.7125390218522373,
      "recall": 0.7226912928759894
    },
    "dot": {
      "accuracy": 0.8542647672408654,
      "accuracy_threshold": 0.5190767512017376,
      "ap": 0.7195510153704815,
      "f1": 0.6653910547715857,
      "f1_threshold": 0.463720537881425,
      "precision": 0.6084864391951006,
      "recall": 0.7340369393139842
    },
    "euclidean": {
      "accuracy": 0.8760207426834357,
      "accuracy_threshold": 0.6165160737648716,
      "ap": 0.787487049951947,
      "f1": 0.718982239576773,
      "f1_threshold": 0.6483155221653825,
      "precision": 0.6878765967703061,
      "recall": 0.7530343007915568
    },
    "evaluation_time": 1.06,
    "manhattan": {
      "accuracy": 0.8686892769863503,
      "accuracy_threshold": 11.50551943912999,
      "ap": 0.7644874221483529,
      "f1": 0.6944297082228117,
      "f1_threshold": 12.111012280868216,
      "precision": 0.6981333333333334,
      "recall": 0.6907651715039578
    },
    "max": {
      "accuracy": 0.8760207426834357,
      "ap": 0.787487049951947,
      "f1": 0.718982239576773
    }
  }
}