{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.2.0",
  "test": {
    "cos_sim": {
      "accuracy": 0.8753054777373785,
      "accuracy_threshold": 0.731681515460233,
      "ap": 0.785745933927938,
      "f1": 0.7198085883390001,
      "f1_threshold": 0.6937406409260727,
      "precision": 0.6885087930619128,
      "recall": 0.754089709762533
    },
    "dot": {
      "accuracy": 0.8581987244441796,
      "accuracy_threshold": 0.4218033839445571,
      "ap": 0.731089473021695,
      "f1": 0.6739215943359118,
      "f1_threshold": 0.4011382057358067,
      "precision": 0.6697941099817566,
      "recall": 0.6781002638522428
    },
    "euclidean": {
      "accuracy": 0.8763187697442928,
      "accuracy_threshold": 0.5522512227687013,
      "ap": 0.7891483309691505,
      "f1": 0.7211857909532327,
      "f1_threshold": 0.5856248274952592,
      "precision": 0.699207135777998,
      "recall": 0.7445910290237467
    },
    "evaluation_time": 2.72,
    "manhattan": {
      "accuracy": 0.8663050604994934,
      "accuracy_threshold": 11.063726480867007,
      "ap": 0.7639827280704481,
      "f1": 0.696029618281629,
      "f1_threshold": 11.877052977927608,
      "precision": 0.6742517932228543,
      "recall": 0.7192612137203166
    },
    "max": {
      "accuracy": 0.8763187697442928,
      "ap": 0.7891483309691505,
      "f1": 0.7211857909532327
    }
  }
}