{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8772724563390356,
      "accuracy_threshold": 0.732294666674355,
      "ap": 0.7882749472878074,
      "f1": 0.719770630765395,
      "f1_threshold": 0.693201299782156,
      "precision": 0.6821833648393195,
      "recall": 0.7617414248021108
    },
    "dot": {
      "accuracy": 0.8629671574178935,
      "accuracy_threshold": 0.5006898977361858,
      "ap": 0.7444860269176067,
      "f1": 0.6858311282174645,
      "f1_threshold": 0.45889554932386123,
      "precision": 0.6301945181255526,
      "recall": 0.7522427440633246
    },
    "euclidean": {
      "accuracy": 0.8788818024676641,
      "accuracy_threshold": 0.5967889437033299,
      "ap": 0.7941403261988468,
      "f1": 0.7233642348515384,
      "f1_threshold": 0.6195719358012766,
      "precision": 0.7369285518751711,
      "recall": 0.7102902374670185
    },
    "evaluation_time": 1.82,
    "manhattan": {
      "accuracy": 0.8698813852297789,
      "accuracy_threshold": 12.667264477050661,
      "ap": 0.7720766170900641,
      "f1": 0.7091454272863569,
      "f1_threshold": 13.468610531873388,
      "precision": 0.673469387755102,
      "recall": 0.7488126649076517
    },
    "max": {
      "accuracy": 0.8788818024676641,
      "ap": 0.7941403261988468,
      "f1": 0.7233642348515384
    }
  }
}