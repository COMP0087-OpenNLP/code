{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.87327889372355,
      "accuracy_threshold": 0.7425811147749598,
      "ap": 0.776486461081324,
      "f1": 0.7103744628606508,
      "f1_threshold": 0.7004191196581465,
      "precision": 0.6642939150401836,
      "recall": 0.7633245382585752
    },
    "dot": {
      "accuracy": 0.8612386004649222,
      "accuracy_threshold": 0.557436001805629,
      "ap": 0.7456245666149489,
      "f1": 0.6863698715550568,
      "f1_threshold": 0.5231783797196917,
      "precision": 0.650744856940175,
      "recall": 0.7261213720316623
    },
    "euclidean": {
      "accuracy": 0.8761995589199499,
      "accuracy_threshold": 0.6172901292366975,
      "ap": 0.7816731261106824,
      "f1": 0.7131926121372032,
      "f1_threshold": 0.64167937212776,
      "precision": 0.7131926121372032,
      "recall": 0.7131926121372032
    },
    "evaluation_time": 1.14,
    "manhattan": {
      "accuracy": 0.8638612386004649,
      "accuracy_threshold": 13.373216109449128,
      "ap": 0.7568936643811386,
      "f1": 0.698038241867395,
      "f1_threshold": 14.265743078911857,
      "precision": 0.6592401500938087,
      "recall": 0.741688654353562
    },
    "max": {
      "accuracy": 0.8761995589199499,
      "ap": 0.7816731261106824,
      "f1": 0.7131926121372032
    }
  }
}