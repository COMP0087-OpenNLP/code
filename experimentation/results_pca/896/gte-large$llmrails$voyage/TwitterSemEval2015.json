{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8732192883113786,
      "accuracy_threshold": 0.7354680865139341,
      "ap": 0.7802639134703425,
      "f1": 0.7144332558739996,
      "f1_threshold": 0.7046993679910151,
      "precision": 0.6994438827098078,
      "recall": 0.7300791556728232
    },
    "dot": {
      "accuracy": 0.8593312272754366,
      "accuracy_threshold": 0.2684573643938228,
      "ap": 0.7330146057864418,
      "f1": 0.6790154152163103,
      "f1_threshold": 0.25025845365369237,
      "precision": 0.6419840150446638,
      "recall": 0.720580474934037
    },
    "euclidean": {
      "accuracy": 0.8733981045478929,
      "accuracy_threshold": 0.4374120929030422,
      "ap": 0.7823399752431457,
      "f1": 0.714632587859425,
      "f1_threshold": 0.4643337413964958,
      "precision": 0.6929368029739778,
      "recall": 0.7377308707124011
    },
    "evaluation_time": 1.19,
    "manhattan": {
      "accuracy": 0.8620730762353221,
      "accuracy_threshold": 8.929409730992287,
      "ap": 0.7533697086693545,
      "f1": 0.6864478624197651,
      "f1_threshold": 9.918444299683062,
      "precision": 0.63443026639803,
      "recall": 0.7477572559366754
    },
    "max": {
      "accuracy": 0.8733981045478929,
      "ap": 0.7823399752431457,
      "f1": 0.714632587859425
    }
  }
}