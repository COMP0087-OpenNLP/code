{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8780473266972642,
      "accuracy_threshold": 0.7357483256931521,
      "ap": 0.7889320645321661,
      "f1": 0.7214098237720287,
      "f1_threshold": 0.6992931284669097,
      "precision": 0.6853478983614344,
      "recall": 0.7614775725593668
    },
    "dot": {
      "accuracy": 0.8607617571675508,
      "accuracy_threshold": 0.45729827236343085,
      "ap": 0.741113497783743,
      "f1": 0.6821743998009703,
      "f1_threshold": 0.42091718216193497,
      "precision": 0.645328312544128,
      "recall": 0.7234828496042216
    },
    "euclidean": {
      "accuracy": 0.8787029862311498,
      "accuracy_threshold": 0.5596844784354374,
      "ap": 0.793996411192841,
      "f1": 0.7247205614764752,
      "f1_threshold": 0.5915979631646165,
      "precision": 0.7141393442622951,
      "recall": 0.7356200527704485
    },
    "evaluation_time": 2.63,
    "manhattan": {
      "accuracy": 0.8710734934732074,
      "accuracy_threshold": 11.492339679183132,
      "ap": 0.7749872039207732,
      "f1": 0.7083596015634852,
      "f1_threshold": 12.21535128481911,
      "precision": 0.6783385655638735,
      "recall": 0.7411609498680739
    },
    "max": {
      "accuracy": 0.8787029862311498,
      "ap": 0.793996411192841,
      "f1": 0.7247205614764752
    }
  }
}