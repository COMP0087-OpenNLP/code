{
  "dataset_revision": "70970daeab8776df92f5ea462b6173c0b46fd2d1",
  "mteb_dataset_name": "TwitterSemEval2015",
  "mteb_version": "1.1.2",
  "test": {
    "cos_sim": {
      "accuracy": 0.8761995589199499,
      "accuracy_threshold": 0.7455036684198533,
      "ap": 0.7870726496105657,
      "f1": 0.7194041350969566,
      "f1_threshold": 0.7075518877516311,
      "precision": 0.7007755816862647,
      "recall": 0.7390501319261213
    },
    "dot": {
      "accuracy": 0.8614770221136079,
      "accuracy_threshold": 0.43576451523716586,
      "ap": 0.7393648459488027,
      "f1": 0.6819239720713731,
      "f1_threshold": 0.4107705778849391,
      "precision": 0.6686105476673428,
      "recall": 0.695778364116095
    },
    "euclidean": {
      "accuracy": 0.8767360076294928,
      "accuracy_threshold": 0.5460482928645554,
      "ap": 0.7908689902668995,
      "f1": 0.7235279251958554,
      "f1_threshold": 0.5864292355746554,
      "precision": 0.6942289039767217,
      "recall": 0.7554089709762533
    },
    "evaluation_time": 1.48,
    "manhattan": {
      "accuracy": 0.8683912499254932,
      "accuracy_threshold": 11.202073564210306,
      "ap": 0.7665854348517838,
      "f1": 0.6977215189873418,
      "f1_threshold": 11.814492030607601,
      "precision": 0.6705596107055961,
      "recall": 0.7271767810026385
    },
    "max": {
      "accuracy": 0.8767360076294928,
      "ap": 0.7908689902668995,
      "f1": 0.7235279251958554
    }
  }
}